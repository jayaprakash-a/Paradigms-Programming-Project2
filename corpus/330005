Combining Probabilistic Population Codes
 Abstract We study the problem of statistically correct inference in networks whose basic representations are population codes.  Population codes are ubiquitous in the brain, and involvethesimultaneous activityofmany units coding for some low dimensional quantity.  A classic example are place cells in the rat hippocampus: these fire when the animal is at a particular place in an environment, so the underlying quantity has two dimensions of spatial location.  We showhowtointerpret the activity as encoding whole probability distributions over the underlying variable rather then just single values, and propose a method of inductively learning mappings between population codes that are computationally tractable and yet offer good approximations to statistically optimal inference.  Wesimulate the method on some simple examples to prove its competence.  In a population code, information about some lowdimensional quantity (such as the position of a visual feature) is represented in the activity of a collection of units, each responding to a limited range of stimuli within this low-dimensional space.  Strong evidence exists for this form of coding at the sensory input areas of the brain (eg retinotopic and tonotopic maps) as well as at the motor output level [ Georgopoulos et al. , 1986 ] .  Evidence is mounting that many other intermediate neural processing areas also use population codes [ Tanaka, 1996 ] .  Certain important questions about population codes have been extensively investigated, including howtoextract an optimal underlying value [ Salinas and Abbott, 1994; Snippe, 1996 ] and how to learn such representations [ Kohonen, 1982 ] .  However, two important issues have been almost ignored (with the important exception of [ Anderson, 1994 ] ).  One is the treatment of population codes as encoding whole probability density functions (PDFs) over the underlying quantities rather than just a single value.  PDFs can convey significant additional information, suchascertainty(eg in the existence in an image of the relevant object), as well as the mean and variance (eg in its position).  The other issue is howtoperform inference in networks whose basic representations are population codes.  Zemel, Dayan, and Pouget [1997] have recently presented a general framework for the probabilistic interpretation of population codes in terms of PDFs.  In this paper we apply this framework to all the population codes in a processing hierarchy, and suggest an inference method that approximates, in a quantifiable manner, Bayesian optimal methods of representing and combining the probability distributions.  We first discuss howtointerpret PDFs from population codes, and then introduce our framework for combining these codes.  We illustrate the techniques with an example based on a form of cue combination.  1 An Example Consider the case of a hunter attempting to shoot a pheasant as it flies out of a tree.  We'll assume that the hunter uses two cues, a visual cue concerning motion in the tree and an auditory cue based on rustling of the leaves, to estimate the pheasant's size and velocity.  Based on this estimate, he selects a time and place to fire his shotgun.  The combination problem concerns how the two inputs should be combined to produce the output.  In the simplest version of the combination problem for this example, visual motion is confined to one part of the tree, and the auditory signal directly corresponds to this visual signal.  Here these two single-valued inputs (which we will term v and a)give rise to a single output, and the hunter confidently aims his shotgun (to location s).  Evidence exists that the two inputs and the output information in this example are each represented in neural population codes in some animals.  That is, a fixed collection of neurons fire for each of the three variables of interest.  The relevant visual input is represented by the activity of a population of motion detectors: in monkeys, a particular cortical area (MT) contains cells that selectively respond to motion of a particular velocity within a small range of visual locations.  Similarly, the relevant auditory input is represented in a population of detectors tuned to particular frequencies and spatial locations in owl auditory cortex [ Knudsen and Konishi, 1978 ] ; the frequency maycontain important information about the bird's size and speed.  Directional motor output is also represented in a population code in monkey motor cortex [ Georgopoulos et al. , 1986 ] .  Therefore even in the simple version of the problem, the brain does not directly represent the values v, a, and s, but instead represents eachina separate population code.  The most straightforward waytosolve this problem is to perform an intermediate step of extracting separate single values from the input population codes, combine these values, and then encode these into the motor output population code.  However, this seems not to be the strategy actually implemented in the brain, where new population codes appear to be generated directly from old ones.  Another level of complexity is introduced into the problem when we consider that the inputs may be uncertain or ambiguous.  For example, if the wind is blowing, then leaves maybemoving all over the tree giving rise to multiple plausible motion hypotheses, while at the same time the auditory cues maybetoo fainttoconfidently estimate the motion.  The experienced hunter maythen be able to narrow down the set of candidate motions based on his knowledge of the combinations of auditory and visual cues, but he might not be able to confidently select a single value.  Two additional problems are introduced in this more general case.  First wemust interpret a population code as representing a whole probability distribution over the underlying variable.  And then the combination method must preserve the probabilistic information in the inputs.  Thus the aim of a combination network is to infer a population code for the motor action that preserves the statistical relationship between the input and output probability distributions.  2 Theory The basic theory underlying the combination of population codes is extremely simple.  Population codes use the explicit activities r = fr i g of multiple cells (as in area MT) to code information about the value of an implicit underlying variable x (such as the direction and speed of motion of the leaves).  We are interested in the case that the activities r code a whole probability distribution over the underlying variable: P [xjr]: (1) Consider the example of the hunter.  Activities fr v i g and fr a j g represent probability distributions over the motion position and velocity based on the visual and auditory signals respectively.  We will assume that afferent information in the different modalities is independent.  The activities fr s k g will represent a probability distribution over the corresponding required position s of the shotgun according to the equivalent of Equation 1.  Two computational operations are required to produce appropriate r s : information from the different modalities must be integrated and then expressed in appropriate coordinates.  These operations have to respect the statistical semantics of r v and r a .  We use an underlying analysis-by-synthesis statistical model as in the Helmholtz machine [ Hinton et al. , 1995 ] .  In such a model, inference is based on the analysis or recognition inverse to a probabilistic synthetic or generativemodel that specifies probability distributions P [v; ajs]over the visual motion signal v and auditory pattern a given the shotgun location s.  Given true probability distributions P [vj!]andP [aj!] over the visual and auditory information (here ! represents the underlying information available to the hunter), recognition requires calculating: P[sj!]= Z v;a P [vj!]P [aj!]P [sjv; a]dvda (2) /P[s] Z v;a P[vj!]P [aj!]P [v; ajs]dvda (3) where P[s] is the prior distribution over s.  Equation 3 establishes the standard by which inferences about the distribution over s should be judged.  We have therefore reduced the computational problem to one of mapping activities r v and r a into activities r s for which P [sjr s ] from Equation 1 is a good approximation to the integration in Equation 3, where P [vj!]is what r v represents (according to Equation 1) and P [aj!] is what r a represents.  Figure 1 illustrates the generative and recognition operations, showing the activities, the distributions that they represent, and the various probabilistic relationships.  The remaining questions concern how activities r specify distributions as in Equation 1, and how r v and r a are actually combined to produce r s .  We describe two models for Equation 1: a model based on a standard form of function approximation, kernel density estimation (KDE) [ Anderson, 1994 ] , and an extension to the conventional statistical population coding model that is designed to handle anyformofPDF [ Zemel et al. ,1997 ] .  Both models form estimates ^ P r (x)ofP [xj!] based on r.  2. 1 The KDE Model One way of treating population codes as distributions is in terms of kernel density estimates (KDEs) [ Anderson, 1994 ] .  Here, activities r represent distribution ^ P r (x)
