Scene and Motion Reconstruction from Defocused and Motion-Blurred Images via Anisotropic Diffusion
 Abstract.  We propose a solution to the problem of inferring the depth map, radiance and motion field of a scene from a collection of motion-blurred and defocused images.  We model motion-blurred and defocused images as the solution of an anisotropic diffusion equation, whose initial conditions depend on the radiance and whose diffusion tensor encodes the shape of the scene, the motion field and the optics parameters.  We show that this model is well-posed and propose an efficient algorithm to infer the unknowns of the model.  Inference is performed by minimizing the discrepancy between the measured defocused images and the ones synthesized via diffusion.  Since the problem is ill-posed, we also introduce additional Tikhonov regularization terms.  The resulting method is fast and robust to noise as shown by experiments with both synthetic and real data.
