Computational Models of Sensorimotor Integration
 Abstract The sensorimotor integration system can be viewed as an observer attempting to estimate its own state and the state of the environment by integrating multiple sources of information.  We describe a computational framework capturing this notion, and some specific models of integration and adaptation that result from it.  Psychophysical results from two sensorimotor systems, subserving the integration and adaptation of visuo-auditory maps, and estimation of the state of the hand during arm movements, are presented and analyzed within this framework.  These results suggest that: (1) Spatial information from visual and auditory systems is integrated so as to reduce the variance in localization.  (2) The effects of a remapping in the relation between visual and auditory space can be predicted from a simple learning rule.  (3) The temporal propagation of errors in estimating the hand's state is captured by a linear dynamic observer, providing evidence for the existence of an internal model which simulates the dynamic behavior of the arm.
