Final Report of Johns Hopkins 2003 Summer Workshop on Syntax for Statistical Machine Translation
 Abstract In recent evaluations of machine translation systems, statistical systems have outperformed classical approaches based on interpretation, transfer, and generation.  Nonetheless, the output of statistical systems often contains obvious grammatical errors.  This can be attributed to the fact that the syntactic well-formedness is only influenced by local n-gram language models and simple alignment models.  We aim to integrate syntactic structure into statistical models to address this problem.  In the workshop we start with a very strong baseline -- the alignment template statistical machine translation system that obtained the best results in the 2002 and 2003 DARPA MT evaluations.  This model is based on a log-linear modeling framework, which allows for the easy integration of many different knowledge sources (i. e.  feature functions) into an overall model and to train the feature function combination weights discriminatively.  During the workshop, we incrementally add new features representing syntactic knowledge that deal with specific problems of the underlying baseline.  We want to investigate a broad range of possible feature functions, from very simple binary features to sophisticated treeto-tree translation models.  Simple feature functions test if a certain constituent occurs in the source and the target language parse tree.  More sophisticated features are derived from an alignment model where whole sub-trees in source and target can be aligned node by node.  We also plan to investigate features based on projection of parse trees from one language onto strings of another, a useful technique when parses are available for only one of the two languages.  We extend previous tree-based alignment models by allowing partial tree alignments when the two syntactic structures are not isomorphic.  We work with the Chinese-English data from the recent evaluations, as large amounts of sentence-aligned training corpora, as well as multiple reference translations are available.  This will also allow to compare results with the various systems participating in the evaluations.  In addition, an annotated Chinese-English parallel tree-bank is available.  We evaluate the improvement of our system using the BLEU metric.  Using the additional feature functions developed during the workshop the BLEU score improved from 31. 6% for the baseline MT system to 33. 2% using rescoring of a 1000-best list.
