An Adaptive Regularization Criterion for Supervised Learning
 Abstract We introduce a new regularization criterion that exploits unlabeled data to adaptively control hypothesis-complexity in general supervised learning tasks.  The technique is based on an abstract metric-space view of supervised learning that has been successfully applied to model selection in previous research.  The new regularization criterion we introduce involves no free parameters and yet performs well on a variety of regression and conditional density estimation tasks.  The only proviso is that sucient unlabeled training data be available.  We demonstrate the e#ectiveness of our approach on learning radial basis functions and polynomials for regression, and learning logistic regression models for conditional density estimation.
