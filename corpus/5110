Approximate Parameter Learning in Discriminative Fields
 Abstract In this paper, we present an approach for approximate maximum likelihood parameter learning in discriminative field models, which is based on approximating true expectations with simple piecewise constant functions constructed using inference techniques.  Gradient ascent with these updates shows interesting weak-convergence behavior which is tied closely to the number of errors made during inference.  The performance of various approximations was evaluated with different inference techniques showing that the learned parameters lead to good classification performance so long as the method used for approximating the gradient is consistent with the inference mechanism.  The proposed approach is general enough to be used for conditional training of conventional MRFs.
