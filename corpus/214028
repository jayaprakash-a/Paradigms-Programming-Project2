Bayesian Belief Propagation for Image Understanding
 Abstract A central theme of computational vision research has been the realization that reliable estimation of local scene properties requires propagating measurements across the image.  Many authors have suggested solving vision problems using architectures of locally connected units updating their activity in parallel.  Unfortunately,the convergence of traditional relaxation methods on such architectures has proven to be excruciatingly slow and in general they do not guarantee that the stable point will be a global minimum.  In this paper we show that a scheme in which Bayesian Beliefs about image properties are propagated between neighboring units may yield convergence times which are several orders of magnitude faster than traditional methods and avoids local minima.  In particular, for some vision problems the scheme provably does not take \too many iterations" in the sense of Marr [11]: at every time step, the local estimates at a given location are optimal given the information which has already been propagated to that location.  We illustrate the algorithm's performance on real images and synthetic images and compare it to several existing methods.  1 1 A preliminary version of this paper appeared in [23] a Y* Y Y* ,# # ,# # # ,# # b c Figure 1: a.  a prototypical ill-posed problem b.  Traditional relaxation approach: dense array of units represent the value of the interpolated function.  Units update their activity based on local information and the activity of neighboring units.  c.  The Bayesian Belief Propagation (BBP) approach.  Units transmit probabilities and combine them according to probability calculus in two non-interacting streams.  Many problems in vision are analogous to the problem shown in figure a { the interpolation of a function from sparse local noisy data.  Many solutions in vision are analogous to that shown in figure b 
