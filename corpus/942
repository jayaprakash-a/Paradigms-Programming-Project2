Dimensionality Reduction of Electropalatographic Data Using Latent Variable Models
 Abstract We consider the problem of obtaining a reduced dimension representation of electropalatographic (EPG) data.  An unsupervised learning approach based on latent variable modelling is adopted, in which an underlying lower dimension representation is inferred directly from the data.  Several latent variable models are investigated, including factor analysis and the generative topographic mapping (GTM).  Experiments were carried out using a subset of the EUR-ACCOR database, and the results indicate that these automatic methods capture important, adaptive structure in the EPG data.  Nonlinear latent variable modelling clearly outperforms the investigated linear models in terms of loglikelihood and reconstruction error and suggests a substantially smaller intrinsic dimensionality for the EPG data than that claimed by previous studies.  A two-dimensional representation is produced with applications to speech therapy, language learning and articulatory dynamics.
