Automated Texture Extraction from Multiple Images to Support Site Model Refinementand Visualization \Lambda
 Abstract Texture mapping has wide and importantapplications in visualization and virtual reality. Surface texture extraction from a single image suffers from perspectivedistortion, data deficiency, and corruption caused byshadows and occlusions.  In this paper, a system is developed for automated acquisition of complete and consistent texture maps from multiple images in order to support subsequent detailed surface analysis and scene rendering.  Given camera and lightsource parameters for each image, and a geometric model of the scene, the textures of object surfaces are systematically collected into an organized orthographic library.  Occlusions and shadows caused byobjects in the scene are computed and associated with each retrieved surface.  A "Best Piece Representation" algorithm is designed to combine intensities from multiple views, resulting in a unique surface intensity representation.  Detailed surface structures, suchaswindows and doors, are extracted from the uniquely represented surface images to refine the geometric model.  Experiments showsuccessful applications of this approachtomodel refinementand scene visualization.
