Surface matching for object recognition in complex three-dimensional scenes
 Abstract We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation.  Our object representation comprises descriptive images associated with oriented points on the surface of an object.  Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters.  The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point.  These images, localized descriptions of the global shape of the object, are invariant to rigid transformations.  Through correlation of images, point correspondences between a model and scene data are established.  Geometric consistency is used to group the correspondences from which plausible rigid transformations that align the model with the scene are calculated.  The transformations are then refined and verified using a modified iterative closest point algorithm.  The effectiveness of our representation comes from its ability to combine the descriptive nature of global object properties with the robustness to partial views and clutter of local shape descriptions. The wide applicability of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion.
