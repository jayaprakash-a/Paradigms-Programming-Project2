An Investigation of Segmental Hidden Dynamic Models of Speech Coarticulation for Automatic Speech Recognition
 Abstract Conversational speech recognition is a challenging problem primarily because speakers rarely fully articulate sounds.  A successful speech recognition approach must infer intended spectral targets from the speech data, or develop a method of dealing with large variances in the data.  The Workshop Project explored a new approach to acoustic-phonetic modelling, the Hidden Dynamic Model (HDM), which explicitly accounts for the coarticulation and transitions between neighbouring phones.  Inspired by the fact that speech is really produced by an underlying dynamic system, an HDM has a vector target per phone in a hidden dynamic space in which speech trajectories are produced by a simple dynamic system.  The hidden space is mapped to the surface acoustic representation via a non-linear mapping in the form of a multilayer perceptron (MLP).  HDMs are a radical departure from conventional hidden Markov models (HMMs), which simply account for variation in the observed data.  In this report we present details of two types of HDM and our experience with using them to model speech patterns.  Although the HDMs are still at an very early stage, we attempted an initial evaluation of such models on a conversational speech recognition task involving a subset of the SWITCHBOARD corpus.  We have indications that in an N-Best rescoring paradigm, HDMs are capable of supplying extra information, even when trained only on a limited amount of speech from a single speaker.
