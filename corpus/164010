LEIBNIZ CENTER FOR RESEARCH IN COMPUTER SCIENCE TECHNICAL REPORT 2003-43 Computing Gaussian Mixture Models with EM using Equivalence Constraints
 Abstract Gaussian mixture models for density estimation are usually estimated in an unsupervised manner, using an Expectation Maximization (EM) procedure.  In this paper we show how equivalence constraints can be incorporated into this procedure, leading to improved model estimation and improved clustering results.  Equivalence constraints provide additional information on pairs of data points, indicating if the points arise from the same source (positive constraint) or from different sources (negative constraint).  Such constraints can be gathered automatically in some learning problems, and are a natural form of supervision in others.  We present a closed form EM procedure for handling positive constraints, and a Generalized EM procedure using a Markov network for the incorporation of negative constraints.  Using publicly available data sets, we demonstrate that incorporating equivalence constraints leads to considerable improvement in clustering performance, and that our algorithm outperforms all available competitors.
