From Conversational Tooltips to Grounded Discourse: Head Pose Tracking in Interactive Dialog Systems
 ABSTRACT Head pose and gesture offer several key conversational grounding cues and are used extensively in face-to-face interaction among people.  While the machine interpretation of these cues has previously been limited to output modalities, recent advances in facepose tracking allow for systems which are robust and accurate enough to sense natural grounding gestures.  We present the design of a module that detects these cues and show examples of its integration in three different conversational agents with varying degrees of discourse model complexity.  Using a scripted discourse model and off-the-shelf animation and speech-recognition components, we demonstrate the use of this module in a novel "conversational tooltip" task, where additional information is spontaneously provided by an animated character when users attend to various physical objects or characters in the environment.  We further describe the integration of our module in two systems where animated and robotic characters interact with users based on rich discourse and semantic models.
