Learning to Communicate and Act in Cooperative Multiagent Systems using Hierarchical Reinforcement Learning
 Abstract In this paper, we address the issue of rational communication behavior among autonomous agents.  We extend our previously reported cooperative hierarchical reinforcement learning (HRL) algorithm to include communication decision and propose a new multiagent HRL algorithm, called COM-Cooperative HRL.  In this algorithm, at specific levels of the hierarchy, called cooperation levels, a group of subtasks, in which coordination among agents has significant effect on the performance of the overall task, are defined as cooperative subtasks.  Coordination skills among agents are learned faster by sharing information at cooperation levels, rather than the level of primitive actions.  We add a communication level to the hierarchical decomposition of the problem, below each cooperation level.  A communication action has a certain cost and is used by each agent to obtain the actions selected by the cooperative subtasks of the other agents.  Before making a decision at a cooperative subtask, agents decide if it is worthwhile to perform a communication action in order to acquire the actions chosen by the cooperative subtasks of the other agents.  Using this algorithm, agents learn a policy to balance the amount of communication needed for proper coordination, and communication cost.  We demonstrate the efficacy of the COM-Cooperative HRL algorithm as well as the relation between communication cost and the learned communication policy, using a multiagent taxi domain.  1
