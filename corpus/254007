AN AUTOMATIC SPEECH RECOGNITION SYSTEM USING NEURAL NETWORKS AND LINEAR DYNAMIC MODELS TO RECOVER AND MODEL ARTICULATORY TRACES
 ABSTRACT We describe a speech recognition system which uses articulatory parameters as basic features and phone-dependent linear dynamic models.  The system first estimates articulatory trajectories from the speech signal.  Estimations of x and y coordinates of 7 actual articulator positions in the midsagittal plane are produced every 2 milliseconds by a recurrent neural network, trained on real articulatory data.  The output of this network is then passed to a set of linear dynamic models, which perform phone recognition.  1.  MOTIVATION Hidden Markov Models (HMMs) have dominated automatic speech recognition for at least the last decade.  The model's success lies in its mathematical simplicity; efficient and robust algorithms have been developed to facilitate its practical implementation.  However, there is nothing uniquely speech-oriented about acoustic-based HMMs.  Standard HMMs model speech as a series of stationary regions in some representation of the acoustic signal.  Speech is a continuous process though, and ideally should be modelled as such.  Furthermore, HMMs assume that state and phone boundaries are strictly synchronized with events in the parameter space, whereas in fact different acoustic and articulatory parameters do not necessarily change value simultaneously at boundaries.  We propose that modelling speech in the articulatory domain will inherently account for for the underlying processes of speech production, such as coarticulation, and will therefore offer improvements in recognition performance.  Because the trajectories evolve smoothly over time, we chose to model them using a Linear Dynamic Model (LDM), extending the approach used in [2].  We have had access to real articulatory data, which has been used to train a neural network mapping from acoustic to articulatory domains.  Both original and recovered data have been modelled.  1. 1.  Data The data consisted of a corpus of 460 TIMIT sentences for which parallel acoustic-articulatory information was recorded using a Carstens Electromagnetic Articulograph (EMA) system (this
