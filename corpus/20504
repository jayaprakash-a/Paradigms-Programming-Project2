Types, super-types and the mutual information distribution
 Abstract Discovering stochastic dependencies in empirical data is a fundamental problem in data modeling.  Dependencies are usually measured using the mutual information or chi square statistics, and then have to be compared to their sampling distribution under the independence hypothesis.  However, for finite sample sizes the exact sampling distribution of these statistics is still unknown.  The current paper presents a novel approach for approximation of these distributions for any finite sample size.  This approach is based on the method of types, used to identify different counts that yield similar independence values.  It provides an approximation to the distribution using a mixture of simple components, thus allowing for ecient numerical calculation of the mutual information distribution.  For binary variables the analysis provides an approximation algorithm that is linear in the sample size and considerably improves on the chi square distribution approximation, especially for the tail of the distribution.
