Maximum Entropy Probabilistic Logic
 Abstract Recent research has shown there are two types of uncertainty that can be expressed in first-order logic--propositional and statistical uncertainty---and that both types can be represented in terms of probability spaces.  However, these efforts have fallen short of providing a general account of how to design probability measures for these spaces; as a result, we lack a crucial component of any system that reasons under these types of uncertainty.  In this paper, we describe an automatic procedure for defining such measures in terms of a probabilistic knowledge base.  In particular, we employ the principle of maximum entropy to select measures that are consistent with our knowledge and that make the fewest assumptions in doing so.  This approach yields models of first-order uncertainty that are principled, intuitive, and economical in their representation.
