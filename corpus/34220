Adaptive View-Based Appearance Models
 Abstract We present a method for online rigid object tracking using an adaptive view-based appearance model.  When the object's pose trajectory crosses itself, our tracker has bounded drift and can track objects undergoing large motion for long periods of time.  Our tracker registers each incoming frame against the views of the appearance model using a twoframe registration algorithm.  Using a linear Gaussian filter, we simultaneously estimate the pose of the object and adjust the view-based model as pose-changes are recovered from the registration algorithm.  The adaptive view-based model is populated online with views of the object as it undergoes different orientations in pose space, allowing us to capture non-Lambertian effects.  We tested our approach on a real-time rigid object tracking task using stereo cameras and observed an RMS error within the accuracy limit of an attached inertial sensor.
