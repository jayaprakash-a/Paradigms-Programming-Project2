Appears in
 Abstract We present an analysis of how the generalization performance (expected test set error) relates to the expected training set error for nonlinear learning systems, such as multilayer perceptrons and radial basis functions.  The principal result is the following relationship (computed to second order) between the expected test set and training set errors: hE test ( )i 0 hE train ( )i + 2oe 2 eff p eff ( ) n : (1) Here, n is the size of the training sample , oe 2 eff is the effective noise variance in the response variable(s), is a regularization or weight decay parameter, and p eff ( ) is the effective number of parameters in the nonlinear model.  The expectations h i of training set and test set errors are taken over possible training sets and training and test sets 0 respectively.  The effective number of parameters p eff ( ) usually differs from the true number of model parameters p for nonlinear or regularized models; this theoretical conclusion is supported by Monte Carlo experiments.  In addition to the surprising result that p eff ( ) 6= p, we propose an estimate of (1) called the generalized prediction error (GPE) which generalizes well established estimates of prediction risk such as Akaike's FPE and AIC, Mallows CP , and Barron's PSE to the nonlinear setting.  1 1 GPE and peff ( ) were previously introduced in Moody (1991).  1 Background and Motivation Many of the nonlinear learning systems of current interest for adaptive control, adaptive signal processing, and time series prediction, are supervised learning systems of the regression type.  Understanding the relationship between generalization performance and training error and being able to estimate the generalization performance of such systems is of crucial importance.  We will take the prediction risk (expected test set error) as our measure of generalization performance.  2 Learning from Examples Consider a set of n real-valued input/output data pairs (n) = fi = (x i ; y i ); i = 1; : : : ; ng drawn from a stationary density \Xi().  The observations can be viewed as being generated according to the signal plus noise model 2 y i = (x i ) + ffl i (2) where y i is the observed response (dependent variable), x i are the independent variables sampled with input probability density \Omega(x), ffl i is independent, identicallydistributed (iid) noise sampled with density \Phi(ffl) having mean 0 and variance oe 2 , 3 and (x) is the conditional mean, an unknown function.  From the signal plus noise perspective, the density \Xi() = \Xi(x; y) can be represented as the product of two components, the conditional density \Psi(yjx) and the input density \Omega(x): \Xi(x; y) = \Psi(yjx) \Omega(x) j \Phi(y \Gamma (x)) \Omega(x) : (3) The learning problem is then to find an estimate b (x) of the conditional mean (x) on the basis of the training set (n).  In many real world problems, few a priori assumptions can be made about the functional form of (x).  Since a parametric function class is usually not known, one must resort to a nonparametric regression approach, whereby one constructs an estimate b (x) = f(x) for (x) from a large class of functions F known to have good approximation properties (for example, F could be all possible radial basis function networks and multilayer perceptrons).  The class of approximation functions is usually the union of a countable set of subclasses (specific network architectures) 4 A ae F for which the elements of each subclass f(w; x) 2 A are continuously parametrized by a set of p = p(A) weights w = fw ff ; ff = 1; : : : ; pg.  The task of finding the estimate f(x) thus consists of two problems: choosing the best architecture b A and choosing the best set of weights b w given the architecture.  Note that in 2 The assumption of additive noise ffl which is independent of x is a standard assumption and is not overly restrictive.  Many other conceivable signal/noise models can be transformed into this form.  For example, the multiplicative model y = (x)(1 + ffl) becomes y 0 = 0 (x) + ffl 0 for the transformed variable y 0 = log(y).  3 Note that we have made only a minimal assumption about the noise ffl, that it is has finite variance oe 2 independent of x.  Specifically, we do not need to make the assumption that the noise density \Phi(ffl) is of known form (e. g.  gaussian) for the following development.  4 For example, a "fully connected two layer perceptron with five internal units".
