Spatial and Temporal Abstractions in POMDPs Applied to Robot Navigation
 Abstract Partially observable Markov decision processes (POMDPs) are a well studied paradigm for programming autonomous robots, where the robot sequentially chooses actions to achieve long term goals efficiently.  Unfortunately, for real world robots and other similar domains, the uncertain outcomes of the actions and the fact that the true world state may not be completely observable make learning of models of the world extremely difficult, and using them algorithmically infeasible.  In this paper we show that learning POMDP models and planning with them can become significantly easier when we incorporate into our algorithms the notions of spatial and temporal abstraction.  We demonstrate the superiority of our algorithms by comparing them with previous flat approaches for large scale robot navigation.
