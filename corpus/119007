TARGET DETECTION USING SALIENCY-BASED ATTENTION
 Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a "saliency map", that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment.  Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target.  Inhibiting this location automatically allows the system to attend to the next most salient location.  We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner.  We have successfully applied this model to a wide range of target detection tasks, using synthetic and natural stimuli.  Performance has however remained difficult to objectively evaluate on natural scenes, because no objective reference was available for comparison.  We here present predicted search times for our model on the Search2 database of rural scenes containing a military vehicle.  Overall, we found a poor correlation between human and model search times.  Further analysis however revealed that in 3/4 of the images, the model appeared to detect the target faster than humans (for comparison, we calibrated the model's arbitrary internal time frame such that no more than 24 image locations were visited per second).  It hence seems that this model, which had originally been designed not to find small, hidden military vehicles, but rather to find the few most obviously conspicuous objects in an image, performed as an efficient target detector on the Search2 dataset.
