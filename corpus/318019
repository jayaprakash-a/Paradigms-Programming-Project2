Learning Simple Non-Stationarities with Hyper-Parameters
 Abstract We consider sequential data that is sampled from an unknown process, so that the data are not necessarily i. i. d. .  Most approaches to machine learning assume that data points are i. i. d. .  Instead we consider a measure of generalization that does not make this assumption, and we consider in this context a recently proposed approach to optimizing hyper-parameters, based on the computation of the gradient of a model selection criterion with respect to hyper-parameters.  Here we use hyper-parameters that control a function that gives different weights to different time steps in the historical data sequence.  The approach is successfully applied to modeling the volatility of stock returns one month ahead.  Comparative experiments with more traditional methods are presented.
