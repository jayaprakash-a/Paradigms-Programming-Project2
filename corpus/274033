Text Classification in Asian Languages without Word Segmentation
 Abstract We present a simple approach for Asian language text classification without word segmentation, based on statistical # -gram language modeling.  In particular, we examine Chinese and Japanese text classification.  With character # -gram models, our approach avoids word segmentation.  However, unlike traditional ad hoc # -gram models, the statistical language modeling based approach has strong information theoretic basis and avoids explicit feature selection procedure which potentially loses significantly amount of useful information.  We systematically study the key factors in language modeling and their influence on classification.  Experiments on Chinese TREC and Japanese NTCIR topic detection show that the simple approach can achieve better performance compared to traditional approaches while avoiding word segmentation, which demonstrates its superiority in Asian language text classification.
