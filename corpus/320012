Explaining away ambiguity: Learning verb selectional preference with Bayesian networks
 Abstract This paper presents a Bayesian model for unsupervised learning of verb selectional preferences.  For each verb the model creates a Bayesian network whose architecture is determined by the lexical hierarchy of Wordnet and whose parameters are estimated from a list of verb-object pairs found from a corpus.  \Explaining away", a wellknown property of Bayesian networks, helps dealing with word sense ambiguity in the training data in a natural fashion.  On a word sense disambiguation test our model performed better than other state of the art systems for unsupervised learning of selectional preferences.  Computational complexity problems, ways of improving this approach and methods for implementing \explaining away" in other graphical frameworks are discussed.  1 Selectional preference and sense ambiguity Semantic regularities about verb arguments (subject, object, and direct object) are called selectional preferences (Katz and Fodor, 1964; Chomsky, 1965; Johnson-Laird, 1983) (SP).  They express the preferences of the verb
