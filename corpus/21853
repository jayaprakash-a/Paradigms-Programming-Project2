A variational approach to Bayesian logistic regression models and their extensions
 Abstract We consider a logistic regression model with a Gaussian prior distribution over the parameters.  We show that accurate variational techniques can be used to obtain a closed form posterior distribution over the parameters given the data thereby yielding a posterior predictive model.  The results are straightforwardly extended to (binary) belief networks.  For the belief networks we also derive closed form parameter posteriors in the presence of missing values.  We show #nally that the dual of the regression problem gives a latent variable density model the variational formulation of which leads to exactly solvable EM updates.
