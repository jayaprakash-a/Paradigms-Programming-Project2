Degree: Master of Science Title of thesis: Computational Color Constancy: Taking Theory into Practice tice
 Abstract The light recorded by a camera is a function of the scene illumination, the reflective characteristics of the objects in the scene, and the camera sensors.  The goal of color constancy is to separate the effect of the illumination from that of the reflectances.  In this work, this takes the form of mapping images taken under an unknown light into images which are estimates of how the scene would appear under a fixed, known light.  The research into color constancy has yielded a number of disparate theoretical results, but testing on image data is rare.  The thrust of this work is to move towards a comprehensive algorithm which is applicable to image data.  Necessary preparatory steps include measuring the illumination and reflectances expected in real scenes, and determining the camera response function.  Next, a number of color constancy algorithms are implemented, with emphasis on the gamut mapping approach introduced by D.  Forsyth and recently extended by G.  Finlayson.  These algorithms all assume that the color of the illumination does not vary across the scene.  The results of these algorithms running on a variety of images, as well as on generated data, are iv presented.  In addition, the possibility of using sensor sharpening to improve algorithm performance is investigated.  The final part of this work deals with images of scenes where the illumination is not necessarily constant.  A recent promising result from Finlayson, Funt, and Barnard demonstrates that if the illumination variation can be identified, it can be used as a powerful constraint.  However, in its current form this algorithm requires human input and is limited to using a single such constraint.  In this thesis the algorithm is first modified so that it provides conjunctive constraints with the other gamut mapping constraints and utilizes all available constraints due to illumination variation.  Then a method to determine the variation in illumination from a properly segmented image is introduced.  Finally the comprehensive algorithm is tested on simple images segmented with region growing.  The results are very encouraging.
