Robust Textual Inference using Diverse Knowledge Sources
 Abstract We present a machine learning approach to robust textual inference, in which parses of the text and the hypothesis sentences are used to measure their asymmetric "similarity", and thereby to decide if the hypothesis can be inferred.  This idea is realized in two different ways.  In the first, each sentence is represented as a graph (extracted from a dependency parser) in which the nodes are words/phrases, and the links represent dependencies.  A learned, asymmetric, graph-matching cost is then computed to measure the similarity between the text and the hypothesis.  In the second approach, the text and the hypothesis are parsed into the logical formula-like representation used by (Harabagiu et al. , 2000).  An abductive theorem prover (using learned costs for making different types of assumptions in the proof) is then applied to try to infer the hypothesis from the text, and the total "cost" of proving the hypothesis is used to decide if the hypothesis is entailed.
