Learning to Use Selective Attention and Short-Term Memory in Sequential Tasks
 Abstract This paper presents U-Tree, a reinforcement learning algorithm that uses selective attention and shortterm memory to simultaneously address the intertwined problems of large perceptual state spaces and hidden state.  By combining the advantages of work in instance-based (or "memory-based") learning and work with robust statistical tests for separating noise from task structure, the method learns quickly, creates only task-relevant state distinctions, and handles noise well.  U-Tree uses a tree-structured representation, and is related to work on Prediction Suffix Trees [Ron et al. , 1994] , Parti-game [Moore, 1993] , G-algorithm [Chapman and Kaelbling, 1991] , and Variable Resolution Dynamic Programming [Moore, 1991] .  It builds on Utile Suffix Memory [McCallum, 1995c] , which only used short-term memory, not selective perception.  The algorithm is demonstrated solving a highway driving task in which the agent weaves around slower and faster traffic.  The agent uses active perception with simulated eye movements.  The environment has hidden state, time pressure, stochasticity, over 21,000 world states and over 2,500 percepts.  From this environment and sensory system, the agent uses a utile distinction test to build a tree that represents depththree memory where necessary, and has just 143 internal states---far fewer than the 2500 3 states that would have resulted from a fixed-sized history-window approach.
