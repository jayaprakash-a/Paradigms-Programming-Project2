Likelihood Computations Using Value Abstraction
 Abstract In this paper, we use evidence-specific value abstraction for speeding Bayesian networks inference.  This is done by grouping variable values and treating the combined values as a single entity.  As we show, such abstractions can exploit regularities in conditional probability distributions and also the specific values of observed variables.  To formally justify value abstraction, we define the notion of safe value abstraction and devise inference algorithms that use it to reduce the cost of inference.  Our procedure is particularly useful for learning complex networks with many hidden variables.  In such cases, repeated likelihood computations are required for EM or other parameter optimization techniques.  Since these computations are repeated with respect to the same evidence set, our methods can provide significant speedup to the learning procedure.  We demonstrate the algorithm on genetic linkage problems where the use of value abstraction sometimes differentiates between a feasible and non-feasible solution.
