COMBINING ARTICULATORY AND ACOUSTIC INFORMATION FOR SPEECH RECOGNITION IN NOISY AND REVERBERANT ENVIRONMENTS
 ABSTRACT Robust speech recognition under varying acoustic conditions may be achieved by exploiting multiple sources of information in the speech signal.  In addition to an acoustic signal representation, we use an articulatory representation consisting of pseudoarticulatory features as an additional information source.  Hybrid ANN/HMM recognizers using either of these representations are evaluated on a continuous numbers recognition task (OGI Numbers95) under clean, reverberant and noisy conditions.  An error analysis of preliminary recognition results shows that the different representations produce qualitatively different errors, which suggests a combination of both representations.  We investigate various combination possibilities at the phoneme estimation level and show that significant improvements can been achieved under all three acoustic conditions.
