Overcoming Incomplete Perception with Utile Distinction Memory
 Abstract This paper presents a method by which a reinforcement learning agent can solve the incomplete perception problem using memory.  The agent uses a hidden Markov model (HMM) to represent its internal state space and creates memory capacity by splitting states of the HMM.  The key idea is a test to determine when and how a state should be split: the agent only splits a state when doing so will help the agent predict utility.  Thus the agent can create only as much memory as needed to perform the task at hand---not as much as would be required to model all the perceivable world.  I call the technique UDM, for Utile Distinction Memory.
