An Efficient Repair Procedure For Quick Transcriptions
 Abstract We describe an efficient procedure for automatic repair of quickly transcribed (QT) speech.  QT speech, typically closed captioned data from television broadcasts, usually has a significant number of deletions and misspellings, and has a characteristic absence of disfluencies such as filled pauses (for example, um, uh).  Errors of these kinds often throw an acoustic model training program out of alignment and make it hard for it to resynchronize.  At best the erroneous utterance is discarded and does not benefit the training procedure.  At worst, it could misalign and end up sabotaging the training data.  The procedure we propose in this paper aims to cleanse such quick transcriptions so that they align better with the acoustic evidence and thus provide for better acoustic models for automatic speech recognition (ASR).  Results from comparing our transcripts with those from careful transcriptions on the same corpus, and from comparable state-of-the-art methods are also presented and discussed.
