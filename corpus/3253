Classification and Feature Selection on Matrix Data with Application to Gene-Expression Analysis
 We consider the classification task for datasets which are described by matrices.  Rows and columns of these matrices correspond to objects where row and column objects may be from dierent sets and column objects are labeled.  Data matrix entries express relationships between row and column objects and are produced by an unknown kernel.  These kernels represent dot products in some (unknown) feature space.  In this feature space a linear column object classifier should be constructed.  However the dot products between column objects are not available.  Therefore standard support vector techniques cannot be utilized.  We derive a new objective function for model selection in such a feature space according to the principle of structural risk minimization.  The new objective allows the analysis of matrices which are not positive definite, and not even symmetric or square.  Because row objects can be interpreted as features and our method assigns support vector weights to the row objects can be used for feature selection.  An additional constraint, which imposes sparseness on the row objects resulting in few selected features.  We analyse data obtained from DNA microarrays, where "column" objects correspond to samples, "row" objects correspond to genes and matrix elements correspond to expression levels.  Benchmarks are conducted using standard one-gene classification and support vector machines and K-nearest neighbors after standard feature selection.  Our new method extracts a sparse set of genes and provides superior classification results.
