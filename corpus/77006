The Variational Transition Kernel
 Abstract We introduce a new Monte Carlo algorithm for performing inference with latent variable models.  The key to our method is a variational approximation to the transition kernel of a Markov chain that has the parameter posterior as invariant distribution.  The transition kernel allows us to circumvent the explicit latent variable sample that is common in twostage Gibbs sampling for latent variable models.  By averaging over latent variables, we find it easier to escape trapping states and smooth over local minima in the latent variable space, giving a more robust sampling method.  The variational kernel is adaptive and fast to calculate from a closed-form solution.  Samples can either be taken from the resulting approximate chain and corrected with an importance-weight, or the variational kernel can be used as a Metropolis-Hastings proposal distribution.  We demonstrate the new algorithm on a mixture modeling problem and on real data and compare with two related methods: two-stage Gibbs sampling and variational Bayes.
