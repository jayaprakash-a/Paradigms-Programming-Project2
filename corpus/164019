Maximum Likelihood 3D Image Understanding and Object Recognition \Lambda
 Abstract We describe a general framework for resolving ambiguities in object recognition and image understanding using maximum likelihood estimation, augmenting existing geometrical techniques.  This extension is needed when images are noisy and the database is large, when existing techniques of 3D image understanding and model-based object recognition cannot provide a unique answer.  We define measures of likelihood and stability of interpretations, and show how to compute these quantities directly from any difference function used to compare between 2D images and 3D shapes.  We then discuss when the most likely interpretation is the most stable one.  We thus give a practical way to measure how "generic" views are, and identify ``characteristic" views.  The proposed approach is concrete, general and relatively easy to use.  To demonstrate the usefulness of this framework, we develop the proposed stability and likelihood functions using two "natural" image metrics, which compare images of objects composed of localized features.  For such objects, the stability and likelihood of any 3D interpretation can be evaluated from a simple expression involving only the three principal second moments of the 3D shape.  Moreover, the most stable and most likely interpretation is the "flattest" view of the 3D shape, obtained when the three dimensional object has its minimal spread along the viewing direction.  Examples of maximum likelihood image understanding and object recognition, using simulated and real images, are given.
