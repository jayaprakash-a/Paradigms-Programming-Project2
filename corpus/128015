Stochastic Dynamics of Learning with Momentum in Neural Networks
 Abstract We study on-line learning with momentum term for nonlinear learning rules.  Through introduction of auxiliary variables, we show that the learning process can be described by a Markov process.  For small learning parameters j and momentum parameters ff close to 1, such that fl = j=(1\Gamma ff) 2 is finite, the time scales for the evolution of the weights and the auxiliary variables are the same.  In this case Van Kampen's expansion can be applied in a straightforward manner.  We obtain evolution equations for the average network state and the fluctuations around this average.  These evolution equations depend (after rescaling of time and fluctuations) only on fl: all combinations (j; ff) with the same value of fl give rise to similar behaviour.  The case ff constant and j small requires a completely different analysis.  There are two different time scales: a fast time scale on which the auxiliary variables equilibrate and a slow time scale for the change of the weights.  By projection on the space of slow variables the fast variables can be eliminated.  We find that for small learning parameters j and finite momentum parameters ff learning with momentum is equivalent to learning without momentum term with rescaled learning parameter ~ j = j=(1\Gamma ff).  Simulations with the nonlinear Oja learning rule confirm the theoretical results.
