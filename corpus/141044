A stochastic neural architecture that exploits dynamically reconfigurable FPGAs
 Abstract In this paper we present an expandable digital architecture that provides an efficient real time implementation platform for large neural networks.  The architecture makes heavy use of the techniques of bit serial stochastic computing to carry out the large number of required parallel synaptic calculations.  In this design all real valued quantities are encoded on to stochastic bit streams in which the `1' density is proportional to the given quantity.  The actual digital circuitry is simple and highly regular thus allowing very efficient space usage of fine grained FPGAs.  Another feature of the design is that the large number of weights required by a neural network are generated by circuitry tailored to each of their specific values, thus saving valuable cells.  Whenever one of these values is required to change, the appropriate circuitry must be dynamically reconfigured.  This may always be achieved in a fixed and minimum number of cells for a given bit stream resolution.
