DATA-DRIVEN EXTENSIONS TO HMM STATISTICAL DEPENDENCIES
 ABSTRACT In this paper, a new technique is introduced that relaxes the HMM conditional independence assumption in a principled way.  Without increasing the number of states, the modeling power of an HMM is increased by including only those additional probabilistic dependencies (to the surrounding observation context) that are believed to be both relevant and discriminative.  Conditional mutual information is used to determine both relevance and discriminability.  Extended Gaussian-mixture HMMs and newEM update equations are introduced.  In an isolated word speech database, results show an average 34% word error improvement over an HMM with the same number of states, and a 15% improvement over an HMM with a comparable number of parameters.
