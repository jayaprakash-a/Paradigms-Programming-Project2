Making stochastic source coding efficient by recovering information
 Abstract In this paper, we introduce a new algorithm called "bits-back coding" that makes stochastic source codes efficient.  For a given one-to-many source code, we show that this algorithm can actually be more efficient than the algorithm that always picks the shortest codeword.  Optimal efficiency is achieved when codewords are chosen according to the Boltzmann distribution based on the codeword lengths.  After presenting a binary Bayesian network model that assigns exponentially many codewords to each symbol, we show how a tractable approximation to the Boltzmann distribution can be used for bits-back coding.  It turns out that a commonly used technique for determining parameters --- maximum likelihood estimation --- actually minimizes the optimal bitsback coding cost.  A tractable approximation to maximum likelihood estimation --incremental expectation maximization --- minimizes the bits-back coding cost as well.  We illustrate the performance of bits-back coding first on a toy problem and then using real data with a binary Bayesian network that produces 2 60 possible codewords for each symbol.  For both tasks, the rate for bits-back coding is nearly one half of that obtained by picking the shortest codeword for each symbol.
