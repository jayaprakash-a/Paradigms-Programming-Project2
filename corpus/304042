Face distinctiveness in recognition across viewpoint: An analysis of the statistical structure of face spaces
 Abstract We present an analysis of the effects of face distinctiveness on the performance of a computational model of recognition over viewpoint change.  In the first stage of the model, the face stimulus is normalized by being mapped to an arbitrary standard view.  In the second stage, the normalized stimulus is mapped into a "face space" spanned by a number of reference faces, and is classified as familiar or unfamiliar.  We carried out experiments employing a parametrically generated family of face stimuli that vary in distinctiveness.  The experiments show that while the "view-mapping" process operates more accurately for typical versus distinctive faces, the base level distinctiveness of the faces is preserved in the face space coding.  These data provide insight into how the psychophysically well-established inverse relationship between the typicality and recognizability of faces might operate for recognition across changes in viewpoint.  1 Psychophysical background The recognition of familiar faces is something that people do very well.  This is true even with relatively dramatic changes in faces that can occur daily (e. g. , hair style), and over longer periods of time as faces age.  Somewhat distinct from the problem of recognizing faces that have changed in various ways is the problem of generalizing this recognition ability across varying viewpoints.  In this case, the 3D structure of a face/head is relatively constant.  The problem is to determine whether or not we know a face when we see it from different, even completely novel, viewpoints.  Notably, the problem of recognition requires the ability to represent the information in individual faces that makes them unique.  The problem of generalization across views entails the additional requirement that this unique information be accessible across viewpoint variations.  It is evident that individual faces vary in the quality of the uniqueness information they provide for a face recognizer --- either human or computational.  More simply stated, individual faces vary in how "distinctive" or unusal they are, and hence in how likely they are to be mistaken for other faces.  The relationship between the distinctiveness of a face (as rated by human subjects) and the accuracy with which human observers recognize the face has been well established in the psychological literature: not surprisingly, distinctive or unusual faces are more accurately recognized than are typical faces [9, 10, 15].  This finding has implications both for theoretical accounts of human memory for faces and for more applied issues concerning the factors that affect, e. g. , the accuracy of eyewitness identification.  From a theoretical perspective, many psychological and computational models of face processing have posited a representation of faces in a "face space," with a prototype/average face at the center e. g. , [2, 14, 15].  By this account, individual faces are encoded in terms of their deviation from the prototype face --- typical faces are harder to recognize than unusual faces, because the face space is more "crowded" close to the prototype, making it easier to confuse typical faces with other (un)familiar faces.  While these data are well-established, they have been collected and applied almost exclusively to the problem of face recognition from a single viewpoint (though see [12], for an exception).  These data suggest that the human performance depends on the statistical structure of the set of faces to which the observer has been exposed.  This observation serves as the main guiding principle behind the model we describe next.  This computational model builds on the basic psychological findings and extends them to consider the effects of face distinctiveness for recognition over viewpoint change.  2 Computational background The central role of the statistics of the stimuli in our model is motivated both by the psychological considerations surveyed above, and by the growing importance attributed to the statistical structure of the visual world in current theories of visual processing.  A number of researchers have attempted to derive the shapes of the receptive fields found at the early stages of the visual system from the statistics of natural images ([6]; see [13] for a review).  More recently, it has been suggested that a similar approach may be productive at the higher levels of vision, which should be tuned to the statistics of natural objects (such as faces), rather than random scenes [16].  Our model relies on the statistics of a collection of face shapes in two ways.  First, the common manner in which images of faces change with viewpoint (due to the common 3D structure of faces) is exploited at the initial stage of the model, which performs normalization of the input image to a "standard" view of the face.  The normalized image is then compared to a number of reference faces, which span our version of the face space.  At this second stage, the statistics of the collection of faces with respect to a set of reference faces constitutes the system's internal representation of the face space.  The rest of this section describes the two stages of the model in some detail.  2. 1 The view space input image view-map (RBF) subsample train output vector equivalent image Figure 1: The view-mapper.  The way in which known faces change across viewpoint is exploited in deriving a normalized representation of a novel face seen from a familiar orientation.  As noted frequently in the vision literature, the human visual system is usually able to make sense of a 2D image, even when the object to which it corresponds was never before encountered under that particular combination of viewing conditions.  A possible solution to this difficult computationl problem is via class-based processing: assuming that the stimulus belongs to a familiar class, the visual system can take advantage of its prior experience with other members of that class in processing the image of a new member.  For example, a normalizing transformation that brings familiar members of the class of faces into a normal form, can be used to estimate the appearance of a less familiar face from some standard viewpoint, facilitating subsequent recognition of that face [8].  2. 2 The shape space recognize (threshold) identify (RBF) face space reference-face modules (RBF) stimulus familiar/unfamiliar? who? view-map (RBF) Figure 2: The entire model.  Following normalization of the stimulus image by the view-mapper [7], it is projected into a view-specific face space spanned by a set of reference faces [5].  At the recognition stage, the system must deal with a stimulus that may have been normalized (e. g. , by class-based processing), but may still turn out to be unfamiliar, i. e. , may not match any of the stimuli for which internal representations are available in long-term memory.  Just as the problem of making sense of an unfamiliar viewpoint can be dealt with by exploiting the similarity of the view space of a given face to those of other members of the class of faces, we treat the problem of making sense of
