Monte Carlo Inference for Belief Networks Using Coupling From the Past
 1999 A common method of inference for belief networks is Gibbs sampling, in which a Markov chain converging to the desired distribution is simulated.  In practice, however, the distribution obtained with Gibbs sampling differs from the desired distribution by an unknown error, since the simulation time is finite.  Coupling from the past selects states from exactly the desired distribution by starting chains in every state at a time far enough back in the past that they reach the same state at time t = 0.  To track every chain is an intractable procedure for large state spaces.  The method proposed in this thesis uses a summary chain to approximate the set of chains.  Transitions of the summary chain are efficient for noisy-or belief networks, provided that sibling variables of the network are not directly connected, but often require more simulation time steps than would be needed if chains were tracked exactly.  Testing shows that the method is a potential alternative to ordinary Gibbs sampling, especially for networks that have poor Gibbs sampling convergence, and when the user has a low error tolerance.
