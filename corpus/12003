A Simple Method for Cost-Sensitive Learning
 Abstract A folk theorem implies a simple reduction which allows anyone to turn an arbitrary cost-insensitive classi#cation algorithm into a cost-sensitive classification algorithm.  The reduction works using a particular reweighting of the examples which can be satis#ed either by feeding the weights to the classification algorithm (as often done in boosting), or by resampling.  Naive methods of resampling often result in drastically poor performance due to a strong tendency to over#t.  The overfitting is analyzed and rejection sampling is used in a technique we call \costing", which provably avoids resampling-based overfitting and results in superior performance.
