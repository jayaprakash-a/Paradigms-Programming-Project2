Classification with Nonmetric Distances: Image Retrieval and Class Representation
 Abstract One of the key problems in appearance-based vision is understanding how to use a set of labeled images to classify new images.  Classification systems that can model human performance, or that use robust image matching methods, often make use of similarity judgments that are non-metric; but when the triangle inequality is not obeyed, most existing pattern recognition techniques are not applicable.  We note that exemplar-based (or nearest-neighbor) methods can be applied naturally when using a wide class of non-metric similarity functions.  The key issue, however, is to find methods for choosing good representatives of a class that accurately characterize it.  We show that existing condensing techniques for finding class representatives are ill-suited to deal with non-metric dataspaces.  We then focus on developing techniques for solving this problem, emphasizing two points: First, we show that the distance between two images is not a good measure of how well one image can represent another in non-metric spaces.  Instead, we use the vector correlation between the distances from each image to other previously seen images.  Second, we show that in non-metric spaces, boundary points are less significant for capturing the structure of a class than they are in Euclidean spaces.  We suggest that atypical points may be more important in describing classes.  We demonstrate the importance of these ideas to learning that generalizes from experience by improving performance using both synthetic and real images.  In addition, we suggest ways of applying parametric techniques to supervised learning problems that involve a specific nonmetric distance functions, showing in particular how to generalize the idea of linear discriminant functions in a way that may be more useful in non-metric spaces.
