Bilinear Sparse Coding for Invariant Vision
 Recent algorithms for sparse coding and independent component analysis (ICA) have demonstrated how localized features can be learned from natural images.  However, these approaches do not take image transformations into account.  We describe an unsupervised algorithm for learning both localized features and their transformations directly from images using a sparse bilinear generative model.  We show that from an arbitrary set of natural images, the algorithm produces oriented basis filters that can simultaneously represent features in an image and their transformations.  The learned generative model can be used to translate features to different locations, thereby reducing the need to learn the same feature at multiple locations, a limitation of previous approaches to sparse coding and ICA.  Our results suggest that by explicitly modeling the interaction between local image features and their transformations, the sparse bilinear approach can provide a basis for achieving transformation-invariant vision.
