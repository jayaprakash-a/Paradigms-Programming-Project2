Matching Shapes
 Abstract We present a novel approach to measuring similarity between shapes and exploit it for object recognition.  In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform.  In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point.  The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization.  Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem.  Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin--plate splines provide a flexible class of transformation maps for this purpose.  Dissimilarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform.  We treat recognition in a nearest-neighbor classification framework.  Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.
