A Brief Introduction to Boosting
 Abstract Boosting is a general method for improving the accuracy of any given learning algorithm.  This short paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting.  Some examples of recent applications of boosting are also described.  Background Boosting is a general method which attempts to "boost" the accuracy of any given learning algorithm.  Boosting has its roots in a theoretical framework for studying machine learning called the "PAC" learning model, due to Valiant [37]; see Kearns and Vazirani [24] for a good introduction to this model.  Kearns and Valiant [22, 23] were the first to pose the question of whether a "weak" learning algorithm which performs just slightly better than random guessing in the PAC model can be ``boosted" into an arbitrarily accurate "strong" learning algorithm.  Schapire [30] came up with the first provable polynomial-time boosting algorithm in 1989.  A year later, Freund [14] developed a much more efficient boosting algorithm which, although optimal in a certain sense, nevertheless suffered from certain practical drawbacks.  The first experiments with these early boosting algorithms were carried out by Drucker, Schapire and Simard [13] on an OCR task.  AdaBoost The AdaBoost algorithm, introduced in 1995 by Freund and Schapire [18], solved many of the practical difficulties of the earlier boosting algorithms, and is the focus of this paper.  Pseudocode for AdaBoost is given in Fig.  1.  The algorithm takes as input a training set (x 1 ; y 1 ); : : : ; (xm ; y m ) where each x i belongs to some domain or instance space X, and each label y i is in some label set Y .  For most of this paper, we assume Y =f\Gamma 1; +1g; later, we discuss extensions to the multiclass case.  AdaBoost calls a given weak or base learning algorithm repeatedly in a series of rounds t = 1; : : : ; T .  Given: (x 1 ; y 1 ); : : : ; (xm ; ym ) where x i 2 X, y i 2 Y =f\Gamma 1; +1g Initialize D 1 (i) = 1=m.
