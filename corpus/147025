TOWARDS ARTICULATORY SPEECH RECOGNITION: LEARNING SMOOTH MAPS TO RECOVER ARTICULATOR INFORMATION
 Abstract We present a novel method for recovering articulator movements from speech acoustics based on a constrained form [9] of a hidden Markov model.  The model attempts to explain sequences of high dimensional data using smooth and slow trajectories in a latent variable space.  The key insight is that this continuity constraint when applied to speech helps to solve the \ill-posed" problem of acoustic to articulatory mapping.  By working with sequences of spectra rather than looking only at individual spectra, it is possible to choose between competing articulatory configurations for any given spectrum by selecting the configuration \closest" to those at nearby times.  We present results of applying this algorithm to recover articulator movements from acoustics using data from the Wisconsin X-ray microbeam project [3].  We find that the recovered traces are highly correlated with the measured articulator movements under a single linear transform.  Such recovered traces have the potential to be used for speech recognition, an application we are currently investigating.
