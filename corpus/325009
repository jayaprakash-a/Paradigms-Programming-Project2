Statistical Signal Processing with Nonnegativity Constraints
 Abstract Nonnegativity constraints arise frequently in statistical learning and pattern recognition.  Multiplicative updates provide natural solutions to optimizations involving these constraints.  One well known set of multiplicative updates is given by the ExpectationMaximization algorithm for hidden Markov models, as used in automatic speech recognition.  Recently, we have derived similar algorithms for nonnegative deconvolution and nonnegative quadratic programming.  These algorithms have applications to low-level problems in voice processing, such as fundamental frequency estimation, as well as high-level problems, such as the training of large margin classifiers.  In this paper, we describe these algorithms and the ideas that connect them.
