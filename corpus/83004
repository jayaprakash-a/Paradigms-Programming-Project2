Bayesian Surprise Attracts Human Attention
 Abstract The concept of surprise is central to sensory processing, adaptation, learning, and attention.  Yet, no widely-accepted mathematical theory currently exists to quantitatively characterize surprise elicited by a stimulus or event, for observers that range from single neurons to complex natural or engineered systems.  We describe a formal Bayesian definition of surprise that is the only consistent formulation under minimal axiomatic assumptions.  Surprise quantifies how data affects a natural or artificial observer, by measuring the difference between posterior and prior beliefs of the observer.  Using this framework we measure the extent to which humans direct their gaze towards surprising items while watching television and video games.  We find that subjects are strongly attracted towards surprising locations, with 72% of all human gaze shifts directed towards locations more surprising than the average, a figure which rises to 84% when considering only gaze targets simultaneously selected by all subjects.  The resulting theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.  Life is full of surprises, ranging from a great christmas gift or a new magic trick, to wardrobe malfunctions, reckless drivers, terrorist attacks, and tsunami waves.  Key to survival is our ability to rapidly attend to, identify, and learn from surprising events, to decide on present and future courses of action [1].  Yet, little theoretical and computational understanding exists of the very essence of surprise, as evidenced by the absence from our everyday vocabulary of a quantitative unit of surprise: Qualities such as the "wow factor" have remained vague and elusive to mathematical analysis.  Informal correlates of surprise exist at nearly all stages of neural processing.  In sensory neuroscience, it has been suggested that only the unexpected at one stage is transmitted to the next stage [2].  Hence, sensory cortex may have evolved to adapt to, to predict, and to quiet down the expected statistical regularities of the world [3, 4, 5, 6], focusing instead on events that are unpredictable or surprising.  Electrophysiological evidence for this early sensory emphasis onto surprising stimuli exists from studies of adaptation in visual [7, 8, 4, 9], olfactory [10, 11], and auditory cortices [12], subcortical structures like the LGN [13], and even retinal ganglion cells [14, 15] and cochlear hair cells [16]: neural response greatly attenuates with repeated or prolonged exposure to an initially novel stimulus.  Surprise and novelty are also central to learning and memory formation [1], to the point that surprise is believed to be a necessary trigger for associative learning [17, 18], as supported by mounting evidence for a role of the hippocampus as a novelty detector [19, 20, 21].  Finally, seeking novelty is a well-identified human character trait, with possible association with the dopamine D4 receptor gene [22, 23, 24].  In the Bayesian framework, we develop the only consistent theory of surprise, in terms of the difference between the posterior and prior distributions of beliefs of an observer over the available class of models or hypotheses about the world.  We show that this definition derived from first principles presents key advantages over more ad-hoc formulations, typically relying on detecting outlier stimuli.  Armed with this new framework, we provide direct experimental evidence that surprise best characterizes what attracts human gaze in large amounts of natural video stimuli.  We here extend a recent pilot study [25], adding more comprehensive theory, large-scale human data collection, and additional analysis.  1 Theory Bayesian Definition of Surprise.  We propose that surprise is a general concept, which can be derived from first principles and formalized across spatio-temporal scales, sensory modalities, and, more generally, data types and data sources.  Two elements are essential for a principled definition of surprise.  First, surprise can exist only in the presence of uncertainty, which can arise from intrinsic stochasticity, missing information, or limited computing resources.  A world that is purely deterministic and predictable in real-time for a given observer contains no surprises.  Second, surprise can only be defined in a relative, subjective, manner and is related to the expectations of the observer, be it a single synapse, neuronal circuit, organism, or computer device.  The same data may carry different amount of surprise for different observers, or even for the same observer taken at different times.  In probability and decision theory it can be shown that the only consistent and optimal way for modeling and reasoning about uncertainty is provided by the Bayesian theory of probability [26, 27, 28].  Furthermore, in the Bayesian framework, probabilities correspond to subjective degrees of beliefs in hypotheses or models which are updated, as data is acquired, using Bayes' theorem as the fundamental tool for transforming prior belief distributions into posterior belief distributions.  Therefore, within the same optimal framework, the only consistent definition of surprise must involve: (1) probabilistic concepts to cope with uncertainty; and (2) prior and posterior distributions to capture subjective expectations.  Consistently with this Bayesian approach, the background information of an observer is captured by his/her/its prior probability distribution {P (M)}M2M over the hypotheses or models M in a model space M.  Given this prior distribution of beliefs, the fundamental effect of a new data observation D on the observer is to change the prior distribution {P (M)}M2M into the posterior distribution {P (M 
