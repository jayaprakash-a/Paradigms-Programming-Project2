Multi-Time Models for Reinforcement Learning
 Abstract Reinforcement learning can be used not only to predict rewards, but also to predict states, i. e.  to learn a model of the world's dynamics.  Models can be defined at different levels of temporal abstraction.  Multi-time models are models that focus on predicting what will happen, rather than when a certain event will take place.  Based on multi-time models, we can define abstract actions, which enable planning (presumably in a more efficient way) at various levels of abstraction.  1 Action models Model-based reinforcement learning offers a possible solution to the problem of integrating planning in a real-time learning agent.  Models are used to make predictions about the environment.  The input of a model is a state and an action.  The model should output a distribution of possible future states, as well as the expected value of the reward along the way.  Since models provide action-dependent predictions, they also define policies for achieving certain states, or for achieving maximum expected rewards.  Reinforcement learning algorithms have traditionally been concerned with 1-step models, which assume that the agent interacts with its environment at some discrete, lowest-level time scale.  We extend this framework by defining multi-time models, which describe the environment at different time scales.  Multi-time models are a formalism for describing abstract actions.
