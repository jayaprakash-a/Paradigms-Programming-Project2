Evolving Team Darwin United
 Abstract.  The RoboCup simulator competition is one of the most challenging international proving grounds for contemporary AI research.  Exactly because of the high level of complexity and a lack of reliable strategic guidelines, the pervasive attitude has been that the problem can most successfully be attacked by human expertise, possibly assisted by some level of machine learning.  This led, in RoboCup'97, to a field of simulator teams all of whose level and style of play were heavily influenced by the human designers of those teams.  It is the thesis of our work that machine learning, if given the opportunity to design (learn) "everything" about how the simulator team operates, can develop a competitive simulator team that solves the problem utilizing highly successful, if largely nonhuman, styles of play.  To this end, Darwin United is a team of eleven players that have been evolved as a team of coordinated agents in the RoboCup simulator.  Each agent is given a subset of the lowest level perceptual inputs and must learn to execute series of the most basic actions (turn, kick, dash) in order to participate as a member of the team.  This paper presents our motivation, our approach, and the specific construction of our team that created itself from scratch.
