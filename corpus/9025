Multistream Dynamic Bayesian Network for Meeting Segmentation
 Abstract.  This paper investigates the automatic analysis and segmentation of meetings.  A meeting is analysed in terms of individual behaviours and group interactions, in order to decompose each meeting in a sequence of relevant phases, named meeting actions.  Three feature families are extracted from multimodal recordings: prosody from individual lapel microphone signals, speaker activity from microphone array data and lexical features from textual transcripts.  A statistical approach is then used to relate low-level features with a set of abstract categories.  In order to provide a flexible and powerful framework, we have employed a dynamic Bayesian network based model, characterized by multiple stream processing and flexible state duration modelling.  Experimental results demonstrate the strength of this system, providing a meeting action error rate of 9%.
