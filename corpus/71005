On Decision Boundaries of Naïve Bayes in Continuous Domains
 Abstract.  Nave Bayesian classifiers assume the conditional independence of attribute values given the class.  Despite this in practice often violated assumption, these simple classifiers have been found efficient, effective, and robust to noise.  Discretization of continuous attributes in nave Bayesian classifiers has achieved a lot of attention recently.  Continuous attributes need not necessarily be discretized, but it unifies their handling with nominal attributes and can lead to improved classifier performance.  We show that optimal partitioning results from decision tree learning carry over to Nave Bayes as well.  In particular, it sets decision boundaries on borders of segments with equal class frequency distribution.  An optimal univariate discretization with respect to the Nave Bayes rule can be found in linear time but, unfortunately, optimal multivariate optimization is intractable.
