A New Learning Algorithm for Mean Field Boltzmann Machines
 Abstract.  We present a new learning algorithm for Mean Field Boltzmann Machines based on the contrastive divergence optimization criterion.  In addition to minimizing the divergence between the data distribution and the equilibrium distribution, we maximize the divergence between one-step reconstructions of the data and the equilibrium distribution.  This eliminates the need to estimate equilibrium statistics, so we do not need to approximate the multimodal probability distribution of the free network with the unimodal mean field distribution.  We test the learning algorithm on the classification of digits.
