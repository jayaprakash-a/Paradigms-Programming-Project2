To Appear COLING-ACL '98: Workshop on Usage of WordNet in Natural Language Processing Systems Incorporating Knowledge in Natural Language Learning: A Case Study
 Abstract Incorporating external information during a learning process is expected to improve its efficiency.  We study a method for incorporating noun-class information, in the context of learning to resolve Prepositional Phrase Attachment (PPA) disambiguation.  This is done within a recently introduced architecture, SNOW, a sparse network of threshold gates utilizing the Winnow learning algorithm.  That architecture has already been demonstrated to perform remarkably well on a number of natural language learning tasks.  The knowledge sources used were compiled from the WordNet database for general linguistic purposes, irrespective of the PPA problem, and are being incorporated into the learning algorithm by enriching its feature space.  We study two strategies of using enriched features and the effects of using class information at different granularities, as well as randomly-generated knowledge which serves as a control set.  Incorporating external knowledge sources within SNOW yields a statistically significant performance improvement.  In addition, we find an interesting relation between the granularity of the knowledge sources used and the magnitude of the improvement.  The encouraging results with noun-class data provide a motivation for carrying out more work on generating better linguistic knowledge sources.
