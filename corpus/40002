From Regression to Classification in Support Vector Machines
 Abstract We study the relation between support vector machines (SVMs) for regression (SVMR) and SVM for classification (SVMC).  We show that for a given SVMC solution there exists a SVMR solution which is equivalent for a certain choice of the parameters.  In particular our result is that for # sufficiently close to one, the optimal hyperplane and threshold for the SVMC problem with regularization parameter C c are equal to 1 1- # times the optimal hyperplane and threshold for SVMR with regularization parameter C r = (1- #)C c .  A direct consequence of this result is that SVMC can be seen as a special case of SVMR.
