Tracking Number 463: Reinforcement Learning for Landmark-based Robot Navigation
 ABSTRACT In previous work, we described a cooperative multi-agent system (MAS) for coordinating various subcomponents of a robot navigation system.  In this system, manually-tuned bidding functions controlled the interaction between different agents to guide a robot to a desired target location.  A difficulty with hand-tuning is that it is hard to handle situations involving complex tradeoffs.  This paper explores the suitability of reinforcement learning for automatically tuning agents within an MAS to optimize a complex tradeoff.  Based on high-fidelity simulations, we conclude that reinforcement learning can learn better bidding functions than our hand-coded procedures.  The learned bidding functions yield higher probability of success, shorter navigation trajectories, and reduced use of expensive sensing actions.  However, we also found that correct functioning of reinforcement learning required extensive experimentation with the state representation.
