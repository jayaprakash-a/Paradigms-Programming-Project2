EMPATH: A Neural Network that Categorizes Facial Expressions
 Abstract There are two competing theories of facial expression recognition.  Some researchers have suggested that facial expression recognition is an example of categorical perception. Inthisview,expression categories are considered to be discrete entities with sharp boundaries between them, and discrimination of similar pairs of expressive faces is enhanced when the faces are near those boundaries.  Other researchers, however, suggest that facial expression perception is more graded and that facial expressions are best thought of as points in a continuous, low-dimensional space, where, for example, "Surprise" expressions are between "Happiness" and "Fear" expressions, due to their perceived similarity.  In this paper, we show that a simple yet biologically plausible neural network model, trained to classify facial expressions into six basic emotions, can fit data used to support both theories.  Without any attempt to fit the model to the data, the model matches a variety of psychological data on categorization, similarity, reaction times, discrimination, and recognition difficulty, both qualitatively and quantitatively.  We thus explain many of the seemingly complex psychological phenomena related to facial expression perception as natural consequences of the task's implementation in the brain.
