On-Line EM Reinforcement Learning
 Abstract--- In this article, we propose a new reinforcement learning (RL) method for a system having continuous state and action spaces.  Our RL method has an architecture like the actorcritic model.  The critic tries to approximate the Q-function, which is the expected future return for the current state-action pair.  The actor tries to approximate a stochastic soft-max policy defined by the Q-function.  The soft-max policy is more likely to select an action that has a higher Q-function value.  The on-line EM algorithm is used to train the critic and the actor.  We apply this method to two control problems.  Computer simulations show that our method is able to acquire fairly good control in the two tasks after a few learning trials.
