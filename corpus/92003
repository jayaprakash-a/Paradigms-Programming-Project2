Average Cost Temporal--Difference Learning
 ABSTRACT We propose a variant of temporal--difference learning that approximates average and differential costs of an irreducible aperiodic Markov chain.  Approximations are comprised of linear combinations of fixed basis functions whose weights are incrementally updated during a single endless trajectory of the Markov chain.  We presentaproof of convergence (with probability 1), and a characterization of the limit of convergence.  We also provide a bound on the resulting approximation error that exhibits an interesting dependence on the "mixing time" of the Markovchain.  The results parallel previous work bythe authors, involving approximations of discounted cost--to--go.
