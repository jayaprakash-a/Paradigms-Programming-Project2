Identifying Useful Subgoals in Reinforcement Learning by Local Graph Partitioning
 Abstract We present a new method for automatically creating useful temporallyextended actions in reinforcement learning.  Our method identifies states that lie between two densely-connected regions of the state space and generates temporally-extended actions that take the agent efficiently to these states.  We search for these states using a graph partitioning algorithm on local estimates of the transition graph---those that are constructed using only the most recent experiences of the agent.  This local perspective is a key property of our algorithm and one that differentiates it from most of the earlier work in this area.
