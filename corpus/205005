Information Bottleneck for Gaussian Variables
 Abstract The problem of extracting the relevant aspects of data was addressed through the information bottleneck (IB) method, by (soft) clustering one variable while preserving information about another - relevance - variable.  An interesting question addressed in the current work is the extension of these ideas to obtain continuous representations (embeddings) that preserve relevant information, rather than discrete clusters.  We give a formal definition of the general continuous IB problem and obtain an analytic solution for the optimal representation for the important case of multivariate Gaussian variables.  The obtained optimal representation is a noisy linear projection to eigenvectors of the normalized correlation matrix # xjy # 1 x , which is also the basis obtained in Canonical Correlation Analysis.  However, in Gaussian IB, the compression tradeoff parameter uniquely determines the dimension, as well as the scale of each eigenvector.  This introduces a novel interpretation where solutions of different ranks lie on a continuum parametrized by the compression level.  Our analysis also provides analytic expression for the optimal tradeoff - the information curve - in terms of the eigenvalue spectrum.
