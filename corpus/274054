Automatic basis selection for RBF networks using Stein's unbiased risk estimator
 Abstract--- The problem of selecting the appropriate number of basis functions is a critical issue for radial basis function neural networks.  An RBF network with an overly restricted basis gives poor predictions on new data, since the model has too little flexibility (yielding high bias and low variance).  By contrast, an RBF network with too many basis functions also gives poor generalization performance since it is too flexible and fits too much of the noise on the training data (yielding low bias but high variance).  Bias and variance are complementary quantities, and it is necessary to assign the number of basis function optimally in order to achieve the best compromise between them.  In this paper we derive a theoretical criterion for assigning the appropriate number of basis functions.  We use Stein's unbiased risk estimator (SURE) to derive a generic criterion that defines the optimum number of basis functions to use for a given problem.  The efficacy of this criterion is illustrated experimentally.
