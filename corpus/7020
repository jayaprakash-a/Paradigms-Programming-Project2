Lower Bounds on the Sample Complexity of Exploration in the Multi-armed Bandit Problem

