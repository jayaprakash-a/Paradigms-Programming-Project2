FULL EXPANSION OF CONTEXT-DEPENDENT NETWORKS IN LARGE VOCABULARY SPEECH RECOGNITION
 ABSTRACT We combine our earlier approach to context-dependent network representation with our algorithm for determinizing weighted networks to build optimized networks for large-vocabulary speech recognition combining an n-gram language model, a pronunciation dictionary and context-dependency modeling.  While fullyexpanded networks have been used before in restrictive settings (medium vocabulary or no cross-word contexts), we demonstrate that our network determinization method makes it practical to use fully-expanded networks also in large-vocabulary recognition with full cross-word context modeling.  For the DARPA North American Business News task (NAB), we give network sizes and recognition speeds and accuracies using bigram and trigram grammars with vocabulary sizes ranging from 10,000 to 160,000 words.  With our construction, the fully-expanded NAB context-dependent networks contain only about twice as many arcs as the corresponding language models.  Interestingly, we also find that, with these networks, real-time word accuracy is improved by increasing vocabulary size and n-gram order.
