GWINDOWS: Towards Robust Perception-Based UI
 Abstract--- Perceptual user interfaces promise modes of fluid computer-human interaction that complement the mouse and keyboard, and have been especially motivated in non-desktop scenarios, such as kiosks or smart rooms.  Such interfaces, however, have been slow to see use for a variety of reasons, including the computational burden they impose, a lack of robustness outside the laboratory, unreasonable calibration demands, and a shortage of sufficiently compelling applications.  We have tackled some of these difficulties by using a fast stereo vision algorithm for recognizing hand positions and gestures.  Our system uses two inexpensive video cameras to extract depth information.  This depth information enhances automatic object detection and tracking robustness, and may also be used in applications.  We demonstrate the algorithm in combination with speech recognition to perform several basic window management tasks, report on a user study probing the ease of using the system, and discuss the implications of such a system for future user interfaces.
