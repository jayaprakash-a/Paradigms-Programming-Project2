Condensation --- conditional density propagation for visual tracking
 ABSTRACT The problem of tracking curves in dense visual clutter is challenging.  Kalman filtering is inadequate because it is based on Gaussian densities which, being unimodal, cannot represent simultaneous alternative hypotheses.  The Condensation algorithm uses "factored sampling", previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set.  Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time.  The result is highly robust tracking of agile motion.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  Contents 1 Tracking curves in clutter 2 2 Discrete-time propagation of state density 3 3 Factored sampling 6 4 The Condensation algorithm 8 5 Stochastic dynamical models for curve motion 10 6 Observation model 13 7 Applying the Condensation algorithm to video-streams 17 8 Conclusions 26 A Non-linear filtering 31 B Derivation of the sampling rule 33 C Asymptotic correctness of the Condensation Algorithm 34 1 Tracking curves in clutter The purpose of this paper 1 is to establish a stochastic framework for tracking curves in visual clutter, using a sampling algorithm.  The approach is rooted in ideas from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case of camouflage, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our approach aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models is pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost (Hogg, 1983; Lowe, 1991; Sullivan, 1992; Huttenlocher et al. , 1993).  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally (Lowe, 1992), especially if motion is modelled as well as shape (Gennery, 1992; Harris, 1992).  One important facility is the modelling of curve segments which interact with images (Fischler and Elschlager, 1973; Yuille and Hallinan, 1992) or image sequences (Kass et al. , 1987; Dickmanns and Graefe, 1988).  This is more general than modelling entire objects but more clutter-resistant than applying signalprocessing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric B-spline curves (Bartels et al. , 1987) tracking over image sequences (Menet et al. , 1990; Cipolla and Blake, 1990).  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space (Koenderink and Van Doorn, 1991; Ullman and Basri, 1991; Blake et al. , 1993), or more generally allowing a "shape-space" of non-rigid motion (Cootes et al. , 1993).  Finally, prior probability densities can be defined over the curves (Cootes et al. , 1993) represented by appropriate parameter vectors x, and also over their motions (Terzopoulos and Metaxas, 1991; Blake et al. , 1993), and this constitutes a powerful facility for tracking.  Reasonable defaults can be chosen for those densities.  However, it is obviously more satisfactory to measure or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this, assuming Gaussian densities, are known in the control-theory literature (Goodwin and Sin, 1984) and have been applied in computer vision (Blake and Isard, 1994; Baumberg and Hogg, 1995).  Given the prior, and an observation density that characterises the statistical variability of image data z given a curve state x, a posterior distribution can, in principle, be estimated for x t given z t at successive times t.  1 This paper has appeared in short form (Isard and Blake, 1996) as joint winner of the prize of the European Conference on Computer Vision, 1996.
