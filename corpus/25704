Image Parsing: Unifying Segmentation, Detection, and Recognition
 Abstract We propose a general framework for parsing images into regions and objects.  In this framework, the detection and recognition of objects proceed simultaneously with image segmentation in a competitive and cooperative manner.  We illustrate our approach on natural images of complex city scenes where the objects of primary interest are faces and text.  This method makes use of bottom-up proposals combined with top-down generative models using the Data Driven Markov Chain Monte Carlo (DDMCMC) algorithm which is guaranteed to converge to the optimal estimate asymptotically.  More precisely, we define generative models for faces, text, and generic regions-- e. g.  shading, texture, and clutter.  These models are activated by bottom-up proposals.  The proposals for faces and text are learnt using a probabilistic version of AdaBoost.  The DDMCMC combines reversible jump and diffusion dynamics to enable the generative models to explain the input images in a competitive and cooperative manner.  Our experiments illustrate the advantages and importance of combining bottom-up and top-down models and of performing segmentation and object detection/recognition simultaneously.
