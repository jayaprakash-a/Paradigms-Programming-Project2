Phase-Space learning for recurrent networks
 Abstract We study the problem of learning nonstatic attractors in recurrent networks.  With concepts from dynamical systems theory, we show that this problem can be reduced to three sub-problems, (a) that of embedding the temporal trajectory in phase space, (b) approximating the local vector field, and (c) function approximation using feedforward networks.  This general framework overcomes problems with traditional methods by providing more appropriate error gradients and enforcing stability explicitly.  We describe an online version of our method we call ARTISTE, that can learn periodic attractors without teach-forcing.
