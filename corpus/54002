Nonparametric empirical Bayes for the Dirichlet process mixture model
 Abstract The Dirichlet process prior allows flexible nonparametric mixture modeling.  The number of mixture components is not specified in advance and can grow as new data come in.  However, the behavior of the model is sensitive to the choice of the parameters, including an infinite-dimensional distributional parameter G0 .  Most previous applications have either fixed G0 as a member of a parametric family or treated G0 in a Bayesian fashion, using parametric prior specifications.  In contrast, we have developed an adaptive nonparametric method for constructing smooth estimates of G0 .  We combine this method with a technique for estimating #, the other Dirichlet process parameter, that is inspired by an existing characterization of its maximum-likelihood estimator.  Together, these estimation procedures yield a flexible empirical Bayes treatment of Dirichlet process mixtures.  Such a treatment is useful in situations where smooth point estimates of G0 are of intrinsic interest, or where the structure of G0 cannot be conveniently modeled with the usual parametric prior families.  Analysis of simulated and real-world datasets illustrates the robustness of this approach.
