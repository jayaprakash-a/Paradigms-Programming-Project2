Representation of similarity as a goal of early visual processing
 Abstract We consider the representational capabilities of systems of receptive fields found in early mammalian vision, under the assumption that the successive stages of processing remap the retinal representation space in a manner that makes objectively similar stimuli (such as different views of the same 3D object) closer to each other, and dissimilar stimuli farther apart.  We present theoretical analysis and computational experiments that compare the similarity between stimuli as they are represented at the successive levels of the processing hierarchy, from the retina to the nonlinear cortical units.  Our results indicate that the representations at the higher levels of the hierarchy are indeed more useful for the classification of natural objects such as human faces.  1 Motivation Systems of receptive fields (RFs) are probably the most prominent and ubiquitous computational mechanism employed in biological information processing, and, in particular, in vision.  A natural question suggested by the hierarchy of RF types found in the visual pathway is, what is it good for? It may seem that the answer is to be found, jointly, in the many models of visual function based on population coding of various stimulus qualities, especially as some of these models draw explicit parallels between the representations they employ and the RFs found in biological vision.  However, mere invocation of the idea of population coding, if not accompanied by a computational (in the sense of Marr, 1982) statement of what it is that the visual system does with its representations, simply begs the question: At all levels of the visual system, complex objects appear to be coded by the activity of populations, or networks, of cells, and the representation of a particular object may be widely distributed throughout one or more visual areas.  That said, the goal of the anatomical pathway for object recognition becomes less obvious.  The photoreceptors are a population of cells, for example, and they are necessarily capable of coding, by their population response, any conceivable stimulus.  Why are subsequent populations needed? (Desimone and Ungerleider, 1989, p. 268).  A number of recent works that do address the computational problem of representation tend to employ information-theoretic terms such as redundancy reduction and efficient coding (Field, 1994; Daugman, 1988; Atick, 1992).  In this paper we suggest an alternative approach, based on the observation that object classification (which may be considered an ultimate goal of vision) requires faithful representation of true similarity between shapes (Edelman, 1993).  This observation leads to the hypothesis that successive stages of early visual processing remap the retinal space in a manner that makes objectively similar shapes closer to each other.  The paper is organized as follows.  In section 2, we consider a general formulation of the issue of similarity under different representations.  Section 3 contains an experimental evaluation of several similarity measures on a database of face images, and, in particular, a comparison of the similarity induced by realistic RFs with that of two control cases.  Section 4 contains a discussion of the results and lists directions for future research.  2 The effect of the choice of representation on similarity between images Recent theories of object recognition based on view interpolation (Poggio and Edelman, 1990) or on linear combination of views (Ullman and Basri, 1991) have underscored the possibility of representing 3D shapes by collections of their views, or images.  However, in models of biological vision, the notion of an image is ill-defined at any stage past the projection of the world onto the photoreceptor sheet in retina.  At all the subsequent levels, the visual system has at its disposal only the activities evoked by this input image in the units of the preceding level, and it can compare two images only by comparing these population activity vectors.  Thus, a representation scheme together with a metric in the representation space naturally induce a measure of similarity among (input) images.  For a recognition scheme such as view interpolation to succeed, this induced or proximal similarity between image representations must correspond in a principled manner to the objective or distal similarity between objects that give rise to the images.  Consequently, we propose to compare various representation schemes according to the similarity measures they induce.
