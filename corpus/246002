Robust Detection and Tracking of Human Faces with an Active Camera
 Abstract We present an efficient framework for the detection and tracking of human faces with an active camera.  The Bhattacharyya coefficient is employed as a similarity measurebetween the color distribution of the face model and face candidates.  The proper derivation of these distributions allows the use of the spatial gradient of the Bhattacharyya coefficient to guide a fast search for the best facecandidate.  The optimization, which is basedonmean shift analysis, requires only a few iterations to converge.  Scale changes of the trackedfaceare handled by exploiting the scale invariance of the similarity measure and the luminancegradient computedon the border of the hypothesized face region.  The detection and tracking modules are almost identical, the differencebeing that the detection involves mean shift optimization with multiple initializations.  Our dual-mode implementation of the cameracontroller determines the pan, tilt, and zoom camera to switch between smooth pursuit and saccadic movements, as a function of the target presence in the fovea region.  The resulting system runs in real-time on a standard PC, being robust to partial occlusion, clutter, facescale variations, rotations in depth, and fast changes in subject/cameraposition.
