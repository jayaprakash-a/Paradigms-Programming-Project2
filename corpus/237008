Shape and Motion under Varying Illumination: Unifying Structure from Motion, Photometric Stereo, and Multi-view Stereo
 Abstract This paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination.  The problem is formulated in a manner that subsumes structure from motion, multi-view stereo, and photometric stereo as special cases.  The algorithm utilizes both spatial and temporal intensity variation as cues: the former constrains flow and the latter constrains surface orientation; combining both cues enables dense reconstruction of both textured and texture-less surfaces.  The algorithm works by iteratively estimating affine camera parameters, illumination, shape, and albedo in an alternating fashion.  Results are demonstrated on videos of hand-held objects moving in front of a fixed light and camera.
