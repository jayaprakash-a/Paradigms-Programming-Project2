Solving Large Systems of Differential Equations in Parallel Using Covers and Skeletons
 Abstract The design and implementation of parallel algorithms for distributed memory architectures is much harder than the development of sequential algorithms.  This is mainly due to the communication and synchronization that is necessary to manage distributed data correctly.  This paper applies a methodology for the transformational derivation of parallel programs using data distribution algebras that enable an abstract description of data distribution issues.  Algorithms are formulated using skeletons, that is, specialized higher-order functions with particular parallel implementations.  The methodology is applied to a the solution of a system of ordinary differential equations where convolutions can be computed using the Fast Fourier transformation.  The example illustrates the practical optimization problems for a development model of the visual system that involves large scale neural network simulations.  Finally, this algorithm is compared to an implementation of the same system of equations in the programming language C* on a CM-5.
