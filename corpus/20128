Linear Programming Boosting via Column Generation
 Abstract.  We examine linear program (LP) approaches to boosting and demonstrate their ecient solution using LPBoost, a column generation based simplex method.  We formulate the problem as if all possible weak hypotheses had already been generated.  The labels produced by the weak hypotheses become the new feature space of the problem.  The boosting task becomes to construct a learning function in the label space that minimizes misclassification error and maximizes the soft margin.  We prove that for classification, minimizing the 1-norm soft margin error function directly optimizes a generalization error bound.  The equivalent linear program can be eciently solved using column generation techniques developed for large-scale optimization problems.  The resulting LPBoost algorithm can be used to solve any LP boosting formulation by iteratively optimizing the dual misclassification costs in a restricted LP and dynamically generating weak hypotheses to make new LP columns.  We provide algorithms for soft margin classification,
