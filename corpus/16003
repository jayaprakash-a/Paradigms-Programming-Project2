Learning from One Example in Machine Vision by Sharing Probability Densities
 Abstract Human beings exhibit rapid learning when presented with a small number of images of a new object.  A person can identify an object under a wide variety of visual conditions after having seen only a single example of that object.  This ability can be partly explained by the application of previously learned statistical knowledge to a new setting.  This thesis presents an approach to acquiring knowledge in one setting and using it in another.  Specifically, we develop probability densities over common image changes.  Given a single image of a new object and a model of change learned from a different object, we form a model of the new object that can be used for synthesis, classification, and other visual tasks.  We start by modeling spatial changes.  We develop a framework for learning statistical knowledge of spatial transformations in one task and using that knowledge in a new task.  By sharing a probability density over spatial transformations learned from a sample of handwritten letters, we develop a handwritten digit classifier that achieves 88. 6% accuracy using only a single hand-picked training example from each class.  The classification scheme includes a new algorithm, congealing, for the joint alignment of a set of images using an entropy minimization criterion.  We investigate properties of this algorithm and compare it to other methods of addressing spatial variability in images.  We illustrate its application to binary images, gray-scale images, and a set of 3-D neonatal magnetic resonance brain volumes.  Next, we extend the method of change modeling from spatial transformations to color transformations.  By measuring statistically common joint color changes of a scene in an office environment, and then applying standard statistical techniques such as principal components analysis, we develop a probabilistic model of color change.  We show that these color changes, which we call color flows, can be shared effectively between certain types of scenes.  That is, a probability density over color change developed by observing one scene can provide useful information about the variability of another scene.  We demonstrate a variety of applications including image synthesis, image matching, and shadow detection.
