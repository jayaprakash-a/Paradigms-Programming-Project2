VOCAL TRACT MODELLING WITH RECURRENT NEURAL NETWORKS
 ABSTRACT In this paper, the speech production system is modelled using the true glottal excitation as the source and a recurrent neural network to represent the vocal tract.  The hidden nodes have multiple delays of one and two samples, making the network equivalent to a parallel formant synthesiser in the linear regions of the hidden node sigmoids.  An ARX model identification is carried out to initialise the neural network parameters.  These parameters are re-estimated in an analysis-bysynthesis framework to minimise the synthesis (output) error.  Unlike other analysis-by-synthesis speech production models such as CELP, the source and filter in this approach are decoupled, enabling manipulation of the source time-scale to achieve high quality pitch changes.
