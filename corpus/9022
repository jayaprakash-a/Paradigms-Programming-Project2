Multi-Stream Segmentation of Meetings
 Abstract--- This paper investigates the automatic segmentation of meetings into a sequence of group actions or phases.  Our work is based on a corpus of multiparty meetings collected in a meeting room instrumented with video cameras, lapel microphones and a microphone array.  We have extracted a set of feature streams, in this case extracted from the audio data, based on speaker turns, prosody and a transcript of what was spoken.  We have related these signals to the higher level semantic categories via a multistream statistical model based on dynamic Bayesian networks (DBNs).  We report on a set of experiments in which different DBN architectures are compared, together with the different feature streams.  The resultant system has an action error rate of 9%.
