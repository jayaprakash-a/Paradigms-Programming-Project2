Optimal Reinsertion: A New Search Operator for Accelerated and More Accurate Bayesian Network Structure Learning
 Abstract We show how a conceptually simple search operator called Optimal Reinsertion can be applied to learning Bayesian Network structure from data.  On each step we pick a node called the target.  We delete all arcs entering or exiting the target.  We then find, subject to some constraints, the globally optimal combination of in-arcs and out-arcs with which to reinsert it.  The heart of the paper is a new algorithm called ORSearch which allows each optimal reinsertion step to be computed efficiently on large datasets.  Our empirical results compare Optimal Reinsertion against a highly tuned implementation of multi-restart hill climbing.  The results typically show one to two orders of magnitude speed-up on a variety of datasets.  They usually show better final results, both in terms of BDEU score and in modeling of future data drawn from the same distribution.  1.  Bayesian Network Structure Search Given a dataset of R records and m categorical attributes, how can we find a Bayesian network structure that provides a good model of the data? Happily, the formulation of this question into a well-defined optimization problem is now fairly well understood (Heckerman et al. , 1995; Cooper & Herskovits, 1992).  However, finding the optimal solution is an NP-complete problem (Chickering, 1996a).  The computational issues in performing heuristic search in this space are also severe, even taking into account the numerous ingenious and effective innovations in recent years (e. g.  (Chickering, 1996b; Friedman & Goldszmidt, 1997;
