Can PAC Learning Algorithms Tolerate Random Attribute Noise?
 Abstract This paper studies the robustness of pac learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the instances (and not the labels).  In the past, conflicting results on this subject have been obtained---the "best agreement" rule can only tolerate small amounts of noise, yet in some cases large amounts of noise can be tolerated.  We show that the truth lies somewhere between these two alternatives.  For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that pac learns monomials for any (unknown) noise rate less than 1=2.  Contrasting this positive result, we show that product random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise---no algorithm can tolerate more than a very small amount of such noise.
