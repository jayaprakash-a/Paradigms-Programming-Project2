Modeling Duration Patterns for Speaker Recognition
 Abstract We present a method for speaker recognition that uses the duration patterns of speech units to aid speaker classification.  The approach represents each word and/or phone by a feature vector comprised of either the durations of the individual phones making up the word, or the HMM states making up the phone.  We model the vectors using mixtures of Gaussians.  The speaker specific models are obtained through adaptation of a "background" model that is trained on a large pool of speakers.  Speaker models are then used to score the test data; they are normalized by subtracting the scores obtained with the background model.  We find that this approach yields significant perfomance improvement when combined with a state-of-the-art speaker recognition system based on standard cepstral features.  Furthermore, the improvement persists even after combination with lexical features.  Finally, the improvement continues to increase with longer test sample durations, beyond the test duration at which standard system accuracy level off.
