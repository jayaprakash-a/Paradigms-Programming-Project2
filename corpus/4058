A Generalized Reinforcement-Learning Model: Convergence and Applications
 Abstract Reinforcement learning is the process by which an autonomous agent uses its experience interacting with an environment to improve its behavior.  The Markov decision process (mdp) model is a popular way of formalizing the reinforcement-learning problem, but it is by no means the only way.  In this paper, we show how many of the important theoretical results concerning reinforcement learning in mdps extend to a generalized mdp model that includes mdps, two-player games and mdps under a worst-case optimality criterion as special cases.  The basis of this extension is a stochastic-approximation theorem that reduces asynchronous convergence to synchronous convergence.
