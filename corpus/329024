Improving Augmented Reality using Image and Scene Constraints
 Abstract The goal of augmented reality is to insert virtual objects into real video sequences.  This paper shows that by incorporating image-based geometric constraints over multiple views, we improve on traditional techniques which use purely 3D information.  The constraints imposed are chosen to directly target perceptual cues, important to the human visual system, by which errors in AR are most readily perceived.  Imposition of the constraints is achieved by constrained maximum-likelihood estimation, and blends projective, affine and Euclidean geometry as appropriate in different cases.  We introduce a number of examples of augmented reality tasks, show how image-based constraints can be incorporated into current 3D-based systems, and demonstrate the improvements conferred.
