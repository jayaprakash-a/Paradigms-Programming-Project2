Quantitative Modeling of Perceptual Salience at Human Eye
 Abstract: We investigate the extent to which a simple model of bottom-up attention and salience may be embedded within a broader computational framework, and compared with human eye movement data.  We focus on quantifying whether increased simulation realism significantly affects quantitative measures of how well the model may predict where in video clips humans direct their gaze.  We hence compare three variants of the model, tested with 15 video clips of natural scenes shown to three observers.  We measure modelpredicted salience at the locations gazed to by the observers, compared to random locations.  The first variant simply processes the raw video clips.  The second adds a gaze-contingent foveation filter.  The third further attempts to realistically simulate dynamic human vision by embedding the video frames within a larger background, and shifting them to eye position.  Our main finding is that increasing simulation realism significantly improves the predictive ability of the model.  Better emulating the details of how a visual stimulus is captured by a constantly rotating retina during active vision has a significant positive impact onto quantitative comparisons between model and human behavior.
