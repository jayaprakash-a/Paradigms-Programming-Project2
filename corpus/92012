and an Application to Pricing High--Dimensional Financial Derivatives
 ABSTRACT We develop a theory characterizing optimal stopping times for discrete-time ergodic Markov processes with discounted rewards.  The theory differs from prior work by its view of per-stage and terminal reward functions as elements of a certain Hilbert space.  In addition to a streamlined analysis establishing existence and uniqueness of a solution to Bellman's equation, this approach provides an elegant framework for the study of approximate solutions.  In particular, we propose a stochastic approximation algorithm that tunes weights of a linear combination of basis functions in order to approximate a value function.  We prove that this algorithm converges (almost surely) and that the limit of convergence has some desirable properties.  We discuss how variations on this line of analysis can be used to develop similar results for other classes of optimal stopping problems, including those involving independent increment processes, finite horizons, and two--player zero--sum games.  We illustrate the approximation method with a computational case study involving the pricing of a path--dependent financial derivative security that gives rise to an optimal stopping problem with a one--hundred--dimensional state space.
