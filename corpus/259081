Particle Filters for Rover Fault Diagnosis
 1 Introduction This article presents a number of complementary algorithms for detecting faults on-board operating robots, where we define a fault as a deviation from expected behavior.  Experience has shown that even carefully designed and tested robots may encounter faults [3].  One of the reasons for this is that components degrade over time another is that the operators of the robot rarely have complete knowledge of the environment in which it operates and hence may not have accounted for certain situations.  In a number of application domains, such as planetary exploration, search and rescue, mine mapping, nuclear waste cleanup, and demining, robots operate in environments where human intervention is expensive, slow, unreliable, or impossible.  It is therefore essential for the robots to monitor their behavior so that faults may be addressed before they result in catastrophic failures.  This monitoring needs to be efficient since there is limited computational power available on robots.  Not only are robots venturing into areas inaccessible or dangerous for humans, but they are also increasingly becoming a part of day to day life.  It is also important for these robots to detect faults in a timely manner, since failure to do so may result in expensive consequences, both monetary and in terms of consumer trust that may be hard to regain.  If faults go undetected, autonomous robots in real-world environments may behave in an unpredictable or dangerous manner.  On the other hand, detecting and recovering from faults can considerably improve the performance of the robots [2] [81].  Fault Detection and Identification (FDI) for robots is a complex problem.  This is because the space of possible faults is very large, robot sensors, actuators, and environment models are uncertain, and there is limited computation time and power.  Probability theory provides a natural representation of the uncertainty in the rover domain, but an exact Bayesian solution to FDI is intractable.  Traditional methods address this intractability by approximating the problem using linear approximations of rover dynamics and/or by ignoring uncertainty.  Often these approximations are unrealistic, and either faults go undetected, or an unreasonable number of false positives are triggered.  We instead prefer to approximate the solution using Monte Carlo methods.  The rationale behind this is that the two stages of this problem, building models and online monitoring, have very different computational constraints.  Theoretically there is little restriction on the time and computation available for building models, since this may be done offline, but monitoring these models must be done in real time with the limited computation available on a robot.  We consider approximate inference using complex models a better trade-off than exact inference with simple models.  Classical Monte Carlo methods for dynamic systems, such as particle filters, are capable of tracking complex nonlinear systems with noisy measurements.  The problem is that estimates from a particle filter tend to have a high variance for small sample sets.  Using large sample sets is computationally expensive and defeats the purpose.  In this article, we present a number of complementary algorithms for improving the accuracy of FDI with a computationally tractable set of samples in a particle filter.  Experimental results in the rover domain show significant improvement in accuracy over the classical approach.  The algorithms described in this article enable detection of a wider range and larger number of faults during robot operation than has hitherto been possible.  Furthermore, these algorithms provide the probability of the robot being in each of the fault and operational states given the sensor data.  They can handle noisy sensors, non-linear, non-Gaussian models of behavior, and are computationally efficient.  Estimating faults in terms of a probability distribution over all fault states captures the uncertainty in fault identification that results from noisy and insufficient data.  In addition, it allows a lot of flexibility in the types of planners/controllers that may be used for controlling the robot and for recovering from faults.  For example, such distributions are compatible with classical conditional planners or Markov Decision Processes (MDPs), which may use the most likely state to determine which action to take, and also Partially Observable Markov Decision Processes (POMDPs) [67], which use the distribution over the entire state space.  2 Particle Filters for Monitoring Faults Our formulation of the fault detection problem requires estimating robot and environmental state, as it changes over time, from a sequence of sensor measurements that provide noisy, partial information about the state.  The Bayesian approach to dynamic state estimation addresses this problem.  Particle filters have been extensively used for Bayesian state estimation in nonlinear systems with noisy measurements [35][22][15].  They approximate the probability distribution with a set of samples or particles.  The algorithms presented in this article all use particle filters.  Particle filters have a number of characteristics that make them attractive for fault detection on robots: they are non-parametric (can represent arbitrary distributions), can handle hybrid state spaces, can handle noisy sensing and motion, and can easily be extended to an anytime approach where the number of particles (and hence the estimation accuracy) can be adjusted to match available computation.  2. 1 Fault Detection and Identification (FDI) for Robots A fault is defined as a deviation from the expected behavior of the system.  Fault detection is defined as the process of determining that a fault has occurred.  Fault identification is the process of determining exactly which exception or fault occurred [36].  Fault detection and identification are typically passive, i. e.  they do not alter control actions.  This paper concentrates on a class of faults that are relatively difficult to detect because they cannot be inferred from sensor values at a given instance, but require a sequence of time-varying sensor values.  In addition, the expected behavior of the robot may be different in different operating conditions.  For example, high power draw on flat ground may be cause for concern, but high power draw on a slope might be perfectly acceptable.  The faults addressed here include mechanical component failures, such as broken motors and gears; faults due to environmental interactions, such as a wheel stuck against a rock; and sensor failures, such as broken encoders.  2. 2 FDI as recursive state estimation State estimation is the process of determining the state of a system from a sequence of data.  FDI has a natural representation as a state estimation problem.  We represent the possible fault and operational modes of the systems as explicit states.  The sequence of measurements is then used to determine the state of the system.  There are two main classes of state estimation methods: batch estimation methods and recursive estimation methods.  Batch methods treat all the data with equal importance and find an optimal estimate of the state given the entire sequence.  However, full batch estimation is computationally expensive and gets slower as the robot accumulates increasing volumes of data.  It is therefore not suitable for FDI.  Recursive state estimation methods make a Markov assumption, i. e. , the past and future are conditionally independent given the current state.  These methods incorporate the data as it becomes available and replace the data with a statistic.  Estimates at subsequent timesteps use this statistic instead of the history of data for state estimation.  2. 3 Classical particle filter For FDI we concentrate on a discrete time, first order Markov formulation of the state estimation problem.  The state being estimated is hybrid, i. e.  it consists of both discrete and continuous components.  Let } d d { D K 1 # = represent K hidden discrete fault and operational states of the robot, D d t the discrete state of the robot at time t and } d , , d { d t 1 t # the discrete, first order Markov chain representing the evolution of the state over time.  In addition to the discrete states there are also continuous states that track the dynamic behavior of the robot.  Let x n t x denote the multivariate continuous state at time t.  The state of the robot is observed through a sequence of measurements, z n t t t z z z z = }, { 1 # .  Probabilistic models of the change in state over time (state transition model) and the relationship between the measurements and the state (measurement model) capture the inherent noise.  State transitions depend on prior state, observation, and (in some cases) the control action.  These models are assumed to be stationary, i. e. , the models do not change with time.  Bayesian filtering, represented by [Equation 1], provides a recursive estimate of the posterior (newly updated) probability distribution over the states.  Here, control is omitted in equations for brevity.  We consider the following factored representation, where the discrete state transition is conditionally independent of the continuous state transitions given the previous discrete state 1 : 1 t 1 t t t d 1 t t t t t t t 1 t t dx )
