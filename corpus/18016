A Generalized Kernel Approach to Dissimilarity-based
 Abstract Usually, objects to be classified are represented by features.  In this paper, we discuss an alternative object representation based on dissimilarity values.  If such distances separate the classes well, the nearest neighbor method oers a good solution.  However, dissimilarities used in practice are usually far from ideal and the performance of the nearest neighbor rule suers from its sensitivity to noisy examples.  We show that other, more global classification techniques are preferable to the nearest neighbor rule, in such cases.  For classification purposes, two dierent ways of using generalized dissimilarity kernels are considered.  In the first one, distances are isometrically embedded in a pseudo-Euclidean space and the classification task is performed there.  In the second approach, classifiers are built directly on distance kernels.  Both approaches are described theoretically and then compared using experiments with dierent dissimilarity measures and datasets including degraded data simulating the problem of missing values.
