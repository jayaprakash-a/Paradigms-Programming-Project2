Estimating Dependency Structure as a Hidden Variable
 Abstract This paper introduces a probability model, the mixture of trees that can account for sparse, dynamically changing dependence relationships.  We present a family of efficient algorithms based on the EM and the Minimum Spanning Tree algorithms that learn mixtures of trees in the ML framework.  The method can be extended to take into account priors and, for a wide class of priors that includes the Dirichlet and the MDL priors, it preserves its computational efficiency.  Experimental results demonstrate the excellent performance of the new model both in density estimation and in classification.  Finally, we show that a single tree classifier acts like an implicit feature selector, thus making the classification performance insensitive to irrelevant attributes.
