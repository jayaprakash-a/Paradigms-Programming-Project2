Learning an Optimally Accurate Representational System
 Abstract The multiple extension problem arises because a default theory can use different subsets of its defaults to propose different, mutually incompatible, answers to some queries.  This paper presents an algorithm that uses a set of observations to learn a credulous version of this default theory that is (essentially) "optimally accurate".  In more detail, we can associate a given default theory with a set of related credulous theories R = fR i g, where each R i uses its own total ordering of the defaults to determine which single answer to return for each query.  Our goal is to select the credulous theory that has the highest ``expected accuracy", where each R i 's expected accuracy is the probability that the answer it produces to a query will correspond correctly to the world.  Unfortunately, a theory's expected accuracy depends on the distribution of queries, which is usually not known.  Moreover, the task of identifying the optimal R opt 2 R, even given that distribution information, is intractable.  This paper presents a method, OptAcc, that sidesteps these problems by using a set of samples to estimate the unknown distribution, and by hill-climbing to a local optimum.  In particular, given any parameters ffl; ffi ? 0, OptAcc produces an R oa 2 R whose expected accuracy is, with probability at least 1 \Gamma ffi , within ffl of a local optimum.
