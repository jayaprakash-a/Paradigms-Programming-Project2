Q2: Memory-Based Active Learning for Optimizing Noisy Continuous Functions
 Abstract This paper introduces a new algorithm, Q2, for optimizing the expected output of a multiinput noisy continuous function.  Q2 is designed to need only a few experiments, it avoids strong assumptions on the form of the function, and it is autonomous in that it requires little problem-specific tweaking.  These capabilities are directly applicable to industrial processes, and may become increasingly valuable elsewhere as the machine learning field expands beyond prediction and function identification, and into embedded active learning subsystems in robots, vehicles and consumer products.  Four existing approaches to this problem (response surface methods, numerical optimization, supervised learning, and evolutionary methods) all have inadequacies when the requirement of "black box" behavior is combined with the need for few experiments.  Q2 uses instance-based determination of a convex region of interest for performing experiments.  In conventional instance-based approaches to learning, a neighborhood was defined by proximity to a query point.  In contrast, Q2 defines the neighborhood by a new geometric procedure that captures the size and shape of the zone of possible optimum locations.  Q2 also optimizes weighted combinations of outputs, and finds inputs to produce target outputs.  We compare Q2 with other optimizers of noisy functions on several problems, including a simulated noisy process with both non-linear continuous dynamics and discreteevent queueing components.  Results are encouraging in terms of both speed and autonomy.  1 ACTIVE LEARNING FOR OPTIMIZATION The apparently humble task of parameter tweaking for noisy systems is of great importance whether the parameters being tweaked are for an algorithm, a real manufacturing process, a simulation, or a scientific experiment.  The purpose of this paper is two-fold.  First, we wish to highlight the potential importance of machine learning as an as-yet underexploited tool in this domain.  Second, we will introduce Q2, a new algorithm designed for this domain.  We consider a generalized noisy optimization task in which a vector x of real-valued inputs produces a scalar output y that is a noisy function of x: y = g(x) + noise (1) Given a constrained space of legal inputs, the task is to find the input vector x opt that maximizes g, using only a small number of experiments.  In both industrial settings and in algorithm-tuning, this task often demands considerable human intervention and insight.  A factory manager who wants to optimize a process can: ffl Buy a computer, statistics software, and hire a professional statistician to solve the problem using insight and experiment design.  ffl Save money and try to "wing it" by manually tuning the parameters.  For highly expensive or safety-critical processes, the first option is always preferable, leaving only the question of which are the best analysis and experiment design tools for the statistician to use.  This area is heavily investigated by the academic statistics community.  But there are also many situations in which it is impractical to enlist human-aided analysis during optimization, for example if a vehicle engine self-tunes during driving.  And there are many other situations in which the potential benefit from optimization is too small to justify paying for expert professional analysis.  In such cases, it is tempting to ask: Can "black box" automated methods optimize noisy systems? If practical black box methods are found, they could be widely used.  Somewhat fancifully, this could lead to the eventual inclusion of Black Box Optimizer chips within a huge range of consumer products, from vehicle engines and industrial equipment down to refrigerators, toasters, and toys.  In the next section we discuss variants of the Black Box Noisy Optimization task.  Then in Section 3 we discuss existing approaches.  After that we present and evaluate Q2, a new algorithm.  2 VARIANTS OF NOISY OPTIMIZATION The generalized noisy optimization task summarized by Equation 1 has many variants.  For instance, in some domains each experiment is a lengthy procedure, and so there is ample computation time between experiments.  In other domains, experiments are very quick, leaving an optimizer little time to make its recommendations.  The specifics of the domain determine which methods are appropriate.  The following factors need to be considered: ffl Minimize regret or the number of experiments? Do we pay a constant cost per experiment, or do experiments with poor results cost us more? In scenarios such as tuning the parameters for an algorithm, or optimizing a test plant in which all products will be discarded, the cost per experiment may be constant.  But in a task such as minimizing the fuel consumption of a running engine, some experiments cost more than others.  Here, we focus on simply minimizing the number of experiments.  Note that this presumes that we are not risk-averse: there is no penalty for performing highly unpredictable experiments.  ffl How much computer time is available to choose experiments? If experiments are very cheap and very quick, then an algorithm that needs extensive CPU time to select the ideal next experiment could still be inferior to one that requires only a fraction of a second to suggest a reasonable-but-less-than-ideal experiment.  Here, we assume that experiments are costly enough (in time or money) that it pays to choose them carefully.  But the Q2 algorithm can be adjusted to satisfy any desired tradeoff between the speed and the quality of proposed experiments.  ffl Are we doing local or global optimization? Unless we have strong prior knowledge, global optimization of a function of more than a couple of inputs requires a very large number of experiments.  Q2 is only designed to find a local optimum, though empirically it appears to be good at discovering the global optimum.  ffl Can we re-use old data? Many algorithms have a "current location" or "current set of k recent evaluations" but otherwise disregard earlier evaluations.  Q2, however, can exploit any existing data, including previous evaluations obtained by other experimental methods.  In this paper we also assume that there are no long term dynamics, i. e.  the output of the n'th experiment depends only on the n'th chosen x, not on previous x values or the time.  Unlike [2, 6] we only try to find the optimum, not to model the g function.  3 POSSIBLE APPROACHES Many disciplines have methods that are relevant to noisy optimization.  Space permits only a brief survey.  Numerical analysis: Numerical methods such as Newton-Raphson or Levenberg-Marquardt [11] have fast convergence properties, but they must be applied carefully to prevent oscillations or divergence to infinity, which violates our desire for black box autonomy.  Furthermore, current numerical methods cannot survive noise.  Stochastic approximation: The algorithm of [12] finds roots without the use of derivative estimates.  Keifer-Wolfowitz (KW) [5] is a related algorithm for noisy optimization.  It estimates the gradient by performing experiments in both directions along each dimension of the input space.  Based on the estimate, it moves its experiment center and repeats.  It uses decreasing step sizes to ensure convergence.  KW's strengths are its aggressive exploration, its simplicity, and that it comes with convergence guarantees.  However, it can attempt wild experiments if there is noise, and discards the data it collects after each gradient estimate is made.  Amoeba (see below) is a similar approach, but in our experience is superior to KW.  Amoeba search: Amoeba [11] searches k-d space using a simplex (i. e.  a k-dimensional tetrahedron).  The function is evaluated at each vertex.  The worstperforming vertex is reflected through the hyperplane defined by the remaining vertices to produce a new simplex that has moved up the estimated gradient.  Ingenious simplex transformations let the simplex shrink near the optimum, grow in large linear zones, and ooze along ridges.
