Active Face Tracking and Pose Estimation in an Interactive Room
 Abstract We demonstrate real-time face tracking and pose estimation in an unconstrained office environment with an active foveated camera.  Using vision routines previously implemented for an interactive environment, we determine the spatial location of a user's head and guide an active camera to obtain foveated images of the face.  Faces are analyzed using a set of eigenspaces indexed over both pose and world location.  Closed loop feedback from the estimated facial location is used to guide the camera when a face is present in the foveated view.  Our system can detect the head pose of an unconstrained user in real-time as he or she moves about an open room.
