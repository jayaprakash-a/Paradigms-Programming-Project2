Probabilistic Parsing Using Left Corner Language Models
 Abstract We introduce a novel parser based on a probabilistic version of a left-corner parser.  The left-corner strategy is attractive because rule probabilities can be conditioned on both top-down goals and bottom-up derivations.  We develop the underlying theory and explain how a grammar can be induced from analyzed data.  We show that the left-corner approach provides an advantage over simple top-down probabilistic context-free grammars in parsing the Wall Street Journal using a grammar induced from the Penn Treebank.  We also conclude that the Penn Treebank provides a fairly weak testbed due to the flatness of its bracketings and to the obvious overgeneration and undergeneration of its induced grammar.
