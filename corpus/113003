Case-Based Explanation of Non--Case-Based Learning Methods
 We show how to generate case-based explanations for non--case-based learning methods such as artificial neural nets or decision trees.  The method uses the trained model (e. g. , the neural net or the decision tree) as a distance metric to determine which cases in the training set are most similar to the case that needs to be explained.  This approach is well suited to medical domains, where it is important to understand predictions made by complex machine learning models, and where training and clinical practice makes users adept at case interpretation.
