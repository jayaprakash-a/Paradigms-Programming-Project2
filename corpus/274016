Monte Carlo inference via greedy importance sampling
 Abstract We present a new method for conducting Monte Carlo inference in graphical models which combines explicit search with generalized importance sampling.  The idea is to reduce the variance of importance sampling by searching for significant points in the target distribution.  We prove that it is possible to introduce search and still maintain unbiasedness.  We then demonstrate our procedure on a few simple inference tasks and show that it can improve the inference quality of standard MCMC methods, including Gibbs sampling, Metropolis sampling, and Hybrid Monte Carlo.  This paper extends previous work which showed how greedy importance sampling could be correctly realized in the one-dimensional case.
