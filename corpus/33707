Classification on Pairwise Proximity Data
 Abstract We investigate the problem of learning a classification task on data represented in terms of their pairwise proximities.  This representation does not refer to an explicit feature representation of the data items and is thus more general than the standard approach of using Euclidean feature vectors, from which pairwise proximities can always be calculated.  Our first approach is based on a combined linear embedding and classification procedure resulting in an extension of the Optimal Hyperplane algorithm to pseudo-Euclidean data.  As an alternative we present another approach based on a linear threshold model in the proximity values themselves, which is optimized using Structural Risk Minimization.  We show that prior knowledge about the problem can be incorporated by the choice of distance measures and examine different metrics w. r. t.  their generalization.  Finally, the algorithms are successfully applied to protein structure data and to data from the cat's cerebral cortex.  They show better performance than K-nearest-neighbor classification.
