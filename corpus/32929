Video Data Mining Using Configurations of Viewpoint Invariant Regions
 Abstract We describe a method for obtaining the principal objects, characters and scenes in a video by measuring the reoccurrence of spatial configurations of viewpoint invariant features.  We investigate two aspects of the problem: the scale of the configurations, and the similarity requirements for clustering configurations.  The problem is challenging firstly because an object can undergo substantial changes in imaged appearance throughout a video (due to viewpoint and illumination change, and partial occlusion), and secondly because configurations are detected imperfectly, so that inexact patterns must be matched.  The novelty of the method is that viewpoint invariant features are used to form the configurations, and that efficient methods from the text analysis literature are employed to reduce the matching complexity.  Examples of `mined' objects are shown for a feature length film and a sitcom.
