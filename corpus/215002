MULTIBAND AUDIO MODELING FOR SINGLE-CHANNEL ACOUSTIC SOURCE SEPARATION
 ABSTRACT Detailed hidden Markov models (HMMs) that capture the constraints implicit in a particular sound can be used to estimate obscured or corrupted portions from partial observations, the situation encountered when trying to identify multiple, overlapping sounds.  However when the complexity and variability of the sounds are high, as in a particular speaker's voice, a detailed model might require several thousand states to cover the full range of different short-term spectra with adequate resolution.  To address the tractability problems of such large models, we break the source signals into multiple frequency bands, and build separate but coupled HMMs for each band, requiring many fewer states per model.  Modeling each frequency band independently, as in multiband speech models proposed by the ASR community, will result in many non-natural full spectral states.  To prevent this and to enforce consistency within and between bands, at any given frame the state in a particular band is determined by the previous state in that band and the states in the adjacent bands.  Coupling the bands in this manner results in a grid like model for the full spectrum.  Since exact inference of such a model is intractable, we derive an efficient approximation based on variational methods.  Results in source separation of combined signals modeled with this approach outperform the separation obtained by full-band models.
