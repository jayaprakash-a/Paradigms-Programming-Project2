Adaptive and Self-Confident On-Line Learning Algorithms
 Abstract Most of the performance bounds for on-line learning algorithms are proven assuming a constant learning rate.  To optimize these bounds, the learning rate must be tuned based on quantities that are generally unknown, as they depend on the whole sequence of examples.  In this paper we show that essentially the same optimized bounds can be obtained when the algorithms adaptively tune their learning rates as the examples in the sequence are progressively revealed.  Our adaptive learning rates apply to a wide class of on-line algorithms, including p-norm algorithms for generalized linear regression and Weighted Majority for linear regression with absolute loss.  We emphasize that our adaptive tunings are radically different from previous techniques, such as the so-called doubling trick.  Whereas the doubling trick restarts the on-line algorithm several times using a constant learning rate for each run, our methods save information by changing the value of the learning rate very smoothly.  In fact, for Weighted Majority over a finite set of experts our analysis provides a better leading constant than the doubling trick.
