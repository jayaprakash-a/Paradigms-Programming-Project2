Learning Low-Level Vision
 Abstract We show a learning-based method for low-level vision problems{estimating scenes from images.  We generate a synthetic world of scenes and their corresponding rendered images.  We model that world with a Markov network, learning the network parameters from the examples.  Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given the image.  We call this approach VISTA{Vision by Image/Scene TrAining.  We apply VISTA to the \super-resolution" problem (estimating high frequency details from a low-resolution image), showing good results.  For the motion estimation problem, we show #gure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery.
