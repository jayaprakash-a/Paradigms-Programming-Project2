Matrix Multiplication: A Case Study of Algorithm Engineering
 ABSTRACT Modern machines present two challenges to algorithm engineers and compiler writers: They have superscalar, super-pipelined structure, and they have elaborate memory subsystems specifically designed to reduce latency and increase bandwidth.  Matrix multiplication is a classical benchmark for experimenting with techniques used to exploit machine architecture and to overcome the limitations of contemporary memory subsystems.  This research aims at advancing the state of the art of algorithm engineering by balancing instruction level parallelism, two levels of data tiling, copying to provably avoid any cache conflicts, and prefetching in parallel to algorithmic operations, in order to fully exploit the memory bandwidth.  Measurements show that the resultant matrix multiplication algorithm outperforms IBM's ESSL by 6. 8-31. 8%, is less sensitive to the size of the input data, and scales better.  The techniques presented in this paper have been developed specifically for matrix multiplication.  However, they are quite general and may be applied to other numeric algorithms.  We believe that some of our concepts may be generalized to be used as compile-time techniques.
