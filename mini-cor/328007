Adequate input for learning in attractor neural networks
 Abstract In the context of learning in attractor neural networks (ANN) we discuss the issue of the constraints imposed by the requirement that the afferents arriving at the neurons in the attractor network from the stimulus, compete successfully with the afferents generated by the recurrent activity inside the network, in a situation in which the both sets of synaptic efficacies are weak and approximately equal.  We simulate and analyze a two component network: one representing the stimulus, the other an ANN.  We show that if stimuli are correlated with the receptive fields of neurons in the ANN, and are of sufficient contrast, the stimulus can provide the necessary information to the recurrent network to allow learning new stimuli, even in very disfavored situation of synaptic predominance in the recurrent part.  Stimuli which are insufficiently correlated with the receptive fields, or are of insufficient contrast, are submerged by the recurrent activity.
