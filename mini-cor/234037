Latent Dirichlet Allocation
 Abstract We propose a generative model for text and other collections of discrete data, that generalizes or improves on several previous models, including naive Bayes/unigram, mixtures of naive Bayes [6], and Hofmann's pLSI/aspect model [3].  In the context of text modeling, our model posits that each document is generated as a mixture of topics, where the continuous-valued mixture proportions are distributed as a latent Dirichlet random variable.  Inference and learning are carried out eciently via variational algorithms.  We present empirical results on applications of this model to problems in text modeling, collaborative filtering, and text classification.
