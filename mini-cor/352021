Seeing Blobs as Faces or Letters: Modeling Effects on Discrimination
 Abstract What is the difference between processing faces and other objects such as letters? What makes humans face experts, and what makes this expertise different from other identification skills? It is well known that people are very sensitive to the configural information in faces.  How does the sensitivity to face configuration compare to sensitivity to configurations of other stimuli? To investigate these issues, Nishimura et al.  (2004) designed a test to contrast two types of processing using the same stimuli.  They primed subjects to see four blobs as either a "Y" or as a face.  Then they asked the subjects to discriminate pairs of these stimuli that differed only in small shifts in the blob locations.  Although the stimuli were exactly the same, subjects were more accurate in the face condition than the "Y" condition.  With Nishimura et al. , we assumed that the subjects were relying on their letter recognition networks in the "Y" condition and their face recognition networks in the face condition to perform the task.  We therefore trained two networks, a face recognition network and a letter recognition network that were otherwise identical in structure, and show here that the internal representations in the letter network for the blobs were less differentiated than the internal representations for the blobs in the face network.  We argue that this is a natural consequence of the requirements of the two tasks.
