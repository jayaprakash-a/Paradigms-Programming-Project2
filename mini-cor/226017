Automatic Labeling of Semantic Roles
 We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame.  Given an input sentence and a target word and frame, the system labels constituents with either abstract semantic roles such as AGENT or PATIENT, or more domain-specific semantic roles such as SPEAKER, MESSAGE, and TOPIC.  The system is based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project.  We then parsed each training sentence into a syntactic tree and extracted various lexical and syntactic features, including the phrase type of each constituent, its grammatical function, and position in the sentence.  These features were combined with knowledge of the predicate verb, noun, or adjective, as well as information such as the prior probabilities of various combinations of semantic roles.  We used various lexical clustering algorithms to generalize across possible fillers of roles.  Test sentences were parsed, were annotated with these features, and were then passed through the classifiers.  Our system achieves 82% accuracy in identifying the semantic role of pre-segmented constituents.  At the more difficult task of simultaneously segmenting constituents and identifying their semantic role, the system achieved 65% precision and 61% recall.  Our study also allowed us to compare the usefulness of different features and featurecombination methods in the semantic role labeling task.  We also explore the integration of role labeling with statistical syntactic parsing, and attempt to generalize to predicates unseen in the training data.  1.  Introduction Recent years have been exhilarating ones for natural language understanding.  The excitement and rapid advances that had characterized other language processing tasks such as speech recognition, part-of-speech tagging, and parsing have finally begun to appear in tasks in which understanding and semantics play a greater role.  For example, there has been widespread commercial deployment of simple speech-based natural language understanding systems that answer questions about flight arrival times, give directions, report on bank balances, or perform simple financial transactions.  More sophisticated research systems generate concise summaries of news articles, answer factbased questions, and recognize complex semantic and dialogue structure.  But the challenges that lie ahead are still similar to the challenge that the field has faced since Winograd (1972):
