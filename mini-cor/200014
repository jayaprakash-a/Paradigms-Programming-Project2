Efficient Learning of Linear Perceptrons
 Abstract We introduce an efficient agnostic learning algorithm for the class of half-spaces in ! n .  We make no assumptions whatsoever on the example-generating distribution.  Our performance guarantee is that, given any j ? 0, our algorithm runs in time polynomial in the sample size and dimension, and outputs a hypothesis half-space that classifies correctly at least the number of points classified correctly with margin j by any other half-space.  While our algorithm's running time is not polynomial in 1=j, we prove that unless P=NP no such `fully polynomial' approximation scheme exists.
