Dependencies vs
 Constituents for Tree-Based Alignment.  Abstract Given a parallel parsed corpus, statistical treeto-tree alignment attempts to match nodes in the syntactic trees for a given sentence in two languages.  We train a probabilistic tree transduction model on a large automatically parsed Chinese-English corpus, and evaluate results against human-annotated word level alignments.  We find that a constituent-based model performs better than a similar probability model trained on the same trees converted to a dependency representation.
