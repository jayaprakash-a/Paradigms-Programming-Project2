Inferring 3D Structure with a Statistical Image-Based Shape Model
 Abstract We present an image-based approach to infer 3D structure parameters using a probabilistic "shape+structure" model.  The 3D shape of an object class is represented by sets of contours from silhouette views simultaneously observed from multiple calibrated cameras, while structural features of interest on the object are denoted by a number of 3D locations.  A prior density over the multi-view shape and corresponding structure is constructed with a mixture of probabilistic principal components analyzers.  Given a novel set of contours, we infer the unknown structure parameters from the new shape's Bayesian reconstruction.  Model matching and parameter inference are done entirely in the image domain and require no explicit 3D construction.  Our shape model enables accurate estimation of structure despite segmentation errors or missing views in the input silhouettes, and it works even with only a single input view.  Using a training set of thousands of pedestrian images generated from a synthetic model, we can accurately infer the 3D locations of 19 joints on the body based on observed silhouette contours from real images.
