On-line Learning of Rectangles in Noisy Environments
 Abstract We investigate the implications of noise in the equivalence query model.  Besides some results for general target and hypotheses classes, we prove bounds on the learning complexity of d-dimensional rectangles (of size at most n d ) in the case where only rectangles are allowed as hypotheses.  Our noise model assumes that a certain fraction of the examples is noisy.  We show that d-dimensional rectangles are learnable if and only if the fraction of noisy examples is less than 1=(d+ 1), where learnable means that the learner can learn the target by a finite number of examples.  Besides this structural result we present an algorithm which learns rectangles in poly( d log n 1\Gamma r(2d+1) ) time using O( d 3 log n (1\Gamma r(2d+1)) 2 ) examples if the fraction of noise r is less than 1 2d+1 .  As a related result we prove for the noise-free case that the number of examples necessary to learn is at least \Omega( d 2 log d log n), where the best known upper bound on the learning complexity is O(d 2 log n).
