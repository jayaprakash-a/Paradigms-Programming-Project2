Sparseness of Support Vector Machines
 Abstract Support vector machines (SVM's) construct decision functions that are linear combinations of kernel evaluations on the training set.  The samples with non-vanishing coecients are called support vectors.  In this work we establish lower (asymptotical) bounds on the number of support vectors.  On our way we prove several results which are of great importance for the understanding of SVM's.  In particular, we describe to which \limit" SVM decision functions tend, discuss the corresponding notion of convergence and provide some results on the stability of SVM's using subdifferential calculus in the associated reproducing kernel Hilbert space.
