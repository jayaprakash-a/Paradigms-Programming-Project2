Face Detection Using Multimodal Density Models
 We present two methods using multimodal density models for face detection in gray-level images.  One generative method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction.  The parameters of the mixture model are estimated using the EM algorithm.  A face is detected if the probability of an input sample is above a predefined threshold.  The other discriminative method uses Kohonen's self-organizing map for clustering, Fisher's linear discriminant to find an optimal projection for pattern classification, and a Gaussian distribution to model the class-conditional density function of the projected samples for each class.  The parameters of the class-conditional density functions are maximum likelihood estimates, and the decision rule is also based on maximum likelihood.  A wide range of face images including ones in different poses, with different expressions and under different lighting conditions, is used as the training set to capture variations of the human face.  Our methods have been tested on three data sets with a total of 225 images containing 871 faces.  Experimental results on the first two data sets show that our generative and discriminative methods perform as well as the best methods in the literature, yet have fewer false detections.  Meanwhile, both methods are able to detect faces of nonfrontal views and under more extreme lighting in the third data set.  c # 2001 Elsevier Science (USA)
