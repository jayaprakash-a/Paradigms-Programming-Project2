Learning in Linear Neural Networks: a Survey
 Abstract--- Networks of linear units are the simplest kind of networks, where the basic questions related to learning, generalization, and self-organisation can sometimes be answered analytically.  We survey most of the known results on linear networks, including: (1) back-propagation learning and the structure of the error function landscape; (2) the temporal evolution of generalization; (3) unsupervised learning algorithms and their properties.  The connections to classical statistical ideas, such as principal component analysis (PCA), are emphasized as well as several simple but challenging open questions.  A few new results are also spread across the paper, including an analysis of the effect of noise on back-propagation networks and a unified view of all unsupervised algorithms.
