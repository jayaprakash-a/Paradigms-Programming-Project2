MULTI-STREAM LANGUAGE IDENTIFICATION USING DATA-DRIVEN DEPENDENCY SELECTION
 ABSTRACT The most widespread approach to automatic language identification in the past has been the statistical modeling of phone sequences extracted from speech signals.  Recently, we have developed an alternative approach to LID based on n-gram modeling of parallel streams of articulatory features, which was shown to have advantages over phone-based systems on short test signals whereas the latter achieved a higher accuracy on longer signals.  Additionally, phone and feature streams can be combined to achieve maximum performance.  Within this "multi-stream" framework two types of statistical dependencies need to be modeled: (a) dependencies between symbols in individual streams and (b) dependencies between symbols in different streams.  The space of possible dependencies is typically too large to be searched exhaustively.  In this paper, we explore the use of genetic algorithms as a method for data-driven dependency selection.  The result is a general framework for the discovery and modeling of dependencies between multiple information sources expressed as sequences of symbols, which has implications for other fields beyond language identification, such as speaker identification or language modeling.
