SPEECH RECOGNITION VIA PHONETICALLY-FEATURED SYLLABLES
 Abstract We describe recent work on two new automatic speech recognition systems.  The first part of this paper describes the components of a system based on phonological features (which we call Espresso-P) in which the values of these features are estimated from the speech signal before being used as the basis for recognition.  In the second part of the paper, another system (which we call Espresso-A) is described in which articulatory parameters are used instead of phonological features and a linear dynamical system model is used to perform recognition from automatically estimated values of these articulatory parameters.  1.  Phonological feature-based system: Espresso-P The first 5 sections of this paper report work on the components of a two stage recognition architecture based on phonological features rather than phones.  While phonological features have been proposed before as the basis of a speech recognition system (see section 1. 2 for a review), the use of features has been out of favour until recently because there had been little success in extracting them from speech waveforms, and a lack of suitable models with which to perform actual recognition.  This paper reports a set of experiments which show that phonological features can be accurately and robustly extracted from speech; furthermore, we have shown that this is possible for speaker independent continuous speech.  1. 1.  The theoretical basis of phonological features Most speech recognisers today are based on phones (or phonemes) which, in our opinion, are often given undue legitimacy in the speech community, particularly with respect to the assumption that a sequence of acoustic observations can be synchronised with a sequence of phones.  Often phones are seen as being the "atoms" of speech in that they are the set of units from which all else (that is, word sequences) can be built.  But just as with atoms in physics, it is now widely accepted in phonology that phones are decomposable into smaller, more fundamental units.  There is no consensus as to what these units are, but the most popular view is that phones can be constructed from a set of phonological distinctive features.  Phones are a useful representation because words can easily be re-written as phones using a lexicon.  We argue here however that it is inappropriate to directly link acoustic observations to HMM states and phones: the HMM paradigm is not valid.  The principle of distinctive features was first proposed in the classic work of Jakobson, Fant and Halle (1952).  Although this work gained much attention when published, many (e. g.  (Jones, 1957)) regarded features as no-more than a useful classification scheme, whereby one could refer to the class of "nasal phones" or "voiced phones".  The power of features became evident with the publication of The Sound Pattern of English by Chomsky and Halle (1968) (hereafter SPE), where the authors showed that what were otherwise complex phonological rules could be written concisely if features were used rather than phones.  The goal of feature theory in phonology has been to discover the most basic set of fundamental underlying units (the features) from which surface forms (e. g.  phones) can be derived; a small number of simple features can be combined to give rise to the larger number of phones, whose behaviour is more complex.  1. 2.  Related work on Phonological Features The idea of using phonological features for speech recognition is not new, as many others have seen the basic theoretical advantages laid out above.  Among others, the CMU Hearsay-II system (Goldberg & Reddy, 1976) made some use of features, as did the CSTR Alvey recogniser (Harrington, 1987).  Often these these systems used knowledge based techniques to extract their features and in the end the performance of these systems was poor on speaker independent continuous speech.  Some more recent work has continued in this vein.
