A Systolic Array Implementation of a Dynamic Sequential Neural Network for Pattern Recognition
 Recently we have developed a sequential algorithm for designing a multi-layer perceptron classifier [1, 2].  Our approach, called Sequential Input Space Partitioning (SISP) algorithm, results in a one pass algorithm and a growing network.  We exploit the fact that class boundary constructed by an MLP classifier is piecewise linear and hence the contribution of each hidden hidden unit to the final decision is essentially local .  We have shown that, in a number of benchmark classification problems, the algorithm achieves performances similar to conventional batch methods of training.  We have also argued that the sequential design has an indirect computational advantage.  This computational advantage comes from the fact that the algorithm sees each data item only once, hence the feasibility of pipelining the training procedures in a true parallel architecture.  In this paper, we show how this one pass algorithm can be pipelined and realised by a systolic array implementation.  The idea is to exploit the fact that the locations of boundary segments are determined by solving localised classification problems.  Training is achieved by updating local covariances using the Recursive Least Squares (RLS) algorithm.  The algorithm is sequential in the sense that training examples are passed only once, and the network will learn and/or expand at the arrival of each example.  The major advantage in this sequential scheme is the feasibility of pipelining the training procedures in a true parallel architecture.  In this paper, we present a systolic array implementation of the SISP algorithm.
