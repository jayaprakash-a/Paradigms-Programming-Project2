Contour Tracking by Stochastic Propagation of Conditional Density
 The problem of tracking curves in dense visual clutter is a challenging one.  Trackers based on Kalman filters are of limited use; because they are based on Gaussian densities which are unimodal, they cannot represent simultaneous alternative hypotheses.  Extensions to the Kalman filter to handle multiple data associations work satisfactorily in the simple case of point targets, but do not extend naturally to continuous curves.  A new, stochastic algorithm is proposed here, the Condensation algorithm --- Conditional Density Propagation over time.  It uses `factored sampling', a method previously applied to interpretation of static images, in which the distribution of possible interpretations is represented by a randomly generated set of representatives.  The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time.  The result is highly robust tracking of agile motion in clutter, markedly superior to what has previously been attainable from Kalman filtering.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  1 The problem of tracking curves in clutter The purpose of this paper is to establish a stochastic framework for tracking curves in visual clutter, and to propose a powerful new technique --- the Condensation algorithm.  The new approach is rooted in strands from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our framework aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models must be pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost [17, 26, 18].  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally [20], especially if motion is modelled as well as shape [12, 16].  One important facility is the modelling of curve segments which interact with images [29] or image sequences [19].  This is more general than modelling entire objects but more clutter-resistant than applying signal-processing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric Bspline curves [3] tracking over image sequences [8].  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space [28, 5], or more generally allowing a linear space of non-rigid motion [9].  Finally, probability densities p(x) can be defined over the class of curves [9], and also over their motions [27, 5], and this constitutes a powerful facility for tracking.  Reasonable default functions can be chosen for those densities.  However, it is obviously more satisfactory to measure the actual densities or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this assuming Gaussian densities are known in the control-theory literature [13] and have been applied in computer vision [6, 7, 4].  1. 2 Sampling methods A standard problem in statistical pattern recognition is to find an object parameterised as x with prior p(x), using data z from a single image.  (This is a simplified, static form of the image sequence problem addressed in this paper. ) In order to estimate x from z, some information is needed about the conditional distribution p(zjx) which measures the likelihood that a hypothetical object configuration x should give rise to the image data z that has just been observed.  The data z could either be an entire grey-level array or a set of sparse features such as corners or, as in this paper, curve fragments obtained by edge detection.  The posterior density p(xjz) represents all the knowledge about x that is deducible from the data.  It can be evaluated in principle by applying Bayes' rule to obtain p(xjz) = kp(zjx)p(x) (1) where k is a normalisation constant that is independent of x.  In the general case that p(zjx) is multi-modal p(xjz) cannot be evaluated simply in closed form: instead iterative sampling techniques can be used.  The first use of such an iterative solution was proposed by Geman and Geman [11] for restoration of an image represented by mixed variables, both continuous (pixels) and discrete (the `line process').  Sampling methods for recovery of a parametric curve x by sampling [24, 14, 25] have generally used spatial Markov processes as the underlying probabilistic model p(x).  The basic method is factored sampling [14].  It is useful when the conditional observation probability p(zjx) can be evaluated pointwise and sampling it is not feasible and when, conversely, the prior p(x) can be sampled but not evaluated.  The algorithm
