Optimizing Parameters in a Ranked Retrieval System Using Multi-Query Relevance Feedback
 Abstract A method is proposed by which parameters in ranked-output text retrieval systems can be automatically optimized to improve retrieval performance.  A ranked-output text retrieval system implements a ranking function which orders documents, placing documents estimated to be more relevant to the user's query before less relevant ones.  The proposed method is to adjust system parameters to maximize the match between the system's document ordering and the user's desired ordering, given by relevance feedback.  The utility of the approach is demonstrated by estimating the similarity measure in a vector space model of information retrieval.  The approach automatically finds a similarity measure which performs equivalent to or better than all "classic" similarity measures studied.  It also performs within 1% of an estimated theoretically optimal measure.
