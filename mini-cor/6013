USING MUTUAL INFORMATION TO DESIGN FEATURE COMBINATIONS
 ABSTRACT Combination of different feature streams is a well-established method for improving speech recognition performance.  This empirical success, however, poses theoretical problems when trying to design combination systems: is it possible to predict which feature streams will combine most advantageously, and which of the many possible combination strategies will be most successful for the particular feature streams in question? We approach these questions with the tool of conditional mutual information (CMI), estimating the amount of information that one feature stream contains about the other, given knowledge of the correct subword unit label.  We argue that CMI of the raw feature streams should be useful in deciding whether to use independent or conjoint acoustic models for the streams; this is only weakly supported by our results.  We also argue that CMI between the outputs of independent classifiers based on each stream should help predict which streams can be combined most beneficially.  Our results confirm the usefulness of this measure.
