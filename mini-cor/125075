Linear Concepts and Hidden Variables: An Empirical Study
 Abstract Some learning techniques for classification tasks work indirectly, by first trying to fit a full probabilistic model to the observed data.  Whether this is a good idea or not depends on the robustness with respect to deviations from the postulated model.  We study this question experimentally in a restricted, yet non-trivial and interesting case: we consider a conditionally independent attribute (CIA) model which postulates a single binary-valued hidden variable z on which all other attributes (i. e. , the target and the observables) depend.  In this model, finding the most likely value of any one variable (given known values for the others) reduces to testing a linear function of the observed values.  We learn CIA with two techniques: the standard EM algorithm, and a new algorithm we develop based on covariances.  We compare these, in a controlled fashion, against an algorithm (a version of Winnow) that attempts to find a good linear classifier directly.  Our conclusions help delimit the fragility of using the CIA model for classification: once the data departs from this model, performance quickly degrades and drops below that of the directly-learned linear classifier.
