Approximate probabilistic inference in dynamic processes
 Abstract When dealing with a dynamic process, we are typically interested in keeping track of where we are, and in predicting where we will be in the future.  When the dynamic process is stochastic and partially observable, as it invariably is, the best we can hope for is to have accurate beliefs about the state of the system.  Thus, we want to maintain a belief state: a probability distribution over the possible states the system can be in.  When the state space is large (or infinite), it is typically impossible to maintain a completely accurate representation of the belief state.  In this paper, we investigate the possibility of maintaining an approximate belief state.  We argue that it can be very useful to use the (approximate) belief state at time t to focus attention on the relevant aspects of the situation at time t+1, thereby providing guidance to the algorithm that computes the next belief state.  Thus, our belief state should guide not just our "real world" actions, but also our computational actions.  We present some preliminary results supporting this claim in the context of stochastic simulation algorithms, and suggest ways in which this idea can be extended.
