TOPICS ON HIDDEN MARKOV MODELS AND THEIR APPLICATIONS IN SPEECH RECOGNITION
 ABSTRACT We present an algorithm for estimating state-dependent polynomial coecients in the nonstationary-state hidden Markov model (or the trended HMM) which allows for the flexibility of linear time warping or scaling in individual model states.  The need for the state-dependent time warping arises from the consideration that due to speaking rate variation and other temporal factors in speech.  Multiple state-segmented speech data sequences used for training a single set of polynomial coecients often vary appreciably in their sequence lengths.  The algorithm is developed based on a general framework with the use of auxiliary parameters, which, of no interests in themselves, nevertheless provide an intermediate tool for achieving maximal accuracy for estimating the polynomial coecients in the trended HMM.  It is proven that the proposed estimation algorithm converges to a solution equivalent to the state-optimized maximum likelihood estimate.  Effectiveness of the algorithm is demonstrated in experiments designed to fit a single trended HMM simultaneously to multiple sequences of speech data (from the TIMIT database) which are different renditions of the same word yet vary over a wide range in the sequence length.  Speech recognition experiments have been performed based on the standard acoustic-phonetic TIMIT database.  The speech recognition results demonstrate the advantages of the time-warping trended HMMs over the regular trended HMMs about 10 to 15 % improvement in terms of the recognition rate.
