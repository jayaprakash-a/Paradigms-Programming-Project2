USING PHIPAC TO SPEED ERROR BACK-PROPAGATION LEARNING
 ABSTRACT We introduce PHiPAC, a coding methodology for developing portable high-performance numerical libraries in ANSI C.  Using this methodology, we have developed code for optimized matrix multiply routines.  These routines can achieve over 90% of peak performance on a variety of current workstations, and are often faster than vendor-supplied optimized libraries.  We then describe the bunch-mode back-propagation algorithm and how it can use the PHiPAC derived matrix multiply routines.  Using a set of plots, we investigate the tradeoffs between bunch size, convergence rate, and training speed using a standard speech recognition data set and show how use of the PHiPAC routines can lead to a significantly faster back-propagation learning algorithm.
