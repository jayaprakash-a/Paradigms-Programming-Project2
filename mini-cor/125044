Feature Extraction Languages for Propositionalized Relational Learning
 Abstract We study representations and relational learning over structured domains within a propositionalization framework that decouples feature construction and model construction.  We describe two complementary approaches that address three aspects of the problem: First, we develop and study a flexible knowledge representation for structured data, with an associated language that provides the syntax and a well defined equivalent semantics for expressing complex structured data succinctly.  Second, we use this language to automate the process of feature construction by expressing `types' of objects in the language, which are instantiated in the ground data, allowing us to determine the level at which learning is done.  Finally, this process of re-representation of the domain allows general purpose learning schemes, such as feature efficient linear algorithms and probabilistic representations, to be defined over the resulting space, yielding efficient and expressive learning of relational functions over a structured domain using propositional means.
