RETRIEVING OBJECTS FROM VIDEOS BASED ON AFFINE REGIONS
 ABSTRACT We present a method to (semi-)automatically annotate video material.  More precisely, we focus on recognizing specific objects and scenes in keyframes.  Objects are learnt simply by having the user delineate them in one (or a few) images.  The basic building block to achieve this goal consists of affine invariant regions.  These are local image patches that adapt their shape based on the image content so as to be invariant to viewpoint changes.  Instead of simply matching the regions and counting the number of matches, we propose to gather more evidence about the presence of the object by exploring the image around the initial matches.  This boosts the performance, especially under difficult, real-world imaging conditions.  Experimental results on news broadcast data demonstrate the viability of the approach.
