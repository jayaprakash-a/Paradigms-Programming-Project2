Approximate Dimension Equalization in Vector-based Information Retrieval
 Abstract Vector-based information retrieval methods such as the vector space model (VSM), latent semantic indexing (LSI), and the generalized vector space model (GVSM) represent both queries and documents by high-dimensional vectors learned from analyzing a training collection of text.  VSM scales well to large collections, but cannot represent term{term correlations, which prevents it from being used in cross-language retrieval.  GVSM and LSI can represent term{term correlations, but do not scale well to large collections.  We point out a deep mathematical similaritybetween VSM, LSI, and GVSM, and use this to derive anovel method we call approximate dimension equalization (ADE) that performs well on large collections, scales well computationally, and can represent term{term correlations.  We compare the performance of ADE to the other methods on both large and small collections with both monolingual and crosslanguage queries.  ADE outperforms all other methods on large cross-language collections, and is close to the best in all other cases.
