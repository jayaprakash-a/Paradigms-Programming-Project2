Kernelized Infomax Clustering| Abstract We propose a simple information-theoretic approach to soft clustering based on maximizing the mutual information I(x, y) between the unknown cluster labels y and the training patterns x with respect to parameters of specifically constrained encoding distributions.  The constraints are chosen such that patterns are likely to be clustered similarly if they lie close to specific unknown vectors in the feature space.  The method may be conveniently applied to learning the optimal anity matrix, which corresponds to learning parameters of the kernelized encoder.  The procedure does not require computations of eigenvalues of the Gram matrices, which makes it potentially attractive for clustering large data sets. 
Online Learning from Finite Training Sets and Robustness to Input Bias| We analyse online gradient descent learning from finite training sets at noninfinitesimal learning rates j.  Exact results are obtained for the time-dependent generalization error of a simple model system: a linear network with a large number of weights N , trained on p = ffN examples.  This allows us to study in detail the effects of finite training set size ff on, for example, the optimal choice of learning rate j.  We also compare online and offline learning, for respective optimal settings of j at given final learning time.  Online learning turns out to be much more robust to input bias and actually outperforms offline learning when such bias is present; for unbiased inputs, online and offline learning perform almost equally well. 
Variational Cumulant Expansions for Intractable| Abstract Intractable distributions are a common difficulty in the probabilistic representation of knowledge and variational methods have recently been popular in providing an approximate solution.  In this article, we describe a perturbational approach in the form of a cumulant expansion which, to lowest order, recovers the standard Kullback-Leibler variational bound.  Higher order terms describe corrections on the variational approach without incurring much further computational cost.  The relationship to other perturbational approaches such as TAP is also elucidated.  We demonstrate the method on a particular class of undirected graphical models, Boltzmann machines, for which our simulation results confirm improved accuracy and enhanced stability during learning. 
Learning in Spiking Neural Assemblies| Abstract We consider a statistical framework for learning in a class of networks of spiking neurons.  Our aim is to show how optimal local learning rules can be readily derived once the neural dynamics and desired functionality of the neural assembly have been specified, in contrast to other models which assume (sub-optimal) learning rules.  Within this framework we derive local rules for learning temporal sequences in a model of spiking neurons and demonstrate its superior performance to correlation (Hebbian) based approaches.  We further show how to include mechanisms such as synaptic depression and outline how the framework is readily extensible to learning in networks of highly complex spiking neurons.  A stochastic quantal vesicle release mechanism is considered and implications on the complexity of learning discussed. 
Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo| Abstract The full Bayesian method for applying neural networks to a prediction problem is to set up the prior/hyperprior structure for the net and then perform the necessary integrals.  However, these integrals are not tractable analytically, and Markov Chain Monte Carlo (MCMC) methods are slow, especially if the parameter space is high-dimensional.  Using Gaussian processes we can approximate the weight space integral analytically, so that only a small number of hyperparameters need be integrated over by MCMC methods.  We have applied this idea to classification problems, obtaining excellent results on the real-world problems investigated so far. 
Variational Cumulant Expansions for Intractable Distributions| Abstract Intractable distributions present a common difficulty in inference within the probabilistic knowledge representation framework and variational methods have recently been popular in providing an approximate solution.  In this article, we describe a perturbational approach in the form of a cumulant expansion which, to lowest order, recovers the standard Kullback-Leibler variational bound.  Higher-order terms describe corrections on the variational approach without incurring much further computational cost.  The relationship to other perturbational approaches such as TAP is also elucidated.  We demonstrate the method on a particular class of undirected graphical models, Boltzmann machines, for which our simulation results confirm improved accuracy and enhanced stability during learning. 
A Dynamical Bayesian Network for Tempo and Polyphonic Pitch Tracking| The model is readily extensible to more complex sound generation processes. 
Generative Vector Quantisation| Abstract -- Based on the assumption that a pattern is constructed out of features which are either fully present or absent, we propose a vector quantisation method which constructs patterns using binary combinations of features.  For this model there exists an efficient EM-like learning algorithm which learns a set of representative codebook vectors.  In terms of a generative model, the collection of allowed binary states `generates' the set of codebook vectors.  The method, therefore, provides not only a compact description of the data in terms of clusters, but also an explanation of the individual clusters in terms of common elementary features.  Preliminary results on image compression and handwritten digit analysis indicate that our approach is an interesting and computationally inexpensive alternative to more complex probabilistic generative graphical models. 
Ensemble Learning for Multi-Layer Networks| Abstract Bayesian treatments of learning in neural networks are typically based either on local Gaussian approximations to a mode of the posterior weight distribution, or on Markov chain Monte Carlo simulations.  A third approach, called ensemble learning, was introduced by Hinton and van Camp (1993).  It aims to approximate the posterior distribution by minimizing the Kullback-Leibler divergence between the true posterior and a parametric approximating distribution.  However, the derivation of a deterministic algorithm relied on the use of a Gaussian approximating distribution with a diagonal covariance matrix and so was unable to capture the posterior correlations between parameters.  In this paper, we show how the ensemble learning approach can be extended to fullcovariance Gaussian distributions while remaining computationally tractable.  We also extend the framework to deal with hyperparameters, leading to a simple re-estimation procedure.  Initial results from a standard benchmark problem are encouraging. 
Variational methods for approximate reasoning in graphical models| Abstract Exact inference in large and complex graphical models (e. g.  Bayesian networks) is computationally intractable.  Approximate schemes are therefore of great importance for real world computation.  In this paper we consider a general scheme in which the original intractable graphical model is approximated by a model with a tractable structure.  The approximating model is optimised by an iterative procedure, which minimises the Kullback-Leibler divergence between the two models.  The procedure is guaranteed to converge to a local minimum of the Kullback-Leibler divergence.  The scheme provides a bridge between naive mean-field theory and exact computation.  Simulation results are provided to illustrate the method. 
Bayesian Classification With Gaussian Processes| Abstract We consider the problem of assigning an input vector x to one of m classes by predicting P (cjx) for c = 1; : : : ; m.  For a two-class problem, the probability of class 1 given x is estimated by oe(y(x)), where oe(y) = 1=(1 + e\Gamma y ).  A Gaussian process prior is placed on y(x), and is combined with the training data to obtain predictions for new x points.  We provide a Bayesian treatment, integrating over uncertainty in y and in the parameters that control the Gaussian process prior; the necessary integration over y is carried out using Laplace's approximation.  The method is generalized to multi-class problems (m ? 2) using the softmax function.  We demonstrate the effectiveness of the method on a number of datasets. 
On-line Learning from Finite Training Sets in Nonlinear Networks| Abstract Online learning is one of the most common forms of neural network training.  We present an analysis of online learning from finite training sets for non-linear networks (namely, soft-committee machines), advancing the theory to more realistic learning scenarios.  Dynamical equations are derived for an appropriate set of order parameters; these are exact in the limiting case of either linear networks or infinite training sets.  Preliminary comparisons with simulations suggest that the theory captures some effects of finite training sets, but may not yet account correctly for the presence of local minima. 
Finite size effects in on-line learning of multi-layer neural networks| Abstract We complement recent advances in thermodynamic limit analyses of mean on-line gradient descent learning dynamics in multi-layer networks by calculating fluctuations possessed by finite dimensional systems.  Fluctuations from the mean dynamics are largest at the onset of specialisation as student hidden unit weight vectors begin to imitate specific teacher vectors, increasing with the degree of symmetry of the initial conditions.  In light of this, we include a term to stimulate asymmetry in the learning process, which typically also leads to a significant decrease in training time.  An attractive feature of neural networks is their ability to learn a parametrised rule from a set of input/output training examples, by which the parameters of the network are adapted to minimise an error measuring the misfit of the network mapping on the training examples.  Different approaches to the learning process are typically evaluated by the expected error that the network will make on a randomly presented input example.  In on-line learning, statistical mechanics plays a strong role in calculating this generalisation error (see [1, 2, 4] and refs.  within) through self-averaging in the thermodynamic limit, for which an understanding of finite size effects would benefit further advances.  Connections to alternative finite dimensional methods (see [3] and refs.  within) will be pointed to in the course of our analysis.  In on-line learning, the weights parametrising the student network are successively updated according to the error incurred on a single example from a stream of input/output examples, f; ()g, generated by a teacher network (\Delta).  We assume that the teacher network the student attempts to learn is a soft committee machine[1, 4] of N inputs, and M hidden units, this being a one hidden layer network with weights connecting each hidden to output unit set to +1, and with each hidden unit n connected to all input units by B n (n = 1::M).  Explicitly, for the N dimensional training input vector , the output of the teacher is given by, i = M X n=1 g(B n \Delta ); (1) where g(x) is the activation function of the hidden units, and we take g(x) = erf(x= p 2).  The teacher generates a stream of training examples (; i ), with input components drawn from a normal distribution of zero mean, unit variance.  The student network that attempts to learn the teacher, by fitting the training examples, is also a soft committee machine, but with K hidden units.  For input , the student output is, oe(J; ) = K X i=1 g(J i \Delta ); (2) where the student weights J = fJ i g(i = 1::K) are sequentially modified to reduce the error that the student makes on an input , ffl(J; ) = 1 2 (oe(J; ) \Gamma i ) 2 = 1 2 / K X i=1 g(x i ) \Gamma M X n=1 g(y n ) ! 2 ; (3) where the activations are defined x i = J i \Delta , and y n = B n \Delta .  Gradient descent on the error(3) results in an update of the student weight vectors, J +1 = J \Gamma j N ffi i ; (4) where, ffi i = g 0 (x i ) 2 4 M X n=1 g(y n ) \Gamma K X j=1 g(x j ) 3 5 ; (5) and g 0 is the derivative of the activation function g.  The typical performance of the student on a randomly selected input example is given by the generalisation error, ffl g = hffl(J; )i, where h::i represents an average over the gaussian input distribution.  One finds that ffl g depends only on the order-parameters, R in = J i \Delta Bn , Q ij = J i \Delta J j , and Tnm = Bn \Delta Bm (i; j = 1::K; n; m = 1::M)[4], for which, using (4), we derive (stochastic) update equations, R +1 in\Gamma R in = j N ffi i y n ; (6) Q +1 ik\Gamma Q ik = j N \Gamma ffi i x j + ffi k x i \Delta + j 2 N 2 ffi i ffi k \Delta : (7) We average over the input distribution to obtain deterministic equations for the mean values of the order parameters, which are self-averaging in the thermodynamic limit, N!1.  The order-parameter approach contrasts with approaches which analyze the dynamics of the individual weight components, based upon approximate Fokker-Plank equations (see [3] and refs.  within).  The advantage of the order-parameter approach is that the system is modelled exactly in the thermodynamic limit, with only a small number of equations.  In this work we present a more realistic treatment by calculating the dynamic fluctuations induced
Gaussian Fields for approximate Inference in Sigmoid Belief Networks| Abstract We are interested in Sigmoid Belief Networks.  Have a layered structure.  Gaussian Field assumption.  Good for inference in large layered networks. 
Ensemble Learning - an alternative Bayesian approach to Neural Networks --DRAFT 1|0.  Abstract.  Bayesian treatments of learning in neural networks are typically based either on local Gaussian approximations to a mode of the posterior weight distribution, or on Markov chain Monte Carlo simulations.  A third approach, called ensemble learning, was introduced by Hinton and van Camp (1993).  It aims to approximate the posterior distribution by minimizing the Kullback-Leibler divergence between the true posterior and a parametric approximating distribution.  However, the derivation of a deterministic algorithm relied on the use of a Gaussian approximating distribution with a diagonal covariance matrix and so was unable to capture the posterior correlations between parameters.  We show how the ensemble learning approach can be extended to full-covariance Gaussian distributions while remaining computationally tractable.  We also extend the framework to deal with hyperparameters, leading to a simple re-estimation procedure.  One of the benefits of our approach is that it yields a strict lower bound on the model likelihood, in contrast to other approximate procedures. 
In the teaching of quality management in| 60-hour third year BSc in Management Sciences joint Honours courses, Dale has found that the overwhelming perception of students is that an effective level of quality is more difficult to achieve in service than in manufacturing situations.  The general view was that quality in manufacturing companies is controlled by technology, the human interaction in the process is minimum, batches of product are always large, and all defects are found prior to shipment to the customer, and so it is bound to be easier than in services.  This led him to probe the reasons for this viewpoint, the major findings of which are summarized in this paper.  Dale has been researching quality management since 1981 and came to the subject with an engineering and technical bias.  The early research carried out by him in manufacturing has been complimented by more recent work in hospitals, financial services, public sector, education and the recently privatized utilities.  A summary of Dale's research work over this timeframe is given in Dale (1996).  Some of the initial thoughts which immediately sprang to mind regarding the perceptions held by the third year students, included: .  their lack of familiarity with manufacturing in comparison with the services which they experienced most days of their life; .  the distinct body of literature which is available on services in general, and service quality in particular; .  the marketing fraternity have made the largest contribution to the literature on service quality; marketing is a popular subject among management science students, the job prospects are considerable and so the subject carries some degree of influence with students; .  academic staff in business and management schools are more comfortable teaching services than they are with manufacturing and consequently provide more examples and speak with more conviction on the former.  In addition, students are usually more interested in the management of quality in service situations because they associate quality management in manufacturing with more quantitative issues which, in general, they have difficulties in understanding and do not like.  They tend to be interested in applying quality management principles to hotels, holiday parks, software, consultancy etc. ,
Ensemble Learning in Bayesian Neural Networks| Abstract Bayesian treatments of learning in neural networks are typically based either on a local Gaussian approximation to a mode of the posterior weight distribution, or on Markov chain Monte Carlo simulations.  A third approach, called ensemble learning, was introduced by Hinton and van Camp (1993).  It aims to approximate the posterior distribution by minimizing the Kullback-Leibler divergence between the true posterior and a parametric approximating distribution.  The original derivation of a deterministic algorithm relied on the use of a Gaussian approximating distribution with a diagonal covariance matrix and hence was unable to capture the posterior correlations between parameters.  In this chapter we show how the ensemble learning approach can be extended to full-covariance Gaussian distributions while remaining computationally tractable.  We also extend the framework to deal with hyperparameters, leading to a simple re-estimation procedure.  One of the benefits of our approach is that it yields a strict lower bound on the marginal likelihood, in contrast to other approximate procedures. 
Bayesian Model Comparison by Monte Carlo Chaining| Abstract The techniques of Bayesian inference have been applied with great success to many problems in neural computing including evaluation of regression functions, determination of error bars on predictions, and the treatment of hyper-parameters.  However, the problem of model comparison is a much more challenging one for which current techniques have significant limitations.  In this paper we show how an extended form of Markov chain Monte Carlo, called chaining, is able to provide effective estimates of the relative probabilities of different models.  We present results from the robot arm problem and compare them with the corresponding results obtained using the standard Gaussian approximation framework.  1 Bayesian Model Comparison In a Bayesian treatment of statistical inference, our state of knowledge of the values of the parameters w in a model M is described in terms of a probability distribution function.  Initially this is chosen to be some prior distribution p(wjM), which can be combined with a likelihood function p(Djw; M) using Bayes' theorem to give a posterior distribution p(wjD; M) in the form p(wjD; M) = p(Djw; M)p(wjM) p(DjM) (1) where D is the data set.  Predictions of the model are obtained by performing integrations weighted by the posterior distribution.  The comparison of different models M i is based on their relative probabilities, which can be expressed, again using Bayes' theorem, in terms of prior probabilities p(M i ) to give p(M i jD) p(M j jD) = p(DjM i )p(M i ) p(DjM j )p(M j ) (2) and so requires that we be able to evaluate the model evidence p(DjM i ), which corresponds to the denominator in (1).  The relative probabilities of different models can be used to select the single most probable model, or to form a committee of models, weighed by their probabilities.  It is convenient to write the numerator of (1) in the form expf\Gamma E(w)g, where E(w) is an error function.  Normalization of the posterior distribution then requires that p(DjM) = Z expf\Gamma E(w)g dw: (3) Generally, it is straightforward to evaluate E(w) for a given value of w, although it is extremely difficult to evaluate the corresponding model evidence using (3) since the posterior distribution is typically very small except in narrow regions of the high-dimensional parameter space, which are unknown a-priori.  Standard numerical integration techniques are therefore inapplicable.  One approach is based on a local Gaussian approximation around a mode of the posterior (MacKay, 1992).  Unfortunately, this approximation is expected to be accurate only when the number of data points is large in relation to the number of parameters in the model.  In fact it is for relatively complex models, or problems for which data is scarce, that Bayesian methods have the most to offer.  Indeed, Neal, R.  M.  (1996) has argued that, from a Bayesian perspective, there is no reason to limit the number of parameters in a model, other than for computational reasons.  We therefore consider an approach to the evaluation of model evidence which overcomes the limitations of the Gaussian framework.  For additional techniques and references to Bayesian model comparison, see Gilks et al.  (1995) and Kass and Raftery (1995).  2 Chaining Suppose we have a simple model M 0 for which we can evaluate the evidence analytically, and for which we can easily generate a sample w l (where l = 1; : : : ; L) from the corresponding distribution p(wjD; M 0 ).  Then the evidence for some other model M can be expressed in the form p(DjM) p(DjM 0 ) = Z expf\Gamma E(w) +E 0 (w)gp(wjD; M 0 ) dw ' 1 L L X l=1 expf\Gamma E(w l ) +E 0 (w l )g: (4) Unfortunately, the Monte Carlo approximation in (4) will be poor if the two error functions are significantly different, since the exponent is dominated by regions where E is relatively small, for which there will be few samples unless E 0 is also small in those regions.  A simple Monte Carlo approach will therefore yield poor results.  This problem is equivalent to the evaluation of free energies in statistical physics,
Variational Belief Networks for Approximate Inference| Abstract Exact inference in large, densely connected probabilistic networks is computationally intractable, and approximate schemes are therefore of great importance.  One approach is to use mean field theory, in which the exact log-likelihood is bounded from below using a simpler approximating distribution.  In the standard mean field theory, the approximating distribution is factorial.  We propose instead to use a (tractable) belief network as an approximating distribution.  The resulting compact framework is analogous to standard mean field theory and no additional bounds are required, in contrast to other recently proposed extensions.  We derive mean field equations which provide an efficient iterative algorithm to optimize the parameters of the approximating belief network.  Simulation results indicate a considerable improvement on previously reported methods. 
A Generative Model for Music Transcription| Abstract In this paper we present a graphical model for polyphonic music transcription.  Our model, formulated as a Dynamical Bayesian Network, embodies a transparent and computationally tractable approach to this acoustic analysis problem.  An advantage of our approach is that it places emphasis on explicitly modelling the sound generation procedure.  It provides a clear framework in which both high level (cognitive) prior information on music structure can be coupled with low level (acoustic physical) information in a principled manner to perform the analysis.  The model is a special case of the, generally intractable, switching Kalman filter model.  Where possible, we derive, exact polynomial time inference procedures, and otherwise efficient approximations.  We argue that our generative model based approach is computationally feasible for many music applications and is readily extensible to more general auditory scene analysis scenarios. 
Tractable Variational Structures for Approximating Graphical Models|
Gaussian Fields for Approximate Inference in Layered Sigmoid Belief Networks|
A generative model for music transcription|
Online Learning from Finite Training Sets: An Analytical Case Study|
Has the OSI Opportunity Been Fully Realised?|
Deterministic Generative Models for Fast Feature Discovery|
Managing quality in manufacturing versus services: a comparative analysis",|
