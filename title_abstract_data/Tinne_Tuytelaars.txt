Real-time affine region tracking and coplanar grouping| Abstract We present a novel approach for tracking locally planar regions in an image sequence and their grouping into larger planar surfaces.  The tracker recovers the affine transformation of the region and therefore yields reliable point correspondences between frames.  Both edges and texture information are exploited in an integrated way, while not requiring the complete region's contour.  The tracker withstands zoom, out-of-plane rotations, discontinuous motion and changes in illumination conditions while achieving real-time performance for a region.  Multiple tracked regions are grouped into disjoint coplanarity classes.  We first define a coplanarity score between each pair of regions, based on motion and texture cues.  The scores are then analyzed by a clique-partitioning algorithm yielding the coplanarity classes that best fit the data.  The method works in the presence of perspective distortions, discontinuous planar surfaces and considerable amounts of measurement noise. 
Wide-baseline Multiple-view Correspondences| Abstract We present a novel approach for establishing multiple-view feature correspondences along an unordered set of images taken from substantially different viewpoints.  While recently several wide-baseline stereo (WBS) algorithms have appeared, the N-view case is largely unexplored.  In this paper, an established WBS algorithm is used to extract and match features in pairs of views.  The pairwise matches are first integrated into disjoint feature tracks, each representing a single physical surface patch in several views.  By exploiting the interplay between the tracks, they are extended over more views, while unrelated image features are removed.  Similarity and spatial relationships between the features are simultaneously used.  The output consists of many reliable and accurate feature tracks, strongly connecting the input views.  Applications include 3D reconstruction and object recognition.  The proposed approach is not restricted to the particular choice of features and matching criteria.  It can extend any method that provides feature correspondences between pairs of images. 
Simultaneous Object Recognition and Segmentation from Single or Multiple Model Views| Abstract We present a novel Object Recognition approach based on affine invariant regions.  It actively counters the problems related to the limited repeatability of the region detectors, and the difficulty of matching, in the presence of large amounts of background clutter and particularly challenging viewing conditions.  After producing an initial set of matches, the method gradually explores the surrounding image areas, recursively constructing more and more matching regions, increasingly farther from the initial ones.  This process covers the object with matches, and simultaneously separates the correct matches from the wrong ones.  Hence, recognition and segmentation are achieved at the same time.  The approach includes a mechanism for capturing the relationships between multiple model views and exploiting these for integrating the contributions of the views at recognition time.  This is based on an efficient algorithm for partitioning a set of region matches into groups lying on smooth surfaces.  Integration is achieved by measuring the consistency of configurations of groups arising from different model views.  Experimental results demonstrate the stronger power of the approach in dealing with extensive clutter, dominant occlusion, and large scale and viewpoint changes.  Non-rigid deformations are explicitly taken into account, and the approximative contours of the object are produced.  All presented techniques can extend any viewpoint invariant feature extractor. 
Dense Matching of Multiple Wide-baseline Views| Abstract This paper describes a PDE-based method for dense depth extraction from multiple wide-baseline images.  Emphasis lies on the usage of only a small amount of images.  The integration of these multiple wide-baseline views is guided by the relative confidence that the system has in the matching to different views.  This weighting is fine-grained in that it is determined for every pixel at every iteration.  Reliable information spreads fast at the expense of less reliable data, both in terms of spatial communications within a view and in terms of information exchange between the views.  Changes in intensity between images can be handled in a similar fine grained fashion. 
3D MODELING AND REGISTRATION UNDER WIDE BASELINE CONDITIONS| ABSTRACT During the 90s important progess has been made in the area of structure-from-motion.  From a series of closely spaced images a 3D model of the observed scene can now be reconstructed, without knowledge about the subsequent camera positions or settings.  From nothing but a video, the camera trajectory and scene shape are extracted.  Progress has also been important in the area of structured light techniques.  Rather than having to use slow and/or bulky laser scanners, compact one-shot systems have been developed.  Upon projection of a pattern onto the scene, its 3D shape and texture can be extracted from a single image.  This paper presents recent extensions on both strands, that have a common theme: how to cope with large baseline conditions.  In the case of shape-from-video we discuss ways to find correspondences and, hence, extract 3D shapes even when the images are taken far apart.  In the case of structured light, the problem solved is how to combine partial 3D patches into complete models, without a good initialisation of their relative poses. 
Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions| Abstract `Invariant regions' are image patches that automatically deform with
Automatic Object Recognition as Part of an Integrated Supervisory Control System| Abstract This paper consists of two main contributions.  First, a generic object recognition algorithm based on affinely invariant regions is proposed.  Next, this algorithm is used in an Integrated Supervisory Control System (ISCS), with special attention to the human machine interaction.  Experiments on an industrial robotic system are included, performing simple tasks such as ``Go to object O 1 '' or ``Put object O 2 on top of object O 3 '', where an object is simply modeled by one or more images thereof. 
Efficient Grouping under Perspective Skew| Abstract We present an efficient grouping strategy for the detection of regular repetitions of planar (but not necessarily coplanar) patterns.  At the heart of our system lie the fixed structures that typify the geometric transformations of the regularities.  The approach unifies a number of grouping types that have traditionally been dealt with separately.  It avoids the use of combinatorics in the search for pattern repetitions, through the combined use of invariants for hashing-based pattern matching on the one hand, and Hough transforms for the detection of the fixed structures on the other hand.  In this paper we concentrate on planar homologies and elations in particular.  Results on real-world scenes demonstrate the performance of the approach. 
Integrating Multiple Model Views for Object Recognition| Abstract We present a new approach to appearance-based object recognition, which captures the relationships between multiple model views and exploits them to improve recognition performance.  The basic building block are local, viewpoint invariant regions.  We propose an efficient algorithm for partitioning a set of region matches into groups lying on smooth surfaces (GAMs).  During modeling, the model views are connected by a large number of region-tracks, each aggregating image regions of a single physical region across the views.  At recognition time, GAMs are constructed matching a test image to each model view.  The consistency of configurations of GAMs is measured by exploiting the model connections.  The most consistent configuration, covering the object as completely as possible is found by a genetic algorithm.  Introducing GAMs as an intermediate grouping level facilitates decision-making and improves discriminative power.  As a complementary application, we introduce a novel GAM-based two-view filter and demonstrate its effectiveness in recovering correct matches in the presence of up to 96% mismatches. 
Grouping via the Matching of Repeated Patterns| `Grouping' is an important step in vision that combines features into higherorder perceptual entities, more amenable to semantic interpretation.  Many grouping types boil down to the repetition of one or more basic patterns.  Different grouping types are distinguished by the specific nature of this repetition, i. e.  the relative placements of the patterns, rather than the nature of the patterns themselves.  In many cases the patterns are planar or even coplanar.  Here we will assume repeated, planar but not necessarily coplanar patterns.  Although the repetition often is of a simple nature, image projection complicates its appearance through the perspective skew that it induces.  Even if a pattern is for instance mirror symmetric, its images are usually not.  What survives projection are the structures that remain fixed.  Structures like points and lines that are their own image under the repetition also remain fixed under the special projectivity that exists between the projected patterns in the image.  As an example, mirror symmetric point pairs remain fixed as a pair, all points on the (projected) symmetry axis are their own symmetric image -- i. e.  form a line of fixed points -- and the joins (lines) connecting symmetric points are also mapped onto themselves, forming a pencil of fixed lines [1].  This property that fixed structures under the original symmetry also remain fixed under the transformation between the repeated patterns in the image is valid in general.  The eigenvalues of the transformation that represents the original repetition are not changed through conjugation with a perspectivity.  Hence, the same kind of fixed structures are found after the perspective skew.  We conclude that fixed structures form a good basis to build a grouping strategy.  This idea, propounded in more detail in [8], lies at the heart of our grouping strategy.  One can build a hierarchy of grouping types based on their fixed structures [8].  Taking all projectivities that keep a specific structure fixed yields a subgroup of the projectivities.  The subgroups that have a line of fixed points or a pencil of fixed lines are of particular interest.  These fixed structures both lift 5 degrees of freedom, yet only require two parameters to specify them.  This eases the detection of these grouping types, as their subgroups have invariants that are strictly simpler than general, projective invariants.  Also, these are the types of fixed structures that are easiest to find, as they correspond to non-accidental configurations.  In this paper we will restrict the discussion to the detection of these cases, and more in particular to repetitions that amount to planar homologies in the images.  If a projectivity has a line of fixed points it automatically also has a pencil of fixed lines and v. v.  Such transformations are called planar homologies [5,9].  A special case are the homologies that have the vertex of the pencil on the axis.  These are called elations [5,4].  Planar homologies occur often in images, e. g.  as the transformation between a planar shape and its shadow, between identical patterns in parallel planes, between the two halves of a mirror symmetric pattern (harmonic planar homologies), between identical patterns under a point symmetry or between coplanar, periodic patterns (elations).  2 A Grouping Strategy Our strategy towards geometry-based grouping, dedicated to finding repeated patterns that are related by planar homologies, is the following: step 1: find small regions of interest, that remain invariant under changing viewpoint and illumination step 2: find matches between these regions, i. e.  repeated patterns step 3: use region matches as input to a cascaded Hough transform, which yields candidate fixed structures (non-accidental alignments) step 4: test the validity of the fixed structures and find out the extent of the image regions that can be mapped onto each other by the corresponding transformation The work that comes closest to our approach is that by Schaffalitzky and Zisserman [4].  They detect coplanar, periodic structures by picking up elations that bring multiple basic features into correspondence. 
Markerless Augmented Reality with a Real-Time Affine Region Tracker| Abstract We present a system for planar augmented reality based on a new real-time affine region tracker.  Instead of tracking fiducial points, we track planar local image patches, and bring these into complete correspondence, so a virtual texture can directly be added to them.  Moreover, the local image patches can be extracted in an invariant way, even without any a priori information from previous frames.  Hence it is possible to use them as natural beacons, that can be used to recognize the scene and to identify the individual patches.  This results in a powerful system, that can work without artificial markers or fiducial points and with a minimal amount of user interference. 
RETRIEVING OBJECTS FROM VIDEOS BASED ON AFFINE REGIONS| ABSTRACT We present a method to (semi-)automatically annotate video material.  More precisely, we focus on recognizing specific objects and scenes in keyframes.  Objects are learnt simply by having the user delineate them in one (or a few) images.  The basic building block to achieve this goal consists of affine invariant regions.  These are local image patches that adapt their shape based on the image content so as to be invariant to viewpoint changes.  Instead of simply matching the regions and counting the number of matches, we propose to gather more evidence about the presence of the object by exploring the image around the initial matches.  This boosts the performance, especially under difficult, real-world imaging conditions.  Experimental results on news broadcast data demonstrate the viability of the approach. 
On Satellite Vision-Aided Robotics Experiment| Abstract This contribution describes the vision-based robotic control (VBRC) experiments executed on the Japanese research satellite ETS-VII.  The VBRC experiments were designed to enhance image quality, refine calibration of different system components, facilitate robotoperation by automatically refining the robot-pose and provide data for robot-calibration. 
Adventurous tourism for couch potatoes| Abstract.  Two tourist guides are described.  One supports a virtual tour through an archaeological site, the other a tour through a real exhibition.  The first system is based on the 3D reconstruction of the ancient city of Sagalassos.  A virtual
Content-Based Image Retrieval Based on Local Affinely Invariant Regions|
Fast Wide Baseline Matching for Visual Navigation|
Wide-baseline muliple-view correspondences|
Simultaneous object recognition and segmentation by image exploration|
Matching affinely invariant regions for visual servoing|
A Cascaded Hough Transform as an Aid in Aerial Image Interpretation|
The cascaded Hough transform|
A comparison of affine region detectors|
Matching widely separated views based on affinely invariant neighborhoods|
Matching Widely Separated Views Based on Affine Invariant Regions|
Matching of Affinely Invariant Regions for Visual Servoing|
Monocular image measurements|
Local, Invariant Features for Registration and Recognition|
Wide base line stereo matching based on local affine invariant regions"|
HPAT Indexing for Fast Object/Scene Recognition Based on Local Appearance|
"3-D modeling and registration under wide baseline conditions",|
Wide baseline stereo matchingbased on local, aInely invariant regions|
