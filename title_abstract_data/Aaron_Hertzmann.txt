Data Synthesis with Expectation-Maximization| Abstract A problem of increasing importance in computer graphics is to generate data with the style of some previous training data, but satisfying new constraints.  If we use a probabilistic latent variable model, then learning the model will normally be performed using Expectation-Maximization (EM), or one of its generalizations.  We show that data synthesis for such problems can also be performed using EM, and that this synthesis process closely parallels learning, including identical E-step algorithms.  This observation simplifies the process of developing synthesis algorithms for latent variable models. 
Texture and Shape Synthesis on Surfaces| Abstract.  We present a novel method for texture synthesis on surfaces from examples.  We consider a very general type of textures, including color, transparency and displacements.  Our method synthesizes the texture directly on the surface, rather than synthesizing a texture image and then mapping it to the surface.  The synthesized textures have the same qualitative visual appearance as the example texture, and cover the surfaces without the distortion or seams of conventional texture-mapping.  We describe two synthesis methods, based on the work of Wei and Levoy and Ashikhmin; our techniques produce similar results, but directly on surfaces. 
Style machines| A pirouette and promenade in five synthetic styles drawn from a space that contains ballet, modern dance, and different body types.  The choreography is also synthetic.  Streamers show the
Stateless Remote Environment Navigation with View Compression| Abstract We present a set of very low bandwidth techniques for navigating remote environments.  In a typical setup using our system, a virtual environment resides on a server machine, and one or more users explore the environment from client machines.  Each client uses previous views of the environment to predict the next view, using the known camera motion and image-based rendering techniques.  The server performs the same prediction, and sends only the difference between the predicted and actual view.  Compressed difference images require significantly less bandwidth than the compressed images of each frame, and thus can yield much higher frame rates.  To request a view, the client simply sends the coordinates of the desired view and of the previous view to the server.  This avoids the overhead of maintaining connections between the server and each client.  No restrictions are placed on the scene or the camera motions; the view compression technique may be used with arbitrarily complex 3D scenes or dynamically changing views from a web camera or a digital television broadcast.  A lossy compression scheme is presented in which the client estimates the cumulative error in each frame, and requests a comprete refresh before errors become noticable.  This work is applicable to remote exploration of virtual worlds such as on head-mounted displays, Digital Television, or over the Internet. 
Curve Analogies| Abstract This paper describes a method for learning statistical models of 2D curves, and shows how these models can be used to design line art rendering styles by example.  A user can create a new style by providing an example of the style, e. g.  by sketching a curve in a drawing program.  Our method can then synthesize random new curves in this style, and modify existing curves to have the same style as the example.  This method can incorporate position constraints on the resulting curves. 
Interactive 3D Scene Reconstruction from Images| Abstract We propose an interactive framework for reconstructing an arbitrary 3D scene consistent with a set of images, for use in example-based image synthesis.  Previous research has used human input to specify feature matches, which are then processed off-line; however, it is very difficult to correctly match images without feedback.  The central idea of this paper is to perform and display 3D reconstruction during user modification.  By allowing the user to interactively manipulate the image correspondence and the resulting 3D reconstruction, we can exploit both the user's intuitive image understanding and the computer's processing power. 
Illustrating smooth surfaces| Abstract We present a new set of algorithms for line-art rendering of smooth surfaces.  We introduce an efficient, deterministic algorithm for finding silhouettes based on geometric duality, and an algorithm for segmenting the silhouette curves into smooth parts with constant visibility.  These methods can be used to find all silhouettes in real time in software.  We present an automatic method for generating hatch marks in order to convey surface shape.  We demonstrate these algorithms with a drawing style inspired by A Topological Picturebook by G.  Francis. 
Shape and Motion under Varying Illumination: Unifying Structure from Motion, Photometric Stereo, and Multi-view Stereo| Abstract This paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination.  The problem is formulated in a manner that subsumes structure from motion, multi-view stereo, and photometric stereo as special cases.  The algorithm utilizes both spatial and temporal intensity variation as cues: the former constrains flow and the latter constrains surface orientation; combining both cues enables dense reconstruction of both textured and texture-less surfaces.  The algorithm works by iteratively estimating affine camera parameters, illumination, shape, and albedo in an alternating fashion.  Results are demonstrated on videos of hand-held objects moving in front of a fixed light and camera. 
Shape and Spatially-Varying BRDFs From Photometric Stereo| Figure 1: From (a) 10 photographs of an object taken under varying illumination, we can reconstruct (b) its normals and materials, represented as (c) a material weight map controlling a mixture of (d,e) fundamental materials.  Using this representation we can (f) rerender the object under novel lighting.  Abstract We describe a suite of techniques for extracting shape and materials from multiple photographs of an object captured from the same viewpoint but with differing illumination.  Our method extracts perpixel BRDFs along with 3D shape, under an assumption that the materials can be described as a convex combination of a small number of fundamental materials.  We also show examples of interactive lighting and editing operations made possible by our methods, including direct manipulation of material coefficients and material transfer between models. 
Learning Physics-Based Motion Style with Nonlinear Inverse Optimization| Abstract This paper presents a novel physics-based representation of realistic character motion.  The dynamical model incorporates several factors of locomotion derived from the biomechanical literature, including relative preferences for using some muscles more than others, elastic mechanisms at joints due to the mechanical properties of tendons, ligaments, and muscles, and variable stiffness at joints depending on the task.  When used in a spacetime optimization framework, the parameters of this model define a wide range of styles of natural human movement.  Due to the complexity of biological motion, these style parameters are too difficult to design by hand.  To address this, we introduce Nonlinear Inverse Optimization, a novel algorithm for estimating optimization parameters from motion capture data.  Our method can extract the physical parameters from a single short motion sequence.  Once captured, this representation of style is extremely flexible: motions can be generated in the same style but performing different tasks, and styles may be edited to change the physical properties of the body. 
Machine Learning for Computer Graphics: A Manifesto and Tutorial| Abstract I argue that computer graphics can benefit from a deeper use of machine learning techniques.  I give an overview of what learning has to offer the graphics community, with an emphasis on Bayesian techniques.  I also attempt to address some misconceptions about learning, and to give a very brief tutorial on Bayesian reasoning. 
--- Final version to appear in Proc| NIPS 2003 Learning Non-Rigid 3D Shape from 2D Motion.  Abstract This paper presents an algorithm for learning the time-varying shape of a non-rigid 3D object from uncalibrated 2D tracking data.  We model shape motion as a rigid component (rotation and translation) combined with a nonrigid deformation.  Reconstruction is ill-posed if arbitrary deformations are allowed.  We constrain the problem by assuming that the object shape at each time instant is drawn from a Gaussian distribution.  Based on this assumption, the algorithm simultaneously estimates 3D shape and motion for each time frame, learns the parameters of the Gaussian, and robustly fills-in missing data points.  We then extend the algorithm to model temporal smoothness in object shape, thus allowing it to handle severe cases of missing data. 
Fast paint texture| Figure 1: Embossing a painting.  A height field is computed by rendering every brush stroke with a height texture.  A normal map is computed from the height field, and used for lighting the surface of the painting.  The entire process takes only a few seconds with current graphics hardware.  (The full painting is shown in Figure 5, top row. 
A SEGMENT-BASED PROBABILISTIC GENERATIVE MODEL OF SPEECH| ABSTRACT We present a purely time domain approach to speech processing which identifies waveform samples at the boundaries between glottal pulse periods (in voiced speech) or at the boundaries of unvoiced segments.  An efficient algorithm for inferring these boundaries and estimating the average spectra of voiced and unvoiced regions is derived from a simple probabilistic generative model.  Competitive results are presented on pitch tracking, voiced/unvoiced detection and timescale modification; all these tasks and several others can be performed using the single segmentation provided by inference in the model. 
Recovering Non-Rigid 3D Shape from Image Streams| Abstract This paper addresses the problem of recovering 3D nonrigid shape models from image sequences.  For example, given a video recording of a talking person, we would like to estimate a 3D model of the lips and the full face and its internal modes of variation.  Many solutions that recover 3D shape from 2D image sequences have been proposed; these so-called structure-from-motion techniques usually assume that the 3D object is rigid.  For example, Tomasi and Kanades' factorization technique is based on a rigid shape matrix, which produces a tracking matrix of rank 3 under orthographic projection.  We propose a novel technique based on a non-rigid model, where the 3D shape in each frame is a linear combination of a set of basis shapes.  Under this model, the tracking matrix is of higher rank, and can be factored in a three-step process to yield pose, configuration and shape.  To the best of our knowledge, this is the first model free approach that can recover from single-view video sequences nonrigid shape models.  We demonstrate this new algorithm on several video sequences.  We were able to recover 3D non-rigid human face and animal models with high accuracy. 
DRAFT - Final version to appear in Proc| of IEEE Conf.  Computer Vision and Pattern Recognition 2000 Recovering Non-Rigid 3D Shape from Image Streams.  Abstract This paper addresses the problem of recovering 3D nonrigid shape models from image sequences.  For example, given a video recording of a talking person, we would like to estimate a 3D model of the lips and the full face and its internal modes of variation.  Many solutions that recover 3D shape from 2D image sequences have been proposed; these so-called structure-from-motion techniques usually assume that the 3D object is rigid.  For example Tomasi and Kanade's factorization technique is based on a rigid shape matrix, which produces a tracking matrix of rank 3 under orthographic projection.  We propose a novel technique based on a non-rigid model, where the 3D shape in each frame is a linear combination of a set of basis shapes.  Under this model, the tracking matrix is of higher rank, and can be factored in a three step process to yield to pose, configuration and shape.  We demonstrate this simple but effective algorithm on video sequences of people and animals.  We were able to recover 3D non-rigid facial models with high accuracy. 
Paint By Relaxation| Abstract We use relaxation to produce painted imagery from images and video.  An energy function is first specified; we then search for a painting with minimal energy.  The appeal of this strategy is that, ideally, we need only specify what we want, not how to directly compute it.  Because the energy function is very difficult to optimize, we use a relaxation algorithm combined with search heuristics.  This formulation allows us to specify painting style by varying the relative weights of energy terms.  The basic energy function yields an economical style that conveys an image with few strokes.  This style produces greater temporal coherence for video than previous techniques.  The system allows as fine user control as desired: the user may interactively change the painting style, specify variations of style over an image, and/or add specific strokes to the painting. 
Learning Non-Rigid 3D Shape from 2D Motion| Abstract This paper presents an algorithm for learning the time-varying shape of a non-rigid 3D object from uncalibrated 2D tracking data.  We model shape motion as a rigid component (rotation and translation) combined with a non-rigid deformation.  Reconstruction is ill-posed if arbitrary deformations are allowed.  We constrain the problem by assuming that the object shape at each time instant is drawn from a Gaussian distribution.  Based on this assumption, the algorithm simultaneously estimates 3D shape and motion for each time frame, learns the parameters of the Gaussian, and robustly fills-in missing data points.  We then extend the algorithm to model temporal smoothness in object shape, thus allowing it to handle severe cases of missing data. 
I'| #Qu'#'. . . rhyv+#vp#Srqr. . . vt TDBBS6QC#((#8'^. . . +r# & H'qh'#( flu #6^t^+#
Learning Shared Latent Structure for Image Synthesis and Robotic Imitation| Abstract We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations.  The observation spaces are linked via a single, reduced-dimensionality latent variable space.  We present results from two datasets demonstrating the algorithms's ability to synthesize novel data from learned correspondences.  We first show that the method can be used to learn the nonlinear mapping between corresponding views of objects, filling in missing data as needed to synthesize novel views.  We then show that the method can be used to acquire a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 
Painterly Rendering with Curved Brush Strokes of Multiple Sizes| ABSTRACT We present a new method for creating an image with a handpainted appearance from a photograph, and a new approach to designing styles of illustration.  We "paint" an image with a series of spline brush strokes.  Brush strokes are chosen to match colors in a source image.  A painting is built up in a series of layers, starting with a rough sketch drawn with a large brush.  The sketch is painted over with progressively smaller brushes, but only in areas where the sketch differs from the blurred source image.  Thus, visual emphasis in the painting corresponds roughly to the spatial energy present in the source image.  We demonstrate a technique for painting with long, curved brush strokes, aligned to normals of image gradients.  Thus we begin to explore the expressive quality of complex brush strokes.  Rather than process images with a single manner of painting, we present a framework for describing a wide range of visual styles.  A style is described as an intuitive set of parameters to the painting algorithm that a designer can adjust to vary the style of painting.  We show examples of images rendered with different styles, and discuss long-term goals for expressive rendering styles as a general-purpose design tool for artists and animators. 
Painterly rendering for video and interaction| Abstract We present new methods for painterly video processing.  Based on our earlier still image processing technique, we "paint over" successive frames of animation, applying paint only in regions where the source video is changing.  Image regions with minimal changes, such as due to video noise, are also left alone, using a simple difference masking technique.  Optionally, brush strokes may be warped between frames using computed or procedural optical flow.  These methods produce video with a novel visual style distinct from previously demonstrated algorithms.  Without optical flow, the video gives the effect of a painting that has been repeatedly updated and photographed, similar to painton-glass animation.  We feel that this gives a subjective impression of the work of a human hand.  With optical flow, the painting surface flows and deforms to follow the shape of the world.  We have constructed an interactive painting exhibit, in which a painting is continually updated.  Viewers have found this to be a compelling experience, suggesting the promise of non-photorealistic rendering for creating compelling interactive visual experiences. 
Image analogies|
Painting By Relaxation|
Curve Analogies|
Shape and Materials by Example: A Photometric Stereo Approach|
Style-based inverse kinematics|
Keyframe-based tracking for rotoscoping and animation|
Compiling Java to a Typed Lambda-Calculus: A Preliminary Report|
Example-Based Stereo with General BRDFs|
Robust Model-Free Tracking of Non-Rigid Shape|
Painterly rendering with curved brush strokes multiple sizes|
