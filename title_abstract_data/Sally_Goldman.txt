Historical Performance of the U|S.  ESCO Industry: Results from the NAESCO Project Database.  ABSTRACT This study draws upon a database of ~800 projects that have been developed by U. S.  Energy Service Companies (ESCOs).  These projects represent a cumulative investment of ~$1. 4 billion in energy-efficiency projects and is the most comprehensive historical "snapshot" of the ESCO industry that is publicly available.  We provide information on the geographic distribution of ESCO projects, analyze project development activity by ESCOs over time and in various market segments, and analyze estimated vs.  actual, verified energy savings.  We also summarize key project characteristics in various market sectors (e. g. , project cost, floor area) and discuss the extent to which ESCOs relied on different types of utility programs in developing these projects.  We also comment upon some of the major policy implications from the study: (1) markets with significant private sector energy efficiency activity, and (2) the relationship between trends in private sector activity and public purpose or ratepayer-funded programs. 
Learning from a Consistently Ignorant Teacher| Abstract One view of computational learning theory is that of a learner acquiring the knowledge of a teacher.  We introduce a formal model of learning capturing the idea that teachers may have gaps in their knowledge.  The goal of the learner is still to acquire the knowledge of the teacher, but now the learner must also identify the gaps.  This is the notion of learning from a consistently ignorant teacher.  We consider the impact of knowledge gaps on learning, for example, monotone DNF and d-dimensional boxes, and show that learning is still possible.  Negatively, we show that knowledge gaps make learning conjunctions of Horn clauses as hard as learning DNF.  We also present general results describing when known learning algorithms can be used to obtain learning algorithms using a consistently ignorant teacher.  ``Consistency requires you to be as ignorant today as you were a year ago. "
A Theoretical and Empirical Study of a Noise-Tolerant Algorithm to Learn Geormetric Patterns| Abstract Developing the ability to recognize a landmark from a visual image of a robot's current location is a fundamental problem in robotics.  We describe a way in which the landmark matching problem can be mapped to that of learning a one-dimensional geometric pattern.  We present an efficient noisetolerant algorithm (designed using the statistical query model) to PAC-learn the class of one-dimensional geometric patterns.  Then we report results from an initial empirical study of our algorithm that provides at least some evidence that statistical query algorithms may be valuable for use in practice. 
Agnostic Learning of Geometric Patterns| Goldberg, Goldman, and Scott demonstrated how the problem of recognizing a landmark from a one-dimensional visual image can be mapped to that of learning a one-dimensional geometric pattern and gave a PAC algorithm to learn that class.  In this paper, we present an efficient on-line agnostic learning algorithm for learning the class of constant-dimensional geometric patterns.  Our algorithm can tolerate both classification and attribute noise.  By working in higher-dimensional spaces we can represent more features from the visual image in the geometric pattern.  Our mapping of the data to a geometric pattern, and hence our learning algorithm, is applicable to any data representable as a constant-dimensional array of values, e. g.  sonar data, temporal difference information, amplitudes of a waveform, or other pattern recognition data.  To our knowledge, these classes of patterns are more complex than any class of geometric patterns previously studied.  Also, our results are easily adapted to learn the union of fixed-dimensional boxes from multipleinstance examples.  Finally, our algorithms are tolerant of concept shift, where the target concept that labels the examples can change over time. 
Teaching a Smarter Learner \Lambda| Abstract We introduce a formal model of teaching in which the teacher is tailored to a particular learner, yet the teaching protocol is designed so that no collusion is possible.  Not surprisingly, such a model remedies the non-intuitive aspects of other models in which the teacher must successfully teach any consistent learner.  We prove that any class that can be exactly identified by a deterministic polynomial-time algorithm with access to a very rich set of example-based queries is teachable by a computationally unbounded teacher and a polynomialtime learner.  In addition, we present other general results relating this model of teaching to various previous results.  We also consider the problem of designing teacher/learner pairs in which both the teacher and learner are polynomial-time algorithms and describe teacher/learner pairs for the classes of 1-decision lists and Horn sentences. 
Noise-Tolerant Distribution-Free Learning of General Geometric Concepts| Abstract We present an efficient algorithm for PAC-learning a very general class of geometric concepts over ! d for fixed d.  More specifically, let T be a set of s halfspaces.  Let x = (x 1 ; : : : ; x d ) be an arbitrary point in ! d .  With each t 2 T we associate a boolean indicator function I t (x) which is 1 if and only if x is in the halfspace t.  The concept class, C d s , that we study consists of all concepts formed by any boolean function over I t 1 ; : : : ; I t s for t i 2 T where T is any set of s halfspaces.  The concept class we study here is much more general than any geometric concept class known to be PAC-learnable.  As special cases of our main result, we obtain learning algorithms for several new geometric concept classes.  While we consider geometric concepts defined by halfspaces, any polyhedron (not necessarily convex) defined by f faces can be formed by combining f halfspaces.  Thus our algorithm can also learn any boolean combination of a polynomial number of polyhedra each with a polynomial number of faces.  Even further, our results can be easily extended to efficiently learn any boolean combination of a polynomial number of concepts selected from any concept class C given that the VC-dimension of C is constant (for d constant) and there is a polynomial time algorithm to determine if there is a concept from C consistent with a given set of points.  We also present a statistical query version of our algorithm that can tolerate random classification noise for any noise rate strictly less than 1/2.  Finally we present a generalization of the standard ffl-net result of Haussler and Welzl [22] and apply it to give an alternative noise-tolerant algorithm for d = 2 based on geometric subdivisions. 
Learning Unions of Boxes with Membership and Equivalence Queries| Abstract We present two algorithms that use membership and equivalence queries to exactly identify the concepts given by the union of
Making Maximum Entropy Computations Easier By Adding Extra Constraints (Extended Abstract)| Abstract This paper presents a new way to compute the probability distribution with maximum entropy satisfying a set of
Agnostic Learning of Geometric Patterns (Extended Abstract)| Abstract Goldberg, Goldman, and Scott demonstrated how the problem of recognizing a landmark from a one-dimensional visual image can be mapped to that of learning a one-dimensional geometric pattern and gave a PAC algorithm to learn that class.  We present an on-line agnostic learning algorithm for learning the class of one-dimensional geometric patterns.  Since, when moving from the processed visual image to a one-dimensional pattern some key information is lost, we define a class of two-dimensional geometric patterns for which the important features from the visual image are incorporated in the geometric pattern, and show how to extend our agnostic learning algorithm to this class of two-dimensional patterns.  Next, we extend our construction to obtain an efficient agnostic learning algorithm (that tolerate classification and attribute noise) for the class of geometric patterns of arbitrary (constant) dimension d.  This mapping and learning algorithm is applicable to any data representable as a constant-dimensional array of values, e. g.  sonar data, temporal difference information, or amplitudes of a waveform.  To our knowledge, these classes of patterns are more complex than any class of geometric patterns previously studied.  Also our results are easily adapted to learn the union of fixed-dimensional boxes from multiple-instance
The Difficulty of Random Attribute Noise| Abstract This paper studies the robustness of pac learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the instances (and not the labels).  In the past, conflicting results on this subject have been obtained---the "best agreement" rule can only tolerate small amounts of noise, yet in some cases large amounts of noise can be tolerated.  We show that the truth lies somewhere between these two alternatives.  For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that pac learns monomials for any (unknown) noise rate less than 1=2.  Contrasting this positive result, we show that nonuniform random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise---no algorithm can tolerate more than a very small amount of such noise. 
Asking Questions to Minimize Errors| Abstract A number of efficient learning algorithms achieve exact identification of an unknown function from some class using membership and equivalence queries.  Using a standard transformation such algorithms can easily be converted to on-line learning algorithms that use membership queries.  Under such a transformation the number of equivalence queries made by the query algorithm directly corresponds to the number of mistakes made by the on-line algorithm.  In this paper we consider several of the natural classes known to be learnable in this setting, and investigate the minimum number of equivalence queries with accompanying counterexamples (or equivalently the minimum number of mistakes in the on-line model) that can be made by a learning algorithm that makes a polynomial number of membership queries and uses polynomial computation time.  We are able both to reduce the number of equivalence queries used by the previous algorithms and often to prove matching lower bounds.  As an example, consider the class of DNF formulas over n variables with at most k = O(log n) terms.  Previously, the algorithm of Blum and Rudich [BR92] provided the best known upper bound of 2 O(k) log n for the minimum number of equivalence queries needed for exact identification.  We greatly improve on this upper bound showing that exactly k counterexamples are needed if the learner knows k a priori and exactly k+1 counterexamples are needed if the learner does not know k a priori.  This exactly matches known lower bounds [BC92].  For many of our results we obtain a complete characterization of the tradeoff between the number of membership and equivalence queries needed for exact identification.  The classes we consider here are monotone DNF formulas, Horn sentences, O(log n)-term DNF formulas, read-k sat-j DNF formulas, read-once formulas over various bases, and deterministic finite automata. 
Piecemeal Learning of an Unknown Environment| Abstract.  We introduce a new learning problem: learning a graph by piecemeal search, in which the learner must return every so often to its starting point (for refueling, say).  We present two linear-time piecemeal-search algorithms for learning city-block graphs: grid graphs with rectangular obstacles. 
Exact Learning of Discretized Geometric Concepts \Lambda| Abstract We first present an algorithm that uses membership and equivalence queries to exactly identify a discretized geometric concept defined by the union of m axis-parallel boxes in ddimensional discretized Euclidean space where each coordinate can have n discrete values.  This algorithm receives at most md counterexamples and uses time and membership queries polynomial in m and log n for d any constant.  Furthermore, all equivalence queries can be formulated as the union of O(md log m) axis-parallel boxes.  Next, we show how to extend our algorithm to efficiently learn, from only equivalence queries, any discretized geometric concept generated from any number of halfspaces with any number of known (to the learner) slopes in a constant dimensional space.  In particular, our algorithm exactly learns (from equivalence queries only) unions of discretized axis-parallel boxes in constant dimensional space in polynomial time.  Further, this algorithm can be modified to handle a polynomial number of lies in the counterexamples provided by the environment.  Finally, we introduce a new complexity measure that better captures the complexity of the union of m boxes than simply the number of boxes and the dimension.  Our new measure, oe, is the number of segments in the target where a segment is a maximum portion of one of the sides of the target that lies entirely inside or entirely outside each of the other halfspaces defining the target.  We present a modification of our first algorithm that uses time and queries polynomial in oe and log n.  In fact, the time and queries (both membership and equivalence) used by this single algorithm are polynomial for either m or d constant.  \Lambda Portions of this paper appear in preliminary form in [16] and [7]. 
Learning from Examples with Unspecified Attribute Values (Extended Abstract)| Abstract We introduce the UAV learning model in which some of the attributes in the examples are unspecified.  In our model, an example x is classified positive (resp. , negative) if all possible assignments for the unspecified attributes result in a positive (resp. , negative) classification.  Otherwise the classification given to x is "?" (for unknown).  Given an example x in which some attributes are unspecified, the oracle UAV-MQ responds with the classification of x.  Given a hypothesis h, the oracle UAV-EQ returns an example x (that could have unspecified attributes) for which h(x) is incorrect.  We show that any class learnable in the exact model using the MQ and EQ oracles is also learnable in the UAV model using the MQ and UAV-EQ oracles as long as the counterexamples provided by the UAV-EQ oracle have a logarithmic number of unspecified attributes.  We also show that any class learnable in the exact model using the MQ and EQ oracles is also learnable in the UAV model using the UAV-MQ and UAV-EQ oracles as well as an oracle to evaluate a given boolean formula on an example with unspecified attributes.  (For some hypothesis classes such as decision trees and unate formulas the evaluation can be done in polynomialtime without an oracle. ) We also study the learnability of a universal class of decision trees under the UAV model and of DNF formulas under a representation-dependent variation of the UAV model. 
Learning One-Dimensional Geometric Patterns Under One-Sided Random Misclassification Noise| Abstract Developing the ability to recognize a landmark from a visual image of a robot's current location is a fundamental problem in robotics.  We consider the problem of PAC-learning the concept class of geometric patterns where the target geometric pattern is a configuration of k points in the real line.  Each instance is a configuration of n points on the real line, where it is labeled according to whether or not it visually resembles the target pattern.  To capture the notion of visual resemblance we use the Hausdorff metric.  Informally, two geometric patterns P and Q resemble each other under the Hausdorff metric, if every point on one pattern is "close" to some point on the other pattern.  We relate the concept class of geometric patterns to the landmark recognition problem and then present a polynomial-time algorithm that PAC-learns the class of one-dimensional geometric patterns when the negative examples are corrupted by a large amount of random misclassification noise.  An interesting feature of this problem is that the target concept is specified by a k-tuple of points on the real line, while the instances are specified by n-tuple of points on the real line where n is potentially much larger than k.  Although there are some important distinctions, in some sense, our work illustrates a concept class in a continuous domain in which a large fraction of each instance can be viewed as "irrelevant".  As in previous work on learning with a large number of irrelevant attributes in the Boolean domain, our algorithm's sample complexity depends polynomially on k and lg n. 
Can PAC Learning Algorithms Tolerate Random Attribute Noise?| Abstract This paper studies the robustness of pac learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the instances (and not the labels).  In the past, conflicting results on this subject have been obtained---the "best agreement" rule can only tolerate small amounts of noise, yet in some cases large amounts of noise can be tolerated.  We show that the truth lies somewhere between these two alternatives.  For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that pac learns monomials for any (unknown) noise rate less than 1=2.  Contrasting this positive result, we show that product random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise---no algorithm can tolerate more than a very small amount of such noise. 
Learning Binary Relations and Total Orders| Abstract We study the problem of learning a binary relation between two sets of objects or between a set and itself.  We represent a binary relation between a set of size n and a set of size m as an n \Theta m matrix of bits, whose (i# j)entry is 1 if and only if the relation holds between the corresponding elements of the twosets.  We present polynomial prediction algorithms for learning binary relations in an extended on-line learning model, where the examples are drawn by the learner, by a helpful teacher, by an adversary, or according to a uniform probability distribution on the instance space.  In the first part of this paper, we present results for the case that the matrix of the relation has at most k rowtypes.  We present upper and lower bounds on the number of prediction mistakes any prediction algorithm makes when learning such a matrix under the extended on-line learning model.  Furthermore, we describe a technique that simplifies the proof of expected mistake bounds against a randomly chosen query sequence.  In the second part of this paper, we consider the problem of learning a binary relation that is a total order on a set.  We describe a general technique using a fully polynomial randomized approximation scheme (fpras) to implement a randomized version of the halving algorithm.  We apply this technique to the problem of learning a total order, using a fpras for counting the number of extensions of a partial order,
EM-DD: An Improved Multiple-Instance Learning Technique| Abstract We present a new multiple-instance (MI) learning technique (EMDD) that combines EM with the diverse density (DD) algorithm.  EM-DD is a general-purpose MI algorithm that can be applied with boolean or real-value labels and makes real-value predictions.  On the boolean Musk benchmarks, the EM-DD algorithm without any tuning significantly outperforms all previous algorithms.  EM-DD is relatively insensitive to the number of relevant attributes in the data set and scales up well to large bag sizes.  Furthermore, EMDD provides a new framework for MI learning, in which the MI problem is converted to a single-instance setting by using EM to estimate the instance responsible for the label of the bag. 
On the Complexity of Teaching \Lambda| Abstract While most theoretical work in machine learning has focused on the complexity of learning, recently there has been increasing interest in formally studying the complexity of teaching .  In this paper we study the complexity of teaching by considering a variant of the on-line learning model in which a helpful teacher selects the instances.  We measure the complexity of teaching a concept from a given concept class by a combinatorial measure we call the teaching dimension.  Informally, the teaching dimension of a concept class is the minimum number of instances a teacher must reveal to uniquely identify any target
On-line Scheduling with Hard Deadlines (Extended Abstract)| Abstract.  We study non-preemptive, online admission control in the hard deadline model: each job must be either serviced prior to its deadline, or be rejected.  Our setting consists of a single resource that services an online sequence of jobs; each job has a length indicating the length of time for which it needs the resource, and a delay indicating the maximum time it can wait for the service to be started.  The goal is to maximize total resource utilization.  We obtain a series of results, under varying assumptions of job lengths and delays. 
WASHINGTON UNIVERSITY SEVER INSTITUTE OF TECHNOLOGY DEPARTMENT OF COMPUTER SCIENCE AN EMPIRICAL APPROACH TO REAL-VALUED MULTIPLE-INSTANCE CLASSIFICATIONS| The model of multiple-instance learning has recently arisen in the machine learning community as a new and important setting for several real-world problems, most notably drug design and discovery.  However, most work, both theoretical and empirical, has been aimed at classifying target objects in a Boolean, or binary, fashion.  Often we are more interested in quantitative (or at least comparative) measures for classifying targets.  This research examines a novel empirical method for real-valued classification of examples in machine learning.  We have devised a tunable offline algorithm that uses Bayesian probability theory to classify examples with a real-valued label on an interval, rather than a discrete label from a set.  We show how the algorithm performs in practice, describe some of its distinct advantages over a Boolean classification algorithm, and evaluate its promise as a new tool in the area of drug activity prediction. 
On Learning Unions of Pattern Languages and Tree Patterns| Abstract.  In this paper, we present efficient on-line algorithms for learning unions of a constant number of tree patterns, unions of a constant number of one-variable pattern languages, and unions of a constant number of pattern languages with fixed length substitutions.  Since we use a reduction to Winnow, our algorithms are robust against attribute noise.  By fixed length substitutions we mean that each variable x i must be substituted by terminal strings of constant length l(x i ).  Note that the length of the substitutions can be different for different variables (i. e.  it is not required that l(x i ) = l(x j )).  The approach we used is quite general and may be applicable to learning other pattern related concept classes.  For example, we could learn a more general pattern language class in which a penalty (i. e.  weight) is assigned to each violation of the rule that a terminal symbol cannot be changed or that a pair of variable symbols, of the same variable, must be substituted by the same terminal string.  An instance is positive if and only if the penalty incurred for violating these rules is below a given tolerable threshold.  We also show that if an arbitrary unions of pattern languages with fixed length substitutions can be learned efficiently then DNFs are efficiently learnable in the mistake bound model. 
Exact Identification of Read-once Formulas Using Fixed Points of Amplification Functions \Lambda| Abstract In this paper we describe a new technique for exactly identifying certain classes of read-once Boolean formulas.  The method is based on sampling the input-output behavior of the target formula on a probability distribution which is determined by the fixed point of the formula's amplification function (defined as the probability that a 1 is output by the formula when each input bit is 1 independently with probability p).  By performing various statistical tests on easily sampled variants of the fixedpoint distribution, we are able to efficiently infer all structural information about any logarithmic-depth formula (with high probability).  We apply our results to prove the existence of short universal identification sequences for large classes of formulas.  We also describe extensions of our algorithms to handle high rates of noise, and to
TCP Dynamic Acknowledgment Delay: Theory and Practice (Extended Abstract)| Abstract We study an on-line problem that is motivated by the networking problem of dynamically adjusting delays of acknowledgments in the Transmission Control Protocol (TCP).  The theoretical problem we study is the following.  There is a sequence of n packet arrival times A = ha1 ; : : : ; ani and a look-ahead coefficient L.  The goal is to partition A into k subsequences oe 1 ; oe 2 ; : : : ; oe k (where a subsequence end is defined by an acknowledgment) that minimizes a linear combination of the cost for the number of acknowledgments sent and the cost for the additional latency introduced by delaying acknowledgments.  At each arrival, an oracle provides the algorithm with the times of the next L arrivals.  First we give an O(n 2 ) dynamic programming algorithm for optimally solving the off-line problem.  Then we describe an on-line algorithm that greedily acknowledges exactly when the cost for an acknowledgment is less than the latency cost obtained by not acknowledging.  We show that for this algorithm there is a sequence of n packet arrivals for which it is \Omega \Gamma p n \Delta -competitive.  Next we present a second on-line algorithm which is a slight modification of the first that we prove is 2-competitive.  Let Copt be the cost of the optimal solution and let CA be the cost of the solution produced by algorithm A.  We then show that for any on-line algorithm A with any constant look-ahead L, CA 2Copt\Gamma c where c is a factor that can be made arbitrarily small with respect to Copt .  Thus, in the worst case, our result for L = 0 is the best possible even for on-line algorithms that can use any constant look-ahead.  We then give some initial empirical results using arrival sequences from real network traffic where we compare the two methods used in TCP for acknowledgment delay with our two on-line algorithms.  In all cases we examine performance with L = 0 and L = 1.  Finally, we consider an alternate definition for the latency cost in our objective function. 
: Proceedings of the 28th Annual ACM Symposium on Theory of Computing, to appear| c fl1996 ACM.  Abstract We present an efficient algorithm for PAC-learning a very general class of geometric concepts over ! d for fixed d.  More specifically, let T be any set of s halfspaces.  Let x = (x1 ; : : : ; xd) be an arbitrary point in ! d .  With each t 2 T we associate a boolean indicator function I t (x) which is 1 if and only if x is in the halfspace t.  The concept class, C d s , that we study consists of all concepts formed by any boolean function over I t 1 ; : : : ; I t s for t i 2 T .  This concept class is much more general than any geometric concept class known to be PAC-learnable.  Our results can be easily extended to efficiently learn any boolean combination of a polynomial number of concepts selected from any concept class C over ! d given that the VC-dimension of C has dependence only on d (and is thus constant for any constant d), and there is a polynomial time algorithm to determine if there is a concept from C consistent with a given set of labeled examples.  We also present a statistical query version of our algorithm that can tolerate random classification noise for any noise rate strictly less than 1/2.  Finally we present a generalization of the standard ffl-net result of Haussler and Welzl [25] and apply it to give an alternative noise-tolerant algorithm for d = 2 based on geometric subdivisions. 
Enhancing Supervised Learning with Unlabeled Data| Abstract In many practical learning scenarios, there is a small amount of labeled data along with a large pool of unlabeled data.  Many supervised learning algorithms have been developed and extensively studied.  We present a new "co-training" strategy for using unlabeled data to improve the performance of standard supervised learning algorithms.  Unlike much of the prior work, such as the co-training procedure of Blum and Mitchell (1998), we do not assume there are two redundant views both of which are sufficient for classification.  The only requirement our cotraining strategy places on each supervised learning algorithm is that its hypothesis partitions the example space into a set of equivalence classes (e. g.  for a decision tree each leaf defines an equivalence class).  We evaluate our co-training strategy via experiments using data from the UCI repository. 
Some Geometric Results in Semidefinite Programming| Abstract. The purpose of this paper is to develop certain geometric results concerning the feasible regions of Semidefinite Programs, called here Spectrahedra.  We first develop a characterization for the faces of spectrahedra.  More specifically, given a point x in a spectrahedron, we derive an expression for the unique face whose relative interior contains x.  Among other things, this is shown to yield characterizations for extreme points and extreme rays of spectrahedra.  We then introduce the notion of an algebraic polar of a spectrahedron, and present its relation to the usual geometric polar.  The results imply a "gap-free" optimality criterion for spectrahedral cones.  We also report some results on the polyhedrality of spectrahedra. 
Learning with Unreliable Boundary Queries| Abstract We introduce a model for learning from examples and membership queries in situations where the boundary between positive and negative examples is somewhat ill-defined.  In our model, queries near the boundary of a target concept may receive incorrect or "don't care" responses, and the distribution of examples has zero probability mass on the boundary region.  The motivation behind our model is that in many cases the boundary between positive and negative examples is complicated or "fuzzy. " However, one may still hope to learn successfully, because the typical examples that one sees do not come from that region.  We present several positive results in this new model.  We show how to learn the intersection of two arbitrary halfspaces when membership queries near the boundary may be answered incorrectly.  Our algorithm is an extension of an algorithm of Baum [7, 6] that learns the intersection of two halfspaces whose bounding planes pass through the origin in the PAC-with-membership-queries model.  We also describe algorithms for learning several subclasses of monotone DNF formulas. 
PAC Learning of One-Dimensional Patterns| Abstract.  Developing the ability to recognize a landmark from a visual image of a robot's current location is a fundamental problem in robotics.  We consider the problem of PAC-learning the concept class of geometric patterns where the target geometric pattern is a configuration of k points on the real line.  Each instance is a configuration of n points on the real line, where it is labeled according to whether or not it visually resembles the target pattern.  To capture the notion of visual resemblance we use the Hausdorff metric.  Informally, two geometric patterns P and Q resemble each other under the Hausdorff metric, if every point on one pattern is "close" to some point on the other pattern.  We relate the concept class of geometric patterns to the landmark recognition problem and then present a polynomial-time algorithm that PAC-learns the class of one-dimensional geometric patterns.  We also present some experimental results on how our algorithm performs. 
On-line Scheduling with Hard Deadlines \Lambda| Abstract We study non-preemptive, online admission control in the hard deadline model: each job must be either serviced prior to its deadline, or be rejected.  Our setting consists of a single resource that services an online sequence of jobs; each job has a length indicating the length of time for which it needs the resource, and a delay indicating the maximum time it can wait for the service to be started.  The goal is to maximize total resource utilization.  The jobs are non-preemptive and exclusive, meaning once a job begins, it runs to completion, and at most one job can use the resource at any time.  We obtain a series of results, under varying assumptions of job lengths and delays, which are summarized in the following table. 
Content-Based Image Retrieval Using Multiple-Instance Learning| Abstract We explore the application of machine learning techniques to the problem of contentbased image retrieval (CBIR).  Unlike most existing CBIR systems in which only global information is used or in which a user must explicitly indicate what part of the image is of interest, we apply the multiple-instance (MI) learning model to use a small number of training images to learn what images from the database are of interest to the user. 
A Co-evaluation Framework for Improving Segmentation Evaluation| ABSTRACT Object segmentation is an important preprocessing step for many target recognition applications.  Many segmentation methods have been studied, but there is still no satisfactory effectiveness measure which makes hard to compare different segmentation methods, or even different parameterizations of a single method.  good segmentation evaluation method not only would enable different approaches to be compared, but could also be integrated within the target recognition system to adaptively select the appropriate granularity of the segmentation which in turn could improve the recognition accuracy.  A few stand-alone effectiveness measures have been proposed, but these measures examine different fundamental criteria of the objects, or examine the same criteria in a different fashion, so they usually work well in some cases, but poorly in the others.  We propose a in which different effectiveness measures judge the performance of the segmentation in different ways, and their measures are combined by using machine learning approach which coalesces the results.  Experimental results demonstrate that our method performs better than the existing methods. 
Democratic Co-Learning| Abstract For many machine learning applications it is important to develop algorithms that use both labeled and unlabeled data.  We present democratic co-learning in which multiple algorithms instead of multiple views enable learners to label data for each other.  Our technique leverages off the fact that different learning algorithms have different inductive biases and that better predictions can be made by the voted majority.  We also present democratic priority sampling, a new example selection method for active learning. 
Quadratic Maps with Convex Images| Abstract.  Seeking exactness for "convex relaxation", we define a map f : ! n ! ! m to be ICON if its image f(! n ) is convex.  Analogously, f is termed LICON(AICON) if its image of every linear (every affine) subspace is convex.  This paper investigates the characterization of quadratic maps of these three types, and the complexity of recognizing them.  We give a characterization of quadratic ICON maps, and use it to show that ICON-map recognition is NP-Hard.  Then we develop a polynomial time algorithm for identifying quadratic LICON maps.  A characterization of quadratic AICON maps is established, that lends itself to an easy recognition algorithm. 
An Entropy-based Objective Evaluation Method for Image Segmentation| ABSTRACT Accurate image segmentation is important for many image, video and computer vision applications.  Over the last few decades, many image segmentation methods have been proposed.  However, the results of these segmentation methods are usually evaluated only visually, qualitatively, or indirectly by the eectiveness of the segmentation on the subsequent processing steps.  Such methods are either subjective or tied to particular applications.  They do not judge the performance of a segmentation method objectively, and cannot be used as a means to compare the performance of dierent segmentation techniques.  A few quantitative evaluation methods have been proposed, but these early methods have been based entirely on empirical analysis and have no theoretical grounding.  In this paper, we propose a novel objective segmentation evaluation method based on information theory.  The new method uses entropy as the basis for measuring the uniformity of pixel characteristics (luminance is used in this paper) within a segmentation region.  The evaluation method provides a relative quality score that can be used to compare dierent segmentations of the same image.  This method can be used to compare both various parameterizations of one particular segmentation method as well as fundamentally dierent segmentation techniques.  The results from this preliminary study indicate that the proposed evaluation method is superior to the prior quantitative segmentation evaluation techniques, and identify areas for future research in objective segmentation evaluation. 
Real-Valued Multiple-Instance Learning with Queries| Abstract.  The multiple-instance model was motivated by the drug activity prediction problem where each example is a possible con#guration for a molecule and each bag contains all likely configurations for the molecule.  While there has been a significant amount of theoretical and empirical research directed towards this problem, most research performed under the multiple-instance model is for concept learning.  However, binding anity between molecules and receptors is quantitative and hence a real-valued classification is preferable.  In this paper we initiate a theoretical study of real-valued multiple instance learning.  We prove that the problem of finding a target point consistent with a set of labeled multiple-instance examples (or bags) is NP-complete.  We also prove that the problem of learning from realvalued multiple-instance examples is as hard as learning DNF.  Another contribution of our work is in defining and studying a multiple-instance membership query (MI-MQ).  We give a positive result on exactly learning the target point for a multiple-instance problem in which the learner is provided with a MI-MQ oracle and a single adversarially selected bag. 
Deterrents to Energy Conservation in Public Housing|
Teaching a Smarter Learner|
On the Complexity of Teaching|
Exact Learning of Discretized Geometric Concepts|
A Space Efficient Greedy Triangulation Algorithm|
Exact Identification of Circuits Using Fixed Points of Amplification Functions (Abstract)|
Theory of linear programming, in Linear Equalities and Related Systems,|
Market trends in the US ESCO industry: results from the NAESCO database project|
Efficient methods for calculating maximum entropy distributions,|
Optimized homology searches of the gene and protein sequence data banks|
Learning from examples with unspecified attribute values|
On the Sample Complexity of Weak Learning|
The Power of Self-Directed Learning|
Online Scheduling with Hard Deadlines|
On-line analysis of the TCP acknowledgment delay problem|
Linear Inequalities and Related Systems,|
ISIS: Interface for a Semantic Information System|
Multi-instance learning of fuzzy geometric concepts|
Learning Binary Relations Using Weighted Majority Voting|
Learning unions of rectangles with membership and equivalence queries|
Exact learning of discretized concepts|
Multiple-Instance Learning of Real-Valued Data|
Learning -Term DNF Formulas with an Incomplete Membership Oracle|
Noise-Tolerant Parallel Learning of Geometric Concepts|
Learning union of rectangles with membership and equivalent queries|
On learning unions of pattern languages and tree patterns in the mistake bound model|
Asking Queries to Minimize Errors|
Exact identification of circuits using fixed points of amplification functions, In Proceedings of the Thirty-First Annual Symposium on Foundations of Computer Science,|
California Customer Load Reductions during the Electricity Crisis: Did They Help Keep the Lights On?|
Exact Identification of Read-Once Formulas Using Fixed Points of Amplification Functions|
Learning Binary Relations, Total Orders, and Read-once Formulas|
`A Non-Iterative Maximum Entropie Algorithm',|
Accumulation of mutant lamin A causes progressive changes in nuclear architecture in Hutchinson-Gilford progeria syndrome|
Market Trends in|
Complexity results in semidefinite programming|
An analysis of Spectrahedra|
