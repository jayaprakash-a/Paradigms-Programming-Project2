The Computational and Experimental Complexity of Gene Perturbations for Regulatory Network Search| Abstract Our primary interest is in determining how many gene perturbation experiments are required to determine the network of regulatory relations among any given set of genes, ignoring questions of uncertainty in statistical decisions.  Secondarily, we are interested in whether it is feasible to compute which further experiments will be most informative.  And, finally, since the sample sizes (number of expression measurements per gene) in such experiments are typically small, we are concerned with the stability of statistical decisions about differential expression given different statistical tests.  Various algorithms have been proposed for learning (partial) genetic regulatory networks through systematic measurements of differential expression in wild type versus strains in which expression of specific genes has been suppressed or enhanced, as well as for determining the most informative next experiment in a sequence.  While the behavior of these algorithms has been investigated for toy examples, the full computational complexity of the problem has not received sufficient attention.  We show that finding the true regulatory network requires (in the worst-case) exponentially many experiments (in the number of genes).  Perhaps more importantly, we provide an algorithm for determining the set of regulatory networks consistent with the observed data.  We then show that this algorithm is infeasible for realistic data (specifically, nine genes and ten experiments).  This infeasibility is not due to an algorithmic flaw, but rather to the fact that there are far too many networks consistent with the data (10 18 in the provided example).  We conclude that gene perturbation experiments are useful in confirming regulatory network models discovered by other techniques, but not a feasible search strategy.  The answers we find are far more pessimistic than has previously been suggested in the literature (e. g. , [Onami et al. , 2001; Ideker et al. , 2000]).  We show that, while perturbation experiments can eventually eliminate possible regulatory relations, they do not efficiently eliminate them.  We give an anytime algorithm for computing weakly monotonically increasing lower bounds on the number of alternative network explanations for the results of any set of gene perturbation experiments.  The lower bound is typically astronomical.  We illustrate the point by computing a lower bound---10 18 ---on the number of networks for 9 genes that are consistent with a recent series of gene perturbation experiments [Ideker et al. , 2001].  Finally, we argue that the computation of the most informative experiments can only be heuristic. 
Dynamical Causal Learning| Abstract Current psychological theories of human causal learning and judgment focus primarily on long-run predictions: two by estimating parameters of a causal Bayes nets (though for different parameterizations), and a third through structural learning.  This paper focuses on people's short-run behavior by examining dynamical versions of these three theories, and comparing their predictions to a real-world dataset. 
Learning the Causal Structure of Overlapping Variable Sets| Abstract.  In many real-world applications of machine learning and data mining techniques, one finds that one must separate the variables under consideration into multiple subsets (perhaps to reduce computational complexity, or because of a shift in focus during data collection and analysis).  In this paper, we use the framework of Bayesian networks to examine the problem of integrating the learning outputs for multiple overlapping datasets.  In particular, we provide rules for extracting causal information about the true (unknown) Bayesian network from the previously learned (partial) Bayesian networks.  We also provide the SLPR algorithm, which efficiently uses these previously learned Bayesian networks to guide learning of the full structure.  A complexity analysis of the #worst-case# scenario for the SLPR algorithm reveals that the algorithm is always less complex than a comparable #reference# algorithm (though no absolute optimality proof is known).  Although no #expectedcase# analysis is given, the complexity analysis suggests that (given the currently available set of algorithms) one should always use the SLPR algorithm, regardless of the underlying generating structure.  The results provided in this paper point to a wide range of open questions, which are briefly discussed.  1 The #Big Picture# Problem Modern data collection has advanced to the point that the size and complexity of our datasets regularly exceed the computational limits of our algorithms (on modern machines).  As a result, analysis is often rendered computationally tractable only when we consider proper subsets of the variables we have measured.  In addition, the variables thought to be relevant often change over the course of an investigation, both in the data collection and analysis phases.  For example, an unexpected correlation might suggest the need to find an unmeasured common cause.  When these changes occur, we want to use as much information as possible from earlier analyses to minimize duplication of effort.  Thus, in both of these situations, we must address the distinctive problems (such as integration of outputs and efficient use of prior learning in subsequent learning) that arise for learning on multiple overlapping sets of variables.  There is a further, more practical, motivation.  Many social science datasets have overlapping variables but the datapoints are unlabelled (for privacy reasons), so that there is no possible way to create a #complete# dataset.  For example, we might have a census dataset and an unemployment dataset, both of which have Income as a variable, but neither of which contains identifiers to be used for creation of a single, integrated dataset.  Hence, in these domains where there are substantial practical barriers to creating a unified dataset, the problem of integrating the learning outputs becomes particularly salient.  At the same time as we face these difficulties, we want our analysis techniques to reveal causal relationships.  Causal information allows for predictions about the (probabilistic) outcomes of interventions, and is more easily understood by human users of machine learning techniques.  Hence, if possible, we want to use a representation that allows for causal inference and prediction.  To better understand these problems, we can try to express them more formally.  Let V be the full set of variables under consideration.  We assume that the variables are either all discrete or all continuous, though in the former case they need not have the same number of values.  Let S 1 ; :::; S n be (nonempty) subsets of V such that S 1 \ ::: \ S n 6= ;.  We further assume that, throughout all stages of learning, there is some stationary generating process producing the data, and that we have sufficient data that the sample statistics are the same as the population statistics.  In this paper, we will be concerned with the following two questions: 1.  If we do not have joint data over V , but we do have the outputs of some reliable, correct learning process (e. g. , a machine learning algorithm) on S 1 ; :::; S n , what can we learn about the relationships among V as a whole? That is, if we can only learn the causal structure of the subsets (because of lack of data), what can we learn (if anything) about the full structure underlying V ? 2.  If we do have joint data over V , as well as the learning outputs, how can we efficiently learn the full structure for V ? That is, how (if at all) can we use learning results over subsets to guide the learning for V as a whole? For example, we might have three datasets (drawn from the same population) over the following variables: 1.  S 1 = fEducation; ParentalEducation; Incomeg; 2.  S 2 = fEducation; Housing; Incomeg; and 3.  S 3 = fEducation; Age; NumberOfChildren; Incomeg.  In this example, the above two questions correspond to: (1) Given just these three datasets, what can be learned about the interrelationships among the six variables (including pairs, like Housing and Age, that do not appear in the same dataset)? and (2) How could we efficiently learn the full causal structure if we actually had a complete dataset? On one level, it will be surprising if the answer to question 1 is anything other than #nothing. # Any positive answer implies that we can determine something
A theory of causal learning in children: Causal maps and Bayes nets| Abstract We outline a cognitive and computational account of causal learning in children.  We propose that children employ specialized cognitive systems that allow them to recover an accurate "causal map" of the world: an abstract, coherent, learned representation of the causal relations among events.  This kind of knowledge can be perspicuously understood in terms of the formalism of directed graphical causal models, or "Bayes nets".  Children's causal learning and inference may involve computations similar to those for learning causal Bayes nets and for predicting with them.  Experimental results suggest that 2- to 4-year-old children construct new causal maps and that their learning is consistent with the Bayes net formalism. 
Dynamical Causal Learning| Abstract Current psychological theories of human causal learning and judgment focus primarily on long-run predictions: two by estimating parameters of a causal Bayes nets (though for different parameterizations), and a third through structural learning.  This paper focuses on people's short-run behavior by examining dynamical versions of these three theories, and comparing their predictions to a real-world dataset. 
Phenotype and genotype heterogeneity in autosomal dominant polycystic kidney disease|
in press)| A theory of causal learning in children: Causal maps and Bayes nets. 
Linearity Properties of Bayes Nets with Binary Variables|
#E#cient Integration of Novel Variables in Bayes Net Learning|# Technical report: Institute for Human & Machine Cognition,. 
Forthcoming|
The epistemology of causal judgment|
Inferring hidden causes|
Equilibria of the Rescorla-Wagner model|
under revision)|
in press)| Causal learning from observations and manipulations. 
