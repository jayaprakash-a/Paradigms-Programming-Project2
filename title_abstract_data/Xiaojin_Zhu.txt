Model Selection with Unlabeled Data for Maximum Entropy Models| Abstract We tried to apply the Pythagorean property on a sequence of increasingly complex maximum entropy models to detect overfitting, and hence select the model with the appropriate level of complexity.  It didn't work. 
Kernel Conditional Random Fields: Representation, Clique Selection, and Semi-Supervised Learning| Abstract Kernel conditional random fields are introduced as a framework for discriminative modeling of graph-structured data.  A representer theorem for conditional graphical models is given which shows how kernel conditional random fields arise from risk minimization procedures defined using Mercer kernels on labeled graphs.  A procedure for greedily selecting cliques in the dual representation is then proposed, which allows sparse representations.  By incorporating kernels and implicit feature spaces into conditional graphical models, the framework enables semi-supervised learning algorithms for structured data through the use of graph kernels.  The clique selection and semisupervised methods are demonstrated in synthetic data experiments, and are also applied to the problem of protein secondary structure prediction. 
Kernel conditional random fields: representation and clique selection| Abstract Kernel conditional random fields (KCRFs) are introduced as a framework for discriminative modeling of graph-structured data.  A representer theorem for conditional graphical models is given which shows how kernel conditional random fields arise from risk minimization procedures defined using Mercer kernels on labeled graphs.  A procedure for greedily selecting cliques in the dual representation is then proposed, which allows sparse representations.  By incorporating kernels and implicit feature spaces into conditional graphical models, the framework enables semi-supervised learning algorithms for structured data through the use of graph kernels.  The framework and clique selection methods are demonstrated in synthetic data experiments, and are also applied to the problem of protein secondary structure prediction. 
Inducing A Distance Metric From User Preferences For Clustering| Abstract Traditional clustering algorithms cannot incorporate domain expert's preferences into the process of clustering.  Since one major goal of clustering is for the experts to gain insight into a dataset, it makes sense to allow experts to express opinions to guide clustering in some ways.  We propose a mechanism for the experts to express a small number of clustering preferences that they wish to be true.  We devise an algorithm which takes into account the expert constraints and guides the clustering towards them by inducing an appropriate distance metric, so that the final clustering maximally satisfies the expert preferences while is still reasonably good in traditional measures. 
Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning| Abstract We present an algorithm based on convex optimization for constructing kernels for semi-supervised learning.  The kernel matrices are derived from the spectral decomposition of graph Laplacians, and combine labeled and unlabeled data in a systematic fashion.  Unlike previous work using diffusion kernels and Gaussian random field kernels, a nonparametric kernel approach is presented that incorporates order constraints during optimization.  This results in flexible kernels and avoids the need to choose among different parametric forms.  Our approach relies on a quadratically constrained quadratic program (QCQP), and is computationally feasible for large datasets.  We evaluate the kernels on real datasets using support vector machines, with encouraging results. 
Multimodal people ID for a multimedia meeting browser| ABSTRACT A meeting browser is a system that allows users to review a multimedia meeting record from a variety of indexing methods.  Identification of meeting participants is essential for creating such a multimedia meeting record.  Moreover, knowing who is speaking can enhance the performance of speech recognition and indexing meeting transcription.  In this paper, we present an approach that identifies meeting participants by fusing multimodal inputs.  We use face ID, speaker ID, color appearance ID, and sound source directional ID to identify and track meeting.  After describing the different modules in detail, we will discuss a framework for combining the information sources.  Integration of the multimodal people ID into the multimedia meeting browser is in its preliminary stage. 
IMPROVING TRIGRAM LANGUAGE MODELING WITH THE WORLD WIDE WEB| ABSTRACT We propose a novel method for using the World Wide Web to acquire trigram estimates for statistical language modeling.  We submit an N-gram as a phrase query to web search engines.  The search engines return the number of web pages containing the phrase, from which the N-gram count is estimated.  The N-gram counts are then used to form web-based trigram probability estimates.  We discuss the properties of such estimates, and methods to interpolate them with traditional corpus based trigram estimates.  We show that the interpolated models improve speech recognition word error rate significantly over a small test set. 
Universalizing Speech: Notes from the USI Project| Abstract This paper discusses progress in designing a standardized interface for speech interaction with simple machines -- the Universal Speech Interface (USI) project.  We discuss the motivation for such a design and issues that must be addressed by such an interface.  We present our current proposals for handling these issues, and comment on the usability of these approaches based on user interactions with the system.  Finally, we discuss future work and plans for the USI project. 
Label Propagation for Eukaryotic Splice Junction Identification| Abstract We study the use of unlabeled data to help classification in a bioinformatic problem of splice junction identification.  We derive two distance measures for DNA segments.  With these distance measures, we compute the accuracy of label propagation algorithm which incorporates unlabeled data.  We compare the accuracy to several baselines.  We found that for this dataset, using unlabeled data does not significantly improve accuracy.  We give a possible reason for the observation. 
Thesis Proposal: Learning from Labeled and Unlabeled Data with Gaussian Random Fields| Abstract One hurdle in supervised learning for many tasks is the diculty in obtaining labeled data.  Unlabeled data may be relatively easy to collect, but traditionally it was ignored in supervised learning.  Recent studies show benefit of including unlabeled data.  I propose to study the statistical learning frameworks that use both labeled and unlabeled data in so called semi-supervised learning, and its application to natural language processing.  I start with a short survey of the state-of-the-art approaches in learning from labeled and unlabeled data, analyzing the assumptions made by various methods.  Next the main mathematical model is introduced, which represents labeled and unlabeled data as vertices in a weighted graph, with edge weights encoding the similarity between instances.  The learning problem is then formulated in terms of a Gaussian random field on this graph.  This model is able to use the distribution of unlabeled data to improve classification.  Moreover, it leads to a natural strategy of active learning, which is also important when labeled data is scarce.  The model has several nice properties.  It has intimate connections with random walks, electric networks, and spectral graph theory.  The mean of the field is a harmonic functions, and can be eciently computed using matrix methods or belief propagation.  Class priors and the predictions of classifiers obtained by supervised learning can be incorporated with the Gaussian field model to improve prediction.  Hyperparameter learning is also feasible by entropy minimization, which can be shown to perform feature selection.  Preliminary experimental results on synthetic data, OCR handwritten digit recognition, and text classification tasks are presented.  Several open questions are posed at the end. 
Semi-Supervised Learning: From Gaussian Fields to Gaussian Processes| Abstract We show that the
Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions| Abstract An approach to semi-supervised learning is proposed that is based on a Gaussian random field model.  Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances.  The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation.  The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory.  We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning.  We also propose a method of parameter learning by entropy minimization, and show the algorithm's ability to perform feature selection.  Promising experimental results are presented for synthetic data, digit classification, and text classification tasks. 
Clustering with Expert Opinion| Abstract Traditional clustering algorithms cannot incorporate domain expert's opinion into the process of clustering.  Since one major goal of clustering is for the experts to gain insight into a dataset, it makes sense to allow experts to have some degree of control over the cluster results.  We propose a mechanism for the experts to request a small number of clustering constraints that they wish to be true.  We devise an algorithm which takes into account the expert constraints and guides the clustering towards them, so that the final clustering satisfies the maximal number of expert constraints while is still reasonably good in traditional measures.  We plan to work on the theory and implementation of this idea, and test it on both synthetic and real world datasets. 
WHOLE-SENTENCE EXPONENTIAL LANGUAGE MODELS: A VEHICLE FOR LINGUISTIC-STATISTICAL INTEGRATION| ABSTRACT We introduce an exponential language model which models a whole sentence or utterance as a single unit.  By avoiding the chain rule, the model treats each sentence as a "bag of features", where features are arbitrary computable properties of the sentence.  The new model is computationally more efficient, and more naturally suited to modeling global sentential phenomena, than the conditional exponential (e. g.  Maximum Entropy) models proposed to date.  Using the model is straightforward.  Training the model requires sampling from an exponential distribution.  We describe the challenge of applying Monte Carlo Markov Chain (MCMC) and other sampling techniques to natural language, and discuss smoothing and step-size selection.  We then present a novel procedure for feature selection, which exploits discrepancies between the existing model and the training corpus.  We demonstrate our ideas by constructing and analyzing competitive models in the Switchboard domain, incorporating lexical and syntactic information.  1.  MOTIVATION AND OUTLINE Conventional statistical language models estimate the probability of a sentence # by using the chain rule to decompose it into a product of conditional probabilities: Pr ##### def # Pr ################# # # # ### # Pr ### ### ########### ### ### def # # # ### # Pr ### # # # # # where # # def ### # ### ##### # # ### # # is the history when predicting word # # .  The vast majority of work in statistical
Combining Active Learning and Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions| Abstract Active and semi-supervised learning are important techniques when labeled data are scarce.  We combine the two under a Gaussian random field model.  Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances.  The semi-supervised learning problem is then formulated in terms of a Gaussian random field on this graph, the mean of which is characterized in terms of harmonic functions.  Active learning is performed on top of the semisupervised learning scheme by greedily selecting queries from the unlabeled data to minimize the estimated expected classification error (risk); in the case of Gaussian fields the risk is efficiently computed using matrix methods.  We present experimental results on synthetic data, handwritten digit recognition, and text classification tasks.  The active learning scheme requires a much smaller number of queries to achieve high accuracy compared with random query selection. 
TOWARDS A UNIVERSAL SPEECH INTERFACE| ABSTRACT We discuss our ongoing attempt to design and evaluate universal human-machine speech-based interfaces.  We describe one such initial design suitable for database retrieval applications, and discuss its implementation in a movie information application prototype.  Initial user studies provided encouraging results regarding the usability of the design, as well as suggest some questions for further investigation. 
INTERACTIVE FEATURE INDUCTION AND LOGISTIC REGRESSION FOR WHOLE SENTENCE EXPONENTIAL LANGUAGE MODELS| ABSTRACT Whole sentence exponential language models directly model the probability of an entire sentence using arbitrary computable properties of that sentence.  We present an interactive methodology for feature induction, and demonstrate it in the simple but common case of a trigram baseline, focusing on features that capture the linguistic notion of semantic coherence.  We then show how parametric regression can be used in this setup to efficiently estimate the model's parameters, whereas non-parametric regression can be used to construct more powerful exponential models from the raw features. 
A Unified Design for Human-Machine Voice Interaction| ABSTRACT We describe a unified design for voice interaction with simple machines; discuss the motivation for and main features of the approach, include a short sample interaction, and report the results of two preliminary experiments. 
Towards Semi-Supervised Classification with Markov Random Fields| Abstract We investigate the use of Boltzmann machines in semi-supervised classification.  We treat the labeled / unlabeled dataset as a Markov random field, and derive a Boltzmann machine learning algorithm for it to learn the feature weights, label noise and labels for unlabeled data all at once.  We present some Markov chain Monte Carlo methods needed for learning, and discuss the need to regularize model parameters.  Preliminary experimental results are presented. 
Multimodal meeting tracker,|
Towards a Multimodal Meeting Record|
Improving trigram langauge modeling with the world wide web,|
Linguistic features for whole sentence maximum entropy language models|
"Multimodal People ID for a Multimedia Meeting Browser," presented at ACM Multimedia '99,|
