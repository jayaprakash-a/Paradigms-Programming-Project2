A Probabilistic Approach to Inference with Limited Information in Sensor Networks| ABSTRACT We present a methodology for a sensor network to answer queries with limited and stochastic information using probabilistic techniques.  This capability is useful in that it allows sensor networks to answer queries effectively even when present information is partially corrupt and when more information is unavailable or too costly to obtain.  We use a Bayesian network to model the sensor network and Markov Chain Monte Carlo sampling to perform approximate inference.  We demonstrate our technique on the specific problem of determining whether a friendly agent is surrounded by enemy agents and present simulation results for it. 
Robust Monte Carlo localization for mobile robots| Abstract Mobile robot localization is the problem of determining a robot's pose from sensor data.  Monte Carlo Localization is a family of algorithms for localization based on particle filters, which are approximate Bayes filters that use random samples for posterior estimation.  Recently, they have been applied with great success for robot localization.  Unfortunately, regular particle filters perform poorly in certain situations.  Mixture-MCL, the algorithm described here, overcomes these problems by using a "dual" sampler, integrating two complimentary ways of generating samples in the estimation.  To apply this algorithm for mobile robot localization, a kd-tree is learned from data that permits fast dual sampling.  Systematic empirical results obtained using data collected in crowded public places illustrate superior performance, robustness, and efficiency, when compared to other state-of-the-art localization algorithms. 
1 Explanation Based Learning for Mobile Robot Perception| Abstract Although machine learning techniques have been applied with remarkable success to several problems of computer perception and vision, most of these problems have been fairly simple in nature.  The difficulty with scaling up to more complex tasks is that inductive learning methods require a very large number of training examples in order to generalize correctly from complex sensor data.  This chapter proposes an approach to overcoming this difficulty, by relying on previously learned information to augment the available training data.  In particular, we consider the task faced by a mobile robot learning to recognize new objects within an already-familiar environment.  Because the robot has previously operated within this environment (here the corridors of a particular building), it has already had the opportunity to learn certain regularities that can be useful in subsequent learning tasks.  Given a new task, such as learning to recognize the distance to the next door in the corridor, knowledge of these regularities enables the system to learn the new task more accurately from a limited quantity of new training data.  We describe the Explanation-Based Neural Network (EBNN) algorithm for utilizing previously learned knowledge, and examine its performance for the mobile robot perception task of door recognition in a familiar corridor based on color vision and sonar sensor data.  Experimental results indicate that EBNN is able to generalize more accurately than purely inductive methods such as Backpropagation, even when its prior knowledge is only approximately correct. 
Bayesian Network Induction via Local Neighborhoods| Abstract In recent years, Bayesian networks have become highly successful tool for diagnosis, analysis, and decision making in real-world domains.  We present an efficient algorithm for learning Bayes networks from data.  Our approach constructs Bayesian networks by firstidentifying each node's Markov blankets, then connecting nodes in a maximally consistent way.  In contrast to the majority of work, which typically uses hill-climbing approaches that may produce dense and causally incorrect nets, our approach yields much more compact causal networks by heeding independencies in the data.  Compact causal networks facilitate fast inference and are also easier to understand.  We prove that under mild assumptions, our approach requires time polynomial in the size of the data and the number of nodes.  A randomized variant, also presented here, yields comparable results at much higher speeds. 
Structure from Motion without Correspondence| Abstract A method is presented to recover 3D scene structure and camera motion from multiple images without the need for correspondence information.  The problem is framed as finding the maximum likelihood structure and motion given only the 2D measurements, integrating over all possible assignments of 3D features to 2D measurements.  This goal is achieved by means of an algorithm which iteratively refines a probability distribution over the set of all correspondence assignments.  At each iteration a new structure from motion problem is solved, using as input a set of 'virtual measurements' derived from this probability distribution.  The distribution needed can be efficiently obtained by Markov Chain Monte Carlo sampling.  The approach is cast within the framework of Expectation-Maximization,which guarantees convergence to a local maximizer of the likelihood.  The algorithm works well in practice, as will be demonstrated using results on several real image sequences. 
Efficient Exploration In Reinforcement Learning| Abstract Exploration plays a fundamental role in any active learning system.  This study evaluates the role of exploration in active learning and describes several local techniques for exploration in finite, discrete domains, embedded in a reinforcement learning framework (delayed reinforcement).  This paper distinguishes between two families of exploration schemes: undirected and directed exploration.  While the former family is closely related to random walk exploration, directed exploration techniques memorize exploration-specific knowledge which is used for guiding the exploration search.  In many finite deterministic domains, any learning technique based on undirected exploration is inefficient in terms of learning time, i. e.  learning time is expected to scale exponentially with the size of the state space (Whitehead, 1991b) .  We prove that for all these domains, reinforcement learning using a directed technique can always be performed in polynomial time, demonstrating the important role of exploration in reinforcement learning.  (The proof is given for one specific directed exploration technique named counter-based exploration. ) Subsequently, several exploration techniques found in recent reinforcement learning and connectionist adaptive control literature are described.  In order to trade off efficiently between exploration and exploitation -a trade-off which characterizes many real-world active learning tasks -- combination methods are described which explore and avoid costs simultaneously.  This includes a selective attention mechanism, which allows smooth switching between exploration and exploitation.  All techniques are evaluated and compared on a discrete reinforcement learning task (robot navigation).  The empirical evaluation is followed by an extensive discussion of benefits and limitations of this work. 
To appear in: AI-based Mobile Robots: Case studies of successful robot systems| Abstract This chapter surveys basic methods for
A General Feed-Forward Algorithm for Gradient Descent in Connectionist Networks| Abstract An extended feed-forward algorithm for recurrent connectionist networks is presented.  This algorithm, which works locally in time, is derived both for discrete-in-time networks and for continuous networks.  Several standard gradient descent algorithms for connectionist networks (e. g.  [48], [30], [28] [15], [34]), especially the backpropagation algorithm [36], are mathematically derived as a special case of this general algorithm.  The learning algorithm presented in this paper is a superset of gradient descent learning algorithms for multilayer networks, recurrent networks and time-delay networks that allows any combinations of their components.  In addition, the paper presents feed-forward approximation procedures for initial activations and external input values.  The former one is used for optimizing starting values of the so-called context nodes, the latter one turned out to be very useful for finding spurious input attractors of a trained connectionist network.  Finally, we compare time, processor and space complexities of this algorithm with backpropagation for an unfolded-in-time network and present some simulation results. 
Point-based value iteration: An anytime algorithm for POMDPs| Abstract This paper introduces the Point-Based Value Iteration (PBVI) algorithm for POMDP planning.  PBVI approximates an exact value iteration solution by selecting a small set of representative belief points and then tracking the value and its derivative for those points only.  By using stochastic trajectories to choose belief points, and by maintaining only one value hyper-plane per point, PBVI successfully solves large problems: we present results on a robotic laser tag problem as well as three test domains from the literature. 
Learning to Classify Text from Labeled and Unlabeled Documents| Abstract In many important text classification problems, acquiring class labels for training documents is costly, while gathering large quantities of unlabeled data is cheap.  This paper shows that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents.  We present a theoretical argument showing that, under common assumptions, unlabeled data contain information about the target function.  We then introduce an algorithm for learning from labeled and unlabeled text based on the combination of Expectation-Maximization with a naive Bayes classifier.  The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents; it then trains a new classifier using the labels for all the documents, and iterates to convergence.  Experimental results, obtained using text from three different realworld tasks, show that the use of unlabeled data reduces classification error by up to 33%. 
Visibility-Based Pursuit-Evasion with Limited Field of View| Abstract We study a form of the pursuit-evasion problem, in which one or more searchers must move through a given environment so as to guarantee detection of any and all evaders, which can move arbitrarily fast.  Our goal is to develop techniques for coordinating teams of robots to execute this task in
NetCube: A Scalable Tool for Fast Data Mining and Compression| Abstract We propose an novel method of computing and storing DataCubes.  Our idea is to use Bayesian Networks, which can generate approximate counts for any query combination of attribute values and "don't cares. " A Bayesian network represents the underlying joint probability distribution of the data that were used to generate it.  By means of such a network the proposed method, NetCube, exploits correlations among attributes.  Our proposed preprocessing algorithm scales linearly on the size of the database, and is thus scalable; it is also parallelizable with a straightforward parallel implementation.  Moreover, we give an algorithm to estimate counts of arbitrary queries that is fast (constant on the database size).  Experimental results show that NetCubes have fast generation and use (a few minutes preprocessing time per 100,000 records and less than a second query time), achieve excellent compression (at least 1800:1 compression ratios on real data) and have low reconstruction error (less than 5% on average).  Moreover, our method naturally allows for visualization and data mining, at no extra cost. 
Approximate Solutions for Partially Observable Stochastic Games with Common Payoffs| Abstract Partially observable decentralized decision making in robot teams is fundamentally different from decision making in fully observable problems.  Team members cannot simply apply single-agent solution techniques in parallel.  Instead, we must turn to game theoretic frameworks to correctly model the problem.  While partially observable stochastic games (POSGs) provide a solution model for decentralized robot teams, this model quickly becomes intractable.  We propose an algorithm that approximates POSGs as a series of smaller, related Bayesian games, using heuristics such as ####### to provide the future discounted value of actions.  This algorithm trades off limited look-ahead in uncertainty for computational feasibility, and results in policies that are locally optimal with respect to the selected heuristic.  Empirical results are provided for both a simple problem for which the full POSG can also be constructed, as well as more complex, robot-inspired, problems. 
ON PLANNING AND EXPLORATION IN NON-DISCRETE ENVIRONMENTS| Abstract The application of reinforcement learning to control problems has received considerable attention in the last few years [And86, Bar89, Sut84].  In general there are two principles to solve reinforcement learning problems: direct and indirect techniques, both having their advantages and disadvantages.  We present a system that combines both methods [TML91, TML90].  By interaction with an unknown environment a world model is progressively constructed using the backpropagation algorithm.  For optimizing actions with respect to future reinforcement planning is applied in two steps: An experience network proposes a plan which is subsequently optimized by gradient descent with a chain of model networks.  While operating in a goal-oriented manner due to the planning process the experience network is trained.  Its accumulating experience is fed back into the planning process in form of initial plans, such that planning can be gradually reduced.  In order to ensure complete system identification, a competence network is trained to predict the accuracy of the model.  This network enables purposeful exploration of the world.  The appropriateness of this approach to reinforcement learning is demonstrated by three different control experiments, namely a target tracking, a robotics and a pole balancing task. 
Spoken Dialogue Management Using Probabilistic Reasoning| ################# 21810 -56 ############# # #!#"##
Auction Mechanism Design for Multi-Robot Coordination| Abstract The design of cooperative multi-robot systems is a highly active research area in robotics.  Two lines of research in particular have generated interest: the solution of large, weakly coupled MDPs, and the design and implementation of market architectures.  We propose a new algorithm which joins together these two lines of research.  For a class of coupled MDPs, our algorithm automatically designs a market architecture which causes a decentralized multi-robot system to converge to a consistent policy.  We can show that this policy is the same as the one which would be produced by a particular centralized planning algorithm.  We demonstrate the new algorithm on three simulation examples: multi-robot towing, multi-robot path planning with a limited fuel resource, and coordinating behaviors in a game of paint ball. 
Real-time Fault Detection and Situational Awareness for Rovers: Report on the Mars Technology Program Task| Abstract--- An increased level of autonomy is critical for meeting many of the goals of advanced planetary rover
Robotic Mapping with Polygonal Random Fields| Abstract Two types of probabilistic maps are popular in the mobile robotics literature: occupancy grids and geometric maps.  Occupancy grids have the advantages of simplicity and speed, but they represent only a restricted class of maps and they make incorrect independence assumptions.  On the other hand, current geometric approaches, which characterize the environment by features such as line segments, can represent complex environments compactly.  However, they do not reason explicitly about occupancy, a necessity for motion planning; and, they lack a complete probability model over environmental structures.  In this paper we present a probabilistic mapping technique based on polygonal random fields (PRF), which combines the advantages of both approaches.  Our approach explicitly represents occupancy using a geometric representation, and it is based upon a consistent probability distribution over environments which avoids the incorrect independence assumptions made by occupancy grids.  We show how sampling techniques for PRFs can be applied to localized laser and sonar data, and we demonstrate significant improvements in mapping performance over occupancy grids. 
Extracting Rules from Artificial Neural Networks with Distributed Representations| Abstract Although artificial neural networks have been applied in a variety of real-world scenarios with remarkable success, they have often been criticized for exhibiting a low degree of human comprehensibility.  Techniques that compile compact sets of symbolic rules out of artificial neural networks offer a promising perspective to overcome this obvious deficiency of neural network representations.  This paper presents an approach to the extraction of if-then rules from artificial neural networks.  Its key mechanism is validity interval analysis, which is a generic tool for extracting symbolic knowledge by propagating rule-like knowledge through Backpropagation-style neural networks.  Empirical studies in a robot arm domain illustrate the appropriateness of the proposed method for extracting rules from networks with real-valued and distributed representations. 
Anytime Dynamic A*: An Anytime, Replanning Algorithm| Abstract We present a graph-based planning and replanning
Finding Structure in Reinforcement Learning| Abstract Reinforcement learning addresses the problem of learning to select actions in order to maximize one's performance in unknown environments.  To scale reinforcement learning to complex real-world tasks, such as typically studied in AI, one must ultimately be able to discover the structure in the world, in order to abstract away the myriad of details and to operate in more tractable problem spaces.  This paper presents the SKILLS algorithm.  SKILLS discovers skills, which are partially defined action policies that arise in the context of multiple, related tasks.  Skills collapse whole action sequences into single operators.  They are learned by minimizing the compactness of action policies, using a description length argument on their representation.  Empirical results in simple grid navigation tasks illustrate the successful discovery of structure in reinforcement learning. 
FastSLAM 2|0: An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges.  Abstract In [15] , Montemerlo et al.  proposed an algorithm called
Finding and Optimizing Solvable Priority Schemes for Decoupled Path Planning Techniques for Teams of Mobile Robots| Abstract Coordinating the motion of multiple mobile robots is one of the fundamental problems in robotics.  The predominant algorithms for coordinating teams of robots are decoupled and prioritized, thereby avoiding combinatorially hard planning problems typically faced by centralized approaches.  While these methods are very efficient, they have two major drawbacks.  First, they are incomplete, i. e.  they sometimes fail to find a solution even if one exists, and second, the resulting solutions are often not optimal.  In this paper we present a method for finding and optimizing priority schemes for such prioritized and decoupled planning techniques.  Existing approaches apply a single priority scheme which makes them overly prone to failure in cases where valid solutions exist.  By searching in the space of priorization schemes, our approach overcomes this limitation.  It performs a randomized search with hill-climbing to find solutions and to minimize the overall path length.  To focus the search, our algorithm is guided by constraints generated from the task specification.  To illustrate the appropriateness of this approach, this paper discusses experimental results obtained with real robots and through systematic robot simulation.  The experimental results illustrate the superior performance of our approach, both in terms of efficiency of robot motion and in the ability to find valid plans. 
A Neural-Network based Approach for Recognition of Pose and Motion Gestures on a Mobile Robot| involve motion (such as waving).  Gestures are recognized in real-time at approximate frame rate, using neural networks.  A fast, color-based tracking algorithm enables the robot to track and follow a person reliably through office environments with drastically changing lighting conditions.  Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned, and the robot picks up trash which it then delivers to the nearest trash-bin. 
Automated Learning and Discovery Stat-Of-The-Art and Research Topics in a Rapidly Growing Field| Abstract This report summarizes the CONALD meeting, which took place June 11-13, 1998, at Carnegie Mellon University.  CONALD brought together an interdisciplinary group of scientists, concerned with decision making based on data.  This report is organized in two parts.  The first part (pages 1-6) summarizes the CONALD meeting and highlights its main outcomes, beyond the individual workshop level.  The second part (pages 7-30) summarize the results obtained in the individual workshops, discussing in depth promising research topics. 
A System for Three-Dimensional Robotic Mapping of Underground Mines| Abstract We describe two robotic systems [6] for acquiring high-resolution volumetric maps of underground mines.  Our systems have been deployed in an operational coal mine in Bruceton, Pennsylvania, where they have been used to generate interactive 3-D maps.  Our approach includes a novel sensor head, assembled from multiple SICK laser range finders, and a real-time algorithm for scan matching that generates accurate volumetric maps.  The scan matching algorithm performs horizontal and vertical simultaneous localization and mapping (SLAM).  Data from the horizontal scans is used to remove artifacts in the vertical scans, and vice versa.  The system can construct full 3-D volumetric maps hundreds of meters in diameter, even when no odometry information is available. 
Planning under Uncertainty for Reliable Health Care Robotics| Abstract.  We describe a mobile robot system, designed to assist residents of an retirement facility.  This system is being developed to respond to an aging population and a predicted shortage of nursing professionals.  In this paper, we discuss the task of finding and escorting people from place to place in the facility, a task containing uncertainty throughout the problem.  Planning algorithms that model uncertainty well such as Partially Observable Markov Decision Processes (POMDPs) do not scale tractably to real world problems such as the health care domain.  We demonstrate an algorithm for representing real world POMDP problems compactly, which allows us to find good policies in reasonable amounts of time.  We show that our algorithm is able to find moving people in close to optimal time, where the optimal policy starts with knowledge of the person's location. 
Planning for Markov Decision Processes with Sparse Stochasticity (Draft Version)| Abstract Planning algorithms designed for deterministic worlds, such as A* search, usually run much faster than algorithms designed for worlds with uncertain action outcomes, such as value iteration.  Real-world planning problems often exhibit uncertainty, which forces us to use the slower algorithms to solve them.  In particular, planning problems which involve sensing actions always have significant uncertainty: there is no point consulting a sensor if you know the outcome in advance.  However, many sensor planning problems exhibit sparse uncertainty: there are long sequences of deterministic actions which accomplish tasks like moving sensor platforms into place, interspersed with a small number of sensing actions which have uncertain outcomes.  In this paper we describe a new planning algorithm, called MCP (short for MDP Compression Planning), which combines A* search with value iteration.  We present experiments which show that MCP can run substantially faster than competing planners in domains with sparse uncertainty; these experiments are based on a simulation of a ground robot cooperating with a helicopter to fill in a partial map and move to a goal location.  In deterministic planning problems, optimal paths are acyclic: no state is visited more than once.  Because of this property, algorithms like A* search can guarantee that they visit each state in the state space no more than once.  By visiting the states in an appropriate order, it is possible to ensure that we know the exact value of all of a state's possible successors before we visit that state; so, the first time we visit a state we can compute its correct value.  By contrast, if actions have uncertain outcomes, optimal paths may contain cycles: some states will be visited two or more times with positive probability.  Because of these cycles, there is no way to order states so that we determine the values of a state's successors before we visit the state itself.  Instead, the only way to compute state values is to solve a set of simultaneous equations.  In problems with sparse stochasticity, only a small fraction of all states have uncertain outcomes.  It is these few states that cause all of the cycles: while a deterministic state s may participate in a cycle, the only way it can do so is if one of its successors has an action with a stochastic outcome (and only if this stochastic action can lead to a predecessor of s).  In such problems, we would like to build a smaller MDP which contains only states which are related to stochastic actions.  (We will call such an MDP a compressed MDP, and we will call its states distinguished states. ) We could then run fast algorithms like A* (a) Segbot (b) Robotic helicopter (d) Planning map (e) Execution simulation (c) 3D Map Figure 1: Robot-Helicopter Coordination search to plan paths between distinguished states, and reserve slower algorithms like value iteration for deciding how to deal with stochastic outcomes.  There are two problems with such a strategy.  First, there can be a large number of states which are related to stochastic actions, and so it may be impractical to enumerate all of them and make them all distinguished states.  (We would prefer instead to distinguish only states which are likely to be encountered while executing some policy which we are considering. ) Second, there can be a large number of ways to get from one distinguished state to another: edges in the compressed MDP correspond to sequences of actions in the original MDP.  If we knew the values of all of the distinguished states exactly, then we could use A* search to generate optimal paths between them, but since we don't we can't.  In this paper, we will describe an algorithm which incrementally builds a compressed MDP using a sequence of deterministic searches.  It adds states and edges to the compressed MDP only by encountering them along trajectories; so, it never adds irrelevant states or edges to the compressed MDP.  Trajectories are generated by deterministic search, and so undistinguished states are treated only with fast algorithms.  Bellman errors in the values for distinguished states show us where to try additional trajectories, and help us build the relevant parts of the compressed MDP as quickly as possible. 
A probabilistic language based upon sampling functions| Abstract As probabilistic computations play an increasing role in solving various problems, researchers have designed probabilistic languages that treat probability distributions as primitive datatypes.  Most probabilistic languages, however, focus only on discrete distributions and have limited expressive power.  In this paper, we present a probabilistic language, called fiff , which uniformly supports all kinds of probability distributions -discrete distributions, continuous distributions, and even those belonging to neither group.  Its mathematical basis is sampling functions, i. e. , mappings from the unit interval (0. 0, 1. 0] to probability domains.  We also briefly describe the implementation of fiff as an extension of Objective CAML and demonstrate its practicality with three applications in robotics: robot localization, people tracking, and robotic mapping.  All experiments have been carried out with real robots. 
Learning to Play the Game of Chess| Abstract This paper presents NeuroChess, a program which learns to play chess from the final outcome of games.  NeuroChess learns chess board evaluation functions, represented by artificial neural networks.  It integrates inductive neural network learning, temporal differencing, and a variant of explanation-based learning.  Performance results illustrate some of the strengths and weaknesses of this approach. 
MINERVA: A Second-Generation Museum Tour-Guide Robot| Abstract This paper describes an interactive tour-guide robot, which was successfully exhibited in a Smithsonian museum.  During its two weeks of operation, the robot interacted with thousands of people, traversing more than 44 km at speeds of up to 163 cm/sec.  Our approach specifically addresses issues such as safe navigation in unmodified and dynamic environments, and short-term human-robot interaction.  It uses learning pervasively at all levels of the software architecture. 
A Probabilistic Approach to Collaborative Multi-Robot Localization| Abstract This paper presents a statistical algorithm for collaborative mobile robot localization.  Our approach uses a sample-based version of Markov localization, capable of localizing mobile robots in an any-time fashion.  When teams of robots localize themselves in the same environment, probabilistic methods are employed to synchronize each robot's belief whenever one robot detects another.  As a result, the robots localize themselves faster, maintain higher accuracy, and high-cost sensors are amortized across multiple robot platforms.  The technique has been implemented and tested using two mobile robots equipped with cameras and laser range-finders for detecting other robots.  The results, obtained with the real robots and in series of simulation runs, illustrate drastic improvements in localization speed and accuracy when compared to conventional single-robot localization.  A further experiment demonstrates that under certain conditions, successful localization is only possible if teams of heterogeneous robots collaborate during localization. 
On-line Robot Adaptation to Environmental Change| Abstract Robots performing tasks constantly encounter changing environmental conditions.  These changes in the environment vary from the dramatic, such as rearrangement of furniture, to the subtle, such as a burnt out light bulb.  We do not recognize many of these changes, especially subtle changes, but robots do.  I propose to use robotic sensor data to identify and adapt to these environmental changes.  Traditional sensor models do not scale well in the face of these frequent environmental changes.  My approach is to aggregate sensor readings into probability distributions and associate them on-line with the state of the environment.  I will use the Sony AIBO robots as a test platform to verify the efficacy of the techniques I develop. 
Robotic Mapping: A Survey| Abstract This article provides a comprehensive introduction into the field of robotic mapping,
Web Interfaces for Mobile Robots in Public Places| Abstract The emergence of the World Wide Web provides a unique opportunity to connect robots to the Internet, enabling people all over the World to control them and monitor their operation.  This paper describes a series of Web interfaces, designed to remotely operate mobile robots in public places through the Web.  The design of these interfaces specifically addresses issues such as low bandwidth of Internet connections, control brokering, and shared control as well as interaction with people in the robot's environment, which arise naturally in applications with Web-based robot control.  The interfaces have been tested extensively using two deployed service robots, which were installed as interactive tour-guides in two museums.  The Web interfaces proved highly effective to provide a "tele-presence" to people all over the world.  The paper also discusses trade-offs and limitations of Web-based robots that interact with people in populated, public places. 
Probabilistic Algorithms in Robotics| Abstract This article describes a methodology for programming robots known as probabilistic robotics.  The probabilistic paradigm pays tribute to the inherent uncertainty in robot perception, relying on explicit representations of uncertainty when determining what to do.  This article surveys some of the progress in the field, using in-depth examples to illustrate some of the nuts and bolts of the basic approach.  Our central conjecture is that the probabilistic approach to robotics scales better to complex real-world applications than approaches that ignore a robot's uncertainty. 
Affine Structure From Sound| Abstract We consider the problem of localizing a set of microphones together with a set of external acoustic events (e. g. , hand claps), emitted at unknown times and unknown locations.  We propose a solution that approximates this problem under a far field approximation defined in the calculus of affine geometry, and that relies on singular value decomposition (SVD) to recover the affine structure of the problem.  We then define low-dimensional optimization techniques for embedding the solution into Euclidean geometry, and further techniques for recovering the locations and emission times of the acoustic events.  The approach is useful for the calibration of ad-hoc microphone arrays and sensor networks. 
A Monte Carlo Algorithm for Multi-Robot Localization| Abstract This paper presents a statistical algorithm for collaborative mobile robot localization.  Our approach uses a sample-based version of Markov localization, capable of localizing mobile robots in an any-time fashion.  When teams of robots localize themselves in the same environment, probabilistic methods are employed to synchronize each robot's belief whenever one robot detects another.  As a result, the robots localize themselves faster, maintain higher accuracy, and high-cost sensors are amortized across multiple robot platforms.  The paper also describes experimental results obtained using two mobile robots, using computer vision and laser range finding for detecting each other and estimating each other's relative location.  The results, obtained in an indoor office environment, illustrate drastic improvements in localization speed and accuracy when compared
Bayesian Network Induction via Local Neighborhoods| Abstract In recentyears, Bayesian networks have become highly successful tool for diagnosis, analysis, and decision making in real-world domains.  We present an efficient algorithm for learning Bayesian networks from data.  Our approach constructs Bayesian networks by first identifying each node's Markov blankets, then connecting nodes in a consistentway.  In contrast to the majorityofwork, whichtypically uses hill-climbing approaches that may produce dense nets and incorrect structure, our approachtypically yields consistent structure and compact networks by heeding independencies in the data.  Compact networks facilitate fast inference and are also easier to understand.  We prove that under mild assumptions, our approach requires time polynomial in the size of the data and the number of nodes.  A Monte Carlo variant, also presented here, is more robust and yields comparable results at much higher speeds. 
A Multi-Agent System for Agent Coordination in Uncertain Environments| ABSTRACT We present a multi-agent architecture for coordinating large numbers of mobile agents (e. g.  robots) cooperating in uncertain environments.  Our approach addresses the problem of navigating large numbers of goal-driven agents through an environment whose state is unknown and has to be discovered during navigation.  In our approach, each agent uses an approximate POMDP planner for generating contingency plans, and an efficient control brokering scheme for dispatching agents to goal locations.  Extensive experimental results have been obtained in the context of natural disaster relief.  Our experiments have been carried out in a realistic simulation of Honduras after Hurricane Mitch destroyed most of the country's infrastructure. 
Coordinated Deployment of Multiple, Heterogeneous Robots| Abstract To be truly useful, mobile robots need to be fairly autonomous and easy to control.  This is especially true in situations where multiple robots are used, due to the increase in sensory information and the fact that the robots can interfere with one another.  This paper describes a system that integrates autonomous navigation, a task executive, task planning, and an intuitive graphical user interface to control multiple, heterogeneous robots.  We have demonstrated a prototype system that plans and coordinates the deployment of teams of robots.  Testing has shown the effectiveness and robustness of the system, and of the coordination strategies in particular. 
LEARNING BY ERROR-DRIVEN DECOMPOSITION| In this paper we describe a new selforganizing decomposition technique for learning high-dimensional mappings.  Problem decomposition is performed in an error-driven manner, such that the resulting subtasks (patches) are equally well approximated.  Our method combines an unsupervised learning scheme (Feature Maps [Koh84]) with a nonlinear approximator (Backpropagation [RHW86]).  The resulting learning system is more stable and effective in changing environments than plain backpropagation and much more powerful than extended feature maps as proposed by [RS88, RMS89].  Extensions of our method give rise to active exploration strategies for autonomous agents facing unknown environments.  The appropriateness of our general purpose method will be demonstrated with an example from mathematical function approximation. 
Locating moving entities in indoor environments with teams of mobile robots| ABSTRACT This article presents an implemented multi-robot system for playing the popular game of laser tag.  The object of the game is to search for and tag opponents that can move freely about the environment.  The main contribution of this paper is a new particle filter algorithm for tracking the location of many opponents in the presence of pervasive occlusion.  We achieve efficient tracking principally through a clever factorization of our posterior into roles that can be dynamically added and merged.  When searching for opponents, the individual agents greedily maximize their information gain, using a negotiation technique for coordinating their search efforts.  Experimental results are provided, obtained with a physical robot system in large-scale indoor environments and through simulation. 
The Information-Form Data Association Filter| Abstract This paper presents a new filter for online data association problems in high-dimensional spaces.  The key innovation is a representation of the data association posterior in information form, in which the "proximity" of objects and tracks are expressed by a numerical links.  Updating these links requires linear time, compared to exponential time required for computing posterior probabilities.  The paper derives the algorithm formally, and provides comparative results for using data obtained by real-world camera array and by a large-scale sensor network simulation. 
A Framework for Programming Embedded Systems: Initial Design and Results| Abstract This paper describes CES, a proto-type of a new programming language for robots and other embedded systems, equipped with sensors and actuators.  CES contains two new ideas, currently not found in other programming languages: support of computing with uncertain information, and support of adaptation and teaching as a means of programming.  These innovations facilitate the rapid development of software for embedded systems, as demonstrated by two mobile robot applications. 
6D SLAM with an Application in Autonomous Mine Mapping| Abstract--- To create with an autonomous mobile robot a 3D volumetric map of a scene it is necessary to gage several 3D scans and to merge them into one consistent 3D model.  This paper provides a new solution to the simultaneous localization and mapping (SLAM) problem with six degrees of freedom.  Robot motion on natural surfaces has to cope with yaw, pitch and roll angles, turning pose estimation into a problem in six mathematical dimensions.  A fast variant of the Iterative Closest Points algorithm registers the 3D scans in a common coordinate system and relocalizes the robot.  Finally, consistent 3D maps are generated using a global relaxation.  The algorithms have been tested with 3D scans taken in the Mathies mine, Pittsburgh, PA.  Abandoned mines pose significant problems to society, yet a large fraction of them lack accurate 3D maps. 
Learning Motion Patterns of Persons for Mobile Service Robots| Abstract We propose a method for learning models of people's motion behaviors in an indoor environment.  As people move through their environments, they do not move randomly.  Instead, they often engage in typical motion patterns, related to specific locations that they might be interested in approaching and specific trajectories that they might follow in doing so.  Knowledge about such patterns may enable a mobile robot to develop improved people following and obstacle avoidance skills.  This paper proposes an algorithm that learns collections of typical trajectories that characterize a person's motion patterns.  Data, recorded by mobile robots equipped with laser range finders, is clustered into different types of motion using the popular expectation maximization algorithm, while simultaneously learning multiple motion patterns.  Experimental results, obtained using data collected in a domestic residence and in an office building, illustrate that highly predictive models of human motion patterns can be learned. 
Policy-contingent abstraction for robust robot control| Abstract This paper presents a scalable control algorithm that enables a deployed mobile robot to make high-level control decisions under full consideration of its probabilistic belief.  We draw on insights from the rich literature of structured robot controllers and hierarchical MDPs to propose PolCA, a hierarchical probabilistic control algorithm which learns both subtask-specific state abstractions and policies.  The resulting controller has been successfully implemented onboard a mobile robotic assistant deployed in a nursing facility.  To the best of our knowledge, this work is a unique instance of applying POMDPs to highlevel robotic control problems. 
The Correlated Correspondence Algorithm for Unsupervised Registration of Nonrigid Surfaces| Abstract We present an unsupervised algorithm for registering 3D surface scans of an object undergoing significant deformations.  Our algorithm does not use markers, nor does it assume prior knowledge about object shape, the dynamics of its deformation, or scan alignment.  The algorithm registers two meshes by optimizing a joint probabilistic model over all point-topoint correspondences between them.  This model enforces preservation of local mesh geometry, as well as more global constraints that capture the preservation of geodesic distance between corresponding point pairs.  The algorithm applies even when one of the meshes is an incomplete range scan; thus, it can be used to automatically fill in the remaining surfaces for this partial scan, even if those surfaces were previously only seen in a different configuration.  We evaluate the algorithm on several real-world datasets, where we demonstrate good results in the presence of significant movement of articulated parts and non-rigid surface deformation.  Finally, we show that the output of the algorithm can be used for compelling computer graphics tasks such as interpolation between two scans of a non-rigid object and automatic recovery of articulated object models. 
Feature Correspondence: A Markov Chain Monte Carlo Approach| Abstract When trying to recover 3D structure from a set of images, the most difficult problem is establishing the correspondence between the measurements.  Most existing approaches assume that features can be tracked across frames, whereas methods that exploit rigidity constraints to facilitate matching do so only under restricted camera motion.  In this paper we propose a Bayesian approach that avoids the brittleness associated with singling out one "best" correspondence, and instead consider the distribution over all possible correspondences.  We treat both a fully Bayesian approach that yields a posterior distribution, and a MAP approach that makes use of EM to maximize this posterior.  We show how Markov chain Monte Carlo methods can be used to implement these techniques in practice, and present experimental results on real data. 
Active Exploration in Dynamic Environments| Abstract Whenever an agent learns to control an unknown environment, two opposing principles have to be combined, namely: exploration (long-term optimization) and exploitation (short-term optimization).  Many real-valued connectionist approaches to learning control realize exploration by randomness in action selection.  This might be disadvantageous when costs are assigned to "negative experiences".  The basic idea presented in this paper is to make an agent explore unknown regions in a more directed manner.  This is achieved by a so-called competence map, which is trained to predict the controller's accuracy, and is used for guiding exploration.  Based on this, a bistable system enables smoothly switching attention between two behaviors -- exploration and exploitation -- depending on expected costs and knowledge gain.  The appropriateness of this method is demonstrated by a simple robot navigation task. 
Experiences with a Mobile Robotic Guide for the Elderly| Abstract This paper describes an implemented robot system, which relies heavily on probabilistic AI techniques for acting under uncertainty.  The robot Pearl
A Lifelong Learning Perspective for Mobile Robot Control| Abstract---Designing robots that learn by themselves to perform complex real-world tasks is a still-open challenge for the field of Robotics and Artificial Intelligence.  In this paper we present the robot learning problem as a lifelong problem, in which a robot faces a collection of tasks over its entire lifetime.  Such a scenario provides the opportunity to gather general-purpose knowledge that transfers across tasks.  We illustrate a particular learning mechanism, explanation-based neural network learning, that transfers knowledge between related tasks via neural network action models.  The learning approach is illustrated using a mobile robot, equipped with visual, ultrasonic and laser sensors.  In less than 10 minutes operation time, the robot is able to learn to navigate to a marked target object in a natural office environment. 
Using EM to Learn 3D Models of Indoor Environments with Mobile Robots| Abstract This paper describes an algorithm for generating compact 3D models of indoor environments with mobile robots.  Our algorithm employs the expectation maximization algorithm to fit a lowcomplexity planar model to 3D data collected by range finders and a panoramic camera.  The complexity of the model is determined during model fitting, by incrementally adding and removing surfaces.  In a final post-processing step, measurements are converted into polygons and projected onto the surface model where possible.  Empirical results obtained with a mobile robot illustrate that high-resolution models can be acquired in reasonable time. 
Monte Carlo EM for Data-Association and its Applications in Computer Vision| Abstract Estimating geometry from images is at the core of many computer vision applications, whether it concerns the imaging geometry, the geometry of the scene, or both.  Examples include image mosaicking, pose estimation, multibaseline stereo, and structure from motion.  All these problems can be modeled probabilistically and translate into well-understood statistical estimation problems, provided the correspondence between measurements in the different images is known.  I will show that, if the correspondence is not known, the statistically optimal estimate for the geometry can be obtained using the expectation-maximization (EM) algorithm.  In contrast to existing techniques, the EM algorithm avoids the estimation bias associated with computing a single "best" set of correspondences, but rather considers the distribution over all possible correspondences consistent with the data.  While the latter computation is intractable in general, show that it can be approximated well in practice using Markov chain Monte Carlo sampling.  As part of this, I have designed an efficient sampler specifically tuned to the correspondence problem.  The resulting Monte Carlo EM approach represents the first truly multiview algorithm for geometric estimation with unknown correspondence.  This is especially relevant in the structure from motion domain, where the state of the art relies on robust estimation of two or three-view geometric constraints.  In addition, will show that the probabilistic approach propose allows for a seamless and principled way of integrating prior knowledge, appearance models, and statistical models for occlusion and clutter. 
A Probabilistic Technique for Simultaneous Localization and Door State Estimation with Mobile Robots in Dynamic Environments| Abstract Virtually all existing mobile robot localization techniques operate on a static map of the environment.  When the environment changes (e. g. , doors are opened or closed), there is an opportunity to simultaneously estimate the robot's pose and the state of the environment.  The resulting estimation problem is high-dimensional, rendering current localization techniques inapplicable.  This paper proposes an efficient, factored estimation algorithm for mixed discrete-continuous state estimation.  Our algorithm integrates particle filters for robot localization, and conditional binary Bayes filters for estimating the dynamic state of the environment.  Experimental results illustrate that our algorithm is highly effective in estimating the status of doors, and outperforms a state-of-the-art localizer in dynamic environments. 
Efficient Multi-Robot Localization Based on Monte Carlo Approximation| each other's relative location.  The results, obtained in an indoor office environment, illustrate drastic improvements in localization speed and accuracy when compared to conventional single-robot localization. 
Finding Approximate POMDP solutions Through Belief Compression| Abstract Standard value function approaches to finding policies for Partially Observable Markov Decision Processes (POMDPs) are generally considered to be intractable for large models.  The intractability of these algorithms is to a large extent a consequence of computing an exact, optimal policy over the entire belief space.  However, in real-world POMDP problems, computing the optimal policy for the full belief space is often unnecessary for good control even for problems with complicated policy classes.  The beliefs experienced by the controller often lie near a structured, low-dimensional subspace embedded in the high-dimensional belief space.  Finding a good approximation to the optimal value function for only this subspace can be much easier than computing the full value function.  We introduce a new method for solving large-scale POMDPs by reducing the dimensionality of the belief space.  We use Exponential family Principal Components Analysis (Collins, Dasgupta, & Schapire, 2002) to represent sparse, high-dimensional belief spaces using small sets of learned features of the belief state.  We then plan only in terms of the low-dimensional belief features.  By planning in this low-dimensional space, we can find policies for POMDP models that are orders of magnitude larger than models that can be handled by conventional techniques.  We demonstrate the use of this algorithm on a synthetic problem and on mobile robot navigation tasks. 
A Monadic Probabilistic Language| ABSTRACT Motivated by many practical applications that have to compute in the presence of uncertainty, we propose a monadic probabilistic language based upon the mathematical notion of sampling function.  Our language provides a unified representation scheme for probability distributions, enjoys rich expressiveness, and offers high versatility in encoding probability distributions.  We also develop a novel style of operational semantics called a horizontal operational semantics, under which an evaluation returns not a single outcome but multiple outcomes.  We have preliminary evidence that the horizontal operational semantics improves the ordinary operational semantics with respect to both execution time and accuracy in representing probability distributions. 
Learning Hierarchical Object Maps of Non-Stationary Environments with Mobile Robots| environments.  The approach outperforms a previously developed non-hierarchical algorithm that models objects but lacks class templates. 
Real time data association for FastSLAM| Abstract--- The ability to simultaneously localise a robot and accurately map its surroundings is considered by many to be a key prerequisite of truly autonomous robots.  This paper presents a real-world implementation of FastSLAM, an algorithm that recursively estimates the full posterior distribution of both robot pose and landmark locations.  In particular, we present an extension to FastSLAM that addresses the data association problem using a nearest neighbour technique.  Building on this, we also present a novel multiple hypothesis tracking implementation (MHT) to handle uncertainty in the data association.  Finally an extension to the multi-robot case is introduced.  Our algorithm has been run successfully using a number of data sets obtained in outdoor environments.  Experimental results are presented that demonstrate the performance of the algorithms when compared with standard Kalman Filter-based approaches. 
A Real-Time Algorithm for Mobile Robot Mapping With Applications to Multi-Robot and 3D Mapping| Abstract We present an incremental method for concurrent mapping and localization for mobile robots equipped with 2D laser range finders.  The approach uses a fast implementation of scan-matching for mapping, paired with a sample-based probabilistic method for localization.  Compact 3D maps are generated using a multi-resolution approach adopted from the computer graphics literature, fed by data from a dual laser system.  Our approach builds 3D maps of large, cyclic environments in real-time.  It is remarkably robust.  Experimental results illustrate that accurate maps of large, cyclic environments can be generated even in the absence of any odometric data. 
An Application of Markov Random Fields to Range Sensing| Abstract This paper describes a highly successful application of MRFs to the problem of generating high-resolution range images.  A new generation of range sensors combines the capture of low-resolution range images with the acquisition of registered high-resolution camera images.  The MRF in this paper exploits the fact that discontinuities in range and coloring tend to co-align.  This enables it to generate high-resolution, low-noise range images by integrating regular camera images into the range data.  We show that by using such an MRF, we can substantially improve over existing range imaging technology. 
Applying Metric-Trees to Belief-Point POMDPs| Abstract Recent developments in grid-based and point-based approximation algorithms for POMDPs have greatly improved the tractability of POMDP planning.  These approaches operate on sets of belief points by individually learning a value function for each point.  In reality, belief points exist in a highly-structured metric simplex, but current POMDP algorithms do not exploit this property.  This paper presents a new metric-tree algorithm which can be used in the context of POMDP planning to sort belief points spatially, and then perform fast value function updates over groups of points.  We present results showing that this approach can reduce computation in point-based POMDP algorithms for a wide range of problems. 
Markov Localization for Mobile Robots in Dynamic Environments| Abstract Localization, that is the estimation of a robot's location from sensor data, is a
with Unknown Correspondence| Abstract.  Learning spatial models from sensor data raises the challenging data association problem of relating model parameters to individual measurements.  This paper proposes an
Using the Condensation Algorithm for Robust, Vision-based Mobile Robot Localization| Abstract To navigate reliably in indoor environments, a mobile robot must know where it is.  This includes both the ability of globally localizing the robot from scratch, as well as tracking the robot's position once its location is known.  Vision has long been advertised as providing a solution to these problems, but we still lack efficient solutions in unmodified environments.  Many existing approaches require modification of the environment to function properly, and those that work within unmodified environments seldomly address the problem of global localization.  In this paper we present a novel, vision-based localization method based on the CONDENSATION algorithm [17, 18], a Bayesian filtering method that uses a samplingbased density representation.  We show how the CONDENSATION algorithm can be used in a novel way to track the position of the camera platform rather than tracking an object in the scene.  In addition, it can also be used to globally localize the camera platform, given a visual map of the environment.  Based on these two observations, we present a visionbased robot localization method that provides a solution to a difficult and open problem in the mobile robotics community.  As evidence for the viability of our approach, we show both global localization and tracking results in the context of a state of the art robotics application. 
Collaborative Multi-Robot Localization| Abstract In this paper we consider the problem of exploring an unknown environment by a team of robots.  As in single-robot exploration the goal is to minimize the overall exploration time.  The key problem to be solved therefore is to choose appropriate target points for the individual robots so that they simultaneously explore different regions of their environment.  We present a probabilistic approach for the coordination of multiple robots which, in contrast to previous approaches, simultaneously takes into account the costs of reaching a target point and the utility of target points.  The utility of target points is given by the size of the unexplored area that a robot can cover with its sensors upon reaching a target position.  Whenever a target point is assigned to a specific robot, the utility of the unexplored area visible from this target position is reduced for the other robots.  This way, a team of multiple robots assigns different target points to the individual robots.  The technique has been implemented and tested extensively in real-world experiments and simulation runs.  The results given in this paper demonstrate that our coordination technique significantly reduces the exploration time compared to previous approaches. 
Simultaneous Mapping and Localization With Sparse Extended Information Filters: Theory and Initial Results| Abstract This paper describes a scalable algorithm for the simultaneous mapping and localization (SLAM) problem.  SLAM is the problem of determining the location of environmental features with a roving robot.  Many of today's popular techniques are based on extended Kalman filters (EKFs), which require update time quadratic in the number of features in the map.  This paper develops the notion of sparse extended information filters (SEIFs), as a new method for solving the SLAM problem.  SEIFs exploit structure inherent in the SLAM problem, representing maps through local, Web-like networks of features.  By doing so, updates can be performed in constant time, irrespective of the number of features in the map.  This paper presents several original constant-time results of SEIFs, and provides simulation results that show the high accuracy of the resulting maps in comparison to the computationally more cumbersome EKF solution. 
Using EM to Learn Motion Behaviors of Persons with Mobile Robots| Abstract We propose a method for learning models of people's motion behaviors in indoor environments.  As people move through their environments, they do not move randomly.  Instead, they often engage in typical motion patterns, related to specific locations that they might be interested in approaching and specific trajectories that they might follow in doing so.  Knowledge about such patterns may enable a mobile robot to develop improved people following and obstacle avoidance skills.  This paper proposes an algorithm that learns collections of typical trajectories that characterize a person's motion patterns.  Data, recorded by mobile robots equipped with laser-range finders, is clustered into different types of motion using the popular expectation maximization algorithm, while simultaneously learning multiple motion patterns.  Experimental results, obtained using data collected in a domestic residence and in an office building, illustrate that highly predictive models of human motion patterns can be learned. 
Planning with an Adaptive World Model| Abstract We present a new connectionist planning method [TML90].  By interaction with an unknown environment, a world model is progressively constructed using gradient descent.  For deriving optimal actions with respect to future reinforcement, planning is applied in two steps: an experience network proposes a plan which is subsequently optimized by gradient descent with a chain of world models, so that an optimal reinforcement may be obtained when it is actually run.  The appropriateness of this method is demonstrated by a robotics application and a pole balancing task. 
A Learning Algorithm for Localizing People Based on Wireless Signal Strength that Uses Labeled and Unlabeled Data| Abstract This paper summarizes a probabilistic approach for localizing people through the signal strengths of a wireless IEEE 802. 11b network.  Our approach uses data labeled by ground truth position to learn a probabilistic mapping from locations to wireless signals, represented by piecewise linear Gaussians.  It then uses sequences of wireless signal data (without position labels) to acquire motion models of individual people, which further improves the localization accuracy.  The approach has been implemented and evaluated in an office environment. 
ARA*: Anytime A* with Provable Bounds on Sub-Optimality| Abstract In real world planning problems, time for deliberation is often limited.  Anytime planners are well suited for these problems: they find a feasible solution quickly and then continually work on improving it until time runs out.  In this paper we propose an anytime heuristic search, ARA*, which tunes its performance bound based on available search time.  It starts by finding a suboptimal solution quickly using a loose bound, then tightens the bound progressively as time allows.  Given enough time it finds a provably optimal solution.  While improving its bound, ARA* reuses previous search efforts and, as a result, is significantly more efficient than other anytime search methods.  In addition to our theoretical analysis, we demonstrate the practical utility of ARA* with experiments on a simulated robot kinematic arm and a dynamic path planning problem for an outdoor rover. 
Perspectives on Standardization in Mobile Robot Programming : The Carnegie Mellon Navigation (CARMEN) Toolkit| Abstract--- In this paper we describe our open-source robot control software, the Carnegie Mellon Navigation (CARMEN) Toolkit.  The ultimate goals of CARMEN are to lower the barrier to implementing new algorithms on real and simulated robots and to facilitate sharing of research and algorithms between different institutions.  In order for CARMEN to be as inclusive of various research approaches as possible, we have chosen not to adopt strict software standards, but to instead focus on good design practices.  This paper will outline the lessons we have learned in developing these practices. 
The Mobile Robot RHINO| Abstract--- Rhinowas the University of Bonn's entry in the 1994 AAAI mobile robot competition.  Rhino is a mobile robot designed for indoor navigation and manipulation tasks.  The general scientific goal of the Rhino project is the development and the analysis of autonomous and complex learning systems.  This paper briefly describes the major components of the Rhino control software, as they were exhibited at the competition.  It also sketches the basic philosophy of the Rhino architecture, and discusses some of the lessons that we learned during the competition.  I.  GENERAL OVERVIEW Rhino, shown in Figure 1, is a B21 mobile robot platform manufactured by Real World Interface Inc.  It is equipped with 24 sonar proximity sensors, a dual color camera system mounted on a pan/tilt unit, and two on-board i486 computers.  Sonar information is obtained at a rate of 1. 3 Hertz, and camera images are processed at a rate of 0. 7 Hertz.  Rhino communicates with external computers (two SUN Sparc stations) via a tetherless Ethernet link.  The Rhino project is generally concerned with the design of autonomous and complex learning systems [8].  The AAAI competition ended an initial six month period of software design.  Key features of Rhino's control software, as exhibited at the competition, are: ffl Autonomy.  Rhino operates completely autonomously.  It has been repeatedly operated for durations of up to one hour in populated office environments without human intervention.  ffl Learning.  To increase the flexibility of the software, learning mechanisms support the adaptation of the robot to its sensors and the environment.  For example, neural network learning is employed to interpret sonar measurements.  ffl Real-time operation.  In order to act continuously in real-time, any-time solutions [2] are employed wherever possible.  Any-time algorithms are able to make decisions regardless of the time spent for computation.  The more time is available, however, the better are the results.  ffl Reactive control and deliberation.  Rhino's navigation system integrates a fast, reactive on-board obstacle avoidance routine with knowledge- and computationintense map building and planning algorithms.  Rhino's software consists of a dozen different modules.  The interface modules (a base/sonar sensor interface, a camera interface and a speech interface) control the basic communication to and from the hardware components of the robot.  On top of these, a fast obstacle avoidance routine analyzes sonar measurements to avoid collisions with obstacles and walls at a speed of up to 90cm per second.  Global metric and topological maps are constructed on-the-fly using a neural network-based approach, combined with a database of maps showing typical rooms, doors and hallways.  Rhino employs a dynamic programming planner to explore unknown terrain and to navigate to arbitrary target locations.  It locates itself by continuously analyzing sonar information.  In addition, a fast vision module segments images from two color cameras, in order to find target objects and obstacles that block the path of the robot.  Rhino's control flow is monitored by an integrated task planner and a central user interface.  The integration of a dozen different software modules, which all exhibit different timing and response characteristics, requires a flexible scheme for the flow and synchronization of information.  The key principles for the design of Rhino's software are: Figure 1: The Rhino robot of
ARA*: Formal Analysis| Abstract In real world problems, time for deliberation is often limited.  Anytime algorithms are beneficial in these conditions as they usually find a first, possibly highly suboptimal, solution very fast and then continually work on improving the solution until allocated time expires.  While anytime algorithms are popular, existing anytime search methods are unable to provide a measure of goodness of their results.  In this paper we propose the ARA* algorithm.  ARA* is an anytime heuristic search which tunes its performance bound based on available search time.  It starts by finding a suboptimal solution quickly using a loose bound, then tightens the bound progressively as time allows.  Given enough time it finds a provably optimal solution.  In addition to the theoretical analysis we demonstrate the practical utility of ARA* with experiments on a simulated robot kinematic arm and dynamic path planning problem for an outdoor rover. 
Map Learning and High-Speed Navigation in RHINO| Abstract This chapter surveys basic methods for
Risk Sensitive Particle Filters| Abstract We propose a new particle filter that incorporates a model of costs when generating particles.  The approach is motivated by the observation that the costs of accidentally not tracking hypotheses might be significant in some areas of state space, and irrelevant in others.  By incorporating a cost model into particle filtering, states that are more critical to the system performance are more likely to be tracked.  Automatic calculation of the cost model is implemented using an MDP value function calculation that estimates the value of tracking a particular state.  Experiments in two mobile robot domains illustrate the appropriateness of the approach. 
An Efficient FastSLAM Algorithm for Generating Maps of Large-Scale Cyclic Environments from Raw Laser Range Measurements| Abstract The ability to learn a consistent model of its environment is a prerequisite for autonomous mobile robots.  A particularly challenging problem in acquiring environment maps is that of closing loops; loops in the environment create challenging data association problems [9].  This paper presents a novel algorithm that combines RaoBlackwellized particle filtering and scan matching.  In our approach scan matching is used for minimizing odometric errors during mapping.  A probabilistic model of the residual errors of scan matching process is then used for the resampling steps.  This way the number of samples required is seriously reduced.  Simultaneously we reduce the particle depletion problem that typically prevents the robot from closing large loops.  We present extensive experiments that illustrate the superior performance of our approach compared to previous approaches. 
Variable Resolution Particle Filter| Abstract Particle filters are used extensively for tracking the state of non-linear dynamic systems.  This paper presents a new particle filter that maintains samples in the state space at dynamically varying resolution for computational efficiency.  Resolution within statespace varies by region, depending on the belief that the true state lies within each region.  Where belief is strong, resolution is fine.  Where belief is low, resolution is coarse, abstracting multiple similar states together.  The resolution of the statespace is dynamically updated as the belief changes.  The proposed algorithm makes an explicit bias-variance tradeoff to select between maintaining samples in a biased generalization of a region of state space versus in a high variance specialization at fine resolution.  Samples are maintained at a coarser resolution when the bias introduced by the generalization to a coarse resolution is outweighed by the gain in terms of reduction in variance, and at a finer resolution when it is not.  Maintaining samples in abstraction prevents potential hypotheses from being eliminated prematurely for lack of a sufficient number of particles.  Empirical results show that our variable resolution particle filter requires significantly lower computation for performance comparable to a classical particle filter. 
Particle Filters for Rover Fault Diagnosis| 1 Introduction This article presents a number of complementary algorithms for detecting faults on-board operating robots, where we define a fault as a deviation from expected behavior.  Experience has shown that even carefully designed and tested robots may encounter faults [3].  One of the reasons for this is that components degrade over time another is that the operators of the robot rarely have complete knowledge of the environment in which it operates and hence may not have accounted for certain situations.  In a number of application domains, such as planetary exploration, search and rescue, mine mapping, nuclear waste cleanup, and demining, robots operate in environments where human intervention is expensive, slow, unreliable, or impossible.  It is therefore essential for the robots to monitor their behavior so that faults may be addressed before they result in catastrophic failures.  This monitoring needs to be efficient since there is limited computational power available on robots.  Not only are robots venturing into areas inaccessible or dangerous for humans, but they are also increasingly becoming a part of day to day life.  It is also important for these robots to detect faults in a timely manner, since failure to do so may result in expensive consequences, both monetary and in terms of consumer trust that may be hard to regain.  If faults go undetected, autonomous robots in real-world environments may behave in an unpredictable or dangerous manner.  On the other hand, detecting and recovering from faults can considerably improve the performance of the robots [2] [81].  Fault Detection and Identification (FDI) for robots is a complex problem.  This is because the space of possible faults is very large, robot sensors, actuators, and environment models are uncertain, and there is limited computation time and power.  Probability theory provides a natural representation of the uncertainty in the rover domain, but an exact Bayesian solution to FDI is intractable.  Traditional methods address this intractability by approximating the problem using linear approximations of rover dynamics and/or by ignoring uncertainty.  Often these approximations are unrealistic, and either faults go undetected, or an unreasonable number of false positives are triggered.  We instead prefer to approximate the solution using Monte Carlo methods.  The rationale behind this is that the two stages of this problem, building models and online monitoring, have very different computational constraints.  Theoretically there is little restriction on the time and computation available for building models, since this may be done offline, but monitoring these models must be done in real time with the limited computation available on a robot.  We consider approximate inference using complex models a better trade-off than exact inference with simple models.  Classical Monte Carlo methods for dynamic systems, such as particle filters, are capable of tracking complex nonlinear systems with noisy measurements.  The problem is that estimates from a particle filter tend to have a high variance for small sample sets.  Using large sample sets is computationally expensive and defeats the purpose.  In this article, we present a number of complementary algorithms for improving the accuracy of FDI with a computationally tractable set of samples in a particle filter.  Experimental results in the rover domain show significant improvement in accuracy over the classical approach.  The algorithms described in this article enable detection of a wider range and larger number of faults during robot operation than has hitherto been possible.  Furthermore, these algorithms provide the probability of the robot being in each of the fault and operational states given the sensor data.  They can handle noisy sensors, non-linear, non-Gaussian models of behavior, and are computationally efficient.  Estimating faults in terms of a probability distribution over all fault states captures the uncertainty in fault identification that results from noisy and insufficient data.  In addition, it allows a lot of flexibility in the types of planners/controllers that may be used for controlling the robot and for recovering from faults.  For example, such distributions are compatible with classical conditional planners or Markov Decision Processes (MDPs), which may use the most likely state to determine which action to take, and also Partially Observable Markov Decision Processes (POMDPs) [67], which use the distribution over the entire state space.  2 Particle Filters for Monitoring Faults Our formulation of the fault detection problem requires estimating robot and environmental state, as it changes over time, from a sequence of sensor measurements that provide noisy, partial information about the state.  The Bayesian approach to dynamic state estimation addresses this problem.  Particle filters have been extensively used for Bayesian state estimation in nonlinear systems with noisy measurements [35][22][15].  They approximate the probability distribution with a set of samples or particles.  The algorithms presented in this article all use particle filters.  Particle filters have a number of characteristics that make them attractive for fault detection on robots: they are non-parametric (can represent arbitrary distributions), can handle hybrid state spaces, can handle noisy sensing and motion, and can easily be extended to an anytime approach where the number of particles (and hence the estimation accuracy) can be adjusted to match available computation.  2. 1 Fault Detection and Identification (FDI) for Robots A fault is defined as a deviation from the expected behavior of the system.  Fault detection is defined as the process of determining that a fault has occurred.  Fault identification is the process of determining exactly which exception or fault occurred [36].  Fault detection and identification are typically passive, i. e.  they do not alter control actions.  This paper concentrates on a class of faults that are relatively difficult to detect because they cannot be inferred from sensor values at a given instance, but require a sequence of time-varying sensor values.  In addition, the expected behavior of the robot may be different in different operating conditions.  For example, high power draw on flat ground may be cause for concern, but high power draw on a slope might be perfectly acceptable.  The faults addressed here include mechanical component failures, such as broken motors and gears; faults due to environmental interactions, such as a wheel stuck against a rock; and sensor failures, such as broken encoders.  2. 2 FDI as recursive state estimation State estimation is the process of determining the state of a system from a sequence of data.  FDI has a natural representation as a state estimation problem.  We represent the possible fault and operational modes of the systems as explicit states.  The sequence of measurements is then used to determine the state of the system.  There are two main classes of state estimation methods: batch estimation methods and recursive estimation methods.  Batch methods treat all the data with equal importance and find an optimal estimate of the state given the entire sequence.  However, full batch estimation is computationally expensive and gets slower as the robot accumulates increasing volumes of data.  It is therefore not suitable for FDI.  Recursive state estimation methods make a Markov assumption, i. e. , the past and future are conditionally independent given the current state.  These methods incorporate the data as it becomes available and replace the data with a statistic.  Estimates at subsequent timesteps use this statistic instead of the history of data for state estimation.  2. 3 Classical particle filter For FDI we concentrate on a discrete time, first order Markov formulation of the state estimation problem.  The state being estimated is hybrid, i. e.  it consists of both discrete and continuous components.  Let } d d { D K 1 # = represent K hidden discrete fault and operational states of the robot, D d t the discrete state of the robot at time t and } d , , d { d t 1 t # the discrete, first order Markov chain representing the evolution of the state over time.  In addition to the discrete states there are also continuous states that track the dynamic behavior of the robot.  Let x n t x denote the multivariate continuous state at time t.  The state of the robot is observed through a sequence of measurements, z n t t t z z z z = }, { 1 # .  Probabilistic models of the change in state over time (state transition model) and the relationship between the measurements and the state (measurement model) capture the inherent noise.  State transitions depend on prior state, observation, and (in some cases) the control action.  These models are assumed to be stationary, i. e. , the models do not change with time.  Bayesian filtering, represented by [Equation 1], provides a recursive estimate of the posterior (newly updated) probability distribution over the states.  Here, control is omitted in equations for brevity.  We consider the following factored representation, where the discrete state transition is conditionally independent of the continuous state transitions given the previous discrete state 1 : 1 t 1 t t t d 1 t t t t t t t 1 t t dx )
Towards robotic assistants in nursing homes: Challenges and results| Abstract This paper describes a mobile robotic assistant, developed to assist elderly individuals with mild cognitive and physical impairments, as well as support nurses in their daily activities.  We present three software modules relevant to ensure successful human--robot interaction: an automated reminder system; a people tracking and detection system; and finally a high-level robot controller that performs planning under uncertainty by incorporating knowledge from low-level modules, and selecting appropriate courses of actions.  During the course of experiments conducted in an assisted living facility, the robot successfully demonstrated that it could autonomously provide reminders and guidance for elderly residents
FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem| Abstract The ability to simultaneously localize a robot and
EM, MCMC, and Chain Flipping for Structure from Motion with Unknown Correspondence| We gratefully acknowledge the support of the following sponsoring institutions: SAIC corporation; KIRIN brewery company; SONY corporation; DOT and NHTSA; NSF through grants IIS-9984672 and IIS-9876136; DARPA-ATO via TACOM (contract number DAAE07-98-CL032) and DARPA-ISO via Rome Labs (contract number F30602-98-2-0137); and CS and Robotics at CMU The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the United States Government or any of the sponsoring institutions. 
Monte Carlo Localization: Efficient Position Estimation for Mobile Robots| Abstract This paper presents a new algorithm for mobile robot localization, called Monte Carlo Localization (MCL).  MCL is a version of Markov localization, a family of probabilistic approaches that have recently been applied with great practical success.  However, previous approaches were either computationally cumbersome (such as grid-based approaches that represent the state space by high-resolution 3D grids), or had to resort to extremely coarse-grained resolutions.  Our approach is computationally efficient while retaining the ability to represent (almost) arbitrary distributions.  MCL applies sampling-based methods for approximating probability distributions, in a way that places computation "where needed. " The number of samples is adapted on-line, thereby invoking large sample sets only when necessary.  Empirical results illustrate that MCL yields improved accuracy while requiring an order of magnitude less computation when compared to previous approaches.  It is also much easier to implement. 
Monte Carlo Localization for Mobile Robots| Abstract To navigate reliably in indoor environments, a mobile robot must know where it is.  Thus, reliable position estimation is a key problem in mobile robotics.  We believe that probabilistic approaches are among the most promising candidates to providing a comprehensive and real-time solution to the robot localization problem.  However, current methods still face considerable hurdles.  In particular, the problems encountered are closely related to the type of representation used to represent probability densities over the robot's state space.  Recent work on Bayesian filtering with particle-based density representations opens up a new approach for mobile robot localization, based on these principles.  In this paper we introduce the Monte Carlo Localization method, where we represent the probability density involved by maintaining a set of samples that are randomly drawn from it.  By using a sampling-based representation we obtain a localization method that can represent arbitrary distributions.  We show experimentally that the resulting method is able to efficiently localize a mobile robot without knowledge of its starting location.  It is faster, more accurate and less memory-intensive than earlier grid-based methods. 
Discovering Structure in Multiple Learning Tasks: The TC Algorithm|
Coordination for Multi-Robot Exploration and Mapping|
Integrating Topological and Metric Maps for Mobile Robot Navigation: A Statistical Approach|
A Probabilistic Approach to Concurrent Mapping and Localization for Mobile Robots|
Probabilistic Mapping of an Environment by a Mobile Robot|
The role of exploration in learning control with neural networks|
Text Classification from Labeled and Unlabeled Documents using EM|
Decision-Theoretic, High-Level Agent Programming in the Situation Calculus|
The MONK's problems: A performance comparison of diIerent learningalgorithms|
Integrating Grid-Based and Topological Maps for Mobile Robot Navigation|
A Gesture Based Interface for Human-Robot Interaction|
Color Constancy Using KL-Divergence|
Learning Metric-Topological Maps for Indoor Mobile Robot Navigation|
Template-Based Recognition of Pose and Motion Gestures On a Mobile Robot|
Map building with mobile robots in dynamic environments|
Experiences with an Interactive Museum Tour-Guide Robot|
Conditional Particle Filters for Simultaneous Mobile Robot Localization and People-Tracking|
Adaptive Look-Ahead Planning|
Inversion in Time|
The Monk's problems: A performance comarison of different learning algorithms|
Bayesian Landmark Learning for Mobile Robot Localization|
Probabilistic robotics|
Lifelong robot learning|
Issues in Using Function Approximation for Reinforcement Learning,|
Monte Carlo Localization with Mixture Proposal Distribution|
and 23 co-authors|
Spontaneous, Short-Term Interaction with Mobile Robots|
Monte Carlo Hidden Markov Models: Learning Non-Parametric Models of Partially Observable Stochastic Processes|
MINERVA: A Tour-Guide Robot that Learns|
Integrating Inductive Neural Network Learning and Explanation-Based Learning|
Simultaneous localization and mapping with unknown data association using fastSLAM|
An integrated approach to hierarchy and abstraction for POMDPs|
Learning to Locate an Object in 3D Space from a Sequence of Camera Images|
Towards Programming Tools for Robots that Integrate Probabilistic Computation and Learning|
Finding Landmarks for Mobile Robot Navigation|
Position Estimation for Mobile Robots in Dynamic Environments|
Monte Carlo POMDPs|
Towards Exact Localization without Explicit Localization with the Generalized Voronoi Graph|
Active Exploration in Dynamic Environments|
Is Learning The n-th Thing Any Easier Than Learning The First?|
Real-Time Acquisition of Compact Volumetric 3D Maps with Mobile Robots|
Online simultaneous localization and mapping with detection and tracking of moving objects: theory and results from a ground vehicle in crowded urban areas|
Particle Filters in Robotics|
A system for volumetric robotic mapping of abandoned mines|
Exploration and model building in mobile robot domains|
Optimizing Schedules for Prioritized Path Planning of Multi-Robot Systems|
A Bayesian Multiresolution Independence Test for Continuous Variables|
Results for outdoor-SLAM using sparse extended information filters|
Active Mobile Robot Localization|
A Multi-Resolution Pyramid for Outdoor Robot Terrain Perception|
's problems: A performance comparison of different learning algorithms|
Efficient Exploration in Enforcement Learning|
Coastal Navigation: Mobile Robot Navigation with Uncertainty in Dynamic Environments|
Learning Occupancy Grid Maps with Forward Sensor Models|
The RHINO museum tour-guide project|
Coastal navigation -- robot motion with uncertainty|
A Robotic Walker that Provides Guidance|
To appear)| Active exploration in dynamic environments. 
Efficient exploration in reinforcement learning|
Markov Localization for Reliable Robot Navigation and People Detection|
The monk's comparison of learning algorithms - introduction and survey|
An approach to learning robot navigation|
The role of exploration on learning control",|
Explanation Based Learning for Mobile Robot Perception|
Constraining Neural Networks to Fit Target Slopes| Internal Memo, Learning Robot. 
Extracting Probably Correct Rules from Artificial Neural Networks|
Backpropagation on the monk's problems|
Computer Science Department Stanford University 353 Serra Mall Gates Building 154 Stanford,|
Locating moving entities in dynamic indoor environments|
The monk's problem: A performance comparison of different learning algorithms|
