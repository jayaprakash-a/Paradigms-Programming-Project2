3D Model Acquisition from Extended Image Sequences| Abstract.  A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models.  The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework.  The matching techniques are both robust (detecting and discarding mismatches) and fully automatic.  The matched tokens are used to compute 3D structure, which is initialised as it appears and then recursively updated over time.  The approach is uncalibrated - camera internal parameters and camera motion are not known or required.  Experimental results are provided for a variety of scenes, including outdoor scenes taken with a hand-held camcorder.  Quantitative statistics are included to assess the matching performance, and renderings of the 3D structure enable a qualitative assessment of the results. 
Metric Calibration of a Stereo Rig| Abstract We describe a method to determine affine and metric calibration for a stereo rig.  The method does not involve the use of calibration objects or special motions, but simply a single general motion of the rig with fixed parameters (i. e.  camera parameters and relative orientation of the camera pair).  The novel aspects of this work are: first, relating the distinguished objects of Euclidean geometry to fixed entities of a Euclidean transformation matrix; second, showing that these fixed entities are accessible from the conjugate Euclidean transformation arising from the projective transformation of the structure under a motion of the fixed stereo rig; third, a robust and automatic implementation of the method.  Results are included of affine and metric calibration and structure recovery using images of real scenes. 
A Sampled Texture Prior for Image Super-Resolution| Abstract Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content.  Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space.  Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case.  Here we present a domain-specific image prior in the form of a p. d. f.  based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a significant improvement over other common multiple-image super-resolution techniques. 
Video Google: A Text Retrieval Approach to Object Matching in Videos| Abstract We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video.  The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion.  The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors.  The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used.  The result is that retrieval is immediate, returning a ranked list of key frames/shots in the manner of Google.  The method is illustrated for matching on two full length feature films. 
Finding Point Correspondences in Motion Sequences Preserving Ane Structure| Abstract In this paper the problem of computing the point correspondences in a sequence of time-varying images of a 3D object undergoing non-rigid (ane) motion is addressed.  It is assumed that the images are obtained through ane projections.  The correspondences are established only from the analysis of the unknown 3D ane structure of the object, without making use of any attributes of the feature points.  It is shown that it is possible to establish the point correspondences uniquely (up to symmetry) in the sense that they yield a unique ane structure of the object and that the computation is possible in polynomial time.  Two different algorithms for computing the point correspondences are presented.  Results on various real image sequences, including a sequence containing independently moving objects, demonstrate the applicability of the structure based approach to motion correspondence. 
Statistical Approaches to Material Classification| Abstract The objective of this paper is classification of materials from a single image obtained under unknown viewpoint and illumination conditions.  Texture classification under such general conditions is an extremely challenging task.  Our methods are based on the statistical distribution of rotationally invariant filter responses in a low dimensional space.  There are two points of novelty: first, two representations of filter outputs, textons and binned histograms, are shown to be equivalent; second, two classification methodologies, nearest neighbour matching and Bayesian classification, are compared.  In essence, given the equivalence of texton and bin representations, the paper carries out an exact comparison between the texton based distribution comparison classifiers of Leung and Malik [IJCV 2001], Cula and Dana [CVPR 2001], and Varma and Zisserman [ECCV 2002], and the Bayesian classification scheme of Konishi and Yuille [CVPR 2000].  The comparisons are assessed by classifying images of all 61 materials present in the Columbia-Utrecht database.  Classification rates of over 97% are achieved for both the methods while classifying more than 2800 images in all. 
Detecting and Tracking Linear Features Efficiently| Abstract An efficient method for detecting and tracking linear features in images is described.  This novel algorithm combines a sparse sampling of the image data with a RANSAC grouper, and is particularly suited for frame-rate vision.  The detector is tunable for both the scale and orientation of the desired line segments.  Experimental results demonstrate fast, robust and accurate feature detection and tracking. 
Image-based Environment Matting| Abstract Environment matting is a powerful technique for modeling the complex light-transport properties of real-world optically active elements: transparent, refractive and reflective objects.  Recent research has shown how environment mattes can be computed for real objects under carefully controlled laboratory conditions.  However, many objects for which environment mattes are necessary for accurate rendering cannot be placed into a calibrated lighting environment.  We show in this paper that analysis of the way in which optical elements distort the appearance of their backgrounds allows the construction of environment mattes in situ without the need for specialized calibration.  Specifically, given multiple images of the same element over the same background, where the element and background have relative motion, it is shown that both the background and the optical element's light-transport path can be computed.  We demonstrate the technique on two different examples.  In the first case, the optical element's geometry is simple, and evaluation of the realism of the output is easy.  In the second, previous techniques would be difficult to apply.  We show that image-based environment matting yields a realistic solution.  We discuss how the stability of the solution depends on the number of images used, and how to regularize the solution where only a small number of images are available. 
Automatic line matching across views| Abstract This paper presents a new method for matching individual line segments between images.  The method uses both greylevel information and the multiple view geometric relations between the images.  For image pairs epipolar geometry facilitates the computation of a cross-correlation based matching score for putative line correspondences.  For image triplets cross-correlation matching scores are used in conjunction with line transfer based on the trifocal geometry.  Algorithms are developed for both short and long range motion.  In the case of long range motion the algorithm involves evaluating a one parameter family of plane induced homographies.  The algorithms are robust to deficiencies in the line segment extraction and partial occlusion.  Experimental results are given for image pairs and triplets, for varying motions between views, and for different scene types.  The three view algorithm eliminates all mismatches. 
Image-based rendering using image-based priors| Abstract Given a set of images acquired from known viewpoints, we describe a method for synthesizing the image which would be seen from a new viewpoint.  In contrast to existing techniques, which explicitly reconstruct the 3D geometry of the scene, we transform the problem to the reconstruction of colour rather than depth.  This retains the benefits of geometric constraints, but projects out the ambiguities in depth estimation which occur in textureless regions.  On the other hand, regularization is still needed in order to generate high-quality images.  The paper's second contribution is to constrain the generated views to lie in the space of images whose texture statistics are those of the input images.  This amounts to a image-based prior on the reconstruction which regularizes the solution, yielding realistic synthetic views.  Examples are given of new view generation for cameras interpolated between the acquisition viewpoints---which enables synthetic steadicam stabilization of a sequence with a high level of realism. 
Minimal Projective Reconstruction for Combinations of Points and Lines in Three Views| Abstract In this paper we address the problem of projective reconstruction of structure and motion given only image data.  In particular we investigate three novel minimal combinations of points and lines over three views, and give complete solutions and reconstruction methods for two of these cases: "four points and three lines in three views", and "two points and six lines in three views".  We show that in general there are three and seven solutions respectively to these cases.  The reconstruction methods are tested on real and simulated data.  We also give tentative results for the case of nine lines in correspondence over three views, where experiments indicate that there may be up to 36 complex solutions. 
Projective Reconstruction of Surfaces of Revolution| Abstract.  This paper addresses the problem of recovering the generating curve of a surface of revolution from a single uncalibrated perspective view, based solely on the object's outline and two (partly) visible crosssections.  Without calibration of the camera's internal parameters such recovery is only possible up to a particular transformation of the true shape.  This is however sufficient for 3D reconstruction up to a 2 DOF transformation, for recognition of objects, and for transfer between views.  We will describe the basic algorithm and show some examples. 
Model selection for automated reconstruction from multiple views| Abstract We describe progress in automatically fitting a plane plus modelled perturbation surface model to represent architectural scenes.  There are two areas of novelty.  The first is a method of fitting parametrized models in which the cost function is based on a combination of disparity and gradient extrema, both computed over multiple views.  The second is the use of an evaluation criteria for model selection, learnt from training examples.  We demonstrate the method on reconstructions of several college scenes from multiple images. 
Automatic 3D Model Construction for Turn-Table Sequences| Abstract.  As virtual worlds demand ever more realistic 3D models,
Learning Layered Pictorial Structures from Video| Abstract We propose a new unsupervised learning method to obtain a layered pictorial structure (LPS) representation of an articulated object from video sequences.  It will be seen that this is related in turn to methods for learning sprite based representations of an image.  The method we describe involves a new generative model for performing segmentation on a set of images.  Included in this model are the effects of motion blur and occlusion.  An initial estimate of the parameters of the model is obtained by dividing the scene into rigidly moving components.  The estimate of the matt of each part is refined using a variation of the #-expansion graph cut algorithm.  This method has the advantage of achieving a strong local minimum over labels.  Results are demonstrated on animals for which an articulated LPS representation is naturally suited. 
Maintaining Multiple Motion Model Hypotheses Through Many Views to Recover Matching and Structure| Abstract In order to recover structure from images it is desirable to use many views to obtain the best possible estimates.  However, whilst recovering projective structure and motion from such extended sequences problems arise that are not apparent from a general viewpoint/structure approach.  Foremost amongst these are (a) maintaining image correspondences consistently through many images, and (b) identifying images, within the sequence, for which structure cannot be reliably recovery.  Within this paper the use of multiple motion model hypotheses is explored as an aid to solve both of these problems. 
Bayesian Estimation of Layers from Multiple Images| Abstract.  When estimating foreground and background layers (or equivalently
Strike a Pose: Tracking People by Finding Stylized Poses| Abstract We develop an algorithm for finding and kinematically tracking multiple people in long sequences.  Our basic assumption is that people tend to take on certain canonical poses, even when performing unusual activities like throwing a baseball or figure skating.  We build a person detector that quite accurately detects and localizes limbs of people in lateral walking poses.  We use the estimated limbs from a detection to build a discriminative appearance model; we assume the features that discriminate a figure in one frame will discriminate the figure in other frames.  We then use the models as limb detectors in a pictorial structure framework, detecting figures in unrestricted poses in both previous and successive frames.  We have run our tracker on hundreds of thousands of frames, and present and apply a methodology for evaluating tracking on such a large scale.  We test our tracker on real sequences including a feature-length film, an hour of footage from a public park, and various sports sequences.  We find that we can quite accurately automatically find and track multiple people interacting with each other while performing fast and unusual motions. 
Direct Estimation of Non-Rigid Registrations| Abstract Registering images of a deforming surface is a well-studied problem.  Solutions include computing optic flow or estimating a parameterized motion model.  In the case of optic flow it is necessary to include some regularization.  We propose an approach based on representing the induced transformation between images using Radial Basis Functions (RBF).  The approach can be viewed as a direct, i. e.  intensity-based, method, or equivalently, as a way of using RBFs as non-linear regularizers on the optic flow field.  The approach is demonstrated on several image sequences of deforming surfaces.  It is shown that the computed registrations are sufficiently accurate to allow convincing augmentations of the images. 
Sampling Methods for Unsupervised Learning| Abstract We present an algorithm to overcome the local maxima problem in estimating the parameters of mixture models.  It combines existing approaches from both EM and a robust fitting algorithm, RANSAC, to give a data-driven stochastic learning scheme.  Minimal subsets of data points, sufficient to constrain the parameters of the model, are drawn from proposal densities to discover new regions of high likelihood.  The proposal densities are learnt using EM and bias the sampling toward promising solutions, giving an efficient algorithm.  We compare it with alternative methods, including EM and RANSAC, on both challenging synthetic data and real visual data from Google's image search. 
Geometric Grouping of Repeated Elements within Images| Abstract The objective of this work is the automatic detection and grouping of imaged elements which repeat in a scene.  We show that structures that repeat in the world (for example wall paper patterns) are related by particular parametrized transformations in perspective images.  These image transformations provide powerful grouping constraints, and can be used at the heart of hypothesize and verify grouping algorithms.  Parametrized transformations are given for some classes of repeating operation in the world as well as some groupers based on these.  These groupers are demonstrated on a number of real images, where both the elements and the grouping are determined automatically.  It is also shown that the repeating element can be learnt from the image, and hence provides an image descriptor. 
Real-time Panoramic Mosaics and Augmented Reality| Abstract This paper investigates estimating exact imaging transformations accurately, reliably and efficiently.  It is shown that in certain common computer vision situations the transformation required can be defined by a small number of parameters.  Search is only required over these parameters, and consequently the search algorithms to estimate the transformation can be run at frame rate, without sacrificing robustness or accuracy.  Performance is superior to often used approximations to these transformations.  Two examples are illustrated: planar panoramic mosaicing, and augmented reality.  Both applications run at frame rate on standard desktop machines, such as an SGI Indy or a PC. 
A Sparse Object Category Model for Efficient Learning and Exhaustive Recognition| Abstract We present a "parts and structure" model for object category recognition that can be learnt efficiently and in a semisupervised manner: the model is learnt from example images containing category instances, without requiring segmentation from background clutter.  The model is a sparse representation of the object, and consists of a star topology configuration of parts modeling the output of a variety of feature detectors.  The optimal choice of feature types (whose repertoire includes interest points, curves and regions) is made automatically.  In recognition, the model may be applied efficiently in an exhaustive manner, bypassing the need for feature detectors, to give the globally optimal match within a query image.  The approach is demonstrated on a wide variety of categories, and delivers both successful classification and localization of the object within the image. 
Improving Augmented Reality using Image and Scene Constraints| Abstract The goal of augmented reality is to insert virtual objects into real video sequences.  This paper shows that by incorporating image-based geometric constraints over multiple views, we improve on traditional techniques which use purely 3D information.  The constraints imposed are chosen to directly target perceptual cues, important to the human visual system, by which errors in AR are most readily perceived.  Imposition of the constraints is achieved by constrained maximum-likelihood estimation, and blends projective, affine and Euclidean geometry as appropriate in different cases.  We introduce a number of examples of augmented reality tasks, show how image-based constraints can be incorporated into current 3D-based systems, and demonstrate the improvements conferred. 
Object Class Recognition by Unsupervised Scale-Invariant Learning| Abstract We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner.  Objects are modeled as flexible constellations of parts.  A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale.  An entropy-based feature detector is used to select regions and their scale within the image.  In learning the parameters of the scale-invariant object model are estimated.  This is done using expectation-maximization in a maximum-likelihood setting.  In recognition, this model is used in a Bayesian manner to classify images.  The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e. g.  faces, cars) and flexible objects (such as animals). 
Minimal Training, Large Lexicon, Unconstrained Sign Language Recognition| Abstract This paper presents a flexible monocular system capable of recognising sign lexicons far greater in number than previous approaches.  The power of the system is due to four key elements: (i) Head and hand detection based upon boosting which removes the need for temperamental colour segmentation; (ii) A body centred description of activity which overcomes issues with camera placement, calibration and user; (iii) A two stage classification in which stage I generates a high level linguistic description of activity which naturally generalises and hence reduces training; (iv) A stage II classifier bank which does not require HMMs, further reducing training requirements.  The outcome of which is a system capable of running in real-time, and generating extremely high recognition rates for large lexicons with as little as a single training instance per sign.  We demonstrate classification rates as high as 92% for a lexicon of 164 words with extremely low training requirements outperforming previous approaches where thousands of training examples are required. 
Discovering object categories in image collections|
Shape from Texture: Homogeneity Revisited| Abstract The objective of this paper is to estimate the orientation of a scene plane from an uncalibrated perspective image under the assumption that the scene is coated with a homogeneous (but unknown) texture.  We make the following novel contributions: first, we show that the problem is equivalent to estimating the vanishing line of the plane; second, we show that estimating the two degrees of freedom of this line can be decomposed into two searches each for one parameter; third, we give an algorithm for this estimation which is applicable to both regular and irregular textures.  The algorithms do not require that texels are identified explicitly.  But once the plane vanishing line has been obtained, then texels locations can be determined, and the geometry of the scene plane computed up to an affine transformation.  We give examples of these computations on real images. 
Video Data Mining Using Configurations of Viewpoint Invariant Regions| Abstract We describe a method for obtaining the principal objects, characters and scenes in a video by measuring the reoccurrence of spatial configurations of viewpoint invariant features.  We investigate two aspects of the problem: the scale of the configurations, and the similarity requirements for clustering configurations.  The problem is challenging firstly because an object can undergo substantial changes in imaged appearance throughout a video (due to viewpoint and illumination change, and partial occlusion), and secondly because configurations are detected imperfectly, so that inexact patterns must be matched.  The novelty of the method is that viewpoint invariant features are used to form the configurations, and that efficient methods from the text analysis literature are employed to reduce the matching complexity.  Examples of `mined' objects are shown for a feature length film and a sitcom. 
Learning epipolar geometry from image sequences| Abstract We wish to determine the epipolar geometry of a stereo camera pair from image measurements alone.  This paper describes a solution to this problem which does not require a parametric model of the camera system, and consequently applies equally well to a wide class of stereo configurations.  Examples in the paper range from a standard pinhole stereo configuration to more exotic systems combining curved mirrors and wide-angle lenses.  The method described here allows epipolar curves to be learned from multiple image pairs presented to the stereo cameras.  By aggregating information over the multiple images, a dense map of the epipolar curves can be determined on the images.  The algorithm requires a large number of images, but has the distinct benefit that the correspondence problem does not have to be explicitly solved.  We show that for standard stereo configurations the results are comparable to those obtained from a state of the art parametric model method, despite the significantly weaker constraints on the non-parametric model.  The new algorithm is simple to implement, so it may easily be employed on a new and possibly complex camera system. 
Single View Metrology| Abstract We describe how 3D affine measurements may be computed from a single perspective view of a scene given only minimal geometric information determined from the image.  This minimal information is typically the vanishing line of a reference plane, and a vanishing point for a direction not parallel to the plane.  It is shown that affine scene structure may then be determined from the image, without knowledge of the camera's internal calibration (e. g.  focal length), nor of the explicit relation between camera and world (pose).  In particular, we show how to (i) compute the distance between planes parallel to the reference plane (up to a common scale factor); (ii) compute area and length ratios on any plane parallel to the reference plane; (iii) determine the camera's (viewer's) location.  Simple geometric derivations are given for these results.  We also develop an algebraic representation which unifies the three types of measurement and, amongst other advantages, permits a first order error propagation analysis to be performed, associating an uncertainty with each measurement.  We demonstrate the technique for a variety of applications, including height measurements in forensic images and 3D graphical modelling from single images. 
Extending Pictorial Structures for Object Recognition| Abstract The goal of this paper is to recognize various deformable objects from images.  To this end we extend the class of generative probabilistic models known as pictorial structures.  This class of models is particularly suited to represent articulated structures, and has previously been used by Felzenszwalb and Huttenlocher for pose estimation of humans.  We extend pictorial structures in three ways: (i) likelihoods are included for both the boundary and the enclosed texture of the animal; (ii) a complete graph is modelled (rather than a tree structure); (iii) it is demonstrated that the model can be fitted in polynomial time using belief propagation.  We show examples for two types of quadrupeds, cows and horses.  We achieve excellent recognition performance for cows with an equal error rate of 3% for 500 positive and 5000 negative images. 
Discovering objects and their location in images| Abstract We seek to discover the object categories depicted in a set of unlabelled images.  We achieve this using a model developed in the statistical text literature: probabilistic Latent Semantic Analysis (pLSA).  In text analysis this is used to discover topics in a corpus using the bag-of-words document representation.  Here we treat object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics.  The model is applied to images by using a visual analogue of a word, formed by vector quantizing SIFT-like region descriptors.  The topic discovery approach successfully translates to the visual domain: for a small set of objects, we show that both the object categories and their approximate spatial layout are found without supervision.  Performance of this unsupervised method is compared to the supervised approach of Fergus et al.  [8] on a set of unseen images containing only one object per image.  We also extend the bag-of-words vocabulary to include `doublets' which encode spatially local co-occurring regions.  It is demonstrated that this extended vocabulary gives a cleaner image segmentation.  Finally, the classification and segmentation methods are applied to a set of images containing multiple objects per image.  These results demonstrate that we can successfully build object class models from an unsupervised analysis of images. 
Bringing Pictorial Space to Life: Computer Techniques for the Analysis of Paintings| This paper explores the use of computer graphics and computer vision techniques in the history of art.  The focus is on analysing the geometry of perspective paintings to learn about the perspectival skills of artists and explore the evolution of linear perspective in history.  Algorithms for a systematic analysis of the two- and three-dimensional geometry of paintings are drawn from the work on "single-view reconstruction" and applied to interpreting works of art from the Italian Renaissance and later periods.  Since a perspectival painting is not a photograph of an actual subject but an artificial construction subject to imaginative manipulation and inadvertent inaccuracies, the internal consistency of its geometry must be assessed before carrying out any geometric analysis.  Some simple techniques to analyse the consistency and perspectival accuracy of the geometry of a painting are discussed.  Moreover, this work presents new algorithms for generating new views of a painted scene or portions of it, analysing shapes and proportions of objects, filling in occluded areas, performing a complete three-dimensional reconstruction of a painting and a rigorous analysis of possible reconstruction ambiguities.  The validity of the techniques described here is demonstrated on a number of historical paintings and frescoes.  Whenever possible, the computer-generated results are compared to those obtained by art historians through careful manual analysis.  This research represents a further attempt to build a constructive dialogue between two very different disciplines: computer science and history of art. 
Vision based Interpretation of Natural Sign Languages| Abstract.  This manuscript outlines our current demonstration system for translating visual Sign to written text.  The system is based around a broad description of scene activity that naturally generalizes, reducing training requirements and allowing the knowledge base to be explicitly stated.  This allows the same system to be used for different sign languages requiring only a change of the knowledge base. 
Class-Based Grouping in Perspective Images| Abstract A major issue for object recognition systems is the organization of object structure and separation of individual objects within an image of a complex scene.  This paper demonstrates that general geometric object classes can be defined which provide effective constraints for grouping image features into coherent object boundaries.  These classes also support the computation of 3D invariant descriptions including symmetry axes, canonical coordinate frames and projective signatures.  The key idea is that a 3D geometric class defines relations which must hold between points on the image outline (the perspective projection of the object's surface).  The resulting image constraints enable both identification and grouping of image features belonging to objects of that class.  The classes include surfaces of revolution, canal surfaces (pipes) and polyhedra.  Recognition proceeds by first recognising an object as belonging to one of the classes (for example a surface of revolution) and subsequently classifying the object (for example as a particular vase).  This differs from conventional object recognition systems where recognition is generally targetted at particular objects.  The constraints and grouping methods are viewpoint invariant, and proceed with no information on object pose.  We demonstrate the effectiveness of this class-based grouping on real, cluttered scenes using grouping algorithms developed for canal-surfaces, rotationally symmetric surfaces and polyhedra. 
A Linguistic Feature Vector for the Visual Interpretation of Sign Language| Independent Component Analysis.  We demonstrate classification rates as high as 97. 67% for a lexicon of 43 words using only single instance training outperforming previous approaches where thousands of training examples are required. 
Performance characterization of fundamental matrix estimation under image degradation|
Robust Detection of Degenerate Configurations for the Fundamental Matrix|
Combining Scene and Auto-Calibration Constraints|
Projectively Invariant Representations Using Implicit Algebraic Curves|
Reflections on Shading|
On Affine Invariant Clustering and Automatic Cast Listing in Movies|
Multibody Structure and Motion: 3-D Reconstruction of Independently Moving Objects|
Navigation using Affine Structure from Motion|
Active Visual Navigation Using Non-Metric Structure|
Super-Resolution Enhancement of Text Image Sequences|
Robust Parameterization and Computation of the Trifocal Tensor|
Transformational invariance - a primer|
Self-Calibration from Image Triplets|
Motion From Point Matches Using Affine Epipolar Geometry|
Multi-view Matching for Unordered Image Sets, or "How Do I Organize My Holiday Snaps?"|
Motion Deblurring and Super-resolution from an Image Sequence|
Automatic Camera Recovery for Closed or Open Image Sequences|
Automated Person Identification in Video|
Invariant Descriptors for 3D Object Recognition and Pose|
Feature Based Methods for Structure and Motion Estimation|
Concerning Bayesian Motion Segmentation, Model, Averaging, Matching and the Trifocal Tensor|
Surface descriptions from stereo and shading|
Viewpoint-invariant representation of generalized cylinders using the symmetry set|
Metric Rectification for Perspective Images of Planes|
Creating Architectural Models from Images|
Quadric Surface Reconstruction from Dual-Space Geometry|
Recognising rotationally symmetric surfaces from their outlines|
An Experimental Comparison of Appearance and Geometric Model Based Recognition|
A new approach to obtain height measurements from video|
Automatic Mosaicing with Super-Resolution Zoom|
Duality, Rigidity and Planar Parallax|
Parallax Geometry of Smooth Surfaces in Multiple Views|
Automated Scene Matching in Movies|
Super-Resolution from Multiple Views Using Learnt Image Models|
Wide Baseline Stereo Matching|
Object Level Grouping for Video Shots|
Matching and Reconstruction from Widely Separated Views|
Canonical Frames for Planar Object Recognition|
Robust Computation and Parametrization of Multiple View Relations|
Classifying Images of Materials: Achieving Viewpoint and Illumination Independence|
Goal-directed Video Metrology|
Automatic Reconstruction of Piecewise Planar Models from Multiple Views|
Visualising Cerebral Asymmetry|
Human Detection Based on a Probabilistic Assembly of Robust Part Detectors|
A Plane Measuring Device|
Collision detection using divergent Image Flow|
Metric calibration of a stereo rig|
Sequential update of projective and affine structure from motion|
Repeated Structures: Image Correspondence Constraints and 3D Structure Recovery|
editors|
and Nic Pillow| 3D Object Recognition using Invariants. 
Visual Reconstruction|
The information available to a moving observer from specularities|
Detection and tracking of independent motion|
Visual reconstruction| MIT press,. 
Extracting structure from an affine view of a 3D point set with one or two bilateral symmetries|
Relative motion and pose from arbitrary plane curves|
Shape from shading in the light of mutual illumination|
Weak Continuity Constraints Generate Uniform Scale-Space Descriptions of Plane Curves|
MORSE: Multiple Object Recognition by Scene Entailment|
Stereo Autocalibration from One Plane|
Geometric Framework for Vision I: Single View and Two-View Geometry"|
Automated multisensor polyhedral model acquisition|
Notes on Geometric Invariance in Vision|
ed|s). 
Using a mixed wave/ diffusion process to elicit the symmetry set|
Real-time Visual Tracking for Surveillance and Path Planning|
3D Object Recognition Using Invariance|
"Automated Reconstruction From Multiple Photographs,|
VHS to VRML: 3D Graphical Models from Video Sequences|
A Case Against Epipolar Geometry|
Single Axis Geometry by Fitting Conics|
MRI heart image: Original image on the top left, edge image on the top right, distance map on the bottom|
Texture Classification: Are Filter Banks Necessary?|
Some properties of weak continuity constraints and the GNC algorithm|
Navigatio usi g a' e structure from motio|
Segmentation and measurement of brain structures in MRI including confidence bounds", Medical Image Analysis,|
Linear Auto-Calibration for Ground Plane Motion|
