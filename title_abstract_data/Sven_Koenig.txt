Probabilistic Planning for Behavior-Based Robots| An advantage of our system over previous POMDP navigation systems is that it is able to find close-to-optimal plans since it plans at a higher level and thus with smaller state spaces.  An advantage of our system over behavior-based systems that need to get programmed by their users is that it can optimize plans during missions and thus deal robustly with probabilistic models that are initially inaccurate. 
Real-Time Search in Non-Deterministic Domains| Abstract Many search domains are non-deterministic.  Although real-time search methods have traditionally been studied in deterministic domains, they are well suited for searching nondeterministic domains since they do not have to plan for every contingency -- they can react to the actual outcomes of actions.  In this paper, we introduce the min-max LRTA* algorithm, a simple extension of Korf's Learning Real-Time A* algorithm (LRTA*) to non-deterministic domains.  We describe which non-deterministic domains min-max LRTA* can solve, and analyze its performance for these domains.  We also give tight bounds on its worst-case performance and show how this performance depends on properties of both the domains and the heuristic functions used to encode prior information about the domains. 
Heuristic Search-Based Replanning| Abstract Many real-world planning problems require one to solve a
Value-Update Rules for Real-Time Search| Abstract Real-time search methods have successfully been used to solve a
Easy and Hard Testbeds for Real-Time Search Algorithms| Abstract Although researchers have studied which factors influence the behavior of traditional search algorithms, currently not much is known about how domain properties influence the performance of real-time search algorithms.  In this paper we demonstrate, both theoretically and experimentally, that Eulerian state spaces(a supersetof undirected state spaces)are very easy for some existing real-time search algorithms to solve: even real-time search algorithms that can be intractable, in general, are efficient for Eulerian state spaces.  Because
Exploring Unknown Environments with Real-Time Search or Reinforcement Learning| Abstract Learning Real-Time A* (LRTA*) is a popular control method that interleaves planning and plan execution and has been shown to solve search problems in known environments efficiently.  In this paper, we apply LRTA* to the problem of getting to a given goal location in an initially unknown environment.  Uninformed LRTA* with maximal lookahead always moves on a shortest path to the closest unvisited state, that is, to the closest potential goal state.  This was believed to be a good exploration heuristic, but we show that it does not minimize the worst-case plan-execution time compared to other uninformed exploration methods.  This result is also of interest to reinforcement-learning researchers since many reinforcement learning methods use asynchronous dynamic programming, interleave planning and plan execution, and exhibit optimism in the face of uncertainty, just like LRTA*. 
Analysis of Greedy Robot-Navigation Methods| Abstract Robots often have to navigate robustly despite incomplete information about the terrain or their location in the terrain.  In this case, they often use greedy methods to make planning tractable.  In this paper, we analyze two such robot-navigation methods.  The first method is Greedy Localization, which determines the location of a robot in known terrain by always moving it to the closest location from which it will make an observation that reduces the number of its possible locations, until it has reduced that number as much as possible.  We reduce the upper bound on the number of movements of Greedy Localization from O(n 3 2 ) to O(n log n) on grid graphs and thus close to the known lower bound of #(n log n/ log log n), where n is the number of (unblocked) vertices of the graph that discretizes the terrain.  The second method is Dynamic A* (D*), which is used on several prototypes of both urban reconnaissance and planetary robots.  It moves a robot in initially unknown terrain from given start coordinates to given goal coordinates by always moving the robot on a shortest presumed unblocked path from its current coordinates to the goal coordinates, pretending that unknown terrain is unblocked, until it has reached the goal coordinates or there are no more presumed unblocked paths.  We reduce the upper bound on the number of movements of D* from O(n 3 2 ) to O(n log 2 n) on arbitrary graphs and O(n log n) on planar graphs (including grid graphs) and thus close to the known lower bound of #(n log n/ log log n), where n is the number of (blocked and unblocked) vertices of the graph that discretizes the terrain. 
Lifelong Planning A| Abstract Heuristic search methods promise to find shortest paths for path-planning problems faster than uninformed search methods.  Incremental search methods, on the other hand, promise to find shortest paths for series of similar path-planning problems faster than is possible by solving each path-planning problem from scratch.  In this article, we develop Lifelong Planning A* (LPA*), an incremental version of A* that combines ideas from the artificial intelligence and the algorithms literature.  It repeatedly finds shortest paths from a given start vertex to a given goal vertex while the edge costs of a graph change or vertices are added or deleted.  Its first search is the same as that of a version of A* that breaks ties in favor of vertices with smaller g-values but many of the subsequent searches are potentially faster because it reuses those parts of the previous search tree that are identical to the new one.  We present analytical results that demonstrate its similarity to A* and experimental results that demonstrate its potential advantage in two different domains if the path-planning problems change only slightly and the changes are close to the goal. 
Minimizing Localization Travel Distance (regular paper)| Delayed Planning Architecture [4],[9], [8], we find that its performance ratio is poor, ranging between #(n) and #(n= log 2 n), depending on sensor and domain type.  In contrast, the algorithm's performance is good when measured in terms of travel cost, on discretized domains such as grid graphs.  On graphs with n vertices, the algorithm's worst-case travel cost is between #(n log n= log log n)) and O(n log n).  As a corollary we find that the total distance traveled by the greedy mapping algorithm is also O(n log n). 
Gridworlds as Testbeds for Planning with Incomplete Information| Abstract Gridworlds are popular testbeds for planning with incomplete information but not much is known about their properties.  We study a fundamental planning problem, localization, to investigate whether gridworlds make good testbeds for planning with incomplete information.  We find empirically that greedy planning methods that interleave planning and plan execution can localize robots very quickly on random gridworlds or mazes.  Thus, they may not provide adequately challenging testbeds.  On the other hand, we show that finding localization plans that are within a log factor of optimal is NP-hard.  Thus there are instances of gridworlds on which all greedy planning methods perform very poorly, and we show how to construct them.  These theoretical results help empirical researchers to select appropriate planning methods for planning with incomplete information as well as testbeds to demonstrate them. 
PDRRTs: Integrating Graph-Based and Cell-Based Planning| Abstract--- Motion-planning problems can be solved by discretizing the continuous configuration space, for example with graph-based or cell-based techniques.  We study rapidly exploring random trees (RRTs) as an example of graph-based techniques and the parti-game method as an example of cell-based techniques.  We then propose partigame directed RRTs (PDRRTs) as a novel technique that combines them.  PDRRTs are based on the parti-game method but use RRTs as local controllers rather than the simplistic controllers used by the parti-game method.  Our experimental results show that PDRRTs plan faster and solve more motion-planning problems than RRTs and plan faster and with less memory than the parti-game method. 
Experience with Rover Navigation for Lunar-Like Terrains| Abstract Reliable navigation is critical for a lunar rover, both for autonomous traverses and safeguarded, remote teleoperation.  This paper describes an implemented system that has autonomously driven a prototype wheeled lunar rover over a kilometer in natural, outdoor terrain.  The navigation system uses stereo terrain maps to perform local obstacle avoidance, and arbitrates steering recommendations from both the user and the rover.  The paper describes the system architecture, each of the major components, and the experimental results to date. 
Existence and Finiteness Conditions for Risk-Sensitive Planning: Results and Conjectures| Abstract Decision-theoretic planning with risk-sensitive planning objectives is important for building
Risk-Sensitive Planning with One-Switch Utility Functions: Value Iteration| Abstract Decision-theoretic planning with nonlinear utility functions is important since decision makers are often risk-sensitive in high-stake planning situations.  One-switch utility functions are an important class of nonlinear utility functions that can model decision makers whose decisions change with their wealth level.  We study how to maximize the expected utility of a Markov decision problem for a given one-switch utility function, which is difficult since the resulting planning problem is not decomposable.  We first study an approach that augments the states of the Markov decision problem with the wealth level.  The properties of the resulting infinite Markov decision problem then allow us to generalize the standard risk-neutral version of value iteration from manipulating values to manipulating functions that map wealth levels to values.  We use a probabilistic blocks-world example to demonstrate that the resulting risk-sensitive version of value iteration is practical. 
Speeding Up the Calculation of Heuristics for Heuristic Search-Based Planning| Abstract Heuristic search-based planners,
Incremental Heuristic Search in Artificial Intelligence| Overview It is often important that searches be fast.  Artificial intelligence has developed several ways of speeding up searches by trading off the search time and the cost of the resulting path.  This includes using inadmissible heuristics (Pohl 1970; Pohl 1973) and search with limited look-ahead (Korf 1990; Ishida and Korf 1991; Koenig 2001), which is also called real-time or agent-centered search.  In this article, we discuss a different way of speeding up searches, namely incremental search.  Incremental search is a search technique for continual planning (or, synonymously, replanning, plan reuse, and lifelong planning) that reuses information from previous searches to find solutions to a series of similar search problems potentially faster than is possible by solving each search problem from scratch.  Different from other ways of speeding up searches, it can guarantee to find shortest paths.  Notice that the terminology is unfortunately somewhat problematic since the term "incremental search" in computer science also refers to both on-line search and search with limited look-ahead (
Improved Fast Replanning for Robot Navigation in Unknown Terrain| Abstract Mobile robots often operate in domains that are only incompletely known, for example, when they have to move from given start coordinates to given goal coordinates in unknown terrain.  In this case, they need to be able to replan quickly as their knowledge of the terrain changes.  Stentz' Focussed Dynamic A* is a heuristic search method that repeatedly determines a shortest path from the current robot coordinates to the goal coordinates while the robot moves along the path.  It is able to replan one to two orders of magnitudes faster than planning from scratch since it modifies previous search results locally.  Consequently, it has been extensively used in mobile robotics.  In this paper, we introduce an alternative to Focussed Dynamic A* that implements the same navigation strategy but is algorithmically different.  Focussed Dynamic A* Lite is simpler, easier to understand, easier to analyze and easier to extend than Focussed Dynamic A*, yet is more efficient.  We believe that our results will make D*-like replanning algorithms even more popular and enable robotics researchers to adapt them to additional applications. 
Solving Robot Navigation Problems with Initial Pose Uncertainty Using Real-Time Heuristic Search| Abstract We study goal-directed navigation tasks in
The Influence of Domain Properties on the Performance of Real-Time Search Algorithms| Abstract In this report, we investigate the influence of domain properties on the performance of real-time search algorithms.  We study uninformed, revolving real-time search algorithms with minimal lookahead that solve suboptimal search problems, for example variants of Korf's LRTA* algorithm and edge counting (these algorithms have been used successfully in the literature).  We demonstrate, both theoretically and experimentally, that they can search Eulerian domains (a superset of undirected domains) very easily: even the real-time search algorithms that can be intractable are always efficient in Eulerian domains.  Because traditional real-time search testbeds (such as the eight puzzle and gridworlds) are Eulerian, they cannot be used to distinguish between efficient and inefficient real-time search algorithms.  It follows that one has to use nonEulerian domains to demonstrate the superiority of a real-time search algorithm across a wide range of domains -- the studied real-time search algorithms differ in this respect from traditional search algorithms.  To this end, we describe two classes of domains ("reset state spaces" and "quicksand state spaces") that do not suffer as much from the problems of the standard test domains and demonstrate the performance of various real-time search algorithms in them. 
Probabilistic Navigation in Partially Observable Environments| Abstract Autonomous mobile robots need very reliable navigation capabilities in
Incremental Replanning for Mapping| Abstract Incremental heuristic search methods can often replan paths much faster than incremental or heuristic search methods individually, yet are simple to use.  So far, they have only been used in mobile robotics to move a robot to given goal coordinates in unknown terrain.  As far as we know, incremental heuristic search methods have not yet been applied to the problem of mapping unknown terrain.  In this paper, we therefore describe how to apply our incremental heuristic search method D* Lite, that combines ideas from Lifelong Planning A* and Focussed D*, to mapping unknown terrain, which is rather nontrivial.  We then compare its runtime against that of incremental search and heuristic search alone, demonstrating the computational benefits of their combination.  By demonstrating the versatility and computational benefits of incremental heuristic search, we hope that this underexploited technique will be used more often in mobile robotics. 
Minimax real-time heuristic search| Abstract Real-time heuristic search methods interleave planning and plan executions and plan only in the part of the domain around the current state of the agents.  So far, real-time heuristic search methods have mostly been applied to deterministic planning tasks.  In this article, we argue that real-time heuristic search methods can efficiently solve nondeterministic planning tasks.  We introduce Min-Max Learning Real-Time A* (Min-Max LRTA*), a real-time heuristic search method that generalizes Korf's LRTA* to nondeterministic domains, and apply it to robot-navigation tasks in mazes, where the robots know the maze but do not know their initial position and orientation (pose).  These planning tasks can be modeled as planning tasks in nondeterministic domains whose states are sets of poses.  We show that Min-Max LRTA* solves the robot-navigation tasks fast, converges quickly, and requires only a small amount of memory. 
Incremental A*| Abstract Incremental search techniques find optimal solutions to series of similar search tasks much faster than is possible by solving each search task from scratch.  While researchers have developed incremental versions of uninformed search methods, we develop an incremental version of A*.  The first search of Lifelong Planning A* is the same as that of A* but all subsequent searches are much faster because it reuses those parts of the previous search tree that are identical to the new search tree.  We then present experimental results that demonstrate the advantages of Lifelong Planning A* for simple route planning tasks.  1 Overview Artificial intelligence has investigated knowledge-based search techniques that allow one to solve search tasks in large domains.  Most of the research on these methods has studied how to solve one-shot search problems.  However, search is often a repetitive process, where one needs to solve a series of similar search tasks, for example, because the actual situation turns out to be slightly different from the one initially assumed or because the situation changes over time.  An example for route planning tasks are changing traffic conditions.  Thus, one needs to replan for the new situation, for example if one always wants to display the least time-consuming route from the airport to the conference center on a web page.  In these situations, most search methods replan from scratch, that is, solve the search problems independently.  Incremental search techniques share with case-based planning, plan adaptation, repair-based planning, and learning search-control knowledge the property that they find solutions to series of similar search tasks much faster than is possible by solving each search task from scratch.  Incremental search techniques, however, differ from the other techniques in that the quality of their solutions is guaranteed to be as good as the quality of the solutions obtained by replanning from scratch.  Although incremental search methods are not widely known in artificial intelligence and control, different researchers have developed incremental search versions of uninformed search methods in the algorithms literature.  An overview can be found in [FMSN00].  We, on the other hand, develop an incremental version of A*, thus combining ideas from the algorithms literature and the artificial intelligence literature.  We call the algorithm Lifelong Planning A* (LPA*), in analogy to "lifelong learning" [Thr98], because it reuses
Building Terrain-Covering Ant Robots: A Feasibility Study| simulation experiment where ten ant robots covered a factory floor of 25 by 25 meters repeatedly over 85 hours without getting stuck. 
Terrain coverage with ant robots: a simulation study| ABSTRACT In this paper, we study a simple means for coordinating teams of simple agents.  In particular, we study ant robots and how they can cover terrain once or repeatedly by leaving markings in the terrain, similar to what ants do.  These markings can be sensed by all robots and allow them to cover terrain even if they do not communicate with each other except via the markings, do not have any kind of memory, do not know the terrain, cannot maintain maps of the terrain, nor plan complete paths.  The robots do not even need to be localized, which completely eliminates solving difficult and time-consuming localization problems.  In this paper, we use real-time heuristic search methods to implement ant robots and present a simulation study with several real-time heuristic search methods to study their properties for terrain coverage.  Our experiments show that all of the realtime heuristic search methods robustly cover terrain even if the robots are moved without realizing this, some robots fail, and some markings get destroyed.  These results demonstrate that terrain coverage with real-time heuristic search methods is an interesting alternative to more conventional terrain coverage methods. 
Sensor Planning with Non-linear Utility Functions| Abstract.  Sensor planning is concerned with when to sense and what to sense.  We study sensor planning in the context of planning objectives that trade-off between minimizing the worst-case, expected, and best-case planexecution costs.  Sensor planning with these planning objectives is interesting because they are realistic and the frequency of sensing changes with the planning objective: more pessimistic decision makers tend to sense more frequently.  We perform sensor planning by combining one of our techniques for planning with non-linear utility functions with an existing sensor-planning method.  The resulting sensor-planning method is not only as easy to implement as the sensor-planning method that it extends but also (almost) as efficient.  We demonstrate empirically how sensor plans change as the planning objective changes, using a common testbed for sensor planning. 
Safeguarded Teleoperation for Lunar Rovers: From Human Factors to Field Trials| Abstract In this paper we present recent advances in developing and validating the safeguarded teleoperation approach to
Unsupervised Learning of Probabilistic Models for Robot Navigation \Lambda| Abstract Navigation methods for office delivery robots need to take various sources of uncertainty into account in order to get robust performance.  In previous work, we developed a reliable navigation technique that uses partially observable Markov models to represent metric, actuator, and sensor uncertainties.  This paper describes an algorithm that adjusts the probabilities of the initialMarkov model by passively observing the robot's interactions with its environment.  The learned probabilities more accurately reflect the actual uncertainties in the environment, which ultimately leads to improved navigation performance.  The algorithm, an extension of the Baum-Welch algorithm, learns without a teacher and addresses the issues of limited memory and the cost of collecting training data.  Empirical results show that the algorithm learns good Markov models with a small amount of training data. 
Risk-averse auction agents| ABSTRACT Auctions are an important means for purchasing material in the era of e-commerce.  Research on auctions often studies them in isolation.  In practice, however, auction agents are part of complete supply-chain management systems and have to make the same decisions as their human counterparts.  To address this issue, we generalize results from auction theory in three ways.  First, auction theory provides the optimal bidding function for the case where auction agents want to maximize the expected profit.  Since companies are often risk-averse, we derive a closed form of the optimal bidding function for auction agents that maximize the expected utility of the profit for concave exponential utility functions.  Second, auction theory often assumes that auction agents know the bidder's valuation of an auctioned item.  However, the valuation depends on how the item can be used in the production process.  We therefore develop theoretical results that enable us to integrate our auction agents into production-planning systems to derive the bidder's valuation automatically.  Third, auction theory often assumes that the probability distribution over the competitors' valuations of the auctioned item is known.  We use simulations of the combined auction- and production-planning system to obtain crude approximations of these probability distributions automatically.  The resulting auction agents are part of a complete supply-chain management system and seamlessly combine ideas from auction theory, utility theory, and dynamic programming. 
The Complexity of Node Counting on Undirected Graphs| Abstract We analyze the complexity of Node Counting, a graph-traversal method.  On many graphs arising in control problems in Artificial Intelligence, Node Counting performs as efficiently as other methods which are known to be of polynomial complexity in the number of states (e. g. , Learning Real-Time A* method).  We show that complexity of Node Counting on undirected graphs is #(n p n ), which is not polynomial in the number of states.  This solves an open problem from the literature. 
Probabilistic Robot Navigation in Partially Observable Environments| Abstract Autonomous mobile robots need very reliable navigation capabilities in order to operate unattended for long periods of time.  This paper reports on first results of a research program that uses partially observable Markov models to robustly track a robot's location in office environments and to direct its goal-oriented actions.  The approach explicitly maintains a probability distribution over the possible locations of the robot, taking into account various sources of uncertainty, including approximate knowledge of the environment, and actuator and sensor uncertainty.  A novel feature of our approach is its integration of topological map information with approximate metric information.  We demonstrate the robustness of this approach in controlling an actual indoor mobile robot navigating corridors. 
Combining Two Fast-Learning Real-Time Search Algorithms Yields Even Faster Learning| Abstract.  Real-time search methods, such as LRTA*, have been used to solve a wide variety of planning problems because they can make decisions fast and still converge to a minimum-cost plan if they solve the same planning task repeatedly.  In this paper, we perform an empirical evaluation of two existing variants of LRTA* that were developed to speed up its convergence, namely HLRTA* and FALCONS.  Our experimental results demonstrate that these two real-time search methods have complementary strengths and can be combined.  We call the new real-time search method eFALCONS and show that it converges with fewer actions to a minimum-cost plan than LRTA*, HLRTA*, and FALCONS. 
A Reactive Robot Architecture with Planning on Demand| Abstract--- In this paper, we describe a reactive robot architecture that uses fast replanning methods to avoid the shortcomings of reactive navigation, such as getting stuck in box canyons or in front of small openings.  Our robot architecture differs from other robot architectures in that it gives planning progressively greater control of the robot if reactive navigation continues to fail, until planning controls the robot directly.  Our first experiments on a Nomad robot and in simulation demonstrate that our robot architecture promises to simplify the programming of reactive robot architectures and results in robust navigation, smooth trajectories, and reasonably good navigation performance. 
Graph Learning with a Nearest Neighbor Approach| Abstract In this paper, we study how to traverse all edges of an unknown graph G = (V; E) that is bi-directed and strongly connected.  This problem can be solved with a simple algorithm that traverses all edges at most twice, and no algorithm can do better in the worst case.  Artificial Intelligence researchers, however, often use the following online nearest neighbor algorithm: "repeatedly take a shortest path to the closest unexplored edge and traverse it. " We prove bounds on the worst-case complexity of this algorithm.  We show, for example, that its worst-case complexity is close to optimal for some classes of graphs, such as graphs with linear or star topology and dense graphs with edge lengths one.  In general, however, its complexity can grow faster than linear in the sum of all edge lengths, although not faster than log(V ) times the sum of all edge lengths. 
Passive Distance Learning for Robot Navigation| Abstract Autonomous mobile robots need good models of their environment, sensors and actuators to navigate reliably and efficiently.  While this information can be supplied by humans, or learned from scratch through active exploration, such approaches are tedious and time-consuming.  Our approach is to provide the robot with the topological and geometrical constraints that are easily obtainable by humans, and have the robot learn the rest while in the course of performing its tasks.  We present GROW-BW, an unsupervised and passive distance learning algorithm that overcomes the problem that the robot can never be sure about its location if it is not allowed to reduce its uncertainty by asking a teacher or executing localization actions.  Advantages of GROW-BW include that the robot can be used immediately to perform navigation tasks and improves its performance over time, focusing its attention to routes that are more relevant for its tasks.  We demonstrate that GROW-BW can learn good distance, sensor, and actuator models with only a small amount of experience. 
Limited Discrepancy Beam Search| Abstract Beam search reduces the memory consumption of bestfirst search at the cost of finding longer paths but its memory consumption can still exceed the given memory capacity quickly.  We therefore develop BULB (Beam search Using Limited discrepancy Backtracking), a complete memory-bounded search method that is able to solve more problem instances of large search problems than beam search and does so with a reasonable runtime.  At the same time, BULB tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory.  We demonstrate these properties of BULB experimentally for three standard benchmark domains. 
An Approximation Algorithm for the Robot Localization Problem| Abstract Localization is a fundamental problem in robotics.  The robot possesses line-of-sight sensors, a compass,
Speeding up the Convergence of Real-Time Search| Abstract Learning Real-Time A* (LRTA*) is a
Improved Analysis of Greedy Mapping| Abstract We analyze Greedy Mapping, a simple mapping method that has successfully been used on mobile robots.  Greedy Mapping moves the robot from its current location on a shortest path towards a closest unvisited, unscanned or informative location, until the terrain is mapped.  Previous work has resulted in upper and lower bounds on its worst-case travel distance but there was a large gap between the bounds.  In this paper, we reduce the gap substantially by decreasing the upper bound from O(|V | 3/2 ) to O(|V | ln |V |) edge traversals, where |V | is the number of vertices of the graph. 
Scaling up WA* with Commitment and Diversity| Abstract Weighted A* (WA*) is a popular search technique that scales up A* while sacrificing solution quality.  Recently, researchers have proposed two variants of WA*: KWA* adds diversity to WA*, and MSC-WA* adds commitment to WA*.  In this paper, we demonstrate that there is benefit in combining them.  The resulting MSC-KWA* scales up to larger domains than WA*, KWA* and MSC-WA*, which is rather surprising since diversity and commitment at first glance seem to be opposing concepts. 
The interaction of representations and planning objectives for decision-theoretic planning tasks| Abstract We study decision-theoretic planning or reinforcement learning in the presence of traps such as steep slopes
A Layered Architecture for Office Delivery Robots \Lambda| Abstract Office delivery robots have to perform many tasks.  They have to determine the order in which to visit offices, plan paths to those offices, follow paths reliably, and avoid static and dynamic obstacles in the process.  Reliability and efficiency are key issues in the design of such autonomous robot systems.  They must deal reliably with noisy sensors and actuators and with incomplete knowledge of the environment.  They must also act efficiently, in real time, to deal with dynamic situations.  Our architecture is composed of four abstraction layers: obstacle avoidance, navigation, path planning, and task scheduling.  The layers are independent, communicating processes that are always active, processing sensory data and status information to update their decisions and actions.  A version of our robot architecture has been in nearly daily use in our building since December 1995.  As of July 1996, the robot has traveled more than 75 kilometers in service of over 1800 navigation requests that were specified using our World Wide Web interface. 
Representations of Decision-Theoretic Planning Tasks| Abstract Goal-directed Markov Decision Process models (GDMDPs) are good models for many decision-theoretic planning tasks.  They have been used in conjunction with two different reward structures, namely the goal-reward representation and the action-penalty representation. 
Xavier: An Autonomous Mobile Robot on the Web| Abstract For the past three years, we have been running an experiment in web-based interaction with an autonomous indoor mobile robot.  The robot, Xavier, can accept commands to travel to different offices in our building, broadcasting camera images as it travels.  The experiment, which was originally designed to test a new navigation algorithm, has proven very successful, with over 30,000 requests received and 210 kilometers travelled, to date.  This article describes the autonomous robot system, the web-based interfaces, and how they communicate with the robot.  It highlights lessons learned during this experiment in web-based robotics and includes recommendations for putting future mobile robots on the web. 
Lifelong Planning for Mobile Robots| Abstract Mobile robots often have to replan as their knowledge of the world changes.  Lifelong planning is a paradigm that allows them to replan much faster than with complete searches from scratch, yet finds optimal solutions.  To demonstrate this paradigm, we apply it to Greedy Mapping, a simple sensor-based planning method that always moves the robot from its current cell to the closest cell that it has not observed yet, until the terrain is mapped.  Greedy Mapping has a small mapping time, makes only action recommendations and can thus coexist with other components of a robot architecture that also make action recommendations, and is able to take advantage of prior knowledge of parts of the terrain (if available).  We demonstrate how a robot can use our lifelongplanning version of A* to repeatedly determine a shortest path from its current cell to the closest cell that it has not observed yet.  Our experimental results demonstrate the advantage of lifelong planning for Greedy Mapping over other search methods.  Similar results had so far been established only for goal-directed navigation in unknown terrain. 
Complexity Analysis of Real-Time Reinforcement Learning| Abstract This paper analyzes the complexity of on-line reinforcement learning algorithms, namely asynchronous realtime versions of Q-learning and value-iteration, applied to the problem of reaching a goal state in deterministic domains.  Previous work had concluded that, in many cases, tabula rasa reinforcement learning was exponential for such problems, or was tractable only if the learning algorithm was augmented.  We show that, to the contrary, the algorithms are tractable with only a simple change in the task representation or initialization.  We provide tight bounds on the worst-case complexity, and show how the complexity is even smaller if the reinforcement learning algorithms have initial knowledge of the topology of the state space or the domain has certain special properties.  We also present a novel bidirectional Q-learning algorithm to find optimal paths from all states to a goal state and show that it is no more complex than the other algorithms. 
Greedy Localization #| Abstract In this paper, we show that finding localization plans with
Greedy Mapping of Terrain| Abstract We study a greedy mapping method that always moves the robot from its current location to the closest location that it has not visited (or observed) yet, until the terrain is mapped.  Although one does not expect such a simple mapping method to minimize the travel distance of the robot, we present analytical results that show (perhaps surprisingly) that the travel distance of the robot is reasonably small.  This is interesting because greedy mapping has a number of desirable properties.  It is simple to implement and integrate into complete robot architectures.  It does not need to have control of the robot at all times, takes advantage of prior knowledge about parts of the terrain (if available), and can be used by several robots cooperatively. 
Speeding up the Parti-Game Algorithm| Abstract In this paper, we introduce an efficient replanning algorithm for nondeterministic domains, namely what we believe to be the first incremental heuristic minimax search algorithm.  We apply it to the dynamic discretization of continuous domains, resulting in an efficient implementation of the parti-game reinforcement-learning algorithm for control in high-dimensional domains. 
Agent-Centered Search| Abstract In this article, we describe agent-centered search (sometimes also called real-time search or
Lifelong Planning A* and Dynamic A* Lite: The proofs| Technical report,. 
Finite Differencing of Computable Expressions|
Robot Navigation with Markov Models: A Framework for Path Planning and Learning with Limited Computational Resources|
A Layered Architecture for Office Delivery Robots|
Agent-Centered Search: Situated Search with Small Look-Ahead|
Trail-Laying Robots for Robust Terrain Coverage|
An Autonomous Mobile Robot on the Web,|
Efficient Goal-Directed Exploration|
The Effect of Representation and Knowledge on Goal-Directed Exploration with Reinforcement-Learning Algorithms|
Efficient and inefficient ant coverage methods|
D*Lite|
Performance bounds for planning in unknown terrain|
Improved analysis of D|
Improved fast replanning for mobile robots|
