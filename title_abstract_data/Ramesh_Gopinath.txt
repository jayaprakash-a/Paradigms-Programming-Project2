DIGIT RECOGNITION IN NOISY ENVIRONMENTS VIA A SEQUENTIAL GMM/SVM SYSTEM| ABSTRACT This paper exploits the fact that when GMM and SVM classifiers with roughly the same level of performance exhibit uncorrelated errors they can be combined to produce a better classifier.  The gain accrues from combining the descriptive strength of GMM models with the discriminative power of SVM classifiers.  This idea, first exploited in the context of speaker recognition [1, 2], is applied to speech recognition - specifically to a digit recognition task in a noisy environment - with significant gains in performance. 
TRANSCRIPTION OF BROADCAST NEWS - SYSTEM ROBUSTNESS ISSUES AND ADAPTATION TECHNIQUES| ABSTRACT This paper describes some of the main problems and issues specific to the transcription of broadcast news and describes some of the methods for solving them that have been incorporated into the IBM Large Vocabulary Continuous Speech Recognition System. 
Task Adaptation of Acoustic and Language Models Based on Large Quantities of Data| Abstract We investigate use of large amounts, over 1500 hours, of untranscribed data recorded from a deployed conversational system to improve the acoustic and language models.  The system that we considered allows users to perform transactions on their retirement accounts.  Using all the untranscribed data we get over 19% relative improvement in word error rate over a baseline system.  In contrast, a system built using 70 hours of transcribed data results in over 31% relative improvement. 
The Phaselet Transform - An Integral Redundancy Nearly Shift-Invariant Wavelet Transform| Abstract This paper introduces an approximately shift invariant redundant dyadic wavelet transform - the phaselet transform - that includes the popular dual-tree complex wavelet transform of Kingsbury [1
GAUSSIAN MIXTURE MODELING WITH VOLUME PRESERVING NONLINEAR FEATURE SPACE TRANSFORMS| ABSTRACT This paper introduces a new class of nonlinear feature space transformations in the context of Gaussian Mixture Models.  This class of nonlinear transformations is characterized by computationally efficient training algorithms.  Experimental results with quadratic feature space transforms are shown to yield modestly improved recognition performance in a speech recognition context.  The quadratic feature space transforms are also shown to be beneficial in an adaptation setting. 
CONSTRAINED MAXIMUM LIKELIHOOD MODELING WITH GAUSSIAN DISTRIBUTIONS| ABSTRACT Maximum Likelihood (ML) modeling of multiclass data using gaussian distributions for classification often suffers from the following problems: a) data insufficiency implying overtrained or unreliable models b) large storage requirementc) large computational requirement and/or d) ML is not discriminating between classes.  Sharing parameters across classes (or constraining the parameters) clearly tends to alleviate the first three problems.  It this paper we show that in some cases it can also lead to better discrimination (as evidenced by reduced misclassification error).  The parameters considered are the means and variances of the gaussians and linear transformations of the feature space (or equivalently the gaussian means).  Some forms of sharing (either explicit or implicit via constraints) on the parameters are shown to lead to Linear Discrimination Analysis (a well-known result) while others (like diagonal, block-diagonal and factor analyzed covariances) are shown to lead to optimal feature spaces.  The key idea is that in constrained ML modeling one may be able to better model the data after it is linearly transformed, perhaps in a class dependent fashion.  If the constrains are invariantto linear transformations (ILT), then, the original feature space is as good as any to model the data.  Results using optimal feature spaces for diagonal covariances is shown using the speech recognition problem as an example. 
Automatic Transcription of Broadcast News| 4 The distribution of powers, #, after training using (28) on the
THE IBM PERSONAL SPEECH ASSISTANT| ABSTRACT In this paper, we describe technology and experience with an experimental personal information manager, which interacts with the user primarily but not exclusively through speech recognition and synthesis.  This device, which controls a client PDA, is known as the Personal Speech Assistant (PSA).  The PSA contains complete speech recognition, speech synthesis and dialog management
Large Vocabulary Conversational Speech Recognition with a Subspace Constraint on Inverse Covariance Matrices| Abstract This paper applies the recently proposed SPAM models for acoustic modeling in a Speaker Adaptive Training (SAT) context on large vocabulary conversational speech databases, including the Switchboard database.  SPAM models are Gaussian mixture models in which a subspace constraint is placed on the precision and mean matrices (although this paper focuses on the case of unconstrained means).  They include diagonal covariance, full covariance, MLLT, and EMLLT models as special cases.  Adaptation is carried out with maximum likelihood estimation of the means and feature-space under the SPAM model.  This paper shows the first experimental evidence that the SPAM models can achieve significant word-error-rate improvements over state-of-the-art diagonal covariance models, even when those diagonal models are given the benefit of choosing the optimal number of Gaussians (according to the Bayesian Information Criterion).  This paper also is the first to apply SPAM models in a SAT context.  All experiments are performed on the IBM "Superhuman" speech corpus, which is a challenging and diverse conversational speech test set that includes the Switchboard portion of the 1998 Hub5 evaluation data set. 
Formulas for Orthogonal IIR Wavelet Filters|
MODELING WITH A SUBSPACE CONSTRAINT ON INVERSE COVARIANCE MATRICES| ABSTRACT We consider a family of Gaussian mixture models for use in HMM based speech recognition system.  These "SPAM" models have state independent choices of subspaces to which the precision (inverse covariance) matrices and means are restricted to belong.  They provide a flexible tool for robust, compact, and fast acoustic modeling.  The focus of this paper is on the case where the means are unconstrained.  The models in the case already generalize the recently introduced EMLLT models, which themselves interpolate between MLLT and full covariance models.  We describe an algorithm to train both the state-dependent and state-independent parameters.  Results are reported on one speech recognition task.  The SPAM models are seen to yield significant improvements in accuracy over EMLLT models with comparable model size and runtime speed.  We find a ##### relative reduction in error rate over an MLLT model can be obtained while decreasing the acoustic modeling time by ##### . 
AUTOMATIC GENERATION AND SELECTION OF MULTIPLE PRONUNCIATIONS FOR DYNAMIC VOCABULARIES| ABSTRACT In this paper, we present a new scheme for the acoustic modeling of speech recognition applications requiring dynamic vocabularies.  It applies especially to the acoustic modeling of out-of-vocabulary words which need to be added to a recognition lexicon based on the observation of a few (say one or two) speech utterances of these words.  Standard approaches to this problem derive a single pronunciation from each speech utterance by combining acoustic and phone transition scores.  In our scheme, multiple pronunciations are generated from each speech utterance of a word to enroll by varying the relative weights assigned to the acoustic and phone transition models.  In our experiments, the use of these multiple baseforms dramatically outperforms the standard approach with a relative decrease of the word error rate ranging from 20% to 40% on all our test sets.  1.  MOTIVATION Speech recognition systems usually rely on a fixed lexicon where the pronunciations of the vocabulary words are given by hand-crafted phonetic baseforms, i. e.  sequences of phones written by a phonetician.  However, many applications require new words to be dynamically added to the recognition vocabulary, or new pronunciations of invocabulary words to be added to the lexicon.  Hence the need for techniques which can automatically derive phonetic baseforms.  This occurs for example in dictation systems that allow personalized vocabularies, in name dialer applications where the user enrolls the names he wants to dial, and in any application where actual pronunciations differ from canonic pronunciations (like for non-native speakers), so that the robustness of linguist-written pronunciations needs to be improved.  In situations where the speech recognition engine is embedded in a small device, there may not be any interface media, such as a keyboard, to allow the user to enter the spelling of the words he wants to add to his/her personalized vocabulary [1].  And even if such an interface were to be available, the spellings may not be of very much help as these applications typically involve words the pronunciation of which is highly unpredictable, like proper names for example.  In this context, it is difficult to use a priori knowledge, such as letter-to-sound rules in a reliable way.  Consequently, the user is asked to utter once or twice the words to add to his/her personalized vocabulary, and phonetic baseforms for these words are derived from the acoustic evidence provided by the user's utterances.  These approaches ( [2], [3], [4], [5]) usually rely on the combined use of: (i) an existing set of speaker-independent acoustic models of subphone units, and (ii) a model of transition between these subphone units.  The way to optimally combine these models is an open issue as it is not known in advance which of the models can most reliably describe the acoustic evidence observed for each new word to enroll.  For example, when the enrolled words are proper names, the reliability of the model of transition between the subphones is questionable since proper names do not follow strict phonotactic rules.  Current techniques of automatic baseform generation do not take into consideration the relative degree of confidence that should be put in either component.  The scheme presented in this paper deviates from standard approaches in that: (i) the acoustic model and the transition model which are combined to generate the baseforms are assigned a weight, (ii) multiple baseforms are derived from a single speech utterance by varying the relative weights of the models.  The basic idea behind this approach is twofold.  First, since we have to guess the pronunciation of the enrolled words from just one or two speech examples, we may as well use multiple guesses to maximize the chance of guessing right.  Second, since we do not know a priori how reliable each of the two models is relative to the other model, we avoid arbitrarily favoring either one of the models by varying their relative weights when generating the guesses.  The distinct baseforms obtained from the speech utterance of a word are added to the recognition lexicon as pronunciation variants of that word.  It has been extensively investigated recently how, in standard recognition frameworks, adding pronunciation variants to the canonic pronunciations of a static lexicon can significantly improve the recognition accuracy [7] [8].  We show that this applies also in the context of dynamic vocabularies, where no canonic pronunciations at all are available.  On the other hand, as multiple baseforms are added to the recognition lexicon, we can expect the acoustic confusability between the entries of the lexicon to increase with the risk of hurting the recognition accuracy.  In this paper, we report on an extensive set of speech recognition experiments showing the influence of the number of automatically generated baseforms on the decoding accuracy.  The structure of this paper is as follows.  In section 2 and 3, we describe our scheme to generate multiple baseforms and build variable-size lexicons.  In section 4, we present speech recognition experiments comparing lexicons of automatically generated baseforms on test data consisting of either isolated or in-context words, and in both quiet and noisy environments.  Section 5 concludes on this work.  2.  GENERATION OF MULTIPLE BASEFORMS In this section, we present a scheme to derive multiple baseforms from acoustic evidence, where it is attempted to make the best possible use of our a priori knowledge, where our a priori knowledge comprises a set of speaker independent acoustic models of subphone units and a statistical model of transitions between subphone units 1 .  In the standard way, the problem of deriving a baseform from acoustic evidence is usually stated as the problem of retrieving the most likely string U # of T subphone units, given the string O of T acoustic observations: U # = arg max fUg log P (U; O) = arg max fUg log P (O j U) + log P (U) The string U # is retrieved with a Viterbi algorithm.  The conditional probability of the acoustic observations given the string of subphone units is computed as: P (O j U) = t=T Y t=1 p(o (t) j u (t) ) The conditional probability of each acoustic observationp(o j u i ) is computed with the acoustic model - in our experiments speaker independent mixtures of gaussians.  The probability of observing the string of subphone units U is computed with the transition model assumed between the subphones - in our experiments a bigram model: P (U) = p(u (1) ) t=T Y t=2 p(u (t) j u (t 1) ) 1 Each subphone unit corresponds to roughly one third of a phone.  The bigram model of subphone units is estimated off-line by aligning a large dataset of speech with a known transcription on the acoustic models of the subphone units.  The probabilities fp(u j j u i )g are computed from the observed relative counts of the subphone models in the alignment (in our experiments, no backoff is used to smooth the bigram probabilities).  Note that both the duration of the units and the transition between the units are modeled.  The modification that we introduce to this baseline approach is to compute the log-likelihood of a baseform as a weighted sum of the log-scores of the acoustic model and of the transition model, with weights respectively of (1 #) and #: U # # = arg max fUg (1 #) log P (O j U) + # log P (U) Each value of # defines a distinct log-likelihood function wich reaches its maximum value for possibly distinct strings of subphone units.  The parameter # can be seen as reflecting the confidence put into each model.  In a context where it is not known which of the two models can most relevantly account for the observations, the generation of multiple strings U # # for various values of # allows to compensate for a possible mismatch.  3.  BUILDING LEXICONS WITH MULTIPLE BASEFORMS In our experiments, we define a set of # values by scanning an interval [#1; #2] (0 # #1 # #2 # 1), with a step of 0:1.  Each string U # # is converted into a phonetic baseform by replacing the subphone units with their phone counterpart and by merging together repeated phones.  All the distinct phonetic baseforms obtained from the speech utterance of a word by scanning a set of values of # are added as pronunciation variants in the recognition lexicon.  Each interval [#1; #2] thus results in a specific recognition lexicon, hence raising the question of how to select a priori the best performing lexicon.  We can expect that accumulating multiple baseforms for each enrollment speech utterance will improve the recognition accuracy by allowing a broader modelling of the pronunciation of the new words.  However it is well known that increasing the number of pronunciation variants increases the acoustic confusability in the recognition lexicon, which eventually hurts the accuracy.  In our experiments, we noticed for example that the baseforms obtained with # equal to or more than 0. 8 tended to look more and more alike, which we attributed to the prevailing influence of the subphone transition model.  As a result, cumulating baseforms with # values higher than 0. 8 was resulting in higher word error rates.  In the following section, we report on experiments where lexicons are build for each interval [#1; #2] with #
IBM's 10x Real-time Broadcast News Transcription System Used in the 1999 Hub4 Evaluation| ABSTRACT We describe the system used by IBM in the 1999 HUB4 Evaluation under the 10 times real-time constraint.  We detail the system architecture and show that the performance of this system is over 20 percent more accurate at the same speed than the system used in the 1998 Evaluation.  Furthermore, we have closed the gap between our unlimited resource system and our 10 times real time system from 45 percent to 14 percent. 
Wavelet Based Speckle Reduction with Application to SAR Based ATD/R| ABSTRACT This paper introduces a novel speckle reduction method based on thresholding the wavelet coefficients of the logarithmically transformed image.  The method is computational efficient and can significantly reduce the speckle while preserving the resolution of the original image.  Both soft and hard thresholding schemes are studied and the results are compared.  When fully polarimetric SAR images are available, we proposal several approcahes to combine the data from different polorizations to achieve even better performance.  Wavelet processed imagery is shown to provide better detection performance for synthetic-aperture radar (SAR) based automatic target detection/recognition (ATD/R) problem. 
Adaptation of front end parameters in a speech recognizer| Abstract In this paper we consider the problem of adapting parameters of the algorithm used for extraction of features.  Typical speech recognition systems use a sequence of modules to extract features which are then used for recognition.  We present a method to adapt the parameters in these modules under a variety of criteria, e. g maximum likelihood, maximum mutual information.  This method works under the assumption that the functions that the modules implement are differentiable with respect to their inputs and parameters.  We use this framework to optimize a linear transform preceding the linear discriminant analysis (LDA) matrix and show that it gives significantly better performance than a linear transform after the LDA matrix with small amounts of data.  We show that linear transforms can be estimated by directly optimizing likelihood or the MMI objective without using auxiliary functions.  We also apply the method to optimize the Mel bins, and the compression power in a system that uses power law compression. 
Extended MLLT for Gaussian Mixture Models| Prior to publication, please maintain the enclosed paper in confidence and use it only for purposes of evaluating the merit of the proposed paper, and other activities reasonably related to the review process, and please do not make it available, in whole or in
Acoustic modeling with mixtures of subspace constrained exponential models| Abstract Gaussian distributions are usually parameterized with their natural parameters: the mean and the covariance #.  They can also be re-parameterized as exponential models with canonical parameters P = #- 1 and = P.  In this paper we consider modeling acoustics with mixtures of Gaussians parameterized with canonical parameters where the parameters are constrained to lie in a shared affine subspace.  This class of models includes Gaussian models with various constraints on its parameters: diagonal covariances, MLLT models, and the recently proposed EMLLT and SPAM models.  We describe how to perform maximum likelihood estimation of the subspace and parameters within a fixed subspace.  In speech recognition experiments, we show that this model improves upon all of the above classes of models with roughly the same number of parameters and with little computational overhead.  In particular we get 30-40% relative improvement over LDA+MLLT models when using roughly the same number of parameters. 
Wavelet-Based Post-Processing of Low Bit Rate Transform Coded Images| ABSTRACT In this paper we propose a novel method based on wavelet thresholding for enhancement of decompressed transform coded images.  Transform coding at low bit rates typically introduces artifacts associated with the basis functions of the transform.  In particular, the method works remarkably well in "deblocking" of DCT compressed images.  The method is nonlinear, computationally efficient, and spatially adaptive and has the distinct feature that it removes artifacts yet retain sharp features in the images.  An important implication of this result is that images coded using the JPEG standard can efficiently be postprocessed to give significantly improved visual quality in the images.  The algorithm can use a conventional JPEG encoder and decoder for which VLSI chips are available. 
STRUCTURING LINEAR TRANSFORMS FOR ADAPTATION USING TRAINING TIME INFORMATION| ABSTRACT Linear transforms are often used for adaptation to test data in speech recognition systems.  However, when used with small amounts of test data, these techniques provide limited improvements if any.  This paper proposes a two-step Bayesian approach where a) the transforms lie in a subspace obtained at training time and b) the expansion coefficients of the transform are obtained using MAP.  Estimation algorithms are given for adaptation transforms for means, covariances, and feature spaces.  Experimental results indicate that our method gives a significant improvement in performance over other methods. 
MODELING INVERSE COVARIANCE MATRICES BY BASIS EXPANSION| ABSTRACT This paper proposes a new covariance modeling technique for Gaussian Mixture Models.  Specifically the inverse covariance (precision) matrix of each Gaussian is expanded in a rank-1 basis i. e. , ##### ##### # ######## ### # ### # ### # , # # ######### # ##### .  A generalized EM algorithm is proposed to obtain maximum likelihood parameter estimates for the basis set # # # # #"! and the expansion coefficients cients
A Robust High Accuracy Speech Recognition System For Mobile Applications| Markov Models for mobile applications.  Among the issues and techniques we explore are improving robustness and eciency of the front-end, using multiple microphones for removing extraneous signals from speech via a new multi-channel CDCN technique, reducing computation via silence detection, applying the Bayesian information criterion (bic) to build smaller and better acoustic models, minimizing finite state grammars, using hybrid maximum likelihood and discriminative models, and automatically generating baseforms from single new-word utterances. 
CEPSTRUM DOMAIN LAPLACE DENOISING| ABSTRACT This paper introduces the Laplace algorithm for de-noising in the cepstrum domain with applications to speech recognition.  Our method uses Gaussian mixture priors for clean speech and noise cepstra and assumes that speech and noise mix linearly in the spectrum domain.  The Laplace algorithm involves two steps (a) computing the posterior mode of the observed noisy cepstra and (b) Gaussian approximation of the posterior around the mode.  We show that the Algonquin algorithm is a special case of our approach where a Newton method is used for (a).  Interestingly, this observation also proves that the Algonquin algorithm does not converge in general.  We propose the use of the BFGS method for (a) which also allows us to efficiently apply the Laplace algorithm in the cepstral domain.  De-noising in the cepstral domain gives more than 31% relative reduction in word error rate on average on the Aurora 2 task. 
ENHANCING GMM SCORES USING SVM "HINTS"| Abstract This paper proposes a classification scheme that combines statistical models and support vector machines.  It exploits the fact (observed in [1]) that GMM and SVM classifiers with roughly the same level of performance produce uncorrelated errors.  We describe a novel scheme which employs an SVM classifier as an "advisor" to the GMM classifier in uncertain cases.  The utility of the combined generative/discriminative approach is demonstrated on standard text-independent speaker verification and speaker identification tasks in matched and mismatched training and test conditions.  Results indicate significant improvements in performance without much computational overhead. 
Discriminative Estimation of Subspace Constrained Gaussian Mixture Models for Speech Recognition| Abstract--- In this paper we study discriminative training of acoustic models for speech recognition under two criteria: maximum mutual information (MMI) and a novel "error weighted" training technique.  We present a proof that the standard MMI training technique is valid for a very general class of acoustic models with any kind of parameter tying.  We report experimental results for subspace constrained Gaussian mixture models (SCGMMs), where the exponential model weights of all Gaussians are required to belong to a common "tied" subspace, as well as for Subspace Precision and Mean (SPAM) models which impose separate subspace constraints on the precision matrices (i. e.  inverse covariance matrices) and means.  It has been shown previously that SCGMMs and SPAM models generalize and yield significant error rate improvements over previously considered model classes such as diagonal models, models with semi-tied covariances, and EMLLT (extended maximum likelihood linear transformation) models.  We show here that MMI and error weighted training each individually result in over 20% relative reduction in word error rate on a digit task over maximum likelihood (ML) training.  We also show that a gain of as much as 28% relative can be achieved by combining these two discriminative estimation techniques. 
Phaselets of Framelets| Abstract Phaselets are a set of dyadic wavelets that are related in a particular way such that the associated redundant wavelet transform is nearly shift-invariant [1].  Framelets are a set of functions that generalize the notion of a single dyadic wavelet in the sense that dyadic dilates and translates of these functions form a frame in L 2 (IR) [2].  This paper generalizes the notion of phaselets to framelets.  Sets of framelets that only dier in their Fourier transform phase are constructed such that the resulting redundant wavelet transform is approximately shift-invariant.  Explicit constructions of phaselets are given for frames with two and three framelet generators.  The results in this paper generalize the construction of Hilbert transform pairs of framelets [3]. 
IMPROVED SPEAKER SEGMENTATION AND SEGMENTS CLUSTERING USING THE BAYESIAN INFORMATION CRITERION| ABSTRACT Detection of speaker, channel and environmentchanges in a continuous audio stream is importantinvarious applications (e. g. , broadcast news, meetings/teleconferences etc. ).  Standard schemes for segmentation use a classifier and hence do not generalize to unseen speaker / channel / environments.  Recently S. Chen introduced new segmentation and clustering algorithms, using the so-called BIC.  This paper presents more accurate and more e#cientvariants of the BIC scheme for segmentation and clustering.  Specifically, the new algorithms improve the speed and accuracy of segmentation and clustering and allow for a real-time implementation of simultaneous transcription, segmentation and speaker tracking. 
Enhancement of Decompressed Images at Low Bit Rates| ABSTRACT Transform coding at low bit rates introduces artifacts associated with the basis functions of the transform.  For example, decompressed images based on the DCT (discrete cosine transform) - like JPEG 16 - exhibit blocking artifacts at low bit rates.  This paper proposes a post-processing scheme to enhance decompressed images that is potentially applicable in several situations.  In particular, the method works remarkably well in "deblocking" of DCT compressed images.  The method is non-linear, computationally efficient, and spatially adaptive - and has the distinct feature that it removes artifacts while yet retaining sharp features in the images.  An important implication of this result is that images coded using the JPEG standard can be efficiently post-processed to give significantly improved visual quality in the images. 
ON THE MOMENTS OF THE SCALING FUNCTION| ABSTRACT This paper derives relationships between the moments of the scaling function /0(t) associated with multiplicity M , K-regular, compactly supported, orthonormal wavelet bases [6, 5], that are extensions of the multiplicity 2, K-regular orthonormal wavelet bases constructed by Daubechies [2].  One such relationship is that the square of the first moment of the scaling function (/0(t)) is equal to its second moment.  This relationship is used to show that uniform sample values of a function provides a third order approximation of its scaling function expansion coefficients.  For the special case of M = 2, the results in this paper have been reported earlier [3]. 
MULTIPLE LINEAR TRANSFORMS| ABSTRACT In the past several years, Linear Discriminant Analysis (LDA) is being replaced by Heteroscedastic Discriminant Analysis (HDA), to improve the performance of a recognition system that uses a mixture of diagonal covariance prototypes to model the data.  A specific version HDA, popularly known as Maximum Likelihood Linear Transform (MLLT) is also used, on the features finally obtained.  However the performance of such systems is not as good as could be obtained for a corresponding system that uses full covariance matrices.  We propose the method of Multiple Linear Transforms (MLT), that bridges this gap in performance, while maintaining the speed efficiency of a diagonal covariance system.  In other words, this technique improves the performance of a diagonal covariance system, over what could be obtained from HDA, or MLLT. 
TECHNIQUES FOR CAPTURING TEMPORAL VARIATIONS IN SPEECH SIGNALS WITH FIXED-RATE PROCESSING| ABSTRACT Fixed-rate feature extraction which is used in most current speech recognizers is equivalent to sampling the feature trajectories at a uniform rate.  Often this sampling rate is well below the Nyquist rate and thus leads to distortions in the sampled feature stream due to aliasing.  In this paper we explore various techniques, ranging from simple cepstral and spectral smoothing to filtering and data-driven dimensionality expansion using Linear Discriminant Analysis (LDA), to counter aliasing and the variable rate nature of information in speech signals.  Smoothing in the spectral domain results in a reduction in the variance of the short term spectral estimates which directly translates to reduction in the variances of the Gaussians in the acoustic models.  With these techniques we obtain modest improvements, both in word error rate and robustness to noise, on large vocabulary speech recognition tasks. 
LARGE VOCABULARY CONVERSATIONAL SPEECH RECOGNITION WITH THE EXTENDED MAXIMUM LIKELIHOOD LINEAR TRANSFORMATION (EMLLT) MODEL| ABSTRACT This paper applies the recently proposed Extended Maximum Likelihood Linear Transformation (EMLLT) model in a Speaker Adaptive Training (SAT) context on the Switchboard database.  Adaptation is carried out with maximum likelihood estimation of linear transforms for the means, precisions (inverse covariances) and the feature-space under the EMLLT model.  This paper shows the first experimental evidence that significant word-error-rate improvements can be achieved with the EMLLT model (in both VTL and VTL+SAT training contexts) over a state-of-the-art diagonal covariance model in a difficult large-vocabulary conversational speech recognition task.  The improvements were of the order of 1% absolute in multiple scenarios. 
Casimir attraction in colloidal crystals| Experimental evidence collected over 20 years [1] suggests that similarly charged colloidal spheres dispersed in water need not simply repel each other.  Under some circumstances they instead experience an unexpected long-ranged attraction.  For example, like-charge attractions are implicated in the cohesion of metastable superheated colloidal crystals [2, 3] even though isolated pairs of the constituent spheres are observed to repel each other [4, 5].  Comparable attractions have been measured for pairs of spheres confined by two [5, 6] charged planar walls.  Recent calculations [7, 8] reveal that such confinement-induced attractions cannot be accounted for by local density theory nor by electrohydrodynamic coupling [9, 10].  Such anomalous effects in charge-stabilized colloid therefore challenge our general understanding of interactions and dynamics in macroionic systems.  This letter addresses fluctuations' contribution to the free energy of highly charged colloidal spheres surrounded by a neutralizing cloud of small singly charged counterions.  Highly symmetric monopolar fluctuations in the counterion distribution increase the system's free energy.  We demonstrate that their suppression by boundary conditions at the spheres' surfaces introduces a long-range attraction into the crystal's free energy analogous to the Casimir force in quantum electrodynamics, but that it is too weak to account for anomalous behavior in charge-stabilized suspensions.  Our treatment is based on the Wigner-Seitz cell model introduced by Wennerstrom, Jonsson and Linse [11] which has been studied extensively [12] both theoretically and through Monte Carlo simulation.  It consists of a single spherical macroion of radius a carrying a uniformly distributed surface charge -Ze and surrounded by a thermal cloud of Z point-like counterions at temperature T , each carrying a single charge e.  The macroion and counterions c # EDP Sciences are confined by a concentric conducting spherical shell of radius R.  This outer shell plays a role analogous to the Wigner-Seitz cell boundary in a colloidal crystal.  More generally, it models the crowding or geometric confinement characteristic of colloidal crystals [13].  Previous investigations of this and related models [12,14] have found short-ranged correlation-driven attractions between the bounding surfaces under some conditions, particularly when the counterions are polyvalent.  They have not found evidence for long-ranged attractions in monovalent electrolytes [13].  Our method for evaluating the counterions' partition function allows us to investigate much higher macroion charges than have been considered before.  The outer boundary's suppression of counterion fluctuations induces a long-ranged Casimir-like attraction [14] between the macroion and its neighbors across the Wigner-Seitz cell boundary.  Although this cell model is far too simple to describe the behavior of real charge-stabilized suspensions, it highlights a previously unexplored mechanism for long-ranged confinement-induced like-charge colloidal attractions.  We adopt the path integral formalism reviewed in [14] and write the counterions' canonical partition function as a functional integral over all possible counterion distributions, n(#r): Q = # 2#Z Z Z # # e -#f[n] Dn, (1) where # -1 = kBT is the thermal energy scale at temperature T , the prime indicates that the number of charges is conserved ( # ndV = Z), and [15] f [n]=U [n]+kBT # n ln ndV . The potential-energy functional U [n]= 1 2 # ne#dV describes the counterions' interaction with the local electric potential #(#r).  The system's Helmholtz free energy is then F = -kBT ln Q.  One ionic distribution, n 0 (#r), minimizes f , and thus has the greatest statistical weight in Q.  We factor the partition function Q = Q 0 Q fl into the saddle point contribution Q 0 = Z Z e -#f 0 , where f 0 = f [n 0 ], and a term Q fl accounting for fluctuations, fin, away from n 0 .  Expressing Q fl as a series expansion in fin yields, as the lowest-order non-vanishing term, Q fl # # 2#Z # # e -fiff 2 f Dn, (2) where # 2 f is the second-order change in f [n] due to fin.  Terminating this expansion at Gaussian order is justified if corrections at higher order in fin contribute negligibly to Q fl .  This condition is met if Z is large [16] and n 0 (r) itself changes negligibly over the mean radial counterion separation: 1 n 0 dn 0 dr # 4#r 2 n 0 , (3) and can be tested a posteriori once n 0 (r) is evaluated.  Expanding around any other distribution [17, 18] would not give such a criterion for establishing convergence.  It has been shown [16, 18] that the saddle point corresponds to the mean-field result n 0 = n s e -#e# which, combined with the Poisson equation # 2 # = - en # , yields the familiar Poisson-Boltzmann (PB) equation, # 2 # =en s # e -#e# .  (4) Selecting n s =3Z/ (4#a 3 ) sets the potential's reference point conveniently without loss of generality.  Equation (4) accounts for the solvent's influence in the so-called primitive model through its dielectric constant #. 
A HYBRID GMM/SVM APPROACH TO SPEAKER IDENTIFICATION| ABSTRACT This paper proposes a classification scheme that incorporates statistical models and support vector machines.  A hybrid system which appropriately combines the advantages of both the generative and discriminant model paradigms is described and experimentally evaluated on a text-independent speaker recognition task in matched and mismatched training and test conditions.  Our results prove that the combination is beneficial in terms of performance and practical in terms of computation.  We report relative improvements of up to 25% reduction in identification error rate compared to the baseline statistical model. 
INITIALIZING SUBSPACE CONSTRAINED GAUSSIAN MIXTURE MODELS| ABSTRACT A recent series of papers [1, 2, 3, 4] introduced Subspace Constrained Gaussian Mixture Models (SCGMMs) and showed that SCGMMs can very efficiently approximate Full Covariance Gaussian Mixture Models (FCGMMs); a significant reduction in the number of parameters is achieved with little loss in the accuracy of the model.  SCGMMs were arrived at as a sequence of generalizations of diagonal covariance GMMs.  As an artifact of this process the initialization of SCGMM parameters in that work is complex i. e. , relies on best parameter settings of less general models.  This paper overcomes this problem by showing how an FCGMM can be used to give a simple and direct initialization of an SCGMM.  The initialization scheme is powerful enough that as the number of parameters in an SCGMM approaches that of an FCGMM (i. e. , large SCGMMs) further training of the SCGMM is unnecessary. 
MAXIMUM LIKELIHOOD DISCRIMINANT FEATURE SPACES| ABSTRACT Linear discriminant analysis (LDA) is known to be inappropriate for the case of classes with unequal sample covariances.  In recent years, there has been an interest in generalizing LDA to heteroscedastic discriminant analysis (HDA) by removing the equal within-class covariance constraint.  This paper presents a new approach to HDA by defining an objective function which maximizes the class discrimination in the projected subspace while ignoring the rejected dimensions.  Moreover, we will investigate the link between discrimination and the likelihood of the projected samples and show that HDA can be viewed as a constrained ML projection for a full covariance gaussian model, the constraint being given by the maximization of the projected between-class scatter volume.  It will be shown that, under diagonal covariance gaussian modeling constraints, applying a diagonalizing linear transformation (MLLT) to the HDA space results in increased classification accuracy even though HDA alone actually degrades the recognition performance.  Experiments performed on the Switchboard and Voicemail databases show a 10%-13% relative improvement in the word error rate over standard cepstral processing. 
Subspace Constrained Gaussian Mixture Models for Speech Recognition| Abstract--- A standard approach to automatic speech
MAXIMUM LIKELIHOOD TRAINING OF SUBSPACES FOR INVERSE COVARIANCE MODELING| ABSTRACT Speech recognition systems typically use mixtures of diagonal Gaussians to model the acoustics.  Using Gaussians with a more general covariance structure can give improved performance; EMLLT [1] and SPAM [2] models give improvements by restricting the inverse covariance to a linear/affine subspace spanned by rank one and full rank matrices respectively.  In this paper we consider training these subspaces to maximize likelihood.  For EMLLT ML training the subspace results in significant gains over the scheme proposed in [1].  For SPAM ML training of the subspace slightly improves performance over the method reported in [2].  For the same subspace size an EMLLT model is more efficient computationally than a SPAM model, while the SPAM model is more accurate.  This paper proposes a hybrid method of structuring the inverse covariances that both has good accuracy and is computationally efficient. 
ADAPTATION EXPERIMENTS ON THE SPINE DATABASE WITH THE EXTENDED MAXIMUM LIKELIHOOD LINEAR TRANSFORMATION (EMLLT) MODEL| ABSTRACT This paper applies the recently proposed Extended Maximum Likelihood Linear Transformation (EMLLT) model for inverse covariances in a Speaker Adaptive Training (SAT) context.  The paper adapts standard algorithms for maximum likelihood estimation of linear transforms for mean, variance and feature space adaptation respectively, to the EMLLT model.  Experimental results showing word-error-rate improvements are reported on the SPINE2 database.  The system described here is the best-performing system
DIMENSIONAL REDUCTION, COVARIANCE MODELING, AND COMPUTATIONAL COMPLEXITY IN ASR SYSTEMS| ABSTRACT In this paper, we study acoustic modeling for speech recognition using mixtures of exponential models with linear and quadratic features tied across all context dependent states.  These models are one version of the SPAM models introduced in [1].  They generalize diagonal covariance, MLLT, EMLLT, and full covariance models.  Reduction of the dimension of the acoustic vectors using LDA/HDA projections corresponds to a special case of reducing the exponential model feature space.  We see, in one speech recognition task, that SPAM models on an LDA projected space of varying dimensions achieve a significant fraction of the WER improvement in going from MLLT to full covariance modeling, while maintaining the low computational cost of the MLLT models.  Further, the feature precomputation cost can be minimized using the hybrid feature technique of [2]; and the number of Gaussians one needs to compute can be greatly reducing using hierarchical clustering of the Gaussians (with fixed feature space).  Finally, we show that reducing the quadratic and linear feature spaces separately produces models with better accuracy, but comparable computational complexity, to LDA/HDA based models. 
FACTOR ANALYSIS INVARIANT TO LINEAR TRANSFORMATIONS OF DATA| ABSTRACT Modeling data with Gaussian distributions is an important statistical problem.  To obtain robust models one imposes constraints the means and covariances of these distributions [6, 4, 10, 8].  Constrained ML modeling implies the existence of optimal feature spaces where the constraints are more valid [2, 3].  This paper introduces one such constrained ML modeling technique called factor analysis invariant to linear transformations (FACILT) which is essentially factor analysis in optimal feature spaces.  FACILT is a generalization of several existing methods for modeling covariances.  This paper presents an EM algorithm for FACILT modeling. 
TRANSCRIPTION OF BROADCAST NEWS - SOME RECENT IMPROVEMENTS TO IBM'S LVCSR SYSTEM| ABSTRACT This paper describes extensions and improvements to IBM's large vocabulary continuous speech recognition (LVCSR) system for transcription of broadcast news.  The recognizer uses an additional 35 hours of training data over the one used in the 1996 Hub4 evaluation [?].  It includes a number of new features: optimal feature space for acoustic modeling (in training and/or testing), filler-word modeling, Bayesian Information Criterion (BIC) based segment clustering, an improved implementation of iterative MLLR and 4-gram language models.  Results using the 1996 DARPA Hub4 evaluation data set are presented. 
Low-Resource Speech Recognition of 500-Word Vocabularies| Abstract We describe techniques for enhancing the accuracy, efficiency and features of a low-resource, medium-vocabulary, grammarbased speech recognition system.  Among the issues and techniques we explore are front-end speech / silence detection to reduce computational workload, the use of the Bayesian information criterion (BIC) to build smaller and better acoustic models, the minimization of finite state grammars, the use of hybrid maximum likelihood and discriminative models, and the automatic generation of baseforms from single new-word utterances.  We report WER figures throughout, as appropriate. 
ELIMINATING INTER-SPEAKER VARIABILITY PRIOR TO DISCRIMINANT TRANSFORMS| E-mail: gsaon,mukund rameshg # @us. ibm. 
ROBUST SPEECH RECOGNITION WITH MULTI-CHANNEL CODEBOOK DEPENDENT CEPSTRAL NORMALIZATION (MCDCN)| ABSTRACT In this paper, we address the issue of speech recognition in the presence of interfering signals, in cases where the signals corrupting the speech are recorded in separate channels.  We propose to combine a trivial form of filtering with MCDCN, a Multi-channel version of the Codebook Dependent Cepstral Normalization, where the cepstra of the noise are estimated from the reference signals.  We report on recognition experiments in a car where the speech signal is corrupted by radio talks or CD music played the car speakers.  Our approach allows relative word error rate reductions in the range of 70-90% compared to a no-compensation baseline, at a relatively low computational cost. 
TRANSCRIPTION OF BROADCAST NEWS SHOWS WITH THE IBM LARGE VOCABULARY SPEECH RECOGNITION SYSTEM| ABSTRACT This paper gives an overview of the IBM Large Vocabulary Continuous Speech Recognition system used in the 1996 Hub4 evaluation.  It describes the acoustic and language models and adaptation techniques in the partitioned and unpartitioned evaluations.  Evaluation results, analysis and further experiments are reported. 
ROBUST CONFIDENCE ANNOTATION AND REJECTION FOR CONTINUOUS SPEECH RECOGNITION| ABSTRACT We are looking for confidence scoring techniques that perform well on a broad variety of tasks.  Our main focus is on word-level error rejection, but most results apply to other scenarios as well.  A variation of the Normalized Cross Entropy that is adapted to that purpose is introduced.  It is successfully used to automatically select features and optimize the word-level confidence measure on several test sets.  Sentence-level confidence geared toward the rejection of out-of-grammar utterances is also investigated.  The combination of a word graph based technique and the acoustic score shows excellent performance across all the tasks we considered. 
OPTIMAL WAVELETS FOR SIGNAL DECOMPOSITION AND THE EXISTENCE OF SCALE-LIMITED SIGNALS| ABSTRACT Wavelet methods give a flexible alternative to Fourier methods in non-stationary signal analysis.  The concept of band-limitedness plays a fundamental role in Fourier analysis.  Since wavelet theory replaces frequency with scale, a natural question is whether there exists a useful concept of scale-limitedness.  Obvious definitions of scale-limitedness are too restrictive, in that there would be few or no useful scale-limited signals.  This paper introduces a viable definition for scale-limited signals, and shows that the class is rich enough to include bandlimited signals, and impulse trains, among others.  Moreover, for a wide choice of criteria, we show how to design the optimal wavelet for representing a given signal, and how to design robust wavelets that optimally represent certain classes of signals. 
An EM algorithm for convolutive independent component analysis| ABSTRACT In this paper, we address the problem of blind separation of convolutive mixtures of spatially and temporally independent sources modeled with mixtures of Gaussians.  We present an EM algorithm to compute Maximum Likelihood estimates of both the separating filters and the source density parameters, whereas in the state-of-the-art separating filters are usually estimated with gradient descent techniques.  The use of the EM algorithm, as opposed to the usual gradient descent techniques, does not require the empirical tuning of a learning rate and thus can be expected to provide a more stable convergence.  Besides, we show how multichannel autoregressive spectral estimation techniques can be used in order to properly initialize the EM algorithm.  We demonstrate the efficiency of our EM algorithm together with the proposed initialization scheme by reporting on simulations with artificial mixtures. 
RECENT IMPROVEMENTS TO IBM'S SPEECH RECOGNITION SYSTEM FOR AUTOMATIC TRANSCRIPTION OF BROADCAST NEWS| ABSTRACT We describe recent extensions and improvements to IBM's system for automatic transcription of broadcast news.  The speech recognizer uses a total of 160 hours of acoustic traininng data, 80 hours more than for the system described in [6].  In addition to improvements obtained in 1997 we made a number of changes and algorithmic enhancements.  Among these were changing the acoustic vocabulary, reducing the number of phonemes, insertion of short pauses, mixture models consisting of non-Gaussian components, pronunciation networks, factor analysis (FACILT) and Bayesian Information Criteria (BIC) applied to choosing the number of components in a Gaussian mixture model.  The models were combined in a single system using NIST's script voting machine known as rover [8]. 
Least Squared Error FIR Filters with Flat Amplitude or Group Delay Constraints| Abstract FIR lowpass filters with prescribed number of zeros at ! = and either prescribed group delay flatness or prescribed amplitude flatness and linear phase are designed by minimizing a squared error.  A simple orthogonal projection of least squared error filters (that are often available in closed form) onto a linear subspace determined via Thiran filters (for group delay flatness) and via Herrmann filters (for amplitude flatness) gives the desired filters. 
Theory of regular m-band wavelet bases|
Short-time Gaussianization for robust speaker verification,|
Adaptation Experiments on the Spine Database with the EMLLT Model,|
A hybrid gmm/svm approach to speaker identification|
The IBM Large Vocabulary Continuous Speech Recognition System for the ARPA NAB News Task",|
"Nonlinear wavelet processing for enhancement of images," submitted to|
On the Correlation Structure of Multiplicity M Scaling Functions and Wavelets|
On the moments of the scaling function / 0|
Implementation of a Prototype Active Network",|
Performance Patterns: Automated Scenario-Based ORB Performance Evaluation|
On The Optimal and Robust Wavelet Representation of Signals and The Wavelet Sampling Theorem|
Covariance Modeling using Factor Analysis in Optimal Feature Spaces", submitted to IEEE Trans|
Optimal wavelets for signal decomposition and the existence of scale limited signals|
Introduction to wavelets and the wavelet transforms| Notes for the IEEE Signal Processing Society's tutorial program held in conjunction with the. 
Factorization approach to unitary time-varying filter bank trees and wavelets,"|
Waveletgalerkin approximation of linear translation invariant operators|
Wavelet-based lowpass/bandpass interpolation|
Wavelets and filter banks|
A tutorial overview of wavelets, filterbanks and interrelations|
Speckle reduction via wavelet shrinkage with application to SAR based ATD/R|
Robust speech recognition in noise -- Performance of the IBM Continuous Speech Recognizer on the ARPA noise spoke task|
Automatic Generation and Selection of Baseforms for Dynamic|
Least squared error fir filter design with transition bands|
Constrained gaussian mixture models for speech recognition,|
Numerical techniques for modeling guided-wave photonic devices,|
Development of a Low Cost Fuel Cell Inverter System with DSP Control,|
Gaussianization|
Wavelet Transforms and Filter Banks,|
\Constrained Maximum Likelihood Modeling With Gaussian Distributions", Proceedings of the DARPA Speech Recognition Workshop,|
Theory of Modulated Filter Banks and Modulated Wavelet Tight Frames|
Design of linear phase cosine modulated filter banks for subband image compression|
Introduction to Wavelets and the Wavelet Transform---A Primer|
State-space Approach to Multiplicity M Orthonormal Wavelet Bases|
Wavelet and Filter Banks - New Results and Applications|
\Modulated filter banks and wavelets | A unified theory,|
\Some results in the theory modulated filter banks and modulated wavelet tight frames,"|
Discriminatively trained acoustic models comprised of mixtures of exponentials with a tied subspace constraint,"|
Introduction to wavelets &|
Efficient computation of the wavelet transforms|
The wavelet transforms and time-scale analysis of signals|
On the correlation structure of the scaling function and wavelets|
Test signal (#|
On Upsampling, Downsampling and Rational Sampling Rate Filter Banks|
Factorization approach to unitary time-varying filter banks|
Modeling inverse covariances in gaussian mixture models,|
Rapid adaptation with linear combinations of rank-one matrices,|
An EM algorithm for convolutive ICA (CICA)|
Comment: Conjugate pair fast Fourier transform,"|
Wavelets and Filterbanks - New Results and Applications,|
Efficient hierarchical labeler algorithm for gaussian likelihoods computation in resource constrained speech recognition systems,"|
Transcription of braodcast news shows with the ibm large vocabulary speech recognition system|
