Reversible Jump MCMC Simulated Annealing for Neural Networks| Abstract We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated annealing algorithm to optimize radial basis function (RBF) networks.  This algorithm enables us to maximize the joint posterior distribution of the network parameters and the number of basis functions.  It performs a global search in the joint space of the parameters and number of parameters, thereby surmounting the problem of local minima.  We also show that by calibrating a Bayesian model, we can obtain the classical AIC, BIC and MDL model selection criteria within a penalized likelihood framework.  Finally, we show theoretically and empirically that the algorithm converges to the modes of the full posterior distribution in an ecient way. 
STABILITY OF STOCHASTIC APPROXIMATION UNDER VERIFIABLE CONDITIONS| Abstract.  In this paper we address the problem of the stability and convergence of the stochastic approximation procedure #n+1 = fin + #n+1 [h(#n ) + #n+1 ].  The stability of such sequences {#n} is known to heavily rely on the behaviour of the mean field h at the boundary of the parameter set and the magnitude of the stepsizes used.  The conditions typically
JOINT CHANNEL TRACKING AND SYMBOL DETECTION IN MIMO SYSTEMS VIA MULTIPLE MODEL METHODS| ABSTRACT We propose a new semi-blind joint channel tracking and symbol detection for spatial multiplexing MIMO system.  The proposed algorithm is based on Generalized Pesudo Bayesian algorithm (GPB) and Probability Data Association (PDA).  The purpose of GPB algorithm is to control the size of the filtering tree and Gaussian approximation idea behind PDA is applied to each time instant to reduce the model size.  Simulation results are given to demonstrate the effectiveness of the new algorithm. 
Convergence of stochastic approximation for Lyapunov stable dynamics: a proof from rst principles| Abstract In this short note we present a proof, aimed at beginners, of the convergence of the stochastic approximation recursion # i+1 = # i +# i+1 h(# i ) +# i+1 # i+1 under the classical 0-level Kushner-Clark noise condition when the underlying dynamic is Lyapunov stable.  The technique of proof relies on simple calculus arguments and bypasses the need for the introduction of the associated continuous time ODE.  Future work includes the extension of the result to the case where the 0-level Kushner-Clark condition is replaced with a r-level condition for r } 0 [2].  We study the convergence of the recursion # i+1 = # i + # i+1 h(# i ) + # i+1 # i+1 ; for a given function h : # ! R n # , a sequence of stepsizes f# i g and a noise sequence f# i g under simple and veri able conditions.  We de ne for any T } 0 m(n; T ) := max ( j # n : j X i=n+1 # i # T ) with the convention that for any sequence fa i g, P n i=n+1 a i = 0.  The required conditions are as follows: Condition 1 We work here with the following assumptions: 1.  # is an open subset of R n # for some integer n # # 1.  2.  h : # ! R n # is continuous and there exists a continuously dierentiable function w : # ! [0; +1) such that: (a) L := f# : hrw(#); h(#)i = 0g is non-empty.  (b) For any # 2 fir L, hrw(#); h(#)i < 0, (c) The closure of w (L) has an empty interior.  3.  f# i g # R + and P +1 i=1 # i = +1 and lim i!1 # i = 0.  4.  f# i g # K for some compact set K fiff such that K \ L 6= ;. 
Particle Filtering for Partially Observed Gaussian State Space Models| Summary.  Solving Bayesian estimation problems where the posterior distribution evolves over time through the accumulation of data has many applications for dynamic models.  A large number of algorithms based on particle filtering methods, also known as sequential Monte Carlo (SMC), have recently been proposed to solve these problems.  In this paper, we propose a special particle filtering method which uses random mixtures of normal distributions to represent the posterior distributions of partially observed Gaussian state space models.  This algorithm is based on a marginalization idea for improving efficiency and can lead to substantial gains over standard algorithms.  It differs from previous algorithms described in Chen and Liu (2000) and Doucet et al.  (2000), which were only applicable to conditionally linear Gaussian state space models.  Computer simulations are carried out to evaluate the performance of the proposed algorithm for dynamic Tobit and Probit models. 
On the Ergodicity Properties of some Adaptive MCMC Algorithms| Abstract In this paper we study the ergodicity properties of some adaptive Monte Carlo Markov chain algorithms (MCMC) that have been recently proposed in the literature.  We prove that under a set of verifiable conditions, ergodic averages calculated from the output of a so-called adaptive MCMC sampler converge to the required value and can even, under more stringent assumptions, satisfy a central limit theorem.  We prove that the conditions required are satisfied for the Independent Metropolis-Hastings algorithm and the Random Walk Metropolis algorithm with symmetric increments.  Finally we propose an application of these results to the case where the proposal distribution of the Metropolis-Hastings update is a mixture of distributions from a curved exponential family. 
ONLINE EXPECTATION-MAXIMIZATION TYPE ALGORITHMS FOR PARAMETER ESTIMATION IN GENERAL STATE SPACE MODELS| ABSTRACT In this paper we present new online algorithms to estimate static parameters in nonlinear non Gaussian state space models.  These algorithms rely on online Expectation-Maximization (EM) type algorithms.  Contrary to standard Sequential Monte Carlo (SMC) methods recently proposed in the literature, these algorithms do not degenerate over time. 
SEQUENTIAL MCMC FOR BAYESIAN MODEL SELECTION| ABSTRACT In this paper, we address the problem of sequential Bayesian model selection.  This problem does not usually admit any closed-form analytical solution.  We propose here an original sequential simulation-based method to solve the associated Bayesian computational problems.  This method combines sequential importance sampling, a resampling procedure and reversible jump MCMC moves.  We describe a generic algorithm and then apply it to the problem of sequential Bayesian model order estimation of autoregressive (AR) time series observed in additive noise. 
Rao-Blackwellised Particle Filtering via Data Augmentation| Abstract In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations.  This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation.  Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers.  We focus on sequential binary classifiers that consist of linear combinations of basis functions, whose coecients evolve according to a Gaussian smoothness prior.  Our results show significant improvements. 
IMPROVING SOFT OUTPUT QUALITY OF MIMO DEMODULATION ALGORITHM VIA IMPORTANCE SAMPLING| Simulation results are given to demonstrate the effectiveness of the new algorithm. 
An Introduction to MCMC for Machine Learning|
Robust Full Bayesian Methods for Neural Networks|
Robust Full Bayesian Learning for Radial Basis Networks|
On the ergodicity properties of some markov chain monte carlo algorithms|,. 
