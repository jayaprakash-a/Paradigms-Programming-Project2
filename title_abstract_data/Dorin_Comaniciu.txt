Incremental Density Approximation and Kernel-Based Bayesian Filtering for Object Tracking| Abstract Statistical density estimation techniques are used in many computer vision applications such as object tracking, background subtraction, motion estimation and segmentation.  The particle filter (Condensation) algorithm provides a general framework for estimating the probability density functions (pdf) of general non-linear and non-Gaussian systems.  However, since this algorithm is based on a Monte Carlo approach, where the density is represented by a set of random samples, the number of samples is problematic, especially for high dimensional problems.  In this paper, we propose an alternative to the classical particle filter in which the underlying pdf is represented with a semi-parametric method based on a mode finding algorithm using mean-shift.  A mode propagation technique is designed for this new representation for tracking applications.  A quasi-random sampling method [14] in the measurement stage is used to improve performance, and sequential density approximation for the measurements distribution is performed for efficient computation.  We apply our algorithm to a high dimensional colorbased tracking problem, and demonstrate its performance by showing competitive results with other trackers. 
Robust Detection and Tracking of Human Faces with an Active Camera| Abstract We present an efficient framework for the detection and tracking of human faces with an active camera.  The Bhattacharyya coefficient is employed as a similarity measurebetween the color distribution of the face model and face candidates.  The proper derivation of these distributions allows the use of the spatial gradient of the Bhattacharyya coefficient to guide a fast search for the best facecandidate.  The optimization, which is basedonmean shift analysis, requires only a few iterations to converge.  Scale changes of the trackedfaceare handled by exploiting the scale invariance of the similarity measure and the luminancegradient computedon the border of the hypothesized face region.  The detection and tracking modules are almost identical, the differencebeing that the detection involves mean shift optimization with multiple initializations.  Our dual-mode implementation of the cameracontroller determines the pan, tilt, and zoom camera to switch between smooth pursuit and saccadic movements, as a function of the target presence in the fovea region.  The resulting system runs in real-time on a standard PC, being robust to partial occlusion, clutter, facescale variations, rotations in depth, and fast changes in subject/cameraposition. 
Scale Selection for Anisotropic Scale-Space: Application to Volumetric Tumor Characterization| Abstract A unified approach for treating the scale selection problem in the anisotropic scale-space is proposed.  The anisotropic scale-space is a generalization of the classical isotropic Gaussian scale-space by considering the Gaussian kernel with a fully parameterized analysis scale (bandwidth) matrix.  The "maximum-over-scales" and the "moststable-over-scales" criteria are constructed by employing the "0 -normalized scale-space derivatives", i. e. , responsenormalized derivatives in the anisotropic scale-space.  This extension allows us to directly analyze the anisotropic (ellipsoidal) shape of local structures.  The main conclusions are (i) the norm of the -and -normalized anisotropic scale-space derivatives with a constant =1/2 are maximized regardless of the signal's dimension iff the analysis scale matrix is equal to the signal's covariance and (ii) the most-stable-over-scales criterion with the isotropic scale-space outperforms the maximum-over-scales criterion in the presence of noise.  Experiments with 1D and 2D synthetic data confirm the above findings.  3D implementations of the most-stable-over-scales methods are applied to the problem of estimating anisotropic spreads of pulmonary tumors shown in high-resolution computedtomography (HRCT) images.  Comparison of the first- and second-order methods shows the advantage of exploiting the second-order information. 
Kernel-Based Object Tracking| Abstract A new approach toward target representation and localization, the central component in visual
A common framework for nonlinear diffusion, adaptive smoothing, bilateral filtering and mean shift| Abstract In this paper, a common framework is outlined for nonlinear diffusion, adaptive smoothing, bilateral filtering and mean shift procedure. 
Bimodal System for Interactive Indexing and Retrieval of Pathology Images| Abstract The prototype of a system to assist the physicians in differential diagnosis of lymphoproliferative disorders of blood cells from digitized specimens is presented.  The user selects the region of interest (ROI) in the image which is then analyzed with a fast, robust color segmenter.  Queries in a database of validated cases can be formulated in terms of shape (similarity invariant Fourier descriptors), texture (multiresolution simultaneous autoregressive model), color (L \Lambda u \Lambda v \Lambda space), and area, derived from the delineated ROI.  The uncertainty of the segmentation process (obtained through a numerical method) determines the accuracy of shape description (number of Fourier harmonics).  Tenfold cross-validated classification over a database of 261 color 640\Theta480 images was implemented to assess the system performance.  The ground truth was obtained through immunophenotyping by flow cytometry.  To provide a natural man-machine interface, most input commands are bimodal: either using the mouse or by voice.  A speech synthesizer provides feedback to the user.  All the employed computational modules are context independent and thus the same system can be used in a large variety of application domains. 
Robust Real-Time Myocardial Border Tracking for Echocardiography: An Information Fusion Approach| Abstract--- Ultrasound is a main non-invasive modality for the assessment of the heart function.  Wall tracking from ultrasound data is, however, inherently difficult due to weak echoes, clutter, poor signal-to-noise ratio, and signal dropouts.  To cope with these artifacts, pre-trained shape models can be applied to constrain the tracking.  However, existing methods for incorporating subspace shape constraints in myocardial border tracking use only partial information from the model distribution, and do not exploit spatially varying uncertainties from feature tracking.  In this paper, we propose a complete fusion formulation in the information space for robust shape tracking, optimally resolving uncertainties from the system dynamics, heteroscedastic measurement noise, and subspace shape model.  We also exploit information from the ground truth initialization where this is available.  The new framework is applied for tracking of myocardial borders in very noisy echocardiography sequences.  Numerous myocardium tracking experiments validate the theory and show the potential of very accurate wall motion measurements.  The proposed framework outperforms the traditional shape-spaceconstrained tracking algorithm by a significant margin.  Due to the optimal fusion of different sources of uncertainties, robust performance is observed even on the most challenging cases. 
Distribution Free Decomposition of Multivariate Data| Abstract We present a practical approach to nonparametric cluster analysis of large data sets.  The number of clusters and the cluster centers are automatically derivedbymode seeking with the mean shift procedure on a reduced set of points randomly selected from the data.  The cluster boundaries are delineated using a k-nearest neighbor technique.  The proposed algorithm is stable and efficient, a 10000 point data set being decomposed in only a few seconds.  Complex clustering examples and applications are discussed, and convergence of the gradient ascent mean shift procedure is demonstrated for arbitrary distribution and cardinality of the data. 
Statistical Modeling and Performance Characterization of a Real-Time Dual Camera Surveillance System| Abstract The engineering of computer vision systems that meet application specific computational and accuracy requirements is crucial to the deployment of real-life computer vision systems.  This paper illustrates how past work on a systematic engineering methodology for vision systems performancecharacterization can be used to develop a real-time people detection and zooming system to meet given application requirements.  We illustrate that by judiciously choosing the system modules and performing a careful analysis of the influence of various tuning parameters on the system it is possible to: perform proper statistical inference, automatically set control parameters and quantify limits of a dual-camerareal-time video surveillance system.  The goal of the system is to continuously provide a high resolution zoomed-in image of a persons head at any location of the monitoredarea.  An omni-directional camera videoisprocessed to detect people and to precisely control a high resolution foveal camera, which has pan, tilt and zoom capabilities.  The pan and tilt parameters of the foveal camera and its uncertainties are shown to be functions of the underlying geometry, lighting conditions, background color/contrast, relative position of the person with respect to both cameras as well as sensor noise and calibration errors.  The uncertainty in the estimates is used to adaptively estimate the zoom parameter that guarantees with a user specifiedprobability, ff, that the detectedperson's faceiscontainedand zoomed within the image 1 . 
Parametric Representations for Nonlinear Modeling of Visual Data| Abstract Accurate characterization of data distribution is of significant importance for vision problems.  In many situations, multivariate visual data often spread into a nonlinear manifold in the high-dimensional space, which makes traditional linear modeling techniques ineffective.  This paper proposes a generic nonlinear modeling scheme based on parametric data representations.  We build a compact representation for the visual data using a set of parameterized basis (wavelet) functions, where the parameters are randomized to characterize the nonlinear structure of the data distribution.  Meanwhile, a new progressive density approximation scheme is proposed to obtain an accurate estimate of the probability density, which imposes discrimination power on the model.  Both synthetic and real image data are used to demonstrate the strength of our modeling scheme. 
A Unified Framework for Uncertainty Propagation in Automatic Shape Tracking| Abstract Uncertainty handling plays an important role during shape tracking.  We have recently shown that the fusion of measurement information with system dynamics and shape priors greatly improves the tracking performance for very noisy images such as ultrasound sequences [22].  Nevertheless, this approach required user initialization of the tracking process.  This paper solves the automatic initialization problem by performing boosted shape detection as a generic measurement process and integrating it in our tracking framework.  We show how to propagate the local detection uncertainties of multiple shape candidates during shape alignment, fusion with the predicted shape prior, and fusion with subspace constraints.  As a result, we treat all sources of information in a unified way and derive the posterior shape model as the shape with the maximum likelihood.  Our framework is applied for the automatic tracking of endocardium in ultrasound sequences of the human heart.  Reliable detection and robust tracking results are achieved when compared to existing approaches and interexpert variations. 
Component Fusion for Face Detection in the Presence of Heteroscedastic Noise| Abstract.  Face detection using components has been proved to produce superior results due to its robustness to occlusions and pose and illumination changes.  A first level of processing is devoted to the detection of individual components, while a second level deals with the fusion of the component detectors.  However, the fusion methods investigated up to now neglect the uncertainties that characterize the component locations.  We show that this uncertainty carries important information that, when exploited, leads to increased face localization accuracy.  We discuss and compare possible solutions taking into account geometrical constraints.  The efficiency and usefulness of the techniques are tested with both synthetic and real world examples. 
Image Segmentation and Residual Coding for Very Low Bit Rate Compression| Abstract To achieve very low bit rate compression a new robust segmentation method is employed to define the most important regions of the image.  The region contours are then approximated with polygonal lines and transmitted together with the color of the region.  The discrete wavelet transform is used to compress the residual image which represents mostly texture and noise.  The overall procedure proves to be an effective compression scheme.  The reconstructed images show satisfactory visual appearance at compression ratios higher than 100:1 for gray level images and 150:1 for color images. 
Conditional Feature Sensitivity: A Unifying View on Active Recognition and Feature Selection| Abstract The objective of active recognition is to iteratively collect the next "best" measurements (e. g. , camera angles or viewpoints), to maximally reduce ambiguities in recognition.  However, existing work largely overlooked feature interaction issues.  Feature selection, on the other hand, focuses on the selection of a subset of measurements for a given classification task, but is not context sensitive (i. e. , the decision does not depend on the current input).  This paper proposes a unified perspective through conditional feature sensitivity analysis, taking into account both current context and feature interactions.  Based on different representations of the contextual uncertainties, we present three treatment models and exploit their joint power for dealing with complex feature interactions.  Synthetic examples are used to systematically test the validity of the proposed models.  A practical application in medical domain is illustrated using an echocardiography database with more than 2000 video segments with both subjective (from experts) and objective validations. 
Mean Shift: A Robust Approach Toward Feature Space Analysis| Abstract A general nonparametric technique is proposed for the analysis of a complex multimodal feature
Mobile Interaction with Remote Worlds: The Acoustic Periscope| ABSTRACT Strictly speaking, a periscope is an optical device that allows one to view and navigate the external environment.  The acoustic periscope is a metaphor for mobile interaction that transparently exploits audio/speech to navigate and provide an unobstructed scene in a real or virtual world.  We aim at both true mobility -- no strings or devices should be attached to human user to be able navigate -- and at a smart multi modal.  The implementation of our concept highlights un underestimated modality, the acoustic one, for making computers transparent to the actual interaction of the user with a remote world and advancing in the direction of ubiquitous computing.  In this paper we describe the basic principles, architecture and implementation of a system for ubiquitous, multimodal and easy visual accesses to the remote world based on the acoustic periscope idea.  In order to assemble the required functionality we resort to audio signal processing (in particular array signal processing) for location and orientation estimation, speech recognition and text-to-speech synthesis for natural language interaction, mobile computing, communication in a LAN/Bluetooth network, and streaming of data from or control of a remote telerobotic platform with vision capabilities. 
Real-Time Tracking of Non-Rigid Objects Using Mean Shift| Abstract A new method for real-time tracking of non-rigid objects seen from a moving camera is proposed.  The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame.  The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient.  The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution.  The capability of the tracker to handle in real-time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences. 
Dissimilarity computation through low rank corrections| Abstract Most of the energy of a multivariate feature is often contained in a low dimensional subspace.  We exploit this property for the e)cient computation of a dissimilarity measure between features using an approximation of the Bhattacharyya distance.  We show that for normally distributed features the Bhattacharyya distance is a particular case of the Jensen--Shannon divergence, and thus evaluation of this distance is equivalent to a statistical test about the similarity of the two populations.  The accuracy of the proposed approximation is tested for the task of texture retrieval. 
Mean Shift Analysis and Applications| Abstract A nonparametric estimator of density gradient, the mean shift, is employed in the joint, spatial-range (value) domain of gray level and color images for discontinuity preserving filtering and image segmentation.  Properties of the mean shift are reviewed and its convergence on lattices is proven.  The proposed filtering method associates with each pixel in the image the closest local mode in the density distribution of the joint domain.  Segmentation into a piecewise constant structure requires only one more step, fusion of the regions associated with nearby modes.  The proposed technique has two parameters controlling the resolution in the spatial and range domains.  Since convergence is guaranteed, the technique does not require the intervention of the user to stop the filtering at the desired image quality.  Several examples, for gray and color images, show the versatility of the method and compare favorably with results described in the literature for the same images. 
Image-guided decision support system for pathology| Abstract.  We present a content-based image retrieval system that supports decision making in clinical pathology.  The image-guided decision support system locates, retrieves, and displays cases which exhibit morphological profiles consistent to the case in question.  It uses an image database containing 261 digitized specimens which belong to three classes of lymphoproliferative disorders and a class of healthy leukocytes.  The reliability of the central module, the fast color segmenter, makes possible unsupervised on-line analysis of the query image and extraction of the features of interest: shape, area, and texture of the nucleus.  The nuclear shape is characterized through similarity invariant Fourier descriptors, while the texture analysis is based on a multiresolution simultaneous autoregressive model.  The system performance was assessed through ten-fold cross-validated classification and compared with that of a human expert.  To facilitate a natural man-machine interface, speech recognition and voice feedback are integrated.  Client-server communication is multithreaded, Internet-based, and provides access to supporting clinical records and video databases. 
Shape-Based Image Indexing and Retrieval for Diagnostic Pathology| Abstract A prototype system performing analysis, indexing and retrieval of pathology images to assist physicians in differential diagnosis of lymphoproliferative disorders is presented.  Robust color segmentation is used to automatically analyse regions of interest in images of leukocytes.  The shape of leukocyte nuclei, described through similarity invariant shape descriptors, represents the main attribute in the search query.  Monte Carlo tests for stability and goaldirected evaluations of the system performance are also shown. 
Image Based Regression Using Boosting Method| Abstract We present a general algorithm of image based regression that is applicable to many vision problems.  The proposed regressor that targets a multiple-output setting is learned using boosting method.  We formulate a multiple-output regression problem in such a way that overfitting is decreased and an analytic solution is admitted.  Because we represent the image via a set of highly redundant Haar-like features that can be evaluated very quickly and select relevant features through boosting to absorb the knowledge of the training data, during testing we require no storage of the training data and evaluate the regression function almost in no time.  We also propose an efficient training algorithm that breaks the computational bottleneck in the greedy feature selection process.  We validate the efficiency of the proposed regressor using three challenging tasks of age estimation, tumor detection, and endocardial wall localization and achieve the best performance with a dramatic speed, e. g. , more than 1000 times faster than conventional data-driven techniques such as support vector regressor in the experiment of endocardial wall localization. 
Computer-assisted discrimination among malignant lymphomas and leukemia using immunophenotyping, intelligent image repositories, and telemicroscopy| Abstract---The process of discriminating among pathologies involving peripheral blood, bone marrow, and lymph node has traditionally begun with subjective morphological assessment of cellular materials viewed using light microscopy.  The subtle visible differences exhibited by some malignant lymphomas and leukemia, however, give rise to a significant number of false negatives during microscopic evaluation by medical technologists.  We have developed a distributed, clinical decision support prototype for distinguishing among hematologic malignancies.  The system consists of two major components, a distributed telemicroscopy system and an intelligent image repository.  The hybrid system enables individuals located at disparate clinical and research sites to engage in interactive consultation and to obtain computer-assisted decision support.  Software, written in JAVA, allows primary users to control the specimen stage, objective lens, light levels, and focus of a robotic microscope remotely while a digital representation of the specimen is continuously broadcast to all session participants.  Primary user status can be passed as a token.  The system features shared graphical pointers, text messaging capability, and automated database management.  Search engines for the database allow one to automatically identify and retrieve images, diagnoses, and correlated clinical data of cases from a "gold standard" database which exhibit spectral and spatial profiles which are most similar to a given query image.  The system suggests the most likely diagnosis based on majority logic of the retrieved cases.  The system was used to discriminate among three lymphoproliferative disorders and healthy cells.  The system provided the correct classification in more than 83% of the cases studied.  System performance was evaluated using rigorous statistical assessment and by comparison with human observers. 
Real-Time Multi-model Tracking of Myocardium in Echocardiography Using Robust Information Fusion| Abstract.  Automatic myocardial wall motion tracking in ultrasound images is an important step in analysis of the heart function.  Existing methods for Myocardial Wall Tracking are not robust to artifacts induced by signal dropout, significant appearance or gain control changes.  We present a unified framework for tracking the myocardium wall motion in real time with uncertainty handling and robust information fusion.  Our method is robust in two aspects, firstly robust information fusion is used for combining matching results from multiple appearance models and secondly fusion is performed in the shape space to combine information from measurement and prior knowledge and models.  Our approach fully exploits uncertainties from the measurement, shape priors, motion dynamics, and matching process based on multiple appearance models.  Experiments illustrate the advantages of our approach validating the theory and showing the potential of very accurate wall motion measurements. 
A PROBABILISTIC FRAMEWORK FOR OBJECT RECOGNITION IN VIDEO| ABSTRACT We propose a solution to the problem of object recognition given a continuous video sequence containing multiple views of an object.  Initially, object models are acquired from images of the objects taken from different views.  Recognition is achieved from the video sequences by employing a multiple hypothesis approach.  Appearance similarity, and pose transition smoothness constraints are used to estimate the probability of the measurement being generated from a certain model hypothesis at each time instant.  A smooth gradient direction feature that is quasi-invariant to illumination changes and noise is used to represent the appearance of object.  The pose of the object at each time instant is modelled as a von Mises-Fisher distribution.  Recognition is achieved by choosing the hypothesis set that has accumulated the maximum evidence at the end of the sequence.  We have performed detailed experiments demonstrating the viability of the proposed approach. 
IMAGE SEGMENTATION USING CLUSTERING WITH SADDLE POINT DETECTION| Abstract We discuss a novel statistical framework for image segmentation based on nonparametric clustering.  By employing the mean shift procedure for analysis, image regions are identified as clusters in the joint color-spatial domain.  To measure the significance of each cluster we use a test statistics that compares the estimated density of the cluster mode with the estimated density on the cluster boundary.  The cluster boundary in the color domain is defined by saddle points lying on the cluster borders defined in the spatial domain.  The proposed technique compares favorably to other segmentation methods described in literature. 
Mean Shift and Optimal Prediction for Efficient Object Tracking| Abstract A new paradigm for the efficient color-based tracking of objects seen from a moving camera is presented.  The proposed technique employs the mean shift analysis to derive the target candidate that is the most similar to a given target model, while the prediction of the next target location is computed with a Kalman filter.  The dissimilarity between the target model and the target candidates is expressed by a metric based on the Bhattacharyya coefficient.  The implementation of the new method achieves real-time performance, being appropriate for a large variety of objects with different color patterns.  The resulting tracking, tested on various sequences, is robust to partial occlusion, significant clutter, target scale variations, rotations in depth, and changes in camera position. 
An Algorithm for Data-Driven Bandwidth Selection| Abstract---The analysis of a feature space that exhibits multiscale patterns often requires kernel estimation techniques with locally adaptive bandwidths, such as the variable-bandwidth mean shift.  Proper selection of the kernel bandwidth is, however, a critical step for superior space analysis and partitioning.  This paper presents a mean shift-based approach for local bandwidth selection in the multimodal, multivariate case.  Our method is based on a fundamental property of normal distributions regarding the bias of the normalized density gradient.  We demonstrate that, within the large sample approximation, the local covariance is estimated by the matrix that maximizes the magnitude of the normalized mean shift vector.  Using this property, we develop a reliable algorithm which takes into account the stability of local bandwidth estimates across scales.  The validity of our theoretical results is proven in various space partitioning experiments involving the variable-bandwidth mean shift. 
The Variable Bandwidth Mean Shift and Data-Driven Scale Selection| Abstract We present two solutions for the scale selection problem in computer vision.  The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient.  Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure.  The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information.  The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector.  Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness.  1 Motivation for Variable Bandwidth The efficacy of Mean Shift analysis has been demonstrated in computer vision problems such as tracking and segmentation in [5, 6].  However, one of the limitations of the mean shift procedure as defined in these papers is that it involves the specification of a scale parameter.  While results obtained appear satisfactory, when the local characteristics of the feature space differs significantly across data, it is difficult to find an optimal global bandwidth for the mean shift procedure.  In this paper we address the issue of locally adapting the bandwidth.  We also study an alternative approach for data-driven scale selection which imposes a local structure on the data.  The proposed solutions are tested in the framework of quasi real-time video analysis.  We review first the intrinsic limitations of the fixed bandwidth density estimation methods.  Then, two of the most popular variable bandwidth estimators, the balloon and the sample point, are introduced and their advantages discussed.  We conclude the section by showing that, with some precautions, the performance of the sample point estimator is superior to both fixed bandwidth and balloon estimators.  1. 1 Fixed Bandwidth Density Estimation The multivariate fixed bandwidth kernel density estimate is defined by ^ f(x) = 1 nh d n X i=1 K ` x\Gamma x i h ' : (1) where the d-dimensional vectors fx i g i=1:::n represent a random sample from some unknown density f and the kernel, K, is taken to be a radially symmetric, nonnegative function centered at zero and integrating to one.  The terminology fixed bandwidth is due to the fact that h is held constant across x 2 R d .  As a result, the fixed bandwidth procedure (1) estimates the density at each point x by taking the average of identically scaled kernels centered at each of the data points.  For pointwise estimation, the classical measure of the closeness of the estimator ^ f to its target value f is the mean squared error (MSE), equal to the sum of the variance and squared bias MSE(x) = E h ^ f(x) \Gamma f(x) i 2 = Var i ^ f(x) j + h Bias i ^ f(x) ji 2 : (2) Using the multivariate form of the Taylor theorem, the bias and the variance are approximated by [20, p. 97] Bias(x) 1 2 h 2 2 (K )\Deltaf (x) (3) and Var(x) n\Gamma 1 h \Gamma d R(K)f(x) ; (4) where 2 (K) = R z 2 1 K(z)dz and R(K) = R K(z)dz are kernel dependent constants, z 1 is the first component of the vector z, and \Delta is the Laplace operator.  The tradeoff of bias versus variance can be observed in (3) and (4).  The bias is proportional to h 2 , which means that smaller bandwidths give a less biased estimator.  However, decreasing h implies an increase in the variance which is proportional to n \Gamma 1 h \Gamma d .  Thus for a fixed bandwidth estimator we should choose h that achieves an optimal compromise between the bias and variance over all x 2 R d , i. e. , minimizes the mean integrated squared error (MISE) MISE(x) = E Z i ^ f(x) \Gamma f(x) j 2 dx : (5) Nevertheless, the resulting bandwidth formula (see [17, p. 85], [20, p. 98]) is of little practical use, since it depends on the Laplacian of the unknown density being estimated.  The best of the currently available data-driven methods for bandwidth selection seems to be the plug-in rule [15], which was proven to be superior to least squares cross validation and biased cross-validation [11], [16, p. 46].  A practical one dimensional algorithm based on this method is described in the Appendix.  For the multivariate case, see [20, p. 108].  Note that these data-driven bandwidth selectors work well for multimodal data, their only assumption being a certain smoothness in the underlying density.  However, the fixed bandwidth affects the estimation performance, by undersmoothing the tails and oversmoothing the peaks of the density.  The performance also decreases when the data exhibits local scale variations.  1. 2 Balloon and Sample Point Estimators According to expression (1), the bandwidth h can be varied in two ways.  First, by selecting a different bandwidth h = h(x) for each estimation point x, one can define the balloon density estimator ^ f 1 (x) = 1 nh(x) d n X i=1 K ` x\Gamma x i h(x) ' : (6) In this case, the estimate of f at x is the average of identically scaled kernels centered at each data point.  Second, by selecting a different bandwidth h = h(x i ) for each data point x i we obtain the sample point density estimator ^ f 2 (x) = 1 n n X i=1 1 h(x i ) d K ` x \Gamma x i h(x i ) ' : (7) for which the estimate of f at x is the average of differently scaled kernels centered at each data point.  While the balloon estimator has more intuitive appeal, its performance improvement over the fixed bandwidth estimator is insignificant.  When the bandwidth h(x) is chosen as a function of the k-th nearest neighbor, the bias and variance are still proportional to h 2 and n\Gamma 1 h \Gamma d , respectively [8].  In addition, the balloon estimators usually fail to integrate to one.  The sample point estimators, on the other hand, are themselves densities, being non-negative and integrating to one.  Their most attractive property is that a particular choice of h(x i ) reduces considerably the bias.  Indeed, when h(x i ) is taken to be reciprocal to the square root of f(x i ) h(x i ) = h 0 f(x i ) 1=2 (8) the bias becomes proportional to h 4 , while the variance remains unchanged, proportional to n \Gamma 1 h \Gamma d [1, 8].  In (8), h 0 represents a fixed bandwidth and is a proportionality constant.  Since f(x i ) is unknown it has to be estimated from the data.  The practical approach is to use one of the methods described in Section 1. 1 to find h 0 and an initial estimate (called pilot) of f denoted by ~ f .  Note that by using ~ f instead of f in (8), the nice properties of the sample point estimators (7) remain unchanged [8].  Various authors [16, p. 56], [17, p. 101] remarked that the method is insensitive to the fine detail of the pilot estimate.  The only provision that should be taken is to bound the pilot density away from zero.  The final estimate (7) is however influenced by the choice of the proportionality constant , which divides the range of density values into low and high densities.  When the local density is low, i. e. , ~ f(x i ) ! , h(x i ) increases relative to h 0 implying more smoothing for the point x i .  For data points that verify ~ f(x i ) ? , the bandwidth becomes narrower.  A good initial choice [17, p. 101] is to take as the geometric mean of n ~ f(x i ) o i=1:::n .  Our experiments have shown that for superior results, a certain degree of tuning is required for .  Nevertheless, the sample point estimator proved to be almost all the time much better than the fixed bandwidth estimator. 
Robust analysis of feature spaces: color image segmentation| Abstract A general technique for the recovery of significant image features is presented.  The technique is based on the mean shift algorithm, a simple nonparametric procedure for estimating density gradients.  Drawbacks of the current methods (including robust clustering) are avoided.  Feature space of any nature can be processed, and as an example, color image segmentation is discussed.  The segmentation is completely autonomous, only its class is chosen by the user.  Thus, the same program can produce a high quality edge image, or provide, by extracting all the significant colors, a preprocessor for content-based query systems.  A 512 \Theta 512 color image is analyzed in less than 10 seconds on a standard workstation.  Gray level images are handled as color images having only the lightness coordinate. 
SMART CAMERAS WITH REAL-TIME VIDEO OBJECT GENERATION| ABSTRACT This paper presents a system for video object generation and selective encoding with applications in surveillance, mobile videophones, and automotive industry.  Object tracking and MPEG-4 compression are performed in realtime.  The system belongs to a new generation of intelligent vision sensors called smart cameras, which execute autonomous vision tasks and report events and data to a remote base-station.  A detection module signals the object of interest presence within the camera field of view, while the tracking part follows the target to generate temporal trajectories.  The compression is MPEG-4 compliant and implements the Simple Profile of the standard, capable of encoding up to four video objects.  At the same time, the compression is selective, maintaining a higher quality for the foreground objects and a lower quality for the background representation.  This property contributes to bandwidth reduction while preserving the essential information of foreground objects.  The system performance is demonstrated in experiments that involve objects representing faces and vehicles seen from both static and moving cameras. 
Nonparametric Information Fusion for Motion Estimation|
A Robust Algorithm for Characterizing Anisotropic Local Structures|
Bayesian Kernel Tracking|
Coupled-Contour Tracking through Non-orthogonal Projections and Fusion for Echocardiography|
An Information Fusion Framework for Robust Shape Tracking|
Mean Shift: A Robust Approach Toward Feature Space Analysis| IEEE Transactions on Pattern Analysis and Machine. 
Multivariate Saddle Point Detection for Statistical Clustering|
Multimodal Data Representations with Parameterized Local Structures|
Decision Support System for Multiuser Remote Microscopy in Telepathology|
