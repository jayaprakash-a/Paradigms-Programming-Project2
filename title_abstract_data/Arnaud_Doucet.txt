Reversible Jump MCMC Simulated Annealing for Neural Networks| Abstract We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated annealing algorithm to optimize radial basis function (RBF) networks.  This algorithm enables us to maximize the joint posterior distribution of the network parameters and the number of basis functions.  It performs a global search in the joint space of the parameters and number of parameters, thereby surmounting the problem of local minima.  We also show that by calibrating a Bayesian model, we can obtain the classical AIC, BIC and MDL model selection criteria within a penalized likelihood framework.  Finally, we show theoretically and empirically that the algorithm converges to the modes of the full posterior distribution in an ecient way. 
A Survey of Convergence Results on Particle Filtering Methods for Practitioners| Abstract---Optimal filtering problems are ubiquitous in signal processing and related fields.  Except for a restricted class of models, the optimal filter does not admit a closed-form expression.  Particle filtering methods are a set of flexible and powerful sequential Monte Carlo methods designed to solve the optimal filtering problem numerically.  The posterior distribution of the state is approximated by a large set of Dirac-delta masses (samples/particles) that evolve randomly in time according to the dynamics of the model and the observations.  The particles are interacting; thus, classical limit theorems relying on statistically independent samples do not apply.  In this paper, our aim is to present a survey of recent convergence results on this class of methods to make them accessible to practitioners. 
Maintaining Multi-Modality through Mixture Tracking| Abstract In recent years particle filters have become a tremendously popular tool to perform tracking for non-linear and/or non-Gaussian models.  This is due to their simplicity, generality and success over a wide range of challenging applications.  Particle filters, and Monte Carlo methods in general, are however poor at consistently maintaining the multi-modality of the target distributions that may arise due to ambiguity or the presence of multiple objects.  To address this shortcoming this paper proposes to model the target distribution as a non-parametric mixture model, and presents the general tracking recursion in this case.  It is shown how a Monte Carlo implementation of the general recursion leads to a mixture of particle filters that interact only in the computation of the mixture weights, thus leading to an efficient numerical algorithm, where all the results pertaining to standard particle filters apply.  The ability of the new method to maintain posterior multi-modality is illustrated on a synthetic example and a real world tracking problem involving the tracking of football players in a video sequence. 
Simulation-Based Methods for Blind Maximum-Likelihood Filter Identification| Abstract Blind linear system identification consists in estimating the parameters of a linear timeinvariant system given its (possibly noisy)
Cambridge University Engineering Department THE UNSCENTED PARTICLE FILTER| Abstract In this paper we propose a novel method for nonlinear, non-Gaussian, on-line estimation.  The algorithm consists of a particle filter that uses an unscented Kalman filter (UKF) to generate the importance proposal distribution.  The UKF allows the particle filter to incorporate the latest observations into a prior updating routine.  In addition, the UKF generates proposal distributions that match the true posterior more closely and also has the capability of generating heavier tailed distributions than the well known extended Kalman filter.  As a result, the convergence results predict that the new filter should outperform standard particle filters, extended Kalman filters and unscented Kalman filters.  A few experiments confirm this prediction. 
RANDOM FINITE SETS AND SEQUENTIAL MONTE CARLO METHODS IN MULTI-TARGET TRACKING| ABSTRACT Random finite set provides a rigorous foundation for optimal Bayes multi-target filtering.  The major hurdle faced in Bayes multi-target filtering is the inherent computational intractability.  Even the Probability Hypothesis Density (PHD) filter, which propagates only the first moment (or PHD) instead of the full multi-target posterior, still involves multiple integrals with no closed forms.  In this paper, we highlight the relationship between Radon-Nikodym derivative and set derivative of random finite sets that enables a Sequential Monte Carlo (SMC) implementation of the optimal multitarget filter.  In addition, a generalised SMC method to implement the PHD filter is also presented.  The SMC PHD filter has an attractive feature-its computational complexity is independent of the (time-varying) number of targets. 
Particle filter for tracking linear Gaussian target with nonlinear observations| ABSTRACT In this paper, a solution to the TENET nonlinear filtering challenge is presented. 
Sequential Monte Carlo Implementation of the PHD Filter for Multi-target Tracking| Abstract -- Random finite sets are natural representations of multi-target states and observations that allow multi-sensor multi-target tracking to fit in the
Smoothing Algorithms for State-Space Models| Abstract A prevalent problem in statistical signal processing, applied statistics, and time series analysis is the calculation of the smoothed posterior distribution, which describes the uncertainty associated with a state, or a sequence of states, conditional on data from the past, the present, and the future.  The aim of this paper is to provide a rigorous foundation for the calculation, or approximation, of such smoothed distributions, to facilitate a robust and efficient implementation.  Through a cohesive and generic exposition of the scientific literature we offer several novel extensions such that one can perform smoothing in the most general case.  Experimental results for: a Jump Markov Linear System; a comparison of particle smoothing methods; and parameter estimation using a particle implementation of the EM algorithm, are provided. 
Probability Hypothesis Density filter versus Multiple Hypothesis Tracking| ABSTRACT The probability hypothesis density (PHD) filter is a practical alternative to the optimal Bayesian multi-target filter based on finite set statistics.  It propagates only the first order moment instead of the full multi-target posterior.  Recently, a sequential Monte Carlo (SMC) implementation of PHD filter has been used in multitarget filtering with promising results.  In this paper, we will compare the performance of the PHD filter with that of the multiple hypothesis tracking (MHT) that has been widely used in multi-target filtering over the past decades.  The Wasserstein distance is used as a measure of the multi-target miss distance in these comparisons.  Furthermore, since the PHD filter does not produce target tracks, for comparison purposes, we investigated ways of integrating the data-association functionality into the PHD filter.  This has lead us to devise methods for integrating the PHD filter and the MHT filter for target tracking which exploits the advantage of both approaches. 
Parameter Estimation in General State-Space Models using Particle Methods| ABSTRACT Particle filtering techniques are a set of powerful and versatile simulation-based methods to perform optimal state estimation in nonlinear non-Gaussian state-space models.  If the model includes fixed parameters, a standard technique to perform parameter estimation consists of extending the state with the parameter to transform the problem into an optimal filtering problem.  However, this approach requires the use of special particle filtering techniques which suffer from several drawbacks.  We consider here an alternative approach combining particle filtering and gradient algorithms to perform batch and recursive maximum likelihood parameter estimation.  An original particle method is presented to implement these approaches and their # corresponding author.  eciency is assessed through simulation. 
Maximum a Posteriori Parameter Estimation for Hidden Markov Models| Summary An iterative stochastic algorithm to perform maximum a posteriori parameter estimation of hidden Markov models is proposed.  It makes the most of the statistical model by introducing an articial probability model based on an increasing number of the unobserved Markov chain at each iteration.  Under minor regularity assumptions, we provide suOEcient conditions to ensure global convergence of this algorithm.  It is applied to parameter estimation for nite Gaussian mixtures, Markov-modulated Poisson processes and switching autoregressions with a Markov regime. 
SUPPORT VECTOR REGRESSION FOR BLACK-BOX SYSTEM IDENTIFICATION| ABSTRACT In this paper, we demonstrate the use of support vector regression (SVR) techniques for black-box system identification.  These methods derive from statistical learning theory, and are of great theoretical and practical interest.  We briefly describe the theory underpinning SVR, and compare support vector methods with other approaches using radial basis networks.  Finally, we apply SVR to modeling the behaviour of a hydraulic robot arm, and show that SVR improves on previously published results. 
Variance Reduction for Monte Carlo Implementation of Adaptive Sensor Management| Abstract -- Adaptive sensor management (scheduling) is usually formulated as a finite horizon POMDP and implemented using sequential Monte Carlo.  In Monte Carlo, variance reduction is important for the reliable performance of the sensor scheduler.  In this paper, we propose a Control Variate method for variance reduction when the sensor is scheduled using the Kullbach Leibler criterion. 
Sequential Bayesian Kernel Regression| Abstract We propose a method for sequential Bayesian kernel regression.  As is the case for the popular Relevance Vector Machine (RVM) [10, 11], the method automatically identifies the number and locations of the kernels.  Our algorithm overcomes some of the computational difficulties related to batch methods for kernel regression.  It is non-iterative, and requires only a single pass over the data.  It is thus applicable to truly sequential data sets and batch data sets alike.  The algorithm is based on a generalisation of Importance Sampling, which allows the design of intuitively simple and efficient proposal distributions for the model parameters.  Comparative results on two standard data sets show our algorithm to compare favourably with existing batch estimation strategies. 
Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks| Abstract Particle lters (PFs) are powerful samplingbased inference/learning algorithms for dynamic Bayesian networks (DBNs).  They allow us to treat, in a principled way, any type of probability distribution, nonlinearity and non-stationarity.  They have appeared in several elds under such names as ^condensatio,^sequential Monte Carlo~ and ^survival of the ttest~.  In this paper, we show how we can exploit the structure of the DBN to increase the efciency of particle ltering, using a technique known as RaoBlackwellisation.  Essentially, this samples some of the variables, and marginalizes out the rest exactly, using the Kalman lter, HMM lter, junction tree algorithm, or any other nite dimensional optimal lter.  We show that RaoBlackwellised particle lters (RBPFs) lead to more accurate estimates than standard PFs.  We demonstrate RBPFs on two problems, namely non-stationary online regression with radial basis function networks and robot localization and map building.  We also discuss other potential application areas and provide references to some nite dimensional optimal lters. 
ONLINE EXPECTATION-MAXIMIZATION TYPE ALGORITHMS FOR PARAMETER ESTIMATION IN GENERAL STATE SPACE MODELS| ABSTRACT In this paper we present new online algorithms to estimate static parameters in nonlinear non Gaussian state space models.  These algorithms rely on online Expectation-Maximization (EM) type algorithms.  Contrary to standard Sequential Monte Carlo (SMC) methods recently proposed in the literature, these algorithms do not degenerate over time. 
SEQUENTIAL MCMC FOR BAYESIAN MODEL SELECTION| ABSTRACT In this paper, we address the problem of sequential Bayesian model selection.  This problem does not usually admit any closed-form analytical solution.  We propose here an original sequential simulation-based method to solve the associated Bayesian computational problems.  This method combines sequential importance sampling, a resampling procedure and reversible jump MCMC moves.  We describe a generic algorithm and then apply it to the problem of sequential Bayesian model order estimation of autoregressive (AR) time series observed in additive noise. 
Practical Filtering for Stochastic Volatility Models| This paper provides a simulation-based approach to filtering and sequential parameter learning for stochastic volatility models.  We develop a fast simulationbased approach using the practical filter of Polson, Stroud and Muller (2002).  We compare our approach to sequential parameter learning and filtering with an auxiliary particle filtering algorithm based on Storvik (2002).  For simulated data, there is close agreement between the two methods.  For data on the S&P 500 market stock index from 1984{1990, our algorithm agrees closely with a full MCMC analysis, whereas the auxiliary particle filter degenerates. 
Rao-Blackwellised Particle Filtering via Data Augmentation| Abstract In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations.  This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation.  Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers.  We focus on sequential binary classifiers that consist of linear combinations of basis functions, whose coecients evolve according to a Gaussian smoothness prior.  Our results show significant improvements. 
Sequential Monte Carlo methods for Multi-target Filtering with Random Finite Sets| Abstract Random finite sets are natural representations of multi-target states and observations that allow multi-sensor multi-
The Unscented Particle Filter| Abstract In this paper, we propose a new particle filter based on sequential importance sampling.  The algorithm uses a bank of unscented #lters to obtain the importance proposal distribution.  This proposal has two very \nice" properties.  Firstly, it makes ecient use of the latest available information and, secondly, it can have heavy tails.  As a result, we find that the algorithm outperforms standard particle filtering and other nonlinear filtering methods very substantially.  This experimental finding is in agreement with the theoretical convergence proof for the algorithm.  The algorithm also includes resampling and (possibly) Markov chain Monte Carlo (MCMC) steps. 
MARKOV CHAIN MONTE CARLO DATA ASSOCIATION FOR TARGET TRACKING| A simulation study shows that the new algorithms are superior to previously proposed methods. 
An Introduction to MCMC for Machine Learning|
Sequential Monte Carlo Methods to Train Neural Network Models|
The unscented particel filter|
Sparse Bayesian Learning for Regression and Classification using Markov Chain Monte Carlo|
Robust Full Bayesian Methods for Neural Networks|
Robust Full Bayesian Learning for Radial Basis Networks|
\Rao-Blackwellized particle filtering for dynamic Bayesian networks,"|
