A Layered Motion Representation with Occlusion and Compact Spatial Support| This allows us to automatically initialize new models, and to compare different depth orderings. 
The Digital Office: Overview| Abstract This paper describes our efforts to develop a "Digital Office" in which we augment a physical office setting with cameras and other electronic devices.  Our goal is to bring the worlds of electronic and physical documents closer together and to facilitate the interaction of humans with all kinds of documents.  In the "Digital Office" we extend the traditional notion of "scanning"documentsto include the capture of whiteboards, books, desktops, and the human office workers themselves.  In particular, we give an overview of three systems in which video cameras unobtrusively observe and capture whiteboards and human gestures, papers on the desktop, and the motion of a user's face which is used to control the display of electronic documents in a browser.  Each of these systems combines the features and affordances of both physical and electronic documents, and together they begin to illuminate the intelligent office environment of the future. 
Mixture Models for Optical Flow Computation| Abstract The computation of optical flow relies on merging information available over an image patch to form an estimate of 2D image velocity at a point.  This merging process raises a host of issues, which include the treatment of outliers in component velocity measurements and the modeling of multiple motions within a patch which arise from occlusion boundaries or transparency.  We present a new approach which allows us to deal with these issues within a common framework.  Our approach is based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch.  We use a simple extension of the EM-algorithm to compute a maximum likelihood estimate for the various motion parameters.  Preliminary experiments indicate that this approach is computationally efficient and can provide robust estimates of the optical flow values in the presence of outliers and multiple motions.  The basic approach can also be applied to other problems in computational vision, such as the computation of 3D relative motion, which require the integration of several partial constraints to obtain a desired quantity. 
Generative modeling for continuous non-linearly embedded visual inference| Abstract Many difficult visual perception problems, like 3D human motion estimation, can be formulated in terms of inference using complex generative models, defined over high-dimensional state spaces.  Despite progress, optimizing such models is difficult because prior knowledge cannot be flexibly integrated in order to reshape an initially designed representation space.  Nonlinearities, inherent sparsity of high-dimensional training sets, and lack of global continuity makes dimensionality reduction challenging and lowdimensional search inefficient.  To address these problems, we present a learning and inference algorithm that restricts visual tracking to automatically extracted, non-linearly embedded, lowdimensional spaces.  This formulation produces a layered generative model with reduced state representation, that can be estimated using efficient continuous optimization methods.  Our prior flattening method allows a simple analytic treatment of low-dimensional intrinsic curvature constraints, and allows consistent interpolation operations.  We analyze reduced manifolds for human interaction activities, and demonstrate that the algorithm learns continuous generative models that are useful for tracking and for the reconstruction of 3D human motion in monocular video. 
Variational Mixture Smoothing for Non-Linear Dynamical Systems| Abstract We present an algorithm for computing joint state, smoothed, density estimates for non-linear dynamical systems in a Bayesian setting.  Many visual tracking problems can be formulated as probabilistic inference over time series, but we are not aware of mixture smoothers that would apply to weakly identifiable models, where multimodality is persistent rather than transient (e. g.  monocular 3D human tracking).  Such processes, in principle, exclude iterated Kalman smoothers, whereas flexible MCMC methods or sample based particle smoothers encounter computational difficulties: accurately locating an exponential number of probable joint state modes representing high-dimensional trajectories, rapidly mixing between those or resampling probable configurations missed during filtering.  In this paper we present an alternative, layered, mixture density smoothing algorithm that exploits the accuracy of efficient optimization within a Bayesian approximation framework.  The distribution is progressively refined by combining polynomial time search over the embedded network of temporal observation likelihood peaks, MAP continuous trajectory estimates, and Bayesian variational adjustment of the resulting joint mixture approximation.  Our results demonstrate the effectiveness of the method on the problem of inferring multiple plausible 3D human motion trajectories from monocular video. 
Sparse coding in practice| Abstract The goal in sparse coding is to seek a linear basis representation where each image is represented by a small number of active coefficients.  The learning algorithm involves adapting a basis vector set while imposing a low-entropy, or sparse, prior on the output coefficients.  Sparse coding applied on natural images has been shown to extract wavelet-like structure [9, 4].  However, our experience in using sparse coding for extracting multi-scale structure in object-specific ensembles, such as face images or images of a gesturing hand, has been negative.  In this paper we highlight three points about the reliability of sparse coding for extracting the desired structure: (1) using an overcomplete representation (2) projecting data into a low-dimensional subspace before attempting to resolve the sparse structure and (3) applying sparsity constraint on the basis elements, as opposed to the output coefficients. 
Robust Online Appearance Models for Visual Tracking| Abstract We propose a framework for learning robust, adaptive, appearance models to be used for motion-based tracking of natural objects.  The approach involves a mixture of stable image structure, learned over long time courses, along with 2-frame motion information and an outlier process.  An online EM-algorithm is used to adapt the appearance model parameters over time.  An implementation of this approach is developed for an appearance model based on the filter responses from a steerable pyramid.  This model is used in a motion-based tracking algorithm to provide robustness in the face of image outliers, such as those caused by occlusions.  It is also provides the ability to adapt to natural changes in appearance, such as those due to facial expressions or variations in 3D pose.  We show experimental results on a variety of natural image sequences of people moving within cluttered environments. 
Estimating Multiple Independent Motions in Segmented Images using Parametric Models with Local Deformations| Abstract This paper presents a new model for optical flow based on the motion of planar regions plus local deformations.  The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene.  Parametric flow models are fitted to these regions in a two step process which first computes a coarse fit and then refines it using a generalization of the standard area-based regression approaches.  Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption.  This parametric+deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches. 
Phase singularities in scale-space| Abstract This paper concerns the use of phase information from band-pass signals for the measurement of binocular disparity, optic flow, and image orientation.  Towards this end, one of the important properties of band-pass phase information is its stability with respect to small geometric deformations and contrast changes.  However, in particular regions phase can also be very unstable due to the occurrence of phase singularities.  We discuss the existence of phase singularities, and their relation to the neighbourhoods where phase is unreliable.  Moreover, we present a simple method for detecting these regions of instability. 
University of Toronto| Abstract We present an algorithm for computing joint state, smoothed, density estimates for non-linear dynamical systems in a Bayesian setting.  Many visual tracking problems can be formulated as probabilistic inference over time series, but we are not aware of mixture smoothers that would apply to weakly identifiable models, where multimodality is persistent rather than transient (e. g.  monocular 3D human tracking).  Such processes, in principle, exclude iterated Kalman smoothers, whereas flexible MCMC methods or sample based particle smoothers encounter computational difficulties: accurately locating an exponential number of probable joint state modes representing high-dimensional trajectories, rapidly mixing between those or resampling probable configurations missed during filtering.  In this paper we present an alternative, layered, mixture density smoothing algorithm that exploits the accuracy of efficient optimization within a Bayesian approximation framework.  The distribution is progressively refined by combining polynomial time search over the embedded network of temporal observation likelihood peaks, MAP continuous trajectory estimates, and Bayesian variational adjustment of the resulting joint mixture approximation.  Our results demonstrate the effectiveness of the method on the problem of inferring multiple plausible 3D human motion trajectories from monocular video. 
Trajectory Segmentation Using Dynamic Programming| Abstract We consider the segmentation of a trajectory into piecewise polynomial parts, or possibly other forms.  Segmentation is typically formulated as an optimization problem which trades off model fitting error versus the cost of introducing new segments.  Heuristics such as split-and-merge are used to find the best segmentation.  We show that for ordered data (eg. , single curves or trajectories) the global optimum segmentation can be found by dynamic programming.  The approach is easily extended to handle different segment types and top down information about segment boundaries, when available.  We show segmentation results for video sequences of a basketball undergoing gravitional and non-gravitaional motion. 
Half-Lives of EigenFlows for Spectral Clustering| Abstract Using a Markov chain perspective of spectral clustering we present an algorithm to automatically find the number of stable clusters in a dataset.  The Markov chain's behaviour is characterized by the spectral properties of the matrix of transition probabilities, from which we derive eigenflows along with their halflives.  An eigenflow describes the flow of probability mass due to the Markov chain, and it is characterized by its eigenvalue, or equivalently, by the halflife of its decay as the Markov chain is iterated.  A ideal stable cluster is one with zero eigenflow and infinite half-life.  The key insight in this paper is that bottlenecks between weakly coupled clusters can be identified by computing the sensitivity of the eigenflow's halflife to variations in the edge weights.  We propose a novel EIGENCUTS algorithm to perform clustering that removes these identified bottlenecks in an iterative fashion. 
Video Input Driven Animation (VIDA)| Abstract There are many challenges associated with the integration of synthetic and real imagery.  One particularly difficult problem is the automatic extraction of salient parameters of natural phenomena in real video footage for subsequent application to synthetic objects.  Can we ensure that the hair and clothing of a synthetic actor placed in a meadow of swaying grass will move consistently with the wind that moved that grass? The video footage can be seen as a controller for the motion of synthetic features, a concept we call video input driven animation (VIDA).  We propose a schema that analyzes an input video sequence, extracts parameters from the motion of objects in the video, and uses this information to drive the motion of synthetic objects.  To validate the principles of VIDA, we approximate the inverse problem to harmonic oscillation, which we use to extract parameters of wind and of regular water waves.  We observe the effect of wind on a tree in a video, estimate wind speed parameters from its motion, and then use this to make synthetic objects move.  We also extract water elevation parameters from the observed motion of boats and apply the resulting water waves to synthetic boats. 
Mixture Models for Image Representation| Abstract We consider the estimation of local grey-level image structure in terms of a layered representation.  This type of representation has recently been successfully used to segment foreground objects from various backgrounds using either optical flow or stereo disparity information.  We argue that the same type of representation is useful for greylevel data in that it allows for the automatic assignment of each pixel to one of several local layers or to an outlier distribution.  The combined description of the local layers, along with the corresponding pixel assignments, provides a compact representation of the original image.  Our emphasis in this paper is on the process used to extract such a layered representation from a given image.  In particular, we consider a variant of the EM-algorithm for the estimation of the layer parameters and pixel assignments, and consider a novel technique for choosing the number of layers to use.  We also briefly consider the use of such a representation for image segmentation. 
Density Propagation for Continuous Temporal Chains Generative and Discriminative Models| Abstract We analyze non-linear, non-Gaussian temporal chain models (dynamical systems) having continuous hidden states and non-linear, non-Gaussian dynamics and observation models.  In this setting we study both discriminative and generative models, describe their underlying independence assumptions, and give the propagation rules for filtering and smoothing.  Despite different graphical model structure and independences, the motivation is similar for using either of these models: infer a dynamically varying hidden state, based on sequences of observations.  The setting is common in the solution of many inverse problems in artificial intelligence (e. g.  computer vision, speech) or control theory.  See our companion papers for demonstrations of discriminative [10] and generative [9] models in 3D human motion reconstruction from monocular video applications. 
Towards the Computational Perception of Action| Abstract Understanding observations of interacting objects requires one to reason about qualitative scene dynamics.  For example, on observing a hand lifting a can, we may infer that an `active' hand is applying an upwards force (by grasping) to lift a `passive' can.  In previous work [6] we presented a system that infers qualitative scene dynamics from the instantaneous motion of objects.  However, since that analysis only considered single frames in isolation, there were often multiple interpretations for each frame.  In this work we show how the dynamic information inferred at each frame can be integrated over time to reduce ambiguity.  Our approach to integrating information is to extend our representation to describe objects by a set of properties or capabilities that are assumed to persist over time.  Given this extended representation we find interpretations that require the smallest set(s) of properties over the whole image sequence. 
Stability of Phase Information| Abstract This paper concerns the robustness of local phase information for measuring image velocity and binocular disparity.  It addresses the dependence of phase behaviour on the initial filters as well as the image variations that exist between different views of a 3d scene.  We are particularly interested in the stability of phase with respect to geometric deformations, and its linearity as a function of spatial position.  These properties are important to the use of phase information, and are shown to depend on the form of the filters as well as their frequency bandwidths.  Phase instabilities are also discussed using the model of phase singularities described by Jepson and Fleet [14].  In addition to phase-based methods, these results are directly relevant to differential optical flow methods and zero-crossing tracking. 
Spectral Embedding and Min-Cut for Image Segmentation| ABSTRACT Min-cut algorithms can provide perceptually salient image segments when they are given appropriate proposals for source and sink regions.  We explore the use of random walks and associated spectral embedding techniques for the automatic generation of suitable proposal regions.  We derive a mathematical connection between spectral embedding and anisotropic image smoothing kernels, and then use properties of the spectral embedding and the associated smoothing kernels to select multiple pairs of source and sink regions for min-cut.  This typically provides an over-segmentation, and therefore region merging is used to form the final image segmentation. 
Phase-Based Disparity Measurement| Abstract The measurement of image disparity is a fundamental precursor to binocular depth estimation.  Recently, Jenkin and Jepson (1988) and Sanger (1988) described promising methods based on the output phase behaviour of band-pass Gabor filters.  Here we discuss further justification for such techniques based on the stability of band-pass phase behaviour as a function of typical distortions that exist between left and right views.  In addition, despite this general stability, we show that phase signals are occasionally very sensitive to spatial position and variations in scale, in which cases incorrect measurements occur.  We find that the primary cause for this instability is the existence of singularities in phase signals.  With the aid of the local frequency of the filter output (provided by the phase derivative) and the local amplitude information, the regions of phase instability near the singularities are detected so that potentially incorrect measurements can be identified.  In addition, we show how the local frequency can be used away from the singularity neighbourhoods to improve the accuracy of the disparity estimates.  Some experimental results are reported. 
Computational Perception of Scene Dynamics| Abstract.  Understanding observations of interacting objects requires one to reason about qualitative scene dynamics.  For example, on observing a hand lifting a can, we may infer that an `active' hand is applying an upwards force (by grasping) to lift a `passive' can.  We present an implemented computational theory that derives such dynamic descriptions directly from camera input.  Our approach is based on an analysis of the Newtonian mechanics of a simplified scene model.  Interpretations are expressed in terms of assertions about the kinematic and dynamic properties of the scene.  The feasibility of interpretations can be determined relative to Newtonian mechanics by a reduction to linear programming.  Finally, to select plausible interpretations, multiple feasible solutions are compared using a preference hierarchy.  We provide computational examples to demonstrate that our model is sufficiently rich to describe a wide variety of image sequences. 
Recovery of Egomotion and Segmentation of Independent Object Motion Using the EM Algorithm| Abstract This paper examines the use of the EM algorithm to perform motion segmentation on image sequences that contain independent object motion.  The input data are linear constraints on 3-D translational motion and bilinear constraints on 3-D translation and rotation, derived from computed optical flow using subspace methods.  The problems of outlier detection, deciding how many processes, and the initial guesses for the EM algorithm are considered.  Results obtained from an image sequence are presented. 
Hierarchical Eigensolver for Transition Matrices in Spectral Methods| Abstract We show how to build hierarchical, reduced-rank representation for large stochastic matrices and use this representation to design an efficient algorithm for computing the largest eigenvalues, and the corresponding eigenvectors.  In particular, the eigen problem is first solved at the coarsest level of the representation.  The approximate eigen solution is then interpolated over successive levels of the hierarchy.  A small number of power iterations are employed at each stage to correct the eigen solution.  The typical speedups obtained by a Matlab implementation of our fast eigensolver over a standard sparse matrix eigensolver [13] are at least a factor of ten for large image sizes.  The hierarchical representation has proven to be effective in a min-cut based segmentation algorithm that we proposed recently [8]. 
Recognizing Temporal Trajectories Using the Condensation Algorithm| Abstract The recognition of human gestures in image sequences is an importantand challengingproblem that enables a host of human-computer interaction applications.  This paper describes an incremental recognition strategy that is an extension of the "Condensation" algorithm proposed by Isard and Blake (ECCV'96).  Gestures are modeled as temporal trajectories of some estimated parameter over time (in this case velocity).  The condensation algorithm is used to incrementally match the gesture models to the inputdata.  The method is demonstrated with an example of an augmented office whiteboard in which a user makes simple hand gestures to grab regions of the board, print them, save them, etc. 
Detecting Floor Anomalies| Abstract When a robot moves about a 2D world such as a planar surface, it is important that obstacles to the robot's motions be detected.  This classical problem of "obstacle detection" has proven to be difficult.  Many researchers have formulated this problem as being the process of determining where a robot cannot move due to the presence of obstacles.  An alternative approach presented here is to determine where an robot can go by identifying floor regions for which the planar floor assumption can be verified.  A stereo vision system is developed for Floor Anomaly Detection (FAD), and its relationship to existing stereo obstacle detection algorithms is described. 
Robust Contrast-Invariant EigenDetection| Abstract We achieve two goals in this paper: (1) to build a novel appearance-based object representation that takes into account variations in contrast often found in training images; (2) to develop a robust appearance-based detection scheme that can handle outliers such as occlusion and structured noise.  To build the representation, we decompose the input ensemble into two subspaces: a principal subspace (within-subspace) and its orthogonal complement (out--of--subspace).  Before computing the principal subspace, we remove any dependency on contrast that the training set might exhibit.  To account for pixel outliers in test images, we model the residual signal in the out-of-subspace by a probabilistic mixture model of an inlier distribution and a uniform outlier distribution.  The mixture model, in turn, facilitates the robust estimation of the within-subspace coefficients.  We show our methodology leads to an effective classifier for separating images of eyes from non-eyes extracted from the FERET dataset. 
Detection and Classification of Motion Boundaries| Abstract We segment the trajectory of a moving object into piecewise smooth motion intervals separated by motion
Object Recognition Using Flexible Groups of Local Features| Abstract.  We propose a new object recognition system based on local features
Linear Subspace Methods for Recovering Translational Direction| Abstract The image motion field for an observer moving through a static environment depends on the observer's translational and rotational velocities along with the distances to surface points.  Given such a motion field as input we have recently introduced subspace methods for the recovery of the observer's motion and the depth structure of the scene.  This class of methods involve splitting the equations describing the motion field into separate equations for the observer's translational direction, the rotational velocity, and the relative depths.  The resulting equations can then be solved successively, beginning with the equations for the translational direction.  Here we concentrate on this first step.  In earlier work, a linear method was shown to provide a biased estimate of the translational direction.  We discuss the source of this bias and show how it can be effectively removed.  The consequence is that the observer's velocity and the relative depths to points in the scene can all be recovered by successively solving three linear problems. 
Skin and Bones: Multi-layer, Locally Affine, Optical Flow and Regularization with Transparency| Abstract This paper describes a new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models.  An affine model of image motion is used within local image patches while a spatial smoothness constraint on the affine flow parameters of neighboring patches enforces continuity of the motion.  We refer to this as a "Skin and Bones" model in which the affine patches can be thought of as rigid "bones" connected by a flexible "skin".  Since local image patches may contain multiple motions we use a layered representation for the affine bones.  To regularize this layered motion representation we develop a new framework for regularization with transparency. 
Learning Parameterized Models of Image Motion| Abstract A framework for learning parameterized models of optical flow from image sequences is presented.  A class of motions is represented by a set of orthogonal basis flow fields that are computed from a training set using principal component analysis.  Many complex image motions can be represented by a linear combination of a small number of these basis flows.  The learned motion models may be used for opticalflow estimationand for model-based recognition.  For optical flow estimation we describe a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives.  As examples we consider learning motion discontinuities, non-rigid motion of human mouths, and articulated human motion. 
Motion Feature Detection Using Steerable Flow Fields| Abstract The estimation and detection of occlusion boundaries and moving bars are important and challenging problems in image sequence analysis.  Here, we model such motion features as linear combinations of steerable basis flow fields.  These models constrain the interpretation of image motion, and are used in the same way as translational or affine motion models.  We estimate the subspace coefficients of the motion feature models directly from spatiotemporal image derivatives using a robust regression method.  From the subspace coefficients we detect the presence of a motion feature and solve for the orientation of the feature and the relative velocities of the surfaces.  Our method does not require the prior computation of optical flow and recovers accurate estimates of orientation and velocity. 
3-D Motion Estimation Using Linear and Bilinear Constraints| Abstract This paper examines the use of the EM algorithm to perform motion segmentation on image sequences that contain independent object motion.  The input data are linear constraints on 3-D translational motion and bilinear
Qualitative Probabilities for Image Interpretation| Abstract Two basic problems in image interpretation are: a) determining which interpretations are the most plausible amoungst many possibilities; and b) controlling the search for plausible interpretations.  We address these issues using a Bayesian approach, with the plausibility ordering and search pruning based on the posterior probabilities of interpretations.  However, due to the need for detailed quantitative prior probabilities and the need to evaluate complex integrals over various conditional distributions, a full Bayesian approach is currently impractical except in tightly constrained domains.  To circumvent these difficulties we introduce the notion of qualitative probabilistic analysis.  In particular, given spatial and contrast resolution parameters, we consider only the asymptotic order of the posterior probability for any interpretation as these resolutions are made finer.  We introduce this approach for a simple card-world domain, and present computational results for blocks-world images. 
Non-accidental Features in Learning \Lambda| Abstract We consider the application of symbolic learning in natural domains.  Given a conceptualization of the domain in terms of a particular set of predicates, we consider how knowledge about the domain can constrain learning.  In particular, by specifying a set of predicates which are not allowed to vary within a category we restrict the set of possible categories.  We suggest that such constraints arise naturally in perception if we distinguish the set of "singular" predicates which describe degenerate configurations of the features (measure-zero events).  This is related to the notion of non-accidental features in vision.  We illustrate the approach by categorizing motion sequences in a simplified visual domain. 
Highlight Identification Using Chromatic Information|
EigenTracking: Robust Matching and Tracking of Articulated Objects Using a View-Based Representation|
Computation of component image velocity from local phase information|
A fast subspace algorithm for recovering rigid motion|
Estimating image motion in layers: the "skin and bones" model|
Linear subspace methods for recovering rigid motion|
Estimating Optical Flow in Segmented Images Using Variable-Order Parametric Models With Local Deformations|
Techniques for disparity measurement|
Multi-scale Phase-based Local Features|
Steady state and periodic solution paths: their bifurcations and computations|
Singular points and their computation|
Eigencuts: Half-lives of eigenflows for spectral clustering|
Visual perception of three-dimensional motion|
A spatio-temporal model for early visual processing|
Robust matching and tracking of articulated objects using a view-based representation|
Hierarchical Construction of Orientation and Velocity Selective Filters|
From [R, G, B] to Surface Reflectance: Computing Color Constant Descriptors in Images|
Ambient illumination and the determination of material changes|
Priors, preferences and categorical percepts|
The Fast Computation of Disparity from Phase Differences,|
A biased view of perceivers|
Design and Use of Linear Models for Image Motion Analysis|
Modal structure and reliable inference|
Skin and Bones: Multilayer, Locally Affine,|
Robust online appearance model for visual tracking,|
Scale-Space Singularities|
Phase-Based Local Features|
The Effects of Ambient Illumination on the Structure of Shadows in Chromatic Images|
Simple method for computing 3D motion and depth,|
On the hierarchical construction of orientation and velocity selective filters,"|
Sparse PCA: Extracting Multi-scale Structure from Data|
An solver for matrices with banded, multi-value structure that uses Gaussian elimination with column pivoting|
Phase-base disparity measurement|
Robust, on-line appearance models for vision tracking|
Priors, preferences and categorial percepts|
Subspace methods for recovering rigid motion II: Theory," University of Toronto|
Robust online appereance models for visual tracking,|
On a reduction process for nonlinear equations|
Wsl: Robust online appearance models for visual tracking|
Controlling the search for convex groups|
Robust Online Appearance Models for Visual Tracking,"pp| 415-422. 
Determination of Egomotion and Environmental Layout from Noisy Time-Varying Image Velocity in Binocular Image Sequences|
Binocular motion and structure from monocular motion and structure|
"EigenTracking: Robust Matching and Tracking of Articulated Objects Using Frame 1, 5, 9 of the moving car sequence Output from the trackerfor|
The numerical solution of nonlinear equations having several parameters, I: Scalar equations|
Numerical opf Bifurcation|
Recovering observer translation with center-surround operators,"|
The computation of color constant descriptors in chromatic images|
Flexible Spatial Models for Grouping Local Image Features|
Spatiotemporal inseparability in early visual processing",|
A cascaded filter approach to the construction of velocity selective mechanisms|
Folds in solutions of two parameter systems and their calculation, part i,|
The numerical calculation of cusps, bifurcation points and isola formation points in two parameter problems|
Non-linearly Embedded Visual Tracking|
Phase-49223 disparity measurement|
in press) Comparing stories: Commentary on `Experiencing and Perceiving visual surfaces,'|
