Scalable Kernel Systems| Abstract.  Kernel-based systems are currently very popular approaches to supervised learning.  Unfortunately, the computational load for training kernel-based systems increases drastically with the number of training data points.  Recently, a number of approximate methods for scaling kernel-based systems to large data sets have been introduced.  In this paper we investigate the relationship between three of those approaches and compare their performances experimentally. 
Hierarchical Bayesian Modelling with Gaussian Processes| Abstract We present a novel method for Gaussian process regression in a hierarchical Bayesian framework.  The method is suited for cases where data from separate, but related problem scenarios is available.  In the hierarchical framework, kernel matrices on a fixed set of input points (transduction) can be learned from data using a simple and efficient EM algorithm.  This does not require a parametric form for the kernel function, thus problems that require, for example, nonstationary kernels, can be handled.  We evaluate our approach as a recommendation engine for art images, where the proposed hierarchical Bayesian method leads to excellent prediction performance. 
The Bayesian Committee Support Vector Machine| Abstract.  Empirical evidence indicates that the training time for the support vector machine (SVM) scales to the square of the number of training data points.  In this paper, we introduce the Bayesian committee support vector machine (BC-SVM) and achieve an algorithm for training the SVM which scales linearly in the number of training data points.  We verify the good performance of the BC-SVM using several data sets. 
Observations on the Nystrom Method for Gaussian Process Prediction| Abstract A number of methods for speeding up Gaussian Process (GP) prediction have been proposed, including the Nystrom method of Williams and Seeger (2001).  In this paper we focus on two issues (1) the relationship of the Nystrom method to the Subset of Regressors method (Poggio and Girosi, 1990; Luo and Wahba, 1997) and (2) understanding in what circumstances the Nystrom approximation would be expected to provide a good approximation to exact GP regression. 
Local Factorization of Functions| Abstract This paper is concerned with the notion of a local factorization of a function where we are mostly interested in the special case that this function is a probability distribution.  We introduce the notions of local independence and of the local Kullback-Leibler divergence.  We introduce a specific approximate local factorization.  The number of terms required in the approximation is linear in the number of input dimensions and the approximation does not require the calculation of higher derivatives (as in a Taylor expansion) and is not limited to approximations near the mode of a function.  We provide examples where we believe the approximation might be useful as in the approximate calculation of certain integrals. 
Transductive and Inductive Methods for Approximate Gaussian Process Regression| Abstract Gaussian process regression allows a simple analytical treatment of exact Bayesian inference and has been found to provide good performance, yet scales badly with the number of training data.  In this paper we compare experimentally three of the leading approaches towards scaling Gaussian processes regression to large data sets: the subset of representers method, the reduced rank approximation, and the Bayesian committee machine.  Furthermore we provide theoretical insight into some of our experimental results.  We found that subset of representers methods can give good and particularly fast predictions for data sets with high and medium noise levels.  On low noise data sets, the Bayesian committee machine achieves significantly better accuracy, yet at a higher computational cost for large test data sets. 
GPPS: A Gaussian Process Positioning System for Cellular Networks| Abstract In this article, we present a novel approach to solving the localization problem in cellular networks.  The goal is to estimate a mobile user's position, based on measurements of the signal strengths received from network base stations.  Our solution works by building Gaussian process models for the distribution of signal strengths, as obtained in a series of calibration measurements.  In the localization stage, the user's position can be estimated by maximizing the likelihood of received signal strengths with respect to the position.  We investigate the accuracy of the proposed approach on data obtained within a large indoor cellular network. 
Removing redundancy and inconsistency in memory-based collaborative filtering|
Probabilistic Memory-Based Collaborative Filtering|
