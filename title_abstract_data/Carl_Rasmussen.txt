Gaussian Process Priors with Uncertain Inputs - Application to Multiple-Step Ahead Time Series Forecasting| Abstract We consider the problem of multi-step ahead prediction in time series analysis using the non-parametric Gaussian process model.  k-step ahead forecasting of a discrete-time non-linear dynamic system can be performed by doing repeated one-step ahead predictions.  For a state-space model of the form y t = f(y
Gaussian Process Model Based Predictive Control| Abstract--- Gaussian process models provide a probabilistic non-parametric modelling approach for black-box identification of non-linear dynamic systems.  The Gaussian processes can highlight areas of the input space where prediction quality is poor, due to the lack of data or its complexity, by indicating the higher variance around the predicted mean.  Gaussian process models contain noticeably less coefficients to be optimised.  This paper illustrates possible application of Gaussian process models within model-based predictive control.  The extra information provided within Gaussian process model is used in predictive control, where optimisation of control signal takes the variance information into account.  The predictive control principle is demonstrated on control of pH process benchmark. 
Draft, accepted for presentation at NIPS 2001 Infinite Mixtures of Gaussian Process Experts| Abstract We present an extension to the Mixture of Experts (ME) model, where the individual experts are Gaussian Process (GP) regression models.  Using a input dependent adaptation of the Dirichlet Process, we implement a gating network for an infinite number of Experts.  Inference in this model may be done efficiently using a Markov Chain relying on Gibbs sampling.  The model allows the effective covariance function to vary with the inputs, and may handle large datasets -- thus potentially overcoming two of the biggest hurdles with GP models.  Simulations show the viability of this approach. 
Bayesian Monte Carlo| Abstract We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals.  Bayesian Monte Carlo (BMC) allows the incorporation of prior knowledge, such as smoothness of the integrand, into the estimation.  In a simple problem we show that this outperforms any classical importance sampling method.  We also attempt more challenging multidimensional integrals involved in computing marginal likelihoods of statistical models (a. k. a.  partition functions and model evidences). 
Gaussian Processes for Regression| Abstract The Bayesian analysis of neural networks is difficult because a simple prior over weights implies a complex prior distribution over functions.  In this paper we investigate the use of Gaussian process priors over functions, which permit the predictive Bayesian analysis for fixed values of hyperparameters to be carried out exactly using matrix operations.  Two methods, using optimization and averaging (via Hybrid Monte Carlo) over hyperparameters have been tested on a number of challenging problems and have produced excellent results. 
A Practical Monte Carlo Implementation of Bayesian Learning| Abstract A practical method for Bayesian training of feed-forward neural networks using sophisticated Monte Carlo methods is presented and evaluated.  In reasonably small amounts of computer time this approach outperforms other state-of-the-art methods on 5 datalimited tasks from real world domains. 
Draft version; accepted for NIPS*03 Warped Gaussian Processes| Abstract We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs.  This allows for non-Gaussian processes and non-Gaussian noise.  The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP.  This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step.  We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation. 
Gaussian Processes to Speed up Hybrid Monte Carlo for Expensive Bayesian Integrals| SUMMARY Hybrid Monte Carlo (HMC) is often the method of choice for computing Bayesian integrals that are not analytically tractable.  However the success of this method may require a very large number of evaluations of the (un-normalized) posterior and its partial derivatives.  In situations where the posterior is computationally costly to evaluate, this may lead to unacceptable computational load for HMC.  I propose to use a Gaussian Process model of the (log of the) posterior for most of the computations required by HMC.  Within this scheme only occasional evaluation of the actual posterior is required to guarantee that the samples generated have exactly the desired distribution, even if the GP model is somewhat inaccurate.  The method is demonstrated on a 10 dimensional problem, where 200 evaluations suce for the generation of 100 roughly independent points from the posterior.  Thus, the proposed scheme allows Bayesian treatment of models with posteriors that are computationally demanding, such as models involving computer simulation. 
Prediction on Spike Data Using Kernel Algorithms| Abstract We report and compare the performance of different learning algorithms based on data from cortical recordings.  The task is to predict the orientation of visual stimuli from the activity of a population of simultaneously recorded neurons.  We compare several ways of improving the coding of the input (i. e. , the spike data) as well as of the output (i. e. , the orientation), and report the results obtained using different kernel algorithms. 
The Infinite Gaussian Mixture Model| Abstract In a Bayesian mixture model it is not necessary a priori to limit the number of components to be finite.  In this paper an infinite Gaussian mixture model is presented which neatly sidesteps the difficult problem of finding the "right" number of mixture components.  Inference in the model is done using an efficient parameter-free Markov Chain that relies entirely on Gibbs sampling. 
Infinite Mixtures of Gaussian Process Experts| Abstract We present an extension to the Mixture of Experts (ME) model, where the individual experts are Gaussian Process (GP) regression models.  Using an input-dependent adaptation of the Dirichlet Process, we implement a gating network for an infinite number of Experts.  Inference in this model may be done efficiently using a Markov Chain relying on Gibbs sampling.  The model allows the effective covariance function to vary with the inputs, and may handle large datasets -- thus potentially overcoming two of the biggest hurdles with GP models.  Simulations show the viability of this approach. 
Bayesian Learning in Feed Forward Neural Networks| Abstract Bayesian methods are applicable to complex modeling tasks.  In this review, the principles of Bayesian inference are presented and applied to neural network models.  Several approximate implementations are discussed, and their advantages over conventional frequentist model training and selection are outlined.  It is argued that Bayesian methods are preferable to traditional approaches, although empirical evidence for this is still sparse. 
A version| Abstract We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals.  Bayesian Monte Carlo (BMC) allows the incorporation of prior knowledge, such as smoothness of the integrand, into the estimation.  In a simple problem we show that this outperforms any classical importance sampling method.  We also attempt more challenging multidimensional integrals involved in computing marginal likelihoods of statistical models (a. k. a.  partition functions and model evidences). 
Bayesian modelling of fMRI time series| Abstract We present a Hidden Markov Model (HMM) for inferring the hidden psychological state (or neural activity) during single trial fMRI activation experiments with blocked task paradigms.  Inference is based on Bayesian methodology, using a combination of analytical and a variety of Markov Chain Monte Carlo (MCMC) sampling techniques.  The advantage of this method is that detection of short time learning effects between repeated trials is possible since inference is based only on single trial experiments. 
The Infinite Hidden Markov Model| Abstract We show that it is possible to extend hidden Markov models to have a countably infinite number of hidden states.  By using the theory of Dirichlet processes we can implicitly integrate out the infinitely many transition parameters, leaving only three hyperparameters which can be learned from data.  These three hyperparameters define a hierarchical Dirichlet process capable of capturing a rich set of transition dynamics.  The three hyperparameters control the time scale of the dynamics, the sparsity of the underlying state-transition matrix, and the expected number of distinct hidden states in a finite sequence.  In this framework it is also natural to allow the alphabet of emitted symbols to be infinite--consider, for example, symbols being possible words appearing in English text. 
PROPAGATION OF UNCERTAINTY IN BAYESIAN KERNEL MODELS --- APPLICATION TO MULTIPLE-STEP AHEAD FORECASTING| ABSTRACT The object of Bayesian modelling is the predictive distribution, which in a forecasting scenario enables evaluation of forecasted values and their uncertainties.  In this paper we focus on reliably estimating the predictive mean and variance of forecasted values using Bayesian kernel based models such as the Gaussian Process and the Relevance Vector Machine.  We derive novel analytic expressions for the predictive mean and variance for Gaussian kernel shapes under the assumption of a Gaussian input distribution in the static case, and of a recursive Gaussian predictive density in iterative forecasting.  The capability of the method is demonstrated for forecasting of time-series and compared to approximate methods. 
Observations on the Nystrom Method for Gaussian Process Prediction| Abstract A number of methods for speeding up Gaussian Process (GP) prediction have been proposed, including the Nystrom method of Williams and Seeger (2001).  In this paper we focus on two issues (1) the relationship of the Nystrom method to the Subset of Regressors method (Poggio and Girosi, 1990; Luo and Wahba, 1997) and (2) understanding in what circumstances the Nystrom approximation would be expected to provide a good approximation to exact GP regression. 
Gaussian Process priors with Uncertain Inputs: Multiple-Step-Ahead Prediction| Abstract We consider the problem of multi-step ahead prediction in time series analysis using the non-parametric Gaussian process model.  k-step ahead forecasting of a discrete-time nonlinear dynamic system can be performed by doing repeated one-step ahead predictions.  For a state-space model of the form y t = f(y t- 1 ,. . . ,y t- L ), the prediction of y at time t + k is based on the estimates ^ y t+k - 1 ,. . . ,^y t+k - L of the previous outputs.  We show how, using an analytical Gaussian approximation, we can formally incorporate the uncertainty about intermediate regressor values, thus updating the uncertainty on the current prediction.  In this framework, the problem is that of predicting responses at a random input and we compare the Gaussian approximation to the Monte-Carlo numerical approximation of the predictive distribution.  The approach is illustrated on a simulated non-linear dynamic example, as well as on a simple one-dimensional static example. 
ADAPTIVE, CAUTIOUS, PREDICTIVE CONTROL WITH GAUSSIAN PROCESS PRIORS| to implement a nonlinear adaptive control law.  Predictions, including propagation of the state uncertainty are made over a k-step horizon.  The expected value of a quadratic cost function is minimised, over this prediction horizon, without ignoring the variance of the model predictions.  The general method and its main features are illustrated on a simulation example. 
Warped Gaussian Processes| Abstract We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs.  This allows for non-Gaussian processes and non-Gaussian noise.  The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP.  This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step.  We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation. 
Occam's Razor| Abstract The Bayesian paradigm apparently only sometimes gives rise to Occam's Razor; at other times very large models perform well.  We give simple examples of both kinds of behaviour.  The two views are reconciled when measuring complexity of functions, rather than of the machinery used to implement them.  We analyze the complexity of functions for some linear in the parameter models that are equivalent to Gaussian Processes, and always find Occam's Razor at work. 
Pruning from Adaptive Regularization| Abstract Inspired by the recent upsurge of interest in Bayesian methods we consider adaptive regularization.  A generalization based scheme for adaptation of regularization parameters is introduced and compared to Bayesian regularization.  We show that pruning arises naturally within both adaptive regularization schemes.  As model example we have chosen the simplest possible: estimating the mean of a random variable with known variance.  Marked similarities are found between the two methods in that they both involve a "noise limit", below which they regularize with infinite weight decay, i. e. , they prune.  However, pruning is not always beneficial.  We show explicitly that both methods in some cases may increase the generalization error.  This corresponds to situations where the underlying assumptions of the regularizer are poorly matched to the environment. 
Gaussian Processes in Reinforcement Learning| Abstract We exploit some useful properties of Gaussian process (GP) regression models for reinforcement learning in continuous state spaces and discrete time.  We demonstrate how the GP model allows evaluation of the value function in closed form.  The resulting policy iteration algorithm is demonstrated on a simple problem with a two dimensional state space.  Further, we speculate that the intrinsic ability of GP models to characterise distributions of functions would allow the method to capture entire distributions over future values instead of merely their expectation, which has traditionally been the focus of much of reinforcement learning. 
The Infinite Gaussian Mixture Model|
Gaussian Proceses for Regression,|
Smith, "Gaussian process with uncertain input application to multiple-step ahead time-series forecasting,"|
Evaluation of Gaussian Processes and other Methods for Non-Linear Regression|
Learning Depth from Stereo|
Decay of equatorial ring current ions and associated aeronomical consequences,|
