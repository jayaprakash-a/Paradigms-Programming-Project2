Infinite Latent Feature Models and the Indian Buffet Process| Abstract We define a probability distribution over equivalence classes of binary matrices with a finite number of rows and an unbounded number of columns.  This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features.  We identify a simple generative process that results in the same distribution over equivalence classes, which we call the Indian buffet process.  We illustrate the use of this distribution as a prior in an infinite latent feature model, deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset. 
A Bayesian approach to reconstructing genetic regulatory networks with hidden factors| ABSTRACT Motivation: We have used state-space models (
Learning from incomplete data| Abstract Real-world learning tasks often involve high-dimensional data sets with complex patterns of missing features.  In this paper we review the problem of learning from incomplete data from two statistical perspectives---the likelihood-based and the Bayesian.  The goal is two-fold: to place current neural network approaches to missing data within a statistical framework, and to describe a set of algorithms, derived from the likelihood-based framework, that handle clustering, classification, and function approximation from incomplete data in a principled and efficient manner.  These algorithms are based on mixture modeling and make two distinct appeals to the Expectation-Maximization (EM) principle (Dempster et al. 
1| Multilayer networks of linear-Gaussian units. 
An Introduction to Hidden Markov Models and Bayesian Networks| Abstract We provide a tutorial on learning and inference in hidden Markov models in the context of
Scaling in a Hierarchical Unsupervised Network| Increasing the image size leads to faster and more reliable learning; (2) Increasing the depth of the network from one to two hidden layers leads to better representations at the first hidden layer, and (3) Once one part of the network has discovered how to represent disparity, it "supervises" other parts of the network, greatly speeding up their learning. 
Optimization with EM and Expectation-Conjugate-Gradient| Abstract We show a close relationship between the Expectation - Maximization (EM) algorithm and direct optimization algorithms such as gradient-based methods for parameter learning.  We identify analytic conditions under which EM exhibits Quasi-Newton behavior, and conditions under which it possesses poor, first-order convergence.  Based on this analysis, we propose two novel algorithms for maximum likelihood estimation of latent variable models, and report empirical results showing that, as predicted by the theory, the proposed new algorithms can substantially outperform standard EM in terms of speed of convergence in certain cases. 
Draft, accepted for presentation at NIPS 2001 Infinite Mixtures of Gaussian Process Experts| Abstract We present an extension to the Mixture of Experts (ME) model, where the individual experts are Gaussian Process (GP) regression models.  Using a input dependent adaptation of the Dirichlet Process, we implement a gating network for an infinite number of Experts.  Inference in this model may be done efficiently using a Markov Chain relying on Gibbs sampling.  The model allows the effective covariance function to vary with the inputs, and may handle large datasets -- thus potentially overcoming two of the biggest hurdles with GP models.  Simulations show the viability of this approach. 
MIT Press 2002 Products of Gaussians| Abstract Recently Hinton (1999) has introduced the Products of Experts (PoE) model in which several individual probabilistic models for data are combined to provide an overall model of the data.  Below we consider PoE models in which each expert is a Gaussian.  Although the product of Gaussians is also a Gaussian, if each Gaussian has a simple structure the product can have a richer structure.  We examine (1) Products of Gaussian pancakes which give rise to probabilistic Minor Components Analysis, (2) products of 1-factor PPCA models and (3) a products of experts construction for an AR(1) process.  Recently Hinton (1999) has introduced the Products of Experts (PoE) model in which several individual probabilistic models for data are combined to provide an overall model of the data.  In this paper we consider PoE models in which each expert is a Gaussian.  It is easy to see that in this case the product model will also be Gaussian.  However, if each Gaussian has a simple structure, the product can have a richer structure.  Using Gaussian experts is attractive as it permits a thorough analysis of the product architecture, which can be dicult with other models, e. g.  models defined over discrete random variables.  Below we examine three cases of the products of Gaussians construction: (1) Products of Gaussian pancakes (PoGP) which give rise to probabilistic Minor Components Analysis (MCA), providing a complementary result to probabilistic Principal Components Analysis (PPCA) obtained by Tipping and Bishop (1999); (2) Products of 1-factor PPCA models; (3) A products of experts construction for an AR(1) process.  Products of Gaussians If each expert is a Gaussian p i (xj# i ) # N(# i ; C i ), the resulting distribution of the product of m Gaussians may be expressed as p(xj#) / exp ( 1 2 m X i=1 (x # i ) T C 1 i (x # i ) ) : By completing the square in the exponent it may be easily shown that p(xj#) # N(## ; C# ), where C 1 # = P m i=1 C 1 i .  To simplify the following derivations we will assume that p i (xj# i ) # N(0; C i ) and thus that p(xj#) # N(0; C# ).  fiff 6= 0 can be obtained by translation of the coordinate system. 
Bayesian Monte Carlo| Abstract We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals.  Bayesian Monte Carlo (BMC) allows the incorporation of prior knowledge, such as smoothness of the integrand, into the estimation.  In a simple problem we show that this outperforms any classical importance sampling method.  We also attempt more challenging multidimensional integrals involved in computing marginal likelihoods of statistical models (a. k. a.  partition functions and model evidences). 
Hierarchical Non-linear Factor Analysis and Topographic Maps| Abstract We first describe a hierarchical, generative model that can be viewed as a non-linear generalization of factor analysis and can be implemented in a neural network.  The model performs perceptual inference in a probabilistically consistent manner by using top-down, bottom-up and lateral connections.  These connections can be learned using simple rules that require only locally available information.  We then show how to incorporate non-adaptive lateral connections into the generative model.  The model extracts a sparse, distributed, hierarchical representation of depth from simplified random-dot stereograms and the localized disparity detectors in the first hidden layer form a topographic map. 
The EM Algorithm for Mixtures of Factor Analyzers| Abstract Factor analysis, a statistical method for modeling the covariance structure of high dimensional data using a small number of latent variables, can be extended by allowing different local factor models in different regions of the input space.  This results in a model which concurrently performs clustering and dimensionality reduction, and can be thought of as a reduced dimension mixture of Gaussians.  We present an exact Expectation--Maximization algorithm for fitting the parameters of this mixture of factor analyzers. 
Bayesian Classifier Combination| Abstract Bayesian model averaging linearly mixes the probabilistic predictions of multiple models, each weighted by its posterior probability.  This is the coherent Bayesian way of combining multiple models only under very restrictive assumptions, which we outline.  We explore a general framework for Bayesian model combination (which differs from model averaging) in the context of classification.  This framework explicitly models the relationship between each model's output and the unknown true label.  The framework does not require that the models be probabilistic (they can even be human assessors), that they share prior information or receive the same training data, or that they be independent in their errors.  Finally, the Bayesian combiner does not need to believe any of the models is in fact correct.  We test several variants of this classifier combination procedure starting from a classic statistical model proposed by [1] and using MCMC to add more complex but important features to the model.  Comparisons on several datasets to simpler methods like majority voting show that the Bayesian methods not only perform well but result in interpretable diagnostics on the data points and the models. 
Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning| Abstract We present an algorithm based on convex optimization for constructing kernels for semi-supervised learning.  The kernel matrices are derived from the spectral decomposition of graph Laplacians, and combine labeled and unlabeled data in a systematic fashion.  Unlike previous work using diffusion kernels and Gaussian random field kernels, a nonparametric kernel approach is presented that incorporates order constraints during optimization.  This results in flexible kernels and avoids the need to choose among different parametric forms.  Our approach relies on a quadratically constrained quadratic program (QCQP), and is computationally feasible for large datasets.  We evaluate the kernels on real datasets using support vector machines, with encouraging results. 
A Unifying Review of Linear Gaussian Models| nonlinearity.  Through the use of other nonlinearities we show how independent component analysis (ICA) is also a variation of the same basic generative model.  We show that factor analysis and mixtures of Gaussians can be implemented in autoencoder neural networks and learned using squared error plus the same regularization term.  We introduce a new model for static data known as sensible principal component analysis (SPCA) as well as a novel concept of spatially adaptive observation noise.  We also review some of the literature involving global and local mixtures of the basic models and provide pseudo-code for inference and learning for all the basic models.  1 A Unifying Review Many common statistical techniques for modeling multidimensional static datasets and multidimensional time series can be seen as variants of one underlying model.  As we will show later in the paper, these include factor analysis (FA), principal component analysis (PCA), mixtures of Gaussian clusters, vector quantization (VQ), independent component analysis models (ICA), Kalman filter models (a. k. a.  linear dynamical systems) and hidden Markov models (HMMs).  The relationships between some of these models has been noted in passing in the recent literature.  For example, Hinton et al.  (1995) note that factor analysis and PCA are closely related and Digalakis et al.  (1993) relate the forward--backward algorithm for HMMs to Kalman filtering.  In this paper we unify many of the disparate observations made by previous authors (Rubin and Thayer, 1982; Delyon, 1993; Digalakis et al. , 1993; Hinton et al. , 1995; Elliott et al. , 1995; Ghahramani and Hinton, 1996a, 1996b, 1997; Hinton and Ghahramani, 1997) and present a review of all these algorithms as instances of a single basic generative model.  This unified view allows us to show some interesting relations between previously disparate algorithms.  For example, factor analysis and mixtures of Gaussians can be implemented using autoencoder neural networks with different nonlinearities but learned using a squared error cost penalized by the same regularization term.  ICA can be seen as a nonlinear version of factor analysis.  The framework also makes it possible to derive a new model for static data which is based on PCA but has a sensible probabilistic interpretation as well as a novel concept of spatially adaptive observation noise.  We also review some of the literature involving global and local mixtures of the basic models and provide pseudocode (in the appendix) for inference and learning for all the basic models.  2 The Basic Model The basic models we will work with are discrete time linear dynamical systems with Gaussian noise.  In such models we assume that the state of the process in question can at any time be summarized by a k-vector of state variables or causes x which we cannot observe directly.  However, the system also produces at each time step an output or observable p-vector y to which we do have access.  The state x is assumed to evolve according to simple first-order Markov dynamics; each output vector y is generated from the current state by a simple linear observation process.  Both the state evolution and the observation processes are corrupted by additive Gaussian noise which is also hidden.  If we work with a continuous valued state variable x, the basic generative model can be written 1 as: x t+1 = Ax t +w t = Ax t +w ffl w ffl s N (0; Q) (1a) y t = Cx t + v t = Cx t + v ffl v ffl s N (0; R) (1b) where A is the k \Theta k state transition matrix and C is the p \Theta k observation, measurement, or generative matrix.  The k-vector w and p-vector v are random variables representing the state evolution and observation noises respectively which are independent of each other and of the values of x and y.  1 All vectors are column vectors.  To denote the transpose of a vector or matrix we use the notation x T .  The determinant of a matrix is denoted by jAj and matrix inversion by A\Gamma 1 .  The symbol s means "distributed according to".  A multivariate normal (Gaussian) distribution with mean and covariance matrix \Sigma is written as N (; \Sigma).  The same Gaussian evaluated at the point z is denoted N (; \Sigma) j z . 
The Variational Bayesian EM Algorithm for Incomplete Data: with Application to Scoring Graphical Model Structures| SUMMARY We present an efficient procedure for estimating the marginal likelihood of probabilistic models with latent variables or incomplete data.  This method constructs and optimises a lower bound on the marginal likelihood using variational calculus, resulting in an iterative algorithm which generalises the EM algorithm by maintaining posterior distributions over both latent variables and parameters.  We define the family of conjugate-exponential models---which includes finite mixtures of exponential family models, factor analysis, hidden Markov models, linear state-space models, and other models of interest---for which this bound on the marginal likelihood can be computed very simply through a modification of the standard EM algorithm.  In particular, we focus on applying these bounds to the problem of scoring discrete directed graphical model structures (Bayesian networks).  Extensive simulations comparing the variational bounds to the usual approach based on the Bayesian Information Criterion (BIC) and to a sampling-based gold standard method known as Annealed Importance Sampling (AIS) show that variational bounds substantially outperform BIC in finding the correct model structure at relatively little computational cost, while approaching the performance of the much more costly AIS procedure.  Using AIS allows us to provide the first serious case study of the tightness of variational bounds.  We also analyse the perfomance of AIS through a variety of criteria, and outline directions in which this work can be extended. 
Draft version; accepted for NIPS*03 Warped Gaussian Processes| Abstract We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs.  This allows for non-Gaussian processes and non-Gaussian noise.  The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP.  This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step.  We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation. 
Active Learning with Statistical Models| Abstract For many types of machine learning algorithms, one can compute the statistically "optimal" way to select training data.  In this paper, we review how optimal data selection techniques have been used with feedforward neural networks.  We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression.  While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate.  Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance. 
Learning Nonlinear Dynamical Systems using an EM Algorithm| Abstract The Expectation--Maximization (EM) algorithm is an iterative procedure for maximum likelihood parameter estimation from data sets with missing or hidden variables [2].  It has been applied to system identification in linear stochastic state-space models, where the state variables are hidden from the observer and both the state and the parameters of the model have to be estimated simultaneously [9].  We present a generalization of the EM algorithm for parameter estimation in nonlinear dynamical systems.  The "expectation" step makes use of Extended Kalman Smoothing to estimate the state, while the "maximization" step re-estimates the parameters using these uncertain state estimates.  In general, the nonlinear maximization step is difficult because it requires integrating out the uncertainty in the states.  However, if Gaussian radial basis function (RBF) approximators are used to model the nonlinearities, the integrals become tractable and the maximization step can be solved via systems of linear equations.  1 Stochastic Nonlinear Dynamical Systems We examine inference and learning in discrete-time dynamical systems with hidden state x t , inputs u t , and outputs y t .  1 The state evolves according to stationary nonlinear dynamics driven by the inputs and by additive noise x t+1 = f(x t ; u t ) + w (1) 1 All lowercase characters (except indices) denote vectors.  Matrices are represented by uppercase characters.  where w is zero-mean Gaussian noise with covariance Q.  2 The outputs are nonlinearly related to the states and inputs by y t = g(x t ; u t ) + v (2) where v is zero-mean Gaussian noise with covariance R.  The vector-valued nonlinearities f and g are assumed to be differentiable, but otherwise arbitrary.  Models of this kind have been examined for decades in various communities.  Most notably, nonlinear state-space models form one of the cornerstones of modern systems and control engineering.  In this paper, we examine these models within the framework of probabilistic graphical models and derive a novel learning algorithm for them based on EM.  With one exception, 3 this is to the best of our knowledge the first paper addressing learning of stochastic nonlinear dynamical systems of the kind we have described within the framework of the EM algorithm.  The classical approach to system identification treats the parameters as hidden variables, and applies the Extended Kalman Filtering algorithm (described in section 2) to the nonlinear system with the state vector augmented by the parameters [5].  4 This approach is inherently on-line, which may be important in certain applications.  Furthermore, it provides an estimate of the covariance of the parameters at each time step.  In contrast, the EM algorithm we present is a batch algorithm and does not attempt to estimate the covariance of the parameters.  There are three important advantages the EM algorithm has over the classical approach.  First, the EM algorithm provides a straightforward and principled method for handing missing inputs or outputs.  Second, EM generalizes readily to more complex models with combinations of discrete and real-valued hidden variables.  For example, one can formulate EM for a mixture of nonlinear dynamical systems.  Third, whereas it is often very difficult to prove or analyze stability within the classical on-line approach, the EM algorithm is always attempting to maximize the likelihood, which acts as a Lyapunov function for stable learning.  In the next sections we will describe the basic components of the learning algorithm.  For the expectation step of the algorithm, we infer the conditional distribution of the hidden states using Extended Kalman Smoothing (section 2).  For the maximization step we first discuss the general case (section 3) and then describe the particular case where the nonlinearities are represented using Gaussian radial basis function (RBF; [6]) networks (section 4).  2 Extended Kalman Smoothing Given a system described by equations (1) and (2), we need to infer the hidden states from a history of observed inputs and outputs.  The quantity at the heart of this inference problem is the conditional density P (x t ju 1 ; : : : ; u T ; y 1 ; : : : ; y T ), for 1 t T , which captures the fact that the system is stochastic and therefore our inferences about x will be uncertain.  2 The Gaussian noise assumption is less restrictive for nonlinear systems than for linear systems since the nonlinearity can be used to generate non-Gaussian state noise.  3 The authors have just become aware that Briegel and Tresp (this volume) have applied EM to essentially the same model.  Briegel and Tresp's method uses multilayer perceptrons (MLP) to approximate the nonlinearities, and requires sampling from the hidden states to fit the MLP.  We use Gaussian radial basis functions (RBFs) to model the nonlinearities, which can be fit analytically without sampling (see section 4). 
Covariance Kernels from Bayesian Generative Models| Abstract We propose the framework of mutual information kernels for learning covariance kernels, as used in Support Vector machines and Gaussian process classifiers, from unlabeled task data using Bayesian techniques.  We describe an implementation of this framework which uses variational Bayesian mixtures of factor analyzers in order to attack classification problems in high-dimensional spaces where labeled data is sparse, but unlabeled data is abundant. 
A graphical model for protein secondary structure prediction| Abstract In this paper, we present a graphical model for protein secondary structure prediction.  This model extends segmental semi-Markov models (SSMM) to exploit multiple sequence alignment profiles which contain information from evolutionarily related sequences.  A novel parameterized model is proposed as the likelihood function for the SSMM to capture the segmental conformation.  By incorporating the information from long range interactions in #-sheets, this model is capable of carrying out inference on contact maps.  The numerical results on benchmark data sets show that incorporating the profiles results in substantial improvements and the generalization performance is promising. 
On Structured Variational Approximations| Abstract The problem of approximating a probability distribution occurs frequently in many areas of applied
Gatsby Technical Report: Propagating Uncertainty in POMDP Value Iteration with Gaussian Processes| Abstract In this paper, we describe the general approach of trying to solve Partially Observable Markov Decision Processes with approximate value iteration.  Methods based on this approach have shown promise for tackling larger problems where exact methods are doomed, but we explain how most of them suffer from the fundamental problem of ignoring information about the uncertainty of their estimates.  We then suggest a new method for value iteration which uses Gaussian processes to form a Bayesian representation of the uncertain POMDP value function.  We evaluate this method on several standard POMDPs and obtain promising results. 
Learning from Labeled and Unlabeled Data with Label Propagation| Abstract We investigate the use of unlabeled data to help labeled data in classification.  We propose a simple iterative algorithm, label propagation, to propagate labels through the dataset along high density areas defined by unlabeled data.  We give the analysis of the algorithm, show its solution, and its connection to several other algorithms.  We also show how to learn parameters by minimum spanning tree heuristic and entropy minimization, and the algorithm's ability to do feature selection.  Experiment results are promising. 
Learning to Parse Images| Abstract We describe a class of probabilistic models that we call credibility networks.  Using parse trees as internal representations of images, credibility networks are able to perform segmentation and recognition simultaneously, removing the need for ad hoc segmentation heuristics.  Promising results in the problem of segmenting handwritten digits were obtained. 
Semi-Supervised Learning: From Gaussian Fields to Gaussian Processes| Abstract We show that the
Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions| Abstract An approach to semi-supervised learning is proposed that is based on a Gaussian random field model.  Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances.  The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation.  The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory.  We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning.  We also propose a method of parameter learning by entropy minimization, and show the algorithm's ability to perform feature selection.  Promising experimental results are presented for synthetic data, digit classification, and text classification tasks. 
Generative Models for Discovering Sparse Distributed Representations| Abstract We describe a hierarchical, generative model that can be viewed as a non-linear generalization of factor analysis and can be implemented in a neural network.  The model uses bottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly.  Once perceptual inference has been performed the connection strengths can be updated using a very simple learning rule that only requires locally available information.  We demonstrate that the network learns to extract sparse, distributed, hierarchical representations. 
Infinite Mixtures of Gaussian Process Experts| Abstract We present an extension to the Mixture of Experts (ME) model, where the individual experts are Gaussian Process (GP) regression models.  Using an input-dependent adaptation of the Dirichlet Process, we implement a gating network for an infinite number of Experts.  Inference in this model may be done efficiently using a Markov Chain relying on Gibbs sampling.  The model allows the effective covariance function to vary with the inputs, and may handle large datasets -- thus potentially overcoming two of the biggest hurdles with GP models.  Simulations show the viability of this approach. 
An Introduction to Variational Methods for Graphical Models| Abstract.  This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields).  We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms.  We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient.  Inference in the simpified model provides bounds on probabilities of interest in the original model.  We describe a general framework for generating variational transformations based on convex duality.  Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case. 
Variational Inference for Bayesian Mixtures of Factor Analysers| Abstract We present an algorithm that infers the model structure of a mixture of factor analysers using an ecient and deterministic variational approximation to full Bayesian integration over model parameters.  This procedure can automatically determine the optimal number of components and the local dimensionality of each component (i. e.  the number of factors in each factor analyser).  Alternatively it can be used to infer posterior distributions over number of components and dimensionalities.  Since all parameters are integrated out the method is not prone to overfitting.  Using a stochastic procedure for adding components it is possible to perform the variational optimisation incrementally and to avoid local maxima.  Results show that the method works very well in practice and correctly infers the number and dimensionality of nontrivial synthetic examples.  By importance sampling from the variational approximation we show how to obtain unbiased estimates of the true evidence, the exact predictive density, and the KL divergence between the variational posterior and the true posterior, not only in this model but for variational approximations in general. 
Gaussian Processes for Ordinal Regression| Abstract We present a probabilistic kernel approach to ordinal regression based on Gaussian processes.  A threshold model that generalizes the probit function is used as the likelihood function for ordinal variables.  Two inference techniques, based on the Laplace approximation and the expectation propagation algorithm respectively, are derived for hyperparameter learning and model selection.  We compare these two Gaussian process approaches with a previous ordinal regression method based on support vector machines on some benchmark and real-world data sets, including applications of ordinal regression to collaborative filtering and gene expression analysis.  Experimental results on these data sets verify the usefulness of our approach. 
Factorial Learning and the EM Algorithm| Abstract Many real world learning problems are best characterized by an interaction of multiple independent causes or factors.  Discovering such causal structure from the data is the focus of this paper.  Based on Zemel and Hinton's cooperative vector quantizer (CVQ) architecture, an unsupervised learning algorithm is derived from the Expectation--Maximization (EM) framework.  Due to the combinatorial nature of the data generation process, the exact E-step is computationally intractable.  Two alternative methods for computing the E-step are proposed: Gibbs sampling and mean-field approximation, and some promising empirical results are presented. 
A version| Abstract We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals.  Bayesian Monte Carlo (BMC) allows the incorporation of prior knowledge, such as smoothness of the integrand, into the estimation.  In a simple problem we show that this outperforms any classical importance sampling method.  We also attempt more challenging multidimensional integrals involved in computing marginal likelihoods of statistical models (a. k. a.  partition functions and model evidences). 
The Variational Kalman Smoother| Abstract In this note we outline the derivation of the variational Kalman smoother, in the context of Bayesian Linear Dynamical Systems.  The smoother is an efficient algorithm for the E-step in the ExpectationMaximisation (EM) algorithm for linear-Gaussian state-space models.  However, inference approximations are required if we hold distributions over parameters.  We derive the E-step updates for the hidden states (the variational smoother), and the M-step updates for the parameter distributions.  We show that inference of the hidden state is tractable for any distribution over parameters, provided the expectations of certain quantities are available, analytically or otherwise. 
Parameter Estimation for Linear Dynamical Systems| Abstract Linear systems have been used extensively in engineering to model and control the behavior of dynamical systems.  In this note, we present the Expectation Maximization (EM) algorithm for estimating the parameters of linear systems (Shumway and Stoffer, 1982).  We also point out the relationship between linear dynamical systems, factor analysis, and hidden Markov models. 
The Infinite Hidden Markov Model| Abstract We show that it is possible to extend hidden Markov models to have a countably infinite number of hidden states.  By using the theory of Dirichlet processes we can implicitly integrate out the infinitely many transition parameters, leaving only three hyperparameters which can be learned from data.  These three hyperparameters define a hierarchical Dirichlet process capable of capturing a rich set of transition dynamics.  The three hyperparameters control the time scale of the dynamics, the sparsity of the underlying state-transition matrix, and the expected number of distinct hidden states in a finite sequence.  In this framework it is also natural to allow the alphabet of emitted symbols to be infinite--consider, for example, symbols being possible words appearing in English text. 
Combining Active Learning and Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions| Abstract Active and semi-supervised learning are important techniques when labeled data are scarce.  We combine the two under a Gaussian random field model.  Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances.  The semi-supervised learning problem is then formulated in terms of a Gaussian random field on this graph, the mean of which is characterized in terms of harmonic functions.  Active learning is performed on top of the semisupervised learning scheme by greedily selecting queries from the unlabeled data to minimize the estimated expected classification error (risk); in the case of Gaussian fields the risk is efficiently computed using matrix methods.  We present experimental results on synthetic data, handwritten digit recognition, and text classification tasks.  The active learning scheme requires a much smaller number of queries to achieve high accuracy compared with random query selection. 
Learning Multiple Related Tasks using Latent Independent Component Analysis| Abstract We propose a probabilistic model based on Independent Component Analysis for learning multiple related tasks.  In our model the task parameters are assumed to be generated from independent sources which account for the relatedness of the tasks.  We use Laplace distributions to model hidden sources which makes it possible to identify the hidden, independent components instead of just modeling correlations.  Furthermore, our model enjoys a sparsity property which makes it both parsimonious and robust.  We also propose efficient algorithms for both empirical Bayes method and point estimation.  Our experimental results on two multi-label text classification data sets show that the proposed approach is promising. 
Are arm trajectories planned in kinematic or dynamic coordinates? An adaptation study| Abstract There are several invariant features of point-to-point human arm movements: trajectories tend to be straight, smooth and have bell-shaped velocity profiles.  One approach to accounting for these data is via optimization theory; a movement is specified implicitly as the optimum of a cost function, e. g.  integrated jerk or torque change.  Optimization models of trajectory planning, as well as models not phrased in the optimization framework, generally fall into two main groups---those specified in kinematic coordinates and those specified in dynamic coordinates.  To distinguish between these two possibilities we have studied the effects of artificial visual feedback on planar two-joint arm movements.  During self-paced point-to-point arm movements the visual feedback of hand position was altered so as to increase the perceived curvature of the movement.  The perturbation was zero at both ends of the movement and reached a maximum at the midpoint of the movement.  Cost functions specified by hand coordinate kinematics predict adaptation to increased curvature so as to reduce the visual curvature, while dynamically specified cost functions predict no adaptation in the underlying trajectory planner, provided the final goal of the movement can still be achieved.  We also studied the effects of reducing the perceived curvature in transverse movements, which are normally slightly curved.  Adaptation should be seen in this condition only if the desired trajectory is both specified in kinematic coordinates and actually curved.  Increasing the perceived curvature of normally straight sagittal movements led to significant (p ! 0:001) corrective adaptation in the curvature of the actual hand movement; the hand movement became curved, thereby reducing the visually perceived curvature.  Increasing the curvature of the normally curved transverse movements produced a significant (p ! 0:01) corrective adaptation; the hand movement became straighter, thereby again reducing the visually perceived curvature.  When the curvature of naturally curved transverse movements was reduced there was no significant adaptation (p ? 0:05).  The results of the curvature increasing study suggest that trajectories are planned in visually-based kinematic coordinates.  The results of the curvature reducing study suggest that the desired trajectory is straight in visual space.  These results are incompatible with purely dynamic-based models such as the minimum torque change model.  We suggest that spatial perception---as mediated by vision---plays a fundamental role in trajectory planning. 
A Bayesian Unsupervised Learning Algorithm that Scales| Abstract A persistent worry with computational models of unsupervised learning is that learning will become more difficult as the
MFDTs: Mean Field Dynamic Trees| Abstract Tree structured belief networks are attractive for image segmentation tasks.  However, networks with fixed architectures are not very suitable as they lead to blocky artefacts, and led to the introduction of Dynamic Trees (DTs) in [6].  The Dynamic Trees architecture provides a prior distribution over tree structures, and in [6] simulated annealing (SA) was used to search for structures with high posterior probability.  In this paper we introduce a mean field approach to inference in DTs.  We find that the mean field method captures the posterior better than just using the maximum a posteriori solution found by SA. 
The EM-EP Algorithm for Gaussian Process Classification| Abstract.  Gaussian process classifiers (GPCs) are fully statistical kernel classification models derived from Gaussian processes for regression.  In GPCs, the probability of belonging to a certain class at an input location is monotonically related to the value of some latent function at that location.  Starting from a prior over this latent function, the data are used to infer both the posterior over the latent function and the values of hyperparameters determining various aspects of the function.  GPCs can also be viewed as graphical models with latent variables.  Based on the work of [1, 2], we present an approximate EM algorithm, the EM-EP algorithm for learning both the latent function and the hyperparameters of a GPC.  The algorithm alternates the following steps until convergence.  In the E-step, given the hyperparameters, a density for the latent variables defining the latent function is computed via the Expectation-Propagation (EP) algorithm [1, 2].  In the M-step, given the density for the latent values, the hyperparameters are selected to maximize a variational lower bound on the marginal likelihood (i. e.  the model evidence).  This algorithm is found to converge in practice and provides an efficient Bayesian framework for learning hyperparameters of the kernel.  We examine the role of various different hyperparameters which model labeling errors, the lengthscales (i. e.  relevances) of different features, and sharpness of the decision boundary.  The added flexibility these provide results in significantly improved performance.  Experimental results on synthetic and real data sets show that the EM-EP algorithm works well, with GPCs giving equal or better performance than support vector machines (SVMs) on all data sets tested. 
Nested sampling for Potts models| Abstract Nested sampling is a new Monte Carlo method by Skilling [1] intended for general Bayesian computation.  Nested sampling provides a robust alternative to annealing-based methods for computing normalizing constants.  It can also generate estimates of other quantities such as posterior expectations.  The key technical requirement is an ability to draw samples uniformly from the prior subject to a constraint on the likelihood.  We demonstrate how this can be achieved for the Potts model, an undirected graphical model. 
Switching State-Space Models| Abstract Weintroduce a statistical model for times series data with nonlinear dynamics which iteratively segments the data into regimes with approximately linear dynamics and learns the parameters of each of those regimes.  This model combines and generalizes two of the most widely used stochastic time series models---the hidden Markov model and the linear dynamical system---and is related to models that are widely used in the control and econometrics literatures.  It can also be derived by extending the mixture of experts neural network model (Jacobs et al. , 1991) to its fully dynamical version, in which both expert and gating networks are recurrent.  Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact Expectation Maximization (EM) alogithm cannot be applied.  However, we presentavariational approximation which maximizes a lower bound on the log likelihood and makes use of both the forward{backward recursions for hidden Markov models and the Kalman filter recursions for linear dynamical systems. 
Perceptual distortion contributes to the curvature of human reaching movements| Abstract Unconstrained point-to-point human arm movements are generally gently curved, a fact which has been used to assess the validity of models of trajectory formation.  In this study we examined the relationship between curvature perception and movement curvature for planar sagittal and transverse arm movements.  We found a significant correlation (p ! 0:0001, n = 16) between the curvature perceived as straight and the curvature of actual arm movements.  We suggest that subjects try to make straight-line movements, but that actual movements are curved because visual perceptual distortion makes the movements appear to be straighter than they really are.  We conclude that perceptual distortion of curvature contributes to the curvature seen in human point-to-point arm movements and that this must be taken into account in the assessment of models of trajectory formation. 
Variational Learning for Switching State-Space Models| Abstract Weintroduce a new statistical model for time series which iteratively segments data into regimes with
Warped Gaussian Processes| Abstract We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs.  This allows for non-Gaussian processes and non-Gaussian noise.  The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP.  This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step.  We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation. 
Simultaneous Mapping and Localization With Sparse Extended Information Filters: Theory and Initial Results| Abstract This paper describes a scalable algorithm for the simultaneous mapping and localization (SLAM) problem.  SLAM is the problem of determining the location of environmental features with a roving robot.  Many of today's popular techniques are based on extended Kalman filters (EKFs), which require update time quadratic in the number of features in the map.  This paper develops the notion of sparse extended information filters (SEIFs), as a new method for solving the SLAM problem.  SEIFs exploit structure inherent in the SLAM problem, representing maps through local, Web-like networks of features.  By doing so, updates can be performed in constant time, irrespective of the number of features in the map.  This paper presents several original constant-time results of SEIFs, and provides simulation results that show the high accuracy of the resulting maps in comparison to the computationally more cumbersome EKF solution. 
Learning Nonlinear Dynamical Systems Using an EM Algorithm| Abstract The Expectation{Maximization (EM) algorithm is an iterativeprocedure for maximum likelihood parameter estimation from data sets with missing or hidden variables [2].  It has been applied to system identification in linear stochastic state-space models, where the state variables are hidden from the observer and both the state and the parameters of the model have to be estimated simultaneously [9].  We present a generalization of the EM algorithm for parameter estimation in nonlinear dynamical systems.  The \expectation" step makes use of Extended Kalman Smoothing to estimate the state, while the \maximization" step re-estimates the parameters using these uncertain state estimates.  In general, the nonlinear maximization step is difficult because it requires integrating out the uncertainty in the states.  However, if Gaussian radial basis function (RBF) approximators are used to model the nonlinearities, the integrals become tractable and the maximization step can be solved via systems of linear equations.  1 Stochastic Nonlinear Dynamical Systems We examine inference and learning in discrete-time dynamical systems with hidden state x t , inputs u t , and outputs y t .  1 The state evolves according to stationary nonlinear dynamics driven by the inputs and by additive noise x t+1 = f(x t ;u t )+w (1) 1 All lowercase characters (except indices) denote vectors.  Matrices are represented by uppercase characters.  where w is zero-mean Gaussian noise with covariance Q.  2 The outputs are nonlinearly related to the states and inputs by y t = g(x t ;u t )+v (2) where v is zero-mean Gaussian noise with covariance R.  The vector-valued nonlinearities f and g are assumed to be differentiable, but otherwise arbitrary.  Models of this kind have been examined for decades in various communities.  Most notably, nonlinear state-space models form one of the cornerstones of modern systems and control engineering.  In this paper, we examine these models within the framework of probabilistic graphical models and deriveanovel learning algorithm for them based on EM.  With one exception, 3 this is to the best of our knowledge the first paper addressing learning of stochastic nonlinear dynamical systems of the kind wehave described within the framework of the EM algorithm.  The classical approach to system identification treats the parameters as hidden variables, and applies the Extended Kalman Filtering algorithm (described in section 2) to the nonlinear system with the state vector augmented by the parameters [5].  4 This approach is inherently on-line, whichmay be important in certain applications.  Furthermore, it provides an estimate of the covariance of the parameters at each time step.  In contrast, the EM algorithm we presentisabatch algorithm and does not attempt to estimate the covariance of the parameters.  There are three important advantages the EM algorithm has over the classical approach.  First, the EM algorithm provides a straightforward and principled method for handing missing inputs or outputs.  Second, EM generalizes readily to more complex models with combinations of discrete and real-valued hidden variables.  For example, one can formulate EM for a mixture of nonlinear dynamical systems.  Third, whereas it is often very difficult to prove or analyze stability within the classical on-line approach, the EM algorithm is always attempting to maximize the likelihood, which acts as a Lyapunov function for stable learning.  In the next sections we will describe the basic components of the learning algorithm.  For the expectation step of the algorithm, we infer the conditional distribution of the hidden states using Extended Kalman Smoothing (section 2).  For the maximization step we#rstdiscuss the general case (section 3) and then describe the particular case where the nonlinearities are represented using Gaussian radial basis function (RBF; [6]) networks (section 4).  2 Extended Kalman Smoothing Given a system described by equations (1) and (2), we need to infer the hidden states from a history of observed inputs and outputs.  The quantity at the heart of this inference problem is the conditional density P (x t ju 1 ;:::;u T ;y 1 ;:::;y T ), for 1 # t # T,which captures the fact that the system is stochastic and therefore our inferences about x will be uncertain.  2 The Gaussian noise assumption is less restrictive for nonlinear systems than for linear systems since the nonlinearity can be used to generate non-Gaussian state noise.  3 The authors have just become aware that Briegel and Tresp (this volume) have applied EM to essentially the same model.  Briegel and Tresp's method uses multilayer perceptrons (MLP) to approximate the nonlinearities, and requires sampling from the hidden states to fit the MLP. We use Gaussian radial basis functions (RBFs) to model the nonlinearities, which can be fit analytically without sampling (see section 4). 
Bayesian Learning in Undirected Graphical Models: Approximate MCMC algorithms| Abstract Bayesian learning in undirected graphical models---computing posterior distributions over parameters and predictive quantities--is exceptionally difficult.  We conjecture that for general undirected models, there are no tractable MCMC (Markov Chain Monte Carlo) schemes giving the correct equilibrium distribution over parameters.  While this intractability, due to the partition function, is familiar to those performing parameter optimisation, Bayesian learning of posterior distributions over undirected model parameters has been unexplored and poses novel challenges.  We propose several approximate MCMC schemes and test on fully observed binary models (Boltzmann machines) for a small coronary heart disease data set and larger artificial systems.  While approximations must perform well on the model, their interaction with the sampling scheme is also important.  Samplers based on variational mean-field approximations generally performed poorly, more advanced methods using loopy propagation, brief sampling and stochastic dynamics lead to acceptable parameter posteriors.  Finally, we demonstrate these techniques on a Markov random field with hidden variables. 
Hidden Markov decision trees \Lambda| Abstract We study a time series model that can be viewed as a decision tree with Markov temporal structure.  The model is intractable for exact calculations, thus we utilize variational approximations.  We consider three different distributions for the approximation: one in which the Markov calculations are performed exactly and the layers of the decision tree are decoupled, one in which the decision tree calculations are performed exactly and the time steps of the Markov chain are decoupled, and one in which a Viterbi-like assumption is made to pick out a single most likely state sequence.  We present simulation results for artificial data and the Bach chorales. 
Occam's Razor| Abstract The Bayesian paradigm apparently only sometimes gives rise to Occam's Razor; at other times very large models perform well.  We give simple examples of both kinds of behaviour.  The two views are reconciled when measuring complexity of functions, rather than of the machinery used to implement them.  We analyze the complexity of functions for some linear in the parameter models that are equivalent to Gaussian Processes, and always find Occam's Razor at work. 
An EM Algorithm for Identification of Nonlinear Dynamical Systems| Abstract| We provide a novel solution to the problem of simultaneously estimating the unknown parameters and hidden states of a nonlinear dynamical system.  Our solution is based on the expectation{maximization (EM) algorithm, an iterative procedure for maximum likelihood parameter estimation from data sets with missing or hidden variables [1].  EM has been applied to system identification in linear statespace models, where the state variables are hidden from the observer and both the state and the parameters of the model have to be estimated simultaneously [2], [3], [4].  Here we generalize the EM algorithm to estimate parameters of nonlinear dynamical state-space models.  The \expectation" step makes use of Extended Kalman Smoothing to estimate the state, while the \maximization" step re-estimates the parameters using these uncertain state estimates.  In general, the nonlinear maximization step is dicult because it requires integrating out the uncertainty in the states.  However, if Gaussian radial basis function (RBF) approximators are used to model the nonlinearities, the integrals become tractable and the maximization step can be solved via systems of linear equations.  We derive an online version of this EM-EKS algorithm, as well as a version for non-stationary time series.  We also consider the identifiability and expressive power of nonlinear dynamical systems and relate our learning algorithm with more traditional system identi#cation procedures based on dual and joint Extended Kalman Filtering.  Finally, we demonstrate our algorithm on several synthetic problems and one real time series.  I.  Learning stochastic nonlinear dynamics S INCE the advent of cybernetics, dynamical systems have been an important modeling tool in fields ranging from engineering to the physical and social sciences.  Most realistic dynamical systems models have two essential features.  First, they are stochastic|the observed outputs are a noisy function of the inputs, and the dynamics itself may be driven by some unobserved noise process.  Second, they can be characterized by some finite-dimensional internal state which, while not directly observable, summarizes at any time all information about the past behaviour of the process relevant to predicting its future evolution.  From a modeling standpoint, stochasticity is essential to allow a model with a few fixed parameters to generate a rich variety of time-series outputs.  1 Explicitly modeling the internal state makes it possible to decouple the internal dynamics from the observation process.  For example, to model a sequence of video images of a balloon floating
Graphical models and variational methods| 1 Abstract We review the use of variational methods of approximating inference and learning in probabilistic graphical models.  In particular, we focus on variational approximations to the integrals required for Bayesian learning.  For models in the conjugate-exponential family, a generalisation of the EM algorithm is derived that iterates between optimising hyperparameters of the distribution over parameters, and inferring the hidden variable distributions.  These approximations make use of available propagation algorithms for probabilistic graphical models.  We give two case studies of how the variational Bayesian approach can be used to learn model structure: inferring the number of clusters and dimensionalities in a mixture of factor analysers, and inferring the dimension of the state space of a linear dynamical system.  Finally, importance sampling corrections to the variational approximations are discussed, along with their limitations. 
Propagation Algorithms for Variational Bayesian Learning| Abstract Variational approximations are becoming a widespread tool for Bayesian learning of graphical models.  We provide some theoretical results for the variational updates in a very general family of conjugate-exponential graphical models.  We show how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning.  Applying these results to the Bayesian analysis of linear-Gaussian state-space models we obtain a learning procedure that exploits the Kalman smoothing propagation, while integrating over all model parameters.  We demonstrate how this can be used to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set. 
Relationship between gradient and EM steps in latent variable models| Abstract We present a close relationship between Expectation - Maximization algorithm and direct optimization approaches such as gradient-based methods for parameter learning.  We show that the step EM takes in the parameter space and true gradient are related by the symmetric positive definite P matrix, and provide an explicit form of this matrix for several widely used latent variable models.  We then go on deriving a general form of the P matrix for the regular exponential family in terms of its natural parameters. 
Learning Dynamic Bayesian Networks| Abstract.  Bayesian networks are directed acyclic graphs that represent dependencies between variables in a probabilistic model.  Many time series models, including the hidden Markov models (HMMs) used in speech recognition and Kalman filter models used in filtering and control applications, can be viewed as examples of dynamic Bayesian networks.  We first provide a brief tutorial on learning and Bayesian networks.  We then present some dynamic Bayesian networks that can capture much richer structure than HMMs and Kalman filters, including spatial and temporal multiresolution structure, distributed hidden state representations, and multiple switching linear regimes.  While exact probabilistic inference is intractable in these networks, one can obtain tractable variational approximations which call as subroutines the forward-backward and Kalman filter recursions.  These approximations can be used to learn the model parameters by maximizing a lower bound on the likelihood. 
Factorial Hidden Markov Models| Abstract.  Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data.  In an HMM, information about the past is conveyed through a single
On the Convergence of Bound Optimization Algorithms| Abstract Many practitioners who use EM and related
Bilinear Dynamical Systems| Abstract In this paper we propose the use of Bilinear Dynamical Systems (BDS) for model-based deconvolution of fMRI time series.  The importance of this work lies in being able to deconvolve hemodynamic timeseries, in an informed way, to disclose the underlying neuronal activity.  Being able to estimate neuronal responses in a particular brain region is fundamental for many models of functional integration and connectivity in the brain.  BDSs comprise a stochastic bilinear neurodynamical model specified in discrete-time and a set of linear convolution kernels for the hemodynamics.  We derive an Expectation-Maximisation (EM) algorithm for parameter estimation, in which fMRI time series are deconvolved in an E-step and model parameters are updated in an M-Step.  We report preliminary results that focus on the assumed stochastic nature of the neurodynamic model and compare the method to Wiener deconvolution. 
Computational Models of Sensorimotor Integration| Abstract The sensorimotor integration system can be viewed as an observer attempting to estimate its own state and the state of the environment by integrating multiple sources of information.  We describe a computational framework capturing this notion, and some specific models of integration and adaptation that result from it.  Psychophysical results from two sensorimotor systems, subserving the integration and adaptation of visuo-auditory maps, and estimation of the state of the hand during arm movements, are presented and analyzed within this framework.  These results suggest that: (1) Spatial information from visual and auditory systems is integrated so as to reduce the variance in localization.  (2) The effects of a remapping in the relation between visual and auditory space can be predicted from a simple learning rule.  (3) The temporal propagation of errors in estimating the hand's state is captured by a linear dynamic observer, providing evidence for the existence of an internal model which simulates the dynamic behavior of the arm. 
Towards Semi-Supervised Classification with Markov Random Fields| Abstract We investigate the use of Boltzmann machines in semi-supervised classification.  We treat the labeled / unlabeled dataset as a Markov random field, and derive a Boltzmann machine learning algorithm for it to learn the feature weights, label noise and labels for unlabeled data all at once.  We present some Markov chain Monte Carlo methods needed for learning, and discuss the need to regularize model parameters.  Preliminary experimental results are presented. 
SMEM Algorithm for Mixture Models| Abstract We present a split and merge EM (SMEM) algorithm to overcome the local maxima problem in parameter estimation of finite mixture models.  In the case of mixture models, local maxima often involve having too many components of a mixture model in one part of the space and too few in another, widely separated part of the space.  To escape from such configurations we repeatedly perform simultaneous split and merge operations using a new criterion for efficiently selecting the split and merge candidates.  We apply the proposed algorithm to the training of Gaussian mixtures and mixtures of factor analyzers using synthetic and real data and show the effectiveness of using the split and merge operations to improve the likelihood of both the training data and of held-out test data.  We also show the practical usefulness of the proposed algorithm by applying it to image compression and pattern recognition problems. 
Unsupervised Learning| Abstract We give a tutorial and overview of the field of unsupervised learning from the perspective of statistical modelling.  Unsupervised learning can be motivated from information theoretic and Bayesian principles. 
Switching statespace models," 6 King's College Road,|
Supervised learning from incomplete data via an EM approach|
Active learning with mixture models|
A hierarchical community of experts|
Modular decomposition in visuomotor learning|
Computational principles of movement neuroscience|
An introduction to variational methods or graphical models|
The variational Bayesian EM algorithm for incomplete data: with application to scoring graphical model structures|
Hidden Markov Decision Trees|
Online variational Bayesian learning| Slides from talk presented at NIPS 2000 workshop on Online Learning. 
Simultaneous localization and mapping with sparse extended information filters|
"Delve,"|
Active learning with statistical methods|
Computation and Psychophysics of Sensorimotor Integration,|
In Press)| Generative models for discovering sparse distributed representations. 
Modeling T-cell activation using gene expression profiling and state-space models|
Modeling genetic regulatory networks using gene expression profiling and state space models|
Gaussian fields and nonparametric markov models,|
Bayesian model search for mixture models based on optimizing variational bounds|
An internal model for sensorimotor integration|
Learning from Labeled and Unlabeled Data with Label Propagation| CMU CALD tech report CMU-. 
Simultaneous mapping and localization with sparse extended information filters|
Chapter 6: An EM algorithm for identification of nonlinear dynamical systems|
Factorial hidden Markov Models| Technical report,. 
Graphical Models and Variational Methods, Advanced Mean Field Method--Theory and Practice|
Optimisation with EM and Expectation-Conjugate-Gradient,|
Learning from incomplete data|
Lecture Notes in Artificial Intelligence, chapter Learning Dynamic Bayesian Networks,|
Function approximation via density estimation using an EM approach|
Temporal processing with connectionist networks|
The variational Kalman smoother|
Graphical models for Bayesian classifier combination|
Perspectives and problems in motor learning,|
Computational principles of multisensory integration: Studies of adaptation to novel visuo-auditory remappings,|
The EM algorithm for mixture of factor analyzers,|
eds|,. 
Learning in graphical models, in|
The DELVE manual [online]|
An EM algorithm for indentification of nonlinear dynamical systems|
Factorial hidden Markov models| MIT. 
Supervised learning from real and discrete incomplete data|
A Bayesian network model for protein fold and remote homologue recognition|
Learning model structure|
The DELVE Manual| DELVE can be found at. 
On structured variational inference,|
Optimal Model Inference for Bayesian Mixture of Experts,|
n em algorithm for identification of nonlinear dynamical systems|
One hidden layer linear networks and canonical correlations|
Generalization to Local Remapping of the Visuo-Motor Coordinate Transformation,|
Solving inverse problems using an EM approach to density estimation|
Expectation propagation for infinite mixtures|
Learning nonlinear dynamical systems using the expectationmaximization algorithm|
