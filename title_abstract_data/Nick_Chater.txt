Category learning without labels---A simplicity approach| Abstract In an extensive research tradition in categorization,
Confidence Judgements, Performance, and Practice, in Artificial Grammar Learning| Abstract Artificial grammar learning is noted for the claim that subjects are unaware of their knowledge.  Chan (1992) and Dienes et al.  (in press) have demonstrated that subjects are unaware in the sense that they lack metaknowledge.  Dissociations between subjects' performance and their confidence in their decisions suggest that the learning mechanism may be in some sense encapsulated from the "confidence system".  Here we tested the alternative hypothesis that the confidence system is initially poorly calibrated, or does not know which aspects of the learning mechanism to attend to, by training and testing subjects over four weekly sessions.  On all four weeks we found a strong, near-perfect association between confidence and performance for trained subjects, but a dissociation for untrained control subjects.  We discuss possible explanations for these results, and previously observed dissociations.  Artificial grammar learning is notable for the controversial claim that subjects acquire knowledge which allows them to distinguish strings which follow the same rules as a set of previously memorised strings, from those which do not, but that they are not consciously aware of this knowledge (Reber, 1967, 1989).  However, measuring subjects' conscious knowledge is plagued with the problems of finding suitably sensitive, explicit tests, and of ensuring that the knowledge these explicit tests measure is the same as the knowledge subjects use to perform the classification (see Shanks and St.  John, 1995, and commentaries).  Chan (1992) and Dienes, Altmann, Kwan and Goode (in press) set issues of consciousness aside and focus instead on behaviour: Subjects' ability to make confidence judgements about their performance.  This tests metaknowledge, or "what subjects know about what they know".  Chan (1992) showed that subjects' confidence in their judgements was unrelated to the likelihood that those judgements were correct.  Similarly, Dienes et al.  (in press) showed that even when subjects thought that they were guessing, their performance was above chance (and untrained control) levels.  Chan (1992) and Dienes et al.  (in press) propose that the dissociation between confidence and accuracy is evidence that subjects lack meta-knowledge.  This suggests that the learning mechanism is to a certain extent encapsulated from the "confidence system", so that its inner workings (e. g. 
Distributional Information and the Acquisition of Linguistic Categories: A Statistical Approach| Abstract Distributional information, in the form of simple, locally computed statistics of an input corpus, provides a potential means of establishing initial syntactic categories (noun, verb, etc. ).  Finch and Chater (1991, 1992) clustered words hierarchically, according to the distribution of local contexts in which they appeared in large, written English corpora, obtaining clusters that corresponded well with the standard syntactic categories.  Here, a stronger demonstration of their method is provided, using `real' data, that to which children are exposed during category acquisition, taken from the childes corpus.  For 2\Delta5 million words of adult speech, clustering on syntactic and semantic bases was observed, with a high degree of clear differentiation between syntactic categories.  For child data, some noun and verb clusters emerged, with some evidence of other categories, but the data set was too small for reliable trends to emerge.  Some initial results investigating the possibility of classifying novel words using only the immediate context of a single instance are also presented.  These results demonstrate that statistical information may play an important role in the processes of early language acquisition.  Acquiring linguistic categories In acquiring language the child solves an enormously difficult problem: To uncover an exquisitely complex model of language structure from a corpus of observed language which is both extremely partial and riddled with false starts, slips of the tongue, and ungrammatical sentences.  One small, but crucially important, aspect of this problem is that of acquiring linguistic categories.  Unless linguistic categories are established, learning how those categories may be composed together to uncover the linguistic rules of the language appears to be impossible.  1 Experimental work was performed by MR, supervised by NC and SF, and supported by SERC studentship No. 
The Guessing Game: A Paradigm for Artificial Grammar Learning| Abstract In a guessing game, Ss reconstruct a sequence by guessing each successive element of the sequence from a finite set of alternatives, receiving feedback after each guess.  An upper bound on Ss knowledge of the sequence is given by ^ H, the estimated entropy of the numbers of guesses.  The method provides a measure of learning independent of material type and distractors, and the resulting data set is very rich.  Here, the method is applied to artificial grammar learning; Ss were exposed to strings from a finite state grammar and subsequently distinguished between strings that followed or violated the grammar reliably better than Ss who had not seen the learning strings (but who themselves performed at above chance levels).  Ss knowledge of the strings, ^ H, reflected both grammaticality and exposure to learning strings, and was correlated with overall judgement performance.  For non-grammatical strings, the strings that Ss knew most about were those they found most difficult to classify correctly.  These results support the hypothesis that fragment knowledge plays an important part in artificial grammar learning, and we suggest that the guessing game paradigm is a useful tool for studies of learning and memory in general. 
The psychological side of Hempel's paradox of confirmation|
Distributional Information: A Powerful Cue for Acquiring Syntactic Categories|
Toward a connectionist model of recursion in human linguistic performance|
Learning syntactic categories : A statistical approach|
Connectionist natural language processing: the state of the art|
The potential contribution of distributional information to early syntactic category acquisition|
Neural networks : The new statistical models of mind|
Classication and prior assumptions about category shape: new evidence concerning prototype and exemplar theories of categorization|
Simplicity and the mind|
Rational explanation of the selection task|
Categorization by simplicity: A minimum description length approach to unsupervised clustering,|
Rational Categories|
in press)| Basic Categories by Simplicity. 
