Using Expectation-Maximisation to Learn Dynamical Models from Visual Data| Abstract Tracking with deformable contours in a filtering framework requires a dynamical model for prediction.  For any given application, tracking is improved by having an accurate model, learnt from training data.  We develop a method for learning dynamical models from training sequences, explicitly taking account of the fact that our data are measurements and not true states.  By introducing an `augmentedstate smoothing filter', we show how the technique of ExpectationMaximisation can be applied to this problem, and show that the resulting algorithm produces more robust and accurate tracking. 
Bank of England| `Real-world' mortgages, consumption volatility and the low inflation environment Sebastian Barnes and Gregory Thwaites `Real-world' mortgages,
A Mixed-State CONDENSATION Tracker with Automatic Model-Switching| The Bayesian mixed-state framework is described in its generality, and the example of a bouncing ball is used to demonstrate that a mixed-state model can significantly improve tracking performance in heavy clutter.  The relevance of the approach to the problem of gesture recognition is then investigated using a tracker which is able to follow the natural drawing action of a hand holding a pen, and switches state according to the hand's motion. 
ICONDENSATION: Unifying Low-Level and High-Level Tracking in a Stochastic Framework| Abstract.  Tracking research has diverged into two camps; low-level approaches which are typically fast and robust but provide little fine-scale information, and high-level approaches which track complex deformations in high-dimensional spaces but must trade off speed against robustness.  Real-time high-level systems perform poorly in clutter and initialisation for most high-level systems is either performed manually or by a separate module.  This paper presents a new technique to combine low- and high-level information in a consistent probabilistic framework, using the statistical technique of importance sampling combined with the Condensation algorithm.  The general framework, which we term Icondensation, is described, and a hand tracker is demonstrated which combines colour blob-tracking with a contour model.  The resulting tracker is robust to rapid motion, heavy clutter and hand-coloured distractors, and re-initialises automatically.  The system runs comfortably in real time on an entry-level desktop workstation. 
Bayesian Correlation| Abstract Cross-correlation is a commonly used principle for intensity-based object localization and consists of two conceptual components, one very effective and the other rather weak.  The effective component is the inner-product score for matching.  The weak component is exhaustive search, inefficient in two dimensions, and infeasible in the higher dimensioned configuration spaces needed for matching object models.  The Bayesian framework for correlation, developed here, replaces exhaustive search with constrained, random hypothesis generation.  Achieving a synthesis of cross-correlation, which is deterministic, with probabilistic sampling has required several developments.  The first is the interpretation of correlation matching functions, in probabilistic terms, by constructing an observation likelihood.  Second, a response-learning algorithm is developed for the distributions of filter-bank responses.  Inescapably, response-learning demands statistical modelling of background intensities, and there are unexpected links here with image coding and Independent Component Analysis.  Lastly, multi-scale processing is well known to be an important component of conventional correlation.  In the Bayesian context it is achieved by means of a new algorithm, termed layered sampling, for which asymptotic properties are derived.  Bayesian correlation has the considerable advantage that, thanks to the response-learning, image-feature tuning and selection are automatic.  Combined with random sampling to deal with ambiguity, response-learning makes for excellent handling of image clutter, and this is demonstrated.  Furthermore, the output of Bayesian correlation is not simply an estimate of location but an entire probability distribution.  This allows sequential inference --- propagation from coarse to fine scale, and also propagation over time, illustrated here by examples of image-sequence analysis. 
Object Localization by Bayesian Correlation| Abstract Maximisation of cross-correlation is a commonly used principle for intensity-based object localization that gives a single estimate of location.  However, to facilitate sequential inference (eg over time or scale) and to allow the representation of ambiguity, it is desirable to represent an entire probability distribution for object location.  Although the crosscorrelation itself (or some function of it) has sometimes been treated as a probability distribution, this is not generally justifiable.  Bayesian correlation achieves a consistent probabilistic treatment by combining several developments.  The first is the interpretation of correlation matching functions in probabilistic terms, as observation likelihoods.  Second, probability distributions of filter-bank responses are learned from training examples.  Inescapably, response-learning also demands statistical modelling of background intensities, and there are links here with image coding and Independent Component Analysis.  Lastly, multi-scale processing is achieved, in a Bayesian context, by means of a new algorithm, layered sampling, for which asymptotic properties are derived. 
Articulated Body Motion Capture by Annealed Particle Filtering| Abstract The main challenge in articulated body motion tracking is the large number of degrees of freedom (around 30) to be recovered.  Search algorithms, either deterministic or stochastic, that search such a space without constraint, fall foul of exponential computational complexity.  One approach is to introduce constraints either labelling using markers or colour coding, prior assumptions about motion trajectories or view restrictions.  Another is to relax constraints arising from articulation, and track limbs as if their motions were independent.  In contrast, here we aim for general tracking without special preparation of subjects or restrictive assumptions.  The principal contribution of this paper is the development of a modied particle lter for search in high dimensional conguration spaces.  It uses a continuation principle, based on annealing, to introduce the inuence of narrow peaks in the tness function, gradually.  The new algorithm, termed annealed particle ltering, is shown to be capable of recovering full articulated body motion efciently. 
Initialisation and Termination of Active Contour Level-Set Evolutions| Abstract This paper deals with the evolution control of level-sets in the context of contour detection.  There is a considerable amount of existing work on PDEs for geodesic contour detection and the investigation of level-set implementations has recently resulted in efficient and stable numerical realisations of the differential evolution.  This paper is based on a finite element implementation for signed distance level-set evolutions and focuses the attention to the initialisation and termination of level-set evolutions.  An initialisation consists of an initial signed distance function which corresponds to some implicit curve.  We discuss two types of initialisation.  We generalise the commonly used a priori type, which can be a rectangle the size of the image, to include more general initial shapes.  We show that the initial shape does not have to be closed and can for instance be a single line.  The second type of initialisations is not specified by the user but a result of previous level-set evolutions.  This type of initialisation is useful when different evolution equations are to be alternated and can be used for instance to detect nested contours or in multi-resolution techniques.  For the termination of a geodesic evolution, we introduce an automatic stopping condition by looking at the Riemannian length of the implicit curve as the quantity that is subject to the minimisation.  It turns out that the length can be computed efficiently from the employed finite element representation and used to terminate the gradient descent. 
Poisson image editing| Abstract Using generic interpolation machinery based on solving Poisson equations, a variety of novel tools are introduced for seamless editing of image regions.  The first set of tools permits the seamless importation of both opaque and transparent source image regions into a destination region.  The second set is based on similar mathematical ideas and allows the user to modify the appearance of the image seamlessly, within a selected region.  These changes can be arranged to affect the texture, the illumination, and the color of objects lying in the region, or to make tileable a rectangular selection. 
Ecient Dense-Stereo and Novel-view Synthesis for Gaze Manipulation in One-to-one Teleconferencing| A new algorithm is proposed for novel-view synthesis, with particular application to teleconferencing.  Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesises images from a virtual camera in arbitrary position (typically located within the monitor area) to facilitate eye contact.  The new technique is based on an improved, dynamic-programming, stereo algorithm for ecient novel-view generation.  The two main contributions of this paper are: i) a new four-layer matching graph for dense-stereo dynamic-programming, that supports accurate occlusion labeling; ii) a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.  Furthermore, the paper presents an algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts (flicker); and a cost aggregation algorithm that acts directly in three-dimensional matching cost space.  The proposed algorithm has been designed to work with input images with large disparity range, a common situation in one-to-one video-conferencing.  The enhanced occlusion-handling capabilities of the new DP algorithm are evaluated against those of the most powerful state-of-the-art dynamic-programming and graph-cut techniques.  A number of examples demonstrate the robustness of the algorithm to artefacts in stereo video streams.  This includes demonstrations of cyclopean view synthesis in extended conversational sequences, synthesis from a freely translating virtual camera and,
Image Divergence and Deformation from Closed Curves| Abstract This paper describes a novel method to measure the differential
Real-Time Traffic Monitoring| Abstract Traffic statistics desired by road engineers and planners, and "traffic warning" systems demand real-time performance which precludes the use of batch processing.  We apply recent real-time tracking techniques along with scene specific tuning of the dynamics to enable the tracker to accurately predict target location and thus reduce the amount of search and/or image processing required.  The benefits of learning dynamics for accurate prediction are speed -- our tracker operates at frame rate -- and smoothing of vibration.  Initial calibration of the projective relationship between the image and ground planes enables metric information to be derived from the image positions and velocities without full camera calibration.  Results are presented on real-world traffic scenes showing the tracker to be both fast and robust to vibrations which are inevitable in traffic locations. 
A Sparse Probabilistic Learning Algorithm for Real-Time Tracking| Abstract This paper addresses the problem of applying powerful pattern recognition algorithms based on kernels to efficient visual tracking.  Recently Avidan [1] has shown that object recognizers using kernel-SVMs can be elegantly adapted to localization by means of spatial perturbation of the SVM, using optic flow.  Whereas Avidan's SVM applies to each frame of a video independently of other frames, the benefits of temporal fusion of data are well known.  This issue is addressed here by using a fully probabilistic `Relevance Vector Machine' (RVM) to generate observations with Gaussian distributions that can be fused over time.  To improve performance further, rather than adapting a recognizer, we build a localizer directly using the regression form of the RVM.  A classification SVM is used in tandem, for object verification, and this provides the capability of automatic initialization and recovery.  The approach is demonstrated in real-time face and vehicle tracking systems.  The `sparsity' of the RVMs means that only a fraction of CPU time is required to track at frame rate.  Tracker output is demonstrated in a camera management task in which zoom and pan are controlled in response to speaker/vehicle position and orientation, over an extended period.  The advantages of temporal fusion in this system are demonstrated. 
WORKING PAPER VARIATIONS IN NATIONAL MANAGEMENT ACCOUNTING APPROACHES| Abstract During the 1990's studies of management accounting practices in Europe and in Latin America have given us data on 23 countries.  In this paper we use this data to identify five distinct aspects of national management accounting culture being: 1.  The influence of regulations on official recommendations; 2.  The source of management accountants; 3.  Influence from one country to another; 4.  Variations in use of specific techniques; 5.  Variations in the objectives of the management accounting system.  We then identify seven significant implications of the manager operating in the multinational environment. 
Super-resolution Enhancement of Video| Abstract We consider the problem of enhancing the resolution of video through the addition of perceptually plausible high frequency information.  Our approach is based on a learned data set of image patches capturing the relationship between the middle and high spatial frequency bands of natural images.  By introducing an appropriate prior distribution over such patches we can ensure consistency of static image regions across successive frames of the video, and also take account of object motion.  A key concept is the use of the previously enhanced frame to provide part of the training set for super-resolution enhancement of the current frame.  Our results show that a marked improvement in video quality can be achieved at reasonable computational cost. 
Rapid Summarisation and Browsing of Video Sequences| Abstract This paper presents a strategy for rapid summarisation and browsing of video sequences.  The input video is first transformed into a sequence of representative feature vectors.  Using this representation a utility function is designed that assigns high reward to subsequences of keyframes that are maximally distinct and individually carry the most information.  For a specified level of detail and endpoints the keyframe sequence that maximises this utility function can be obtained by a non-iterative Dynamic Programming procedure, thus allowing the user to efficiently zoom in on any part or all of the video sequence.  For the sake of compactness and clarity the working of the algorithm is illustrated on a television commercial. 
Object localization by Bayesian correlation| Abstract This paper is based on the article [2]
The Variational Ising Classifier (VIC) algorithm for coherently contaminated data| Abstract There has been substantial progress in the past decade in the development of object classifiers for images, for example of faces, humans and vehicles.  Here we address the problem of contaminations (e. g.  occlusion, shadows) in test images which have not explicitly been encountered in training data.  The Variational Ising Classifier (VIC) algorithm models contamination as a mask (a field of binary variables) with a strong spatial coherence prior.  Variational inference is used to marginalize over contamination and obtain robust classification.  In this way the VIC approach can turn a kernel classifier for clean data into one that can tolerate contamination, without any specific training on contaminated positives. 
Contour Tracking by Stochastic Propagation of Conditional Density| The problem of tracking curves in dense visual clutter is a challenging one.  Trackers based on Kalman filters are of limited use; because they are based on Gaussian densities which are unimodal, they cannot represent simultaneous alternative hypotheses.  Extensions to the Kalman filter to handle multiple data associations work satisfactorily in the simple case of point targets, but do not extend naturally to continuous curves.  A new, stochastic algorithm is proposed here, the Condensation algorithm --- Conditional Density Propagation over time.  It uses `factored sampling', a method previously applied to interpretation of static images, in which the distribution of possible interpretations is represented by a randomly generated set of representatives.  The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time.  The result is highly robust tracking of agile motion in clutter, markedly superior to what has previously been attainable from Kalman filtering.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  1 The problem of tracking curves in clutter The purpose of this paper is to establish a stochastic framework for tracking curves in visual clutter, and to propose a powerful new technique --- the Condensation algorithm.  The new approach is rooted in strands from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our framework aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models must be pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost [17, 26, 18].  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally [20], especially if motion is modelled as well as shape [12, 16].  One important facility is the modelling of curve segments which interact with images [29] or image sequences [19].  This is more general than modelling entire objects but more clutter-resistant than applying signal-processing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric Bspline curves [3] tracking over image sequences [8].  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space [28, 5], or more generally allowing a linear space of non-rigid motion [9].  Finally, probability densities p(x) can be defined over the class of curves [9], and also over their motions [27, 5], and this constitutes a powerful facility for tracking.  Reasonable default functions can be chosen for those densities.  However, it is obviously more satisfactory to measure the actual densities or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this assuming Gaussian densities are known in the control-theory literature [13] and have been applied in computer vision [6, 7, 4].  1. 2 Sampling methods A standard problem in statistical pattern recognition is to find an object parameterised as x with prior p(x), using data z from a single image.  (This is a simplified, static form of the image sequence problem addressed in this paper. ) In order to estimate x from z, some information is needed about the conditional distribution p(zjx) which measures the likelihood that a hypothetical object configuration x should give rise to the image data z that has just been observed.  The data z could either be an entire grey-level array or a set of sparse features such as corners or, as in this paper, curve fragments obtained by edge detection.  The posterior density p(xjz) represents all the knowledge about x that is deducible from the data.  It can be evaluated in principle by applying Bayes' rule to obtain p(xjz) = kp(zjx)p(x) (1) where k is a normalisation constant that is independent of x.  In the general case that p(zjx) is multi-modal p(xjz) cannot be evaluated simply in closed form: instead iterative sampling techniques can be used.  The first use of such an iterative solution was proposed by Geman and Geman [11] for restoration of an image represented by mixed variables, both continuous (pixels) and discrete (the `line process').  Sampling methods for recovery of a parametric curve x by sampling [24, 14, 25] have generally used spatial Markov processes as the underlying probabilistic model p(x).  The basic method is factored sampling [14].  It is useful when the conditional observation probability p(zjx) can be evaluated pointwise and sampling it is not feasible and when, conversely, the prior p(x) can be sampled but not evaluated.  The algorithm
Classification of Human Body Motion| Abstract The classication of human body motion is a difcult problem.  In particular, the automatic segmentation of sequences containing more than one class of motion is challenging.  An effective approach is to use mixed discrete/continuous states to couple perception with classication.  A spline contour is used to track the outline of the person.  We show that for a quasi-periodic human body motion, an autoregressive process is a suitable model for the contour dynamics.  This can then be used as a dynamical model for mixed state CONDENSATION ltering, switching automatically between different motion classes.  We have developed ^Partial Importance Sampling~ to enhance the efciency of the mixed state CONDENSATION lter.  It is also shown here that the importance sampling can be done in linear time, in place of the previous quadratic algorithm.  ~Tying~ of discrete states is used to obtain further efciency improvements.  Automatic segmentation is demonstrated on video sequences of aerobic exercises.  Performance is promising, but there remains a residual misclassication rate and possible explanations for this are discussed. 
Mathematical modelling of animate and intentional motion| (ablake@microsoft. com) Our aim is to enable a machine to observe and interpret the behaviour of others.  Mathematical models are employed to describe certain biological motions.  The main challenge is to design models that are both tractable and meaningful.  In the first part we will describe how computer vision techniques, in particular visual tracking, can be applied to recognize a small vocabulary of human actions in a constrained scenario.  Mainly the problems of viewpoint and scale invariance need to be overcome to formalize a general framework.  Hence the second part of the article is devoted to the question whether a particular human action should be captured in a single complex model or whether it is more promising to make extensive use of semantic knowledge and a collection of low-level models that encode certain motion primitives.  Scene context plays a crucial role if we intend to give a higher-level interpretation rather than a low-level physical description of the observed motion.  A semantic knowledge base is used to establish the scene context.  This approach consists of three main components: visual analysis, the mapping from vision to language and the search of the semantic database.  A small number of robust visual detectors is used to generate a higher-level description of the scene.  The approach together with a number of results is presented in the third part of this article. 
A Probabilistic Exclusion Principle for Tracking Multiple Objects| Abstract Tracking multiple targets whose models are indistinguishable is a challenging problem.  Simply instantiating several independent 1-body trackers is not an adequate solution, because the independent trackers can coalesce onto the best-fitting target.  This paper presents an observation density for tracking which solves this problem by exhibiting a probabilistic exclusion principle.  Exclusion arises naturally from a systematic derivation of the observation density, without relying on heuristics.  Another important contribution of the paper is the presentation of partitioned sampling, a new sampling method for multiple object tracking.  Partitioned sampling avoids the high computational load associated with fully coupled trackers, while retaining the desirable properties of coupling. 
Generative Affine Localisation and Tracking| Abstract We present an extension to the Jojic and Frey (2001) layered sprite model which allows for layers to undergo affine transformations.  This extension allows for affine object pose to be inferred whilst simultaneously learning the object shape and appearance.  Learning is carried out by applying an augmented variational inference algorithm which includes a global search over a discretised transform space followed by a local optimisation.  To aid correct convergence, we use bottom-up cues to restrict the space of possible affine transformations.  We present results on a number of video sequences and show how the model can be extended to track an object whose appearance changes throughout the sequence. 
Interactive Image Segmentation Using an Adaptive GMMRF Model| Abstract.  The problem of interactive foreground/background segmentation in still images is of great practical importance in image editing.  The state of the art in interactive segmentation is probably represented by the graph cut algorithm of Boykov and Jolly (ICCV 2001).  Its underlying model uses both colour and contrast information, together with a strong prior for region coherence.  Estimation is performed by solving a graph cut problem for which very efficient algorithms have recently been developed.  However the model depends on parameters which must be set by hand and the aim of this work is for those constants to be learned from image data.  First, a generative, probabilistic formulation of the model is set out in terms of a "Gaussian Mixture Markov Random Field" (GMMRF).  Secondly, a pseudolikelihood algorithm is derived which jointly learns the colour mixture and coherence parameters for foreground and background respectively.  Error rates for GMMRF segmentation are calculated throughout using a new image database, available on the web, with ground truth provided by a human segmenter.  The graph cut algorithm, using the learned parameters, generates good object-segmentations with little interaction.  However, pseudolikelihood learning proves to be frail, which limits the complexity of usable models, and hence also the achievable error rate. 
Condensation --- conditional density propagation for visual tracking| ABSTRACT The problem of tracking curves in dense visual clutter is challenging.  Kalman filtering is inadequate because it is based on Gaussian densities which, being unimodal, cannot represent simultaneous alternative hypotheses.  The Condensation algorithm uses "factored sampling", previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set.  Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time.  The result is highly robust tracking of agile motion.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  Contents 1 Tracking curves in clutter 2 2 Discrete-time propagation of state density 3 3 Factored sampling 6 4 The Condensation algorithm 8 5 Stochastic dynamical models for curve motion 10 6 Observation model 13 7 Applying the Condensation algorithm to video-streams 17 8 Conclusions 26 A Non-linear filtering 31 B Derivation of the sampling rule 33 C Asymptotic correctness of the Condensation Algorithm 34 1 Tracking curves in clutter The purpose of this paper 1 is to establish a stochastic framework for tracking curves in visual clutter, using a sampling algorithm.  The approach is rooted in ideas from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case of camouflage, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our approach aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models is pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost (Hogg, 1983; Lowe, 1991; Sullivan, 1992; Huttenlocher et al. , 1993).  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally (Lowe, 1992), especially if motion is modelled as well as shape (Gennery, 1992; Harris, 1992).  One important facility is the modelling of curve segments which interact with images (Fischler and Elschlager, 1973; Yuille and Hallinan, 1992) or image sequences (Kass et al. , 1987; Dickmanns and Graefe, 1988).  This is more general than modelling entire objects but more clutter-resistant than applying signalprocessing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric B-spline curves (Bartels et al. , 1987) tracking over image sequences (Menet et al. , 1990; Cipolla and Blake, 1990).  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space (Koenderink and Van Doorn, 1991; Ullman and Basri, 1991; Blake et al. , 1993), or more generally allowing a "shape-space" of non-rigid motion (Cootes et al. , 1993).  Finally, prior probability densities can be defined over the curves (Cootes et al. , 1993) represented by appropriate parameter vectors x, and also over their motions (Terzopoulos and Metaxas, 1991; Blake et al. , 1993), and this constitutes a powerful facility for tracking.  Reasonable defaults can be chosen for those densities.  However, it is obviously more satisfactory to measure or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this, assuming Gaussian densities, are known in the control-theory literature (Goodwin and Sin, 1984) and have been applied in computer vision (Blake and Isard, 1994; Baumberg and Hogg, 1995).  Given the prior, and an observation density that characterises the statistical variability of image data z given a curve state x, a posterior distribution can, in principle, be estimated for x t given z t at successive times t.  1 This paper has appeared in short form (Isard and Blake, 1996) as joint winner of the prize of the European Conference on Computer Vision, 1996. 
Spatial Dependence in the Observation of Visual Contours| Abstract Two challenging problems in object recognition are: to output structures that can be interpreted statistically; and to degrade gracefully under occlusion.  This paper proposes a new method for addressing both problems simultaneously.  Specifically, a likelihood ratio termed the Markov discriminant is used to make statistical inferences about partially occluded objects.  The Markov discriminant is based on a probabilistic model of occlusion.  This model is a Markov random field, which acts as the prior for Bayesian estimation of the posterior using Markov chain Monte Carlo (MCMC) simulation.  The method takes as its starting point a "contour discriminant" designed to differentiate between a target and random background clutter.  We show that incorporating the prior on occlusions has two important advantages.  First, partially occluded targets are assigned reasonable relative probability distributions even when they appear in scenes with unoccluded targets; this would allow a higher-level system to perform useful reasoning subsequently.  Second, discrimination between partially occluded targets and background clutter is significantly improved.  Both these advances can be explained by theoretical reasoning, and are demonstrated in experiments. 
Learning Dynamical Models Using Expectation-Maximisation| Abstract Tracking with deformable contours in a filtering framework requires a dynamical model for prediction.  For any given application, tracking is improved by having an accurate model, learned from training data.  We develop a method for learning dynamical models from training sequences, explicitly taking account of the fact that training data are noisy measurements and not true states.  By introducing an `augmentedstate smoothing filter', we show how the technique of Expectation-Maximisation can be applied to this problem, and show that the resulting algorithm produces more robust and accurate tracking. 
Towards a Complete Dense Geometric and Photometric Reconstruction under Varying Pose and Illumination| Abstract This paper proposes a novel framework to construct a geometric and photometric model of a viewed object that can be used for visualisation in arbitrary pose and illumination.  The method is solely based on images and does not require any specialised equipment.  We assume that the object has a piece-wise smooth surface and that its reflectance can be modelled using a parametric bidirectional reflectance distribution function.  Without assuming any prior knowledge on the object, geometry and reflectance have to be estimated simultaneously and occlusion and shadows have to be treated consistently.  We exploit the geometric and photometric consistency using the fact that surface orientation and reflectance are local invariants.  In a first implementation, we demonstrate the method using a Lambertian object placed on a turn-table and illuminated by a number of unknown point light-sources.  A discrete voxel model is initialised to the visual hull and voxels identified as inconsistent with the invariants are removed iteratively.  The resulting model is used to render images in novel pose and illumination. 
Estimating uncertainty in dense stereo disparity maps| Dense stereo is a well studied problem in computer vision.  Generally dense stereo algorithms provide only a single estimate of disparity, ignoring uncertainty in the disparity map.  Here however, we present a new, linear-time, exact method for recovering entire distributions for disparity at all pixels.  This is accomplished by using a recent extension, due to Durbin et al. , of the well-known forward-backward algorithm to work with two unsynchronised input streams, rather than just one as in the conventional case.  The two input streams, in the stereo context are simply two corresponding epipolar lines, one from each stereo image.  Specifically we consider the problem of view interpolation.  The availability of a distribution over disparity is particularly appealing here.  In that case, disparities themselves are not the required end product, but merely an intermediate representation.  It is therefore unnecessary to estimate a unique disparity map.  Instead, the image intensity at each cyclopean pixel can be estimated as a mean of predicted intensities for all possible disparities.  These principles are illustrated for a teleconferencing application: enabling eye contact by positioning a virtual camera at the centre of a display screen used in a two-way conference.  We show that the new approach can significantly improve the quality of the interpolated cyclopean image, compared with using unique estimated disparities. 
The SPS Algorithm: Patching Figural Continuity and Transparency by Split-Patch Search| Abstract This paper describes a novel algorithm for the efficient synthesis of high-quality virtual views from only two input images.  The emphasis is on the recovery of continuity of objects boundaries (figural continuity) with faithful synthesis of transparency effects.  The contribution of this paper is two-fold: i) the SplitPatch Search (SPS) technique is introduced for dense stereo which handles transparency effects by assigning multiple disparities to mixed pixels; ii) an efficient extension of exemplar-based image synthesis to the case of two-camera stereo is proposed.  Furthermore, this paper presents an approximate but effective solution to the challenging problem of layer estimation and compositing in the case of small image patches.  The effectiveness of the proposed technique is demonstrated on a number of stereo image pairs taken from twocamera video-conferencing setups, where the quality of the synthesized talking heads is of paramount importance.  Moreover, the improvement in the quality of image synthesis is quantified by comparing the output of the SPS algorithm with thirteen ground-truth images. 
WORKING PAPER DIMENSIONS OF NATIONAL CULTURE AND THE ACCOUNTING ENVIRONMENT - THE SPANISH CASE| Abstract Abstract Gray (1988) has put forward a hypothesis on how a national accounting environment might reflect the cultural dimensions identified by Hofstede (1980, 1983).  A number of studies have tested Gray's hypothesis, including one by Pourjalali and Meek (1995) which identified a match between changes in cultural dimensions and the accounting environment in Iran following the revolution.  In this paper we replicate this work in the context of Spain following the death of Franco in 1975 and the emergence of a democratic constitution in 1978.  Specifically, we: 1) Consider Gray's hypothesis built on Hofstede's cultural dimensions and review some empirical tests of the hypotheses.  2) Building on the work of Hofstede and Gray, we: put forward some hypotheses on how we would expect cultural dimensions to change in Spain with the transition to democracy.  3) Review developments in accounting in Spain following the transition to democracy, in order to identify how well these fit with our hypotheses. 
A Smoothing Filter for CONDENSATION| Abstract.  Condensation, recently introduced in the computer vision literature, is a particle filtering algorithm which represents a tracked object's state using an entire probability distribution.  Clutter can cause the distribution to split temporarily into multiple peaks, each representing a different hypothesis about the object configuration.  When measurements become unambiguous again, all but one peak, corresponding to the true object position, die out.  While several peaks persist estimating the object position is problematic.  "Smoothing" in this context is the statistical technique of conditioning the state distribution on both past and future measurements once tracking is complete.  After smoothing, peaks corresponding to clutter are reduced, since their trajectories eventually die out.  The result can be a much improved state-estimate during ambiguous time-steps.  This paper implements two algorithms to smooth the output of a Condensation filter.  The techniques are derived from the work of Kitagawa, reinterpreted in the Condensation framework, and considerably simplified. 
B y| The analysis of visual motion against dense background clutter is a challenging problem.  Uncertainty in the positions of visually sensed features and ambiguity of feature correspondence call for a probabilistic treatment, capable of maintaining not simply a single estimate of position and shape but an entire distribution.  Exact representation of the evolving distribution is possible when the distributions are Gaussian and this yields some powerful approaches.  However normal distributions are limited when clutter is present: because of their unimodality, they cannot be used to represent simultaneous alternative hypotheses.  One powerful methodology for maintaining non-Gaussian distributions is based on random sampling techniques.  The effectiveness of "factored sampling" and ``Markov chain Monte Carlo" for interpretation of static images is widely accepted.  More recently, factored sampling has been combined with learned dynamical models to propagate probability distributions for object position and shape.  Progress in several areas is reported here.  First a new observational model is described that takes object opacity into account.  Secondly, complex shape models to represent combined rigid and nonrigid motion have been developed, together with a new algorithm to decompose rigid from nonrigid.  Lastly, more powerful dynamical prior models have been constructed by appending suitable discrete labels to a continuous system state; this may also have applications to gesture recognition. 
Probabilistic Tracking in a Metric Space| Abstract A new, exemplar-based, probabilistic paradigm for visual tracking is presented.  Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner.  Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations.  Their use avoids tedious hand-construction of object models and problems with changes of topology.  Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the "Metric Mixture" (M 2 ) approach.  The M 2 model has several valuable properties.  Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space.  Secondly, it uses a noise model that is learned from training data.  Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence.  Experiments demonstrate the effectiveness of the M 2 model in two domains: tracking walking people using chamfer distances on binary edge images and tracking mouth movements by means of a shuffle distance. 
Probabilistic Tracking with Exemplars in a Metric Space| Abstract.  A new, exemplar-based, probabilistic paradigm for visual tracking is presented.  Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner.  Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations.  Their use avoids tedious hand-construction of object models, and problems with changes of topology.  Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the "Metric Mixture" (M 2 ) approach, which has a number of attractions.  Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space.  Secondly, it uses a noise model that is learned from training data.  Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence.  Experiments demonstrate the effectiveness of the M 2 model in two domains: tracking walking people using "chamfer" distances on binary edge images, and tracking mouth movements by means of a shuffle distance. 
Tracking through Singularities and Discontinuities by Random Sampling| Abstract Some issues in markerless tracking of human body motion are addressed.  Extended Kalman filters have commonly been applied to kinematic variables, to combine predictions consistent with plausible motion, with the incoming stream of visual measurements.  Kalman filtering is applicable only when the underlying distribution is approximately Gaussian.  Often, this assumption proves remarkably robust.  There are two pervasive circumstances under which the Gaussianity assumption can break down.  The first is kinematic singularity, and the second is at joint endstops.  Failure of Kalman filtering under these circumstance is illustrated.  The non-Gaussian nature of the distributions is demonstrated experimentally by means of Monte-Carlo simulation.  Random simulation --- particle filtering or Condensation --- proves to provide a robust alternative algorithm for tracking that can also deal with these difficult conditions. 
Bayesian Object Localisation in Images| Abstract A Bayesian approach to intensity-based object localisation is presented that employs a learned probabilistic model of image filter-bank output, applied via Monte Carlo methods, to escape the inefficiency of exhaustive search.  An adequate probabilistic account of image data requires intensities both in the foreground (ie over the object), and in the background, to be modelled.  Some previous approaches to object localisation by Monte Carlo methods have used models which, we claim, do not fully address the issue of the statistical independence of image intensities.  It is addressed here by applying to each image a bank of filters whose outputs are approximately statistically independent. 
Gaze Manipulation for One-to-one Teleconferencing| Abstract A new algorithm is proposed for novel view generation in one-toone teleconferencing applications.  Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesises images from a virtual camera in arbitrary position (typically located within the monitor) to facilitate eye contact.  Our technique is based on an improved, dynamicprogramming, stereo algorithm for efficient novel-view generation.  The two main contributions of this paper are: i) a new type of three-plane graph for dense-stereo dynamic-programming, that encourages correct occlusion labeling; ii) a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.  Furthermore, this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts (flicker); and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space.  Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams.  These include demonstrations of synthesis of cyclopean views of extended conversational sequences.  We further demonstrate synthesis from a freely translating virtual camera. 
Learning Multi-Class Dynamics| Abstract Standard techniques (eg.  Yule-Walker) are available for learning Auto-Regressive process models of simple, directly observable, dynamical processes.  When sensor noise means that dynamics are observed only approximately, learning can still been achieved via Expectation-Maximisation (EM) together with Kalman Filtering.  However, this does not handle more complex dynamics, involving multiple classes of motion.  For that problem, we show here how EM can be combined with the Condensation algorithm, which is based on propagation of random sample-sets.  Experiments have been performed with visually observed juggling, and plausible dynamical models are found to emerge from the learning process. 
JetStream: Probabilistic Contour Extraction with Particles| Abstract The problem of extracting continuous structures from noisy or cluttered images is a difficult one.  Successful extraction depends critically on the ability to balance prior constraints on continuity and smoothness against evidence garnered from image analysis.  Exact, deterministic optimisation algorithms, based on discretized functionals, suffer from severe limitations on the form of prior constraint that can be imposed tractably.  This paper proposes a sequential Monte-Carlo technique, termed JetStream, that enables constraints on curvature, corners, and contour parallelism to be mobilized, all of which are infeasible under exact optimization.  The power of JetStream is demonstrated in two contexts: (1) interactive cut-out in photo-editing applications, and (2) the recovery of roads in aerial photographs. 
Towards Improved Observation Models for Visual Tracking: Selective Adaptation| Abstract.  An important issue in tracking is how to incorporate an appropriate degree of adaptivity into the observation model.  Without any adaptivity, tracking fails when object properties change, for example when illumination changes a'ect surface colour.  Conversely, if an observation model adapts too readily then, during some transient failure of tracking, it is liable to adapt erroneously to some part of the background.  The approach proposed here is to adapt selectively, allowing adaptation only during periods when two particular conditions are met: that the object should be both present and in motion.  The proposed mechanism for adaptivity is tested here with a foreground colour and motion model.  The experimental setting itself is novel in that it uses combined colour and motion observations from a fixed filter bank, with motion used also for initialisation via a Monte Carlo proposal distribution.  Adaptation is performed using a stochastic EM algorithm, during periods that meet the conditions above.  Tests verify the value of such adaptivity, in that immunity to distraction from clutter of similar colour to the object is considerably enhanced. 
WORKING PAPER ENVIRONMENTAL FACTORS GIVING RISE TO VARIATIONS IN NATIONAL MANAGEMENT ACCOUNTING PRACTICE| Abstract Comparative national management accounting is the least developed aspect in the field of international accounting.  Only during the second half of the 1990's some comparisons of national management accounting practice have appeared published but only at the regional level.  In this paper a range of factors that give rise to variations in national management accounting practice are postulated.  We support this list with examples from a range of analyses of national management accounting practices, drawing particularly on the work of Lizcano (1996) and Bhimani (1996).  Finally, twelve key factors are identified as influencing an individual country's approach to management accounting. 
Reconstructing a Visible Surface|
Invariant Surface Reconstruction using Weak Continuity Constraints,|
Comparison of the Efficiency of Deterministic and Stochastic Algorithms for Visual Reconstruction|
Multistage Interconnection Network Reliability|
Reliability analysis of interconnection networks using hierarchical composition,|
Lena image: 0|23 bit/pixel compression obtained with the JPEG algorithm: edges are preserved better than in the previous image,. 
Learning Dynamics of Complex Motions from Image Sequences|
Robust real time tracking and classificiation of facial expressions|
Learning and Classification of Complex Dynamics|
Probabilistic tracking in metric space|
Statistical Learning of Multi-view Face Detection|
A framework for spatio-temporal control in the tracking of visual contours|
Estimating the shape of a moving contour|
Learning to Track the Visual Motion of Contours|
Automatic Speechreading using Dynamic Contours,|
Condensation - conditional density propogation for visual tracking|
Real-Time Lip Tracking for Audio-Visual Speech Recognition Applications|
Contour tracking by sotchastic propagation of conditional density|
Detecting specular reflections using lambertian constraints|
Specular Stereo|
Grasping visual symmetry|
The dynamic analysis of apparent contours|
Motion Deblurring and Super-resolution from an Image Sequence|
Separability of Pose and Expression in Facial Tracing and Animation|
Evaluating a robust contour tracker on echocardiographic sequences,|
Robust estimation of egomotion from normal flow|
Planar region detection and motion recovery|
A Probabilistic Contour Discriminant for Object Localisation|
D position, attitude and shape input using video tracking of hands and lips|
Does the brain know the physics of specular reflection?|
Two-dimensional constraints on three-dimensional structure from motion tasks|
Boundary conditions for lightness computation in mondrian world|
The dynamics of Consumers' expenditure: the UK Consumption ECM redux|
Surface descriptions from stereo and shading|
Surface shape from the deformation of apparent contour|
Shape from Texture: Estimation, Isotropy and Moments|
Shape from texture: the homogeneityhypothesis|
Quantitative Planar Region Detection|
Shape from Texture:|
Analogue computation of collision-free paths|
`A Social Accounting Matrix for Uganda,|
Shape from texture: Ideal observers and human psychophysics|
Sensitivity Analysis of Reliability and Performability Measures for Multiprocessor Systems|
"GrabCut": interactive foreground extraction using iterated graph cuts|
Data fusion for visual tracking with particles|
Mechanics of ciliary locomotion|
Statistical Feature Modelling for Active Contours|
Active contours: The application of techniques from graphics, vision, control theory and statistics to visual tracking of shapes in motion,|
Parallel implementation of lagrangian dynamics for real-time snakes|
`On-Orbit Observations of Single Event Upsets in Harris HM-6508 1K RAMS',|
Contour tracking by stochastic propogation of conditional density|
Nonlinear filtering for speaker tracking in noisy and reverberant environments,|
Canonical Expressions in Boolean Algebra|
Motion planning using image divergence and deformation|
Statistical models of visual shape and motion|
Affine-invariant contour tracking with automatic control of spatiotemporal scale,|
JetStream: Probabilistic Contour Extraction with Particles|
Contour tracking by stochatic propagation of conditional density|
Determining facial expressions in real time| volume 1,. 
Visual exploration of free-space,|
`A Chinese perspective on international variations in accounting'|
"Management accounting in Latin America",|
Improbable views|
Articulated body motion capture by annealled particle filtering|
Real-time tracking of surfaces with structured light|
Robust Contour Tracking in Echocardiographic Sequences|
Interactive foreground extraction using iterated graph cuts|
Robust Estimation of Surface Curvature from Deformation of Apparent Contours|
Planning Planar Grasps of Smooth Contours|
A Probabilistic Background Model for Tracking|
Statistical background modelling for tracking with a virtual camera|
A radial basis function artificial neural network test for ARCH",|
Articulated motion capture by annealed particle filtering|
Statistical Foreground Modelling for Object Localisation|
Visual Reconstruction|
Exploiting shadows in a visual, hand-driven user interface|
Localizing discontinuities using weak continuity constraints,|
International Symposium on Robotics,|
Sequential Monte Carlo Fusion of Sound and Vision for Speaker Tracking|
Shape from specularity: Computation and psychophysics|
The information available to a moving observer from specularities|
Geometry from specularity|
Visual reconstruction| MIT press,. 
Caging 2D bodies by one-parameter two-fingered gripping systems|
Probabilistic exemplar-based tracking in a metric space|
On the projective normalisation of planar shape,|
Statistical mosaics for tracking|
Eliciting qualitative structure from image curve deformations,|
\An analysis of emergency room wait time issues via computer simulation,"|
Probabilistic tracking with exemplar in a metric space|
Active vision|
Visually Guided Grasping in 3D|
Caging planar bodies by one-parameter two fingered gripping systems,|
Visual short-term memory in the hearing and the deaf|
Geometry of specularities|
Probabilistic Tracking in a Metrix Space|
Object localisation by bayesian correlation|
Shape from Specularities: Computation and Psychophysics,|
`Forecast error bounds by stochastic simulation',|
`La contabilidad creativa',|
`The ethics of creative accounting - some Spanish evidence',|
"The ethics of creative accounting" included in `Ethical issues in accounting' editors|
Computational modelling of hand-eye coordination|
Weak Continuity Constraints Generate Uniform Scale-Space Descriptions of Plane Curves|
Learning multiclass dynamics, in `Advances in Neural Information Processing Systems',|
Credibility and the Eectiveness of Ination Targeting Regimes,~|
editors|
Grasping the Apparent Contour|
Real-time Visual Tracking for Surveillance and Path Planning|
Determining Facial Expressions in Real-Time|
Consensus scoring for ligand/protein interactions|
On the projective normalization of planar shape|
The least--disturbance principle and weak constraints|
Caging Planar Objects with a Three-Finger One-Parameter Gripper|
Visual navigation around curved obstacles|
"A Multi-Regional CGE Model of Tourism in Spain"| Paper prepared for the European Trade Study Group annual conference,. 
\Time Consistent Mixed Precommitment Macropolicy|
Learnung multi-class dynamics|
Contour tracking by stochastic propagation of condition density," pp| 343-356. 
Shape from texture: the homogeneity hypothesis|
An optimal approach to sar image segmentation and classification|
Optimal approach to sar image segmentation and classification|
Applying visual curve tracking to graphics|
Probabilistic exclusion and partitioned sampling for multiple object tracking|",. 
Rapid summarization and browisng of video sequences,|
Surface description from stereo and shading|
Computing lightness|
MRI heart image: Original image on the top left, edge image on the top right, distance map on the bottom|
Social integration and social Support| Ch.  15. 
Mites and thrips as bacterial and fungal vectors between plant tissue cultures|
Evaluating quantitative measures of grammatical complexity in spontaneous speech samples|
A probabilistic contour discriminant for object localization|
Some properties of weak continuity constraints and the GNC algorithm|
Detecting specular reflection using lambertian constraints,|
A Radial Basis Function Artificial Neural Network Test for Neglected Nonlinearity|
Articulated motion capture by annealing particle filering|
Accurate, Real-Time, Unadorned Lip Tracking|
Anlisis de autores, citas y revistas de contabilidad en Espaa" Revista Espaola de Financiacin y Contabilidad,|
Why Have UK Consumption Function Broken Down? Discussion Paper 38,|
An efficient and stable level-set method for active contours|
"Contabilidad Creativa" Barcelona: Ediciones Gestin|
