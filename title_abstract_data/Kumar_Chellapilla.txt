Fitness distributions in evolutionary computation: motivation and examples in the continuous domain| Abstract Evolutionary algorithms are, fundamentally, stochastic search procedures.  Each next population is a probabilistic
Verifying Anaconda's expert rating by competing against Chinook: experiments in co-evolving a neural checkers player| Abstract Since the early days of arti5cial intelligence, there has been interest in having a computer teach itself how to play a game of skill, like checkers, at a level that is competitive with human experts.  To be truly noteworthy, such e7orts should minimize the amount of human intervention in the learning process.  Recently, co-evolution has been used to evolve a neural network (called Anaconda) that, when coupled with a minimax search, can evaluate checker-boards and play to the level of a human expert, as indicated by its rating of 2045 on an international web site for playing checkers.  The neural network uses only the location, type, and number of pieces on the board as input.  No other features that would require human expertise are included.  Experiments were conducted to verify the neural network's expert rating by competing it in 10 games against a "novice-level" version of Chinook, a world-champion checkers program.  The neural network had 2 wins, 4 losses, and 4 draws in the 10-game match.  Based on an estimated rating of Chinook at the novice level, the results corroborate Anaconda's expert rating. 
Two new mutation operators for enhanced search and optimization in evolutionary programming| ABSTRACT Evolutionary programming (EP) has been successfully applied to many parameter optimization problems.  We propose a mean mutation operator, consisting of a linear combination of Gaussian and Cauchy mutations.  Preliminary results indicate that both the adaptive and non-adaptive versions of the mean mutation operator are capable of producing solutions that are as good as, or better than those produced by Gaussian mutations alone.  The success of the adaptive operator could be attributed to its ability to self-adapt the shape of the probability density function that generates the mutations during the run. 
Evolving Neural Networks to Play Checkers without Relying on Expert Knowledge| Abstract An experiment was conducted where neural networks compete for survival in an evolving population based on their ability to play checkers.  More specifically, multilayer feedforward neural networks were used to evaluate alternative board positions and games were played using a minimax search strategy.  At each generation, the extant neural networks were paired in competitions and selection was used to eliminate those that performed poorly relative to other networks.  Offspring neural networks were created from the survivors using random variation of all weights and bias terms.  After a series of 250 generations, the best-evolved neural network was played against human opponents in a series of 90 games on an internet website.  The neural network was able to defeat two expert-level players and played to a draw against a master.  The final rating of the neural network placed it in the "Class A" category using a standard rating system.  Of particular importance in the design of the experiment was the fact that no features beyond the piece differential were given to the neural networks as a priori knowledge.  The process of evolution was able to extract all of the additional information required to play at this level of competency.  It accomplished this based almost solely on the feedback offered in the final aggregated outcome of each game played (i. e. , win, lose, or draw).  This procedure stands in marked contrast to the typical artifice of explicitly injecting expert knowledge into a game-playing program. 
Evolving an expert checkers playing program without using human expertise| time.  The results suggest that the principles of Darwinian evolution may be usefully applied to solving problems that have not yet been solved by human expertise. 
Investigating the Influence of Depth and Degree of Genotypic Change on Fitness in Genetic Programming| Abstract In this paper we investigate the influence of (a) the amount of variation generated in the genotype and (b) the depth of application of variation operators on the offspring fitness in genetic programming.  Simulation results on three common test problems indicate that for certain features of the fitness distribution the location of the variation may play as important a role as the choice of the applied operators. 
Evolutionary Computation with Extinction: Experiments and Analysis| Abstract- Under a species-level abstraction of classical evolutionary programming, the standard tournament selection model is not appropriate.  When viewed in this manner, it is more appropriate to consider two modes of life histories: background evolution and extinction.  The utility of this approach as an optimization procedure is evaluated on a series of test functions relative to the performance of classical evolutionary programming and fast evolutionary programming.  The results indicate that on some smooth, convex landscapes and over noisy, highly multimodal landscapes, extinction evolutionary programming can outperform classical and fast evolutionary programming.  On other landscapes, however, extinction evolutionary programming performs considerably worse than classical and fast evolutionary programming.  Potential reasons for this variability in performance are indicated. 
Evolving computer programs without subtree crossover|
Fitness distributions: Tools for designing efficient evolutionary computations|
Combining mutation operators in evolutionary programming|
Evolution, Neural Networks, Games, and Intelligence|
Evolutionary programming with tree mutations: Evolving computer programs without crossover|
Data mining using genetic programming: the implications of parsimony on generalization error|
"Gaining Insight into Evolutionary Programming Through Landscape Visualization: An Investigation into IIR|
Simulated Sequencing by Hybridization Using Evolutionary Programming",|
Fitness distributions in evolutionary computation: Analysis of local extrema in the continuous domain|
Inductive reasoning and bounded rationality reconsidered|
Revisiting Evolutionary Programming,|
Multiple sequence alignment using evolutionary programming|
Co-evolving checkers playing programs using only win, lose, or draw|
Building Segmentation Based Human-Friendly Human Interactive Proofs (HIPs),"|
Gaining Insight into Evolutionary Programming Through Landscape Visualization: An Investigation into IIR Filtering|
Evolving reduced parameter bilinear models for time series prediction using fast evolutionary programming|
Exploring Self-Adaptive Methods to Improve the Efficiency of Generating Approximate Solutions to Travelling Salesman Problems Using Evolutionary Programming|
