Detecting Faces in Images: A Survey| However, many reported methods assume that the faces in an image or an image sequence have been identified and localized.  To build fully automated systems that analyze the information contained in face images, robust and efficient face detection algorithms are required.  Given a single image, the goal of face detection is to identify all image regions which contain a face regardless of its three-dimensional position, orientation, and lighting conditions.  Such a problem is challenging because faces are nonrigid and have a high degree of variability in size, shape, color, and texture.  Numerous techniques have been developed to detect faces in a single image, and the purpose of this paper is to categorize and evaluate these algorithms.  We also discuss relevant issues such as data collection, evaluation metrics, and benchmarking.  After analyzing these algorithms and identifying their limitations, we conclude with several promising directions for future research. 
A SNoW-Based Face Detector| Abstract A novel learning approach for human face detection using a network of linear units is presented.  The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features.  A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces.  Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others.  Furthermore, learning and evaluation using the SNoW-based method are significantly more ecient than with other methods. 
Face Detection Using Multimodal Density Models| We present two methods using multimodal density models for face detection in gray-level images.  One generative method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction.  The parameters of the mixture model are estimated using the EM algorithm.  A face is detected if the probability of an input sample is above a predefined threshold.  The other discriminative method uses Kohonen's self-organizing map for clustering, Fisher's linear discriminant to find an optimal projection for pattern classification, and a Gaussian distribution to model the class-conditional density function of the projected samples for each class.  The parameters of the class-conditional density functions are maximum likelihood estimates, and the decision rule is also based on maximum likelihood.  A wide range of face images including ones in different poses, with different expressions and under different lighting conditions, is used as the training set to capture variations of the human face.  Our methods have been tested on three data sets with a total of 225 images containing 871 faces.  Experimental results on the first two data sets show that our generative and discriminative methods perform as well as the best methods in the literature, yet have fewer false detections.  Meanwhile, both methods are able to detect faces of nonfrontal views and under more extreme lighting in the third data set.  c # 2001 Elsevier Science (USA)
View-Based 3D Object Recognition Using SNoW| ABSTRACT This paper describes a novel view-based algorithm for 3D object recognition using a network of linear units.  The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features.  We use the pixel-level representation in the experiments and compare the performance of SNoW with Support Vector Machines and nearest neighbor methods on 3D object recognition using the 100 objects in the Columbia Image Object Database (COIL100).  Experimental results show that SNoW-based method outperform SVM-based system in terms of recognition rate and the computational cost involved in learning.  The empirical results also provide insight for practical and theoretical considerations on view-based methods for 3D object recognition. 
Prediction of the Pressure Drop Through Micromachined Particle Filters| ABSTRACT Micro-filters are fabricated using MEMS technology, and both measurements and numerical calculations are carried out in order to estimate the power requirement in a micron-size particle collection process using the microfilter.  In order to numerically predict the pressure drop through the micro-filter, we focus on the characterization of the geometrical factors, such as internal profile of the filtering hole and the hole dimension.  The surface slip is also considered.  It is found that the pressure drop through the micro-filter is strongly dependent upon the internal profile of the filtering hole and that the surface-slip is not dominant in determining the pressure drop.  When the size of the hole is accurately measured and the internal profile of the filtering hole is correctly modeled, the calculated pressure drop shows good agreement with the measured pressure drop.  From the numerical calculation, a formula is proposed which can accurately predict the pressure drop through the micro-filter. 
Clustering Appearances of Objects Under Varying Illumination Conditions| Abstract We introduce two appearance-based methods for clustering a set of images of 3-D objects, acquired under varying illumination conditions, into disjoint subsets corresponding to individual objects.  The first algorithm is based on the concept of illumination cones.  According to the theory, the clustering problem is equivalent to finding convex polyhedral cones in the high-dimensional image space.  To efficiently determine the conic structures hidden in the image data, we introduce the concept of conic affinity which measures the likelihood of a pair of images belonging to the same underlying polyhedral cone.  For the second method, we introduce another affinity measure based on image gradient comparisons.  The algorithm operates directly on the image gradients by comparing the magnitudes and orientations of the image gradient at each pixel.  Both methods have clear geometric motivations, and they operate directly on the images without the need for feature extraction or computation of pixel statistics.  We demonstrate experimentally that both algorithms are surprisingly effective in clustering images acquired under varying illumination conditions with two large, well-known image data sets. 
Visual Tracking and Recognition Using Probabilistic Appearance Manifolds| Abstract This paper presents an algorithm for modelling, tracking, and recognizing human faces in video sequences within one integrated framework.  Conventional video-based face recognition systems have usually been embodied with two independent components: the tracking and recognition modules.  In contrast, our algorithm emphasizes an algorithmic architecture that tightly couples these two components within one single framework.  This is accomplished through a novel appearance model which is utilized simultaneously by both modules, even with their disparate requirements and functions.  The complex nonlinear appearance manifold of each registered person is partitioned into a collection of sub-manifolds where each models the face appearances of the person in nearby poses.  The submanifold is approximated by a low-dimensional linear subspace computed by principal component analysis using images sampled from training video sequences.  The connectivity between the submanifolds is modeled as transition probabilities between pairs of submanifolds, and these are learned directly from training video sequences.  The integrated task of tracking and recognition is formulated as a maximum a posteriori estimation problem.  Within our framework, the tracking and recognition modules are complementary to each other, and the capability and performance of one are enhanced by the other.  Our approach contrasts sharply with more rigid conventional approaches in which these two modules work independently and in sequence.  We report on a number of experiments and results that demonstrate the robustness, effectiveness and stability of our algorithm. 
Video-Based Face Recognition Using Probabilistic Appearance Manifolds| Abstract This paper presents a novel method to model and recognize human faces in video sequences.  Each registered person is represented by a low-dimensional appearance manifold in the ambient image space.  The complex nonlinear appearance manifold expressed as a collection of subsets (named pose manifolds), and the connectivity among them.  Each pose manifold is approximated by an affine plane.  To construct this representation, exemplars are sampled from videos, and these exemplars are clustered with a K-means algorithm; each cluster is represented as a plane computed through principal component analysis (PCA).  The connectivity between the pose manifolds encodes the transition probability between images in each of the pose manifold and is learned from a training video sequences.  A maximum a posteriori formulation is presented for face recognition in test video sequences by integrating the likelihood that the input image comes from a particular pose manifold and the transition probability to this pose manifold from the previous frame.  To recognize faces with partial occlusion, we introduce a weight mask into the process.  Extensive experiments demonstrate that the proposed algorithm outperforms existing frame-based face recognition methods with temporal voting schemes. 
Corresponding author: Mark| Received Abstract.  The field emission of carbon nanotubes (CNTs) synthesized from different sources is investigated.  Comparisons are made between graphite with Ni metal as catalyst and polycyclic aromatic hydrocarbon as precursor in arc discharge.  Key parameters are also evaluated to obtain high quality and high yield CNT for application of field emission display.  Cathode deposits are examined using SEM and HRTEM to determine microstructure.  Raman spectroscopy is also used to study carbon structure.  Electron field emission characteristic is measured with the diode method.  Microstructural investigation provides evidence that both metal catalyst and precursor not only can be used to synthesize CNTs but also to enhance their production rate.  From field emission measurement, the lowest onset field is about 1. 0 V/mm and can be attributed to highly sharp tips and high density of CNTs.  Based on microstructure characterization and field emission measurement, influence on field emission of CNT synthesized from different sources is discussed. 
Face Detection Using Mixtures of Linear Subspaces| Abstract We present two methods using mixtures of linear subspaces for face detection in gray level images.  One method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction.  The parameters of the mixture model are estimated using an EM algorithm.  A face is detected if the probability of an input sample is above a predefined threshold.  The other mixture of subspaces method uses Kohonen's self-organizing map for clustering and Fisher Linear Discriminant to find the optimal projection for pattern classification, and a Gaussian distribution to model the class-conditional density function of the projected samples for each class.  The parameters of the class-conditional density functions are maximum likelihood estimates and the decision rule is also based on maximum likelihood.  A wide range of face images including ones in different poses, with different expressions and under different lighting conditions are used as the training set to capture the variations of human faces.  Our methods have been tested on three sets of 225 images which contain 871 faces.  Experimental results on the first two datasets show that our methods perform as well as the best methods in the literature, yet have fewer false detects. 
Gender Classification with Support Vector Machines| Abstract Support Vector Machines (SVMs) are investigated for visual gender classification with low resolution "thumbnail" faces (21-by-12 pixels) processed from 1,755 images from the FERET face database.  The performance of SVMs (3. 4% error) is shown to be superior to traditional pattern
Simultaneous Localization and Mapping using Multiple View Feature Descriptors| Abstract--- We propose a vision-based SLAM algorithm incorporating feature descriptors derived from multiple views of a scene, incorporating illumination and viewpoint variations.  These descriptors are extracted from video and then applied to the challenging task of wide baseline matching across significant viewpoint changes.  The system incorporates a single camera on a mobile robot in an extended Kalman filter framework to develop a 3D map of the environment and determine egomotion.  At the same time, the feature descriptors are generated from the video sequence, which can be used to localize the robot when it returns to a mapped location.  The kidnapped robot problem is addressed by matching descriptors without any estimate of position, then determining the epipolar geometry with respect to a known position in the map. 
Adaptive Discriminative Generative Model for Object Tracking| Abstract This paper presents an adaptive discriminative generative model that generalizes the conventional Fisher Linear Discriminant algorithm and renders a proper probabilistic interpretation.  Within the context of object tracking, we aim to find a discriminative generative model that best separates the target from the background.  We present a computationally efficient algorithm to constantly update this discriminative model as time progresses.  While most tracking algorithms operate on the premise that the object appearance or ambient lighting condition does not significantly change as time progresses, our method adapts a discriminative generative model to reflect appearance variation of the target and background, thereby facilitating the tracking task in ever-changing environments.  Numerous experiments show that our method is able to learn a discriminative generative model for tracking target objects undergoing large pose and lighting changes. 
Face Detection Using a Mixture of Factor Analyzers| ABSTRACT We present a probabilistic method to detect human faces using a mixture of factor analyzers.  One characteristic of this mixture model is that it concurrently performs clustering and, within each cluster, local dimensionality reduction.  A wide range of face images including ones in different poses, with different expressions and under different lighting conditions are used as the training set to capture the variations of human faces.  In order to fit the mixture model to the sample face images, the parameters are estimated using an EM algorithm.  Experimental results show that faces in different poses, with different facial expressions, and under different lighting conditions are accurately detected by our method. 
A linear-time algorithm for computing inversion distance between signed permutations with an experimental study, 365{376|
Detecting Human Faces in Color Images|
Gaussian mixture model for human skin color and its application in image and video databases|
Measurement of Drape Coefficients of Fabrics and Description of Those Hanging Shapes, Part 3: The Effect of Fabric Parameters on Drape Shapes",|
Recognizing Hand Gesture Using Motion Trajectories|
A fast linear-time algorithm for inversion distance with an experimental comparison|
Learning to recognize 3D objects|
New S function series and non-compact Lie groups|
Learning Gender with Support Faces|
Kernel Eigenfaces vs| Kernel Fisherfaces: Face Recognition Using Kernel Methods. 
Face detection using mixtures of linear subspaces",|
Sex with Support Vector Machines|
Recognizing hand gestures using motion trajectories,|
Segmentation of measured point data using a parametric quadric surface approximation|
Learning to Recognize 3D Objects with SNoW|
Extracting Gestural Motion Trajectories|
The design of due date assignment model and the determination of flow control parameters for the wafer fabrication factories|
Time-resolved spectroscopy of wild-type and mutant green fluorescent proteins reveals excited state deprotonation consistent with fluorophore-protein interactions|
When the brain changes its mind: Interocular grouping during binocular rivalry|
Dressing Animated Synthetic Actors with Complex Deformable Clothes,|
Moving average conditional heteroskedastic processes|
Hough transform modified by line connectivity and line thickness|
\Meta-Analysis Using Multilevel Models with an Application to the Study of Class Size Effects|
Extraction of 2D Motion Trajectories and Its Application to Hand Gesture Recognition|
Learning to Recognize Objects|
High-performance algorithm engineering for gene-order phylogenies|
GRAPPA: a highperformance computational tool for phylogeny reconstruction from gene-order data|
Energy transfer in photosystem I of cyanobacteria Synechococcus elongatus: model study with structure-based semi-empirical Hamiltonian and experimental spectral density,|
Automated measurement of alpha, beta, sigma and theta burst charasteristics|
Coherent noise in marine seismic data:|
Non-informative priors for the two sample normal problem|
Detecting face in images: a survey|
Completion of the 1990s National Land Cover Data set for the conterminous United States from Landsat Thematic Mapper data and Ancillary data sources|
Influences of Mixing Methods on the Microstructure and Rheological Behavior of Cement Paste,|
Multiple View Feature Descriptors from Image Sequences via Kernel Principal Component Analysis|
Nestin expression in hair follicle sheath progenitor cells|
Biosensor measurement of the interaction kinetics between insulin-like growth factors and their binding proteins|
