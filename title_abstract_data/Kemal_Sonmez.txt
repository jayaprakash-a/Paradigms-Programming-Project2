Combining Words and Speech Prosody for Automatic Topic Segmentation| ABSTRACT We present a probabilistic model that uses both prosodic and lexical cues for the automatic segmentation of speech into topic units.  The approach combines hidden Markov models, statistical language models, and prosody-based decision trees.  Lexical information is obtained from a speech recognizer, and prosodic features are extracted automatically from speech waveforms.  We evaluate our approach on the Broadcast News corpus, using standard evaluation metrics.  Results show that the prosodic model alone outperforms the word-based segmentation method.  Furthermore, we achieve an additional reduction in error by combining the prosodic and wordbased knowledge sources. 
CONSONANT DISCRIMINATION IN ELICITED AND SPONTANEOUS SPEECH: A CASE FOR SIGNAL-ADAPTIVE FRONT ENDS IN ASR| ABSTRACT The constant frame length in typical ASR front ends is too long to capture transient phenomena in speech, such as stop bursts.  However, current HMM systems have consistently outperformed systems based solely on non-uniform units.  This work investigates an approach to "add back" such transient information to a speech recognizer, without losing the robustness of the standard acoustic models.  We demonstrate a set of phonetically-motivated acoustic features that discriminate a preliminary test set of highly ambiguous voiceless stops in CV contexts.  The features are automatically computed from data that had been hand-marked for consonant burst location and voicing onset (extension to automatic marking is also proposed).  Two corpora are processed using a parallel set of features: conversational speech over the telephone (Switchboard), and a corpus of carefully elicited speech.  The latter provides an upper bound on discrimination, and allows for comparison of feature usage across speaking style.  We explore data-driven approaches to obtaining variable-length time-localized features compatible with an HMM statistical framework.  We also suggest techniques for extension to automatic annotation of burst location, for computation of features at such points, and for augmentation of an HMM system with the added information. 
SPEAKER RECOGNITION USING PROSODIC AND LEXICAL FEATURES| ABSTRACT Conventional speaker recognition systems identify speakers by using spectral information from very short slices of speech.  Such systems perform well (especially in quiet conditions), but fail to capture idiosyncratic longer-term patterns in a speaker's habitual speaking style, including duration and pausing patterns, intonation contours, and the use of particular phrases.  We investigate the contribution of modeling such prosodic and lexical patterns, on performance in the NIST 2003 Speaker Recognition Evaluation extended data task.  We report results for (1) systems based on individual feature types alone, (2) systems in combination with a state-of-the-art frame-based baseline system, and (3) an all-system combination.  Our results show that certain longer-term stylistic features provide powerful complementary information to both frame-level cepstral features and to each other.  Stylistic features thus significantly improve speaker recognition performance over conventional systems, and offer promise for a variety of intelligence and security applications. 
THE SRI MARCH 2000 HUB-5 CONVERSATIONAL SPEECH TRANSCRIPTION SYSTEM| ABSTRACT We describe SRI's large vocabulary conversational speech recognition system as used in the March 2000 NIST Hub-5E evaluation.  The system performs four recognition passes: (1) bigram recognition with phone-loop-adapted, within-word triphone acoustic models, (2) lattice generation with transcription-mode-adapted models, (3) trigram lattice recognition with adapted cross-word triphone models, and (4) N-best rescoring and reranking with various additional knowledge sources.  The system incorporates two new kinds of acoustic model: triphone models conditioned on speaking rate, and an explicit joint model of within-word phone durations.  We also obtained an unusually large improvement from modeling crossword pronunciation variants in "multiword" vocabulary items.  The languagemodel (LM) was enhanced with an "anti-LM" representing acoustically confusable word sequences.  Finally, we applied a generalized ROVER algorithm to combine the N-best hypotheses from several systems based on different acoustic models. 
Building an ASR System for Noisy Environments: SRI's 2001 SPINE Evaluation System| ABSTRACT We describe SRI's recognition system as used in the 2001 DARPA Speech in Noisy Environments (SPINE) evaluation.  The SPINE task involves recognition of speech in simulated military environments.  The task had some unique challenges, including segmentation of foreground speech from noisy background, the need for robust acoustic models to handle noisy speech, and development of language models from limited training data.  In developing the SRI evaluation system for this task, we addressed each of these challenges using a combination of state-of-the-art techniques, including several types of feature normalization,
NONLINEAR DISCRIMINANT FEATURE EXTRACTION FOR ROBUST TEXT-INDEPENDENT SPEAKER RECOGNITION| E Cet article propose une methode basee sur l'analyse discriminative non-lineaire pour extraire et selectionner un ensemble de vecteurs acoustiques utilises pour l'identification de locuteurs.  L'approche consiste ` a mesurer et grouper un grand nombre de mesures acoustiques (correspondant ` a plusieurs trames de donnees consecutives), et ` areduire la dimensionalite du vecteur resultant au moyen d'un reseau de neurones artificielles.  Le critre utilise pour optimiser les poids du reseau consiste ` a maximiser une mesure de la separation entre les locuteurs d'une base de donnees d'apprentissage.  L'architecture du reseau est telle que l'une de ses couches intermediaires represente la projection des vecteurs acoustiques d'entree sur un espace de dimensionalite inferieure.  Aprs la phase d'apprentissage, cette partie du reseau peut etre isolee et utilisee pour projeter les vecteurs acoustiques d'une base de donnees de test.  Les vecteurs acoustiques projetes peuvent alors ^ etre classifies.  Combineun classificateur cepstral, le classificateur utilisant ces nouveaux vecteurs acoustiques reduit de 15% le taux d'erreur de classification de la base de donnees definie par NIST en 1997 pour l'evaluation des systmes de reconnaissance du locuteur.  ABSTRACT We study a nonlinear discriminant analysis (NLDA) technique that extracts a speaker-discriminant feature set.  Our approach is to train a multilayer perceptron (MLP) to maximize the separation between speakers by nonlinearly projecting a large set of acoustic features (e. g. , several frames) to a lower-dimensional feature set.  The extracted features are optimized to discriminate between speakers and to be robust to mismatched training and testing conditions.  We train the MLP on a development set and apply it to the training and testing utterances.  Our results show that by combining the NLDA-based system with a state of the art cepstrum-based system we improve the speaker verification performance on the 1997 NIST Speaker Recognition Evaluation set by 15% in average compared with our cepstrum-only system. 
PROSODIC FEATURES FOR AUTOMATIC TEXT-INDEPENDENT EVALUATION OF DEGREE OF NATIVENESS FOR LANGUAGE LEARNERS| ABSTRACT Predicting the degree of nativeness of a student's utterance is an important issue in computer-aided language learning.  This task has been addressed by many studies focusing on the segmental assessment of the speech signal.  To achieve improved correlations between human and automatic nativeness scores, other aspects of speech should also be considered, such as prosody.  The goal of this study is to evaluate the use of prosodic information to help predict the degree of nativeness of pronunciation, independent of the text.  A supervised strategy based on human grades is used in an attempt to select promising features for this task.  Preliminary results show improvements in the correlation between human and automatic scores. 
SRI'S 2004 NIST SPEAKER RECOGNITION EVALUATION SYSTEM| ABSTRACT This paper describes our recent efforts in exploring longerrange features and their statistical modeling techniques for speaker recognition.  In particular, we describe a system that uses discriminant features from cepstral coefficients, and systems that use discriminant models from word n-grams and syllable-based NERF n-grams.  These systems together with a cepstral baseline system are evaluated on the 2004 NIST speaker recognition evaluation dataset.  The effect of the development set is measured using two different datasets, one from Switchboard databases and another from the FISHER database.  Results show that the difference between the development and evaluation sets affects the performance of the systems only when more training data is available.  Results also show that systems using longer-range features combined with the baseline result in about a 31% improvement with 1-side training over the baseline system and about a 61% improvement with 8-side training over the baseline system. 
EVALUATION OF SPEAKER'S DEGREE OF NATIVENESS USING TEXT-INDEPENDENT PROSODIC FEATURES| Abstract Giving feedback on the degree of nativeness of a student's speech is an important aspect of computer-aided language learning.  This task has been addressed by many studies focusing on the segmental assessment of the speech signal.  To better model human nativeness scores, other aspects of speech should also be considered, such as prosody.  This study examines the use of prosodic information to evaluate the degree of nativeness of student pronunciation, independent of the text.  Supervised strategies based on human grades are used in an attempt to select promising features for this task.  Previous results obtained with non-native speakers showed improvements in the correlation between human and automatic scores.  New strategies were evaluated with tests including native and non-native speakers.  Specific features based on durations, namely for intra-sentence pauses, revealed potential use for further improvements. 
Modeling Duration Patterns for Speaker Recognition| Abstract We present a method for speaker recognition that uses the duration patterns of speech units to aid speaker classification.  The approach represents each word and/or phone by a feature vector comprised of either the durations of the individual phones making up the word, or the HMM states making up the phone.  We model the vectors using mixtures of Gaussians.  The speaker specific models are obtained through adaptation of a "background" model that is trained on a large pool of speakers.  Speaker models are then used to score the test data; they are normalized by subtracting the scores obtained with the background model.  We find that this approach yields significant perfomance improvement when combined with a state-of-the-art speaker recognition system based on standard cepstral features.  Furthermore, the improvement persists even after combination with lexical features.  Finally, the improvement continues to increase with longer test sample durations, beyond the test duration at which standard system accuracy level off. 
MODELING DYNAMIC PROSODIC VARIATION FOR SPEAKER VERIFICATION| ABSTRACT Statistics of frame-level pitch have recently been used in speaker recognition systems with good results [1, 2, 3].  Although they convey useful long-term information about a speaker's distribution of f 0 values, such statistics fail to capture information about local dynamics in intonation that characterize an individual's speaking style.  In this work, we take a first step toward capturing such suprasegmental patterns for automatic speaker verification.  Specifically, we model the speaker's f 0 movements by fitting a piecewise linear model to the f 0 track to obtain a stylized f 0 contour.  Parameters of the model are then used as statistical features for speaker verification.  We report results on 1998 NIST speaker verification evaluation.  Prosody modeling improves the verification performance of a cepstrum-based Gaussian mixture model system (as measured by a task-specific Bayes risk) by 10%. 
Modelling dynamic prosodic variation for speaker verification|
Landmark-based speech recognition: report of the 2004 Johns Hopkins summer workshop|
Modeling NERFs for Speaker Recognition",|
Combining standard and throat microphones for robust speech recognition",|
Conditional distribution learning with neural networks and its application to channel equalization|
Relationship between acute pyelonephritis, renal scarring, and vesicoureteral reflux| Results of a coordinated research project. 
Machine learning techniques for the identification of cues for stop place|
