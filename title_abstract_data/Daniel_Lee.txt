Algorithms for Non-negative Matrix Factorization| Abstract Non-negative matrix factorization (NMF) has previously been shown to be a useful decomposition for multivariate data.  Two different multiplicative algorithms for NMF are analyzed.  They differ only slightly in the multiplicative factor used in the update rules.  One algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence.  The monotonic convergence of both algorithms can be proven using an auxiliary function analogous to that used for proving convergence of the ExpectationMaximization algorithm.  The algorithms can also be interpreted as diagonally rescaled gradient descent, where the rescaling factor is optimally chosen to ensure convergence. 
Avrora: Scalable Sensor Network Simulation with Precise Timing| ABSTRACT Simulation can be an important step in the development of software for wireless sensor networks and has been the subject of intense research in the past decade.  While most previous efforts in simulating wireless sensor networks have focused on protocol-level issues utilizing models of the software implementation, a significant challenge remains in precisely measuring time-dependent properties such as radio channel utilization.  One promising approach, first demonstrated by ATEMU, is to simulate the behavior of sensor network programs at the machine code level in a cycle-accurate way, but poor performance has so far limited its scalability.  In this paper we present Avrora, a cycle-accurate instruction-level sensor network simulator which scales to networks of up to 10,000 nodes and performs as much as 20 times faster than previous simulators with equivalent accuracy, handling as many as 25 nodes in real-time.  We show how an event queue can enable efficient instruction-level simulation of microcontroller programs and allow the hidden parallelism in finegrained sensor network simulations to be extracted, once two core synchronization problems are identified and solved.  Avrora's ability to measure detailed time-critical phenomena can shed new light on design issues for large-scale sensor networks. 
The Autapse: A Simple Illustration of Short-Term Analog Memory Storage by Tuned Synaptic Feedback| Abstract According to
Learning in Intelligent Embedded Systems| Abstract Information processing capabilities of embedded systems presently lack the robustness and rich complexity found in biological systems.  Endowing artificial systems with the ability to adapt to changing conditions requires algorithms that can rapidly learn from examples.  We demonstrate the application of one such learning algorithm on an inexpensive robot constructed to perform simple sensorimotor tasks.  The robot learns to track a particular object by discovering the salient visual and auditory cues unique to that object.  The system uses a convolutional neural network to combine color, luminance, motion, and auditory information.  The weights of the networks are adjusted using feedback from a teacher to reflect the reliability of the various input channels in the surrounding environment.  We also discuss how unsupervised learning can discover features in data without external interaction.  An unsupervised algorithm based upon nonnegative matrix factorization is able to automatically learn the different parts of objects.  Such a parts-based representation of data is crucial for robust object recognition. 
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION The following paper was originally published in the Proceedings of the Embedded Systems Workshop| Abstract Information processing capabilities of embedded systems presently lack the robustness and rich complexity found in biological systems.  Endowing artificial systems with the ability to adapt to changing conditions requires algorithms that can rapidly learn from examples.  We demonstrate the application of one such learning algorithm on an inexpensive robot constructed to perform simple sensorimotor tasks.  The robot learns to track a particular object by discovering the salient visual and auditory cues unique to that object.  The system uses a convolutional neural network to combine color, luminance, motion, and auditory information.  The weights of the networks are adjusted using feedback from a teacher to reflect the reliability of the various input channels in the surrounding environment.  We also discuss how unsupervised learning can discover features in data without external interaction.  An unsupervised algorithm based upon nonnegative matrix factorization is able to automatically learn the different parts of objects.  Such a parts-based representation of data is crucial for robust object recognition. 
Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines| Abstract We derive multiplicative updates for solving the nonnegative quadratic programming problem in support vector machines (SVMs).  The updates have a simple closed form, and we prove that they converge monotonically to the solution of the maximum margin hyperplane.  The updates optimize the traditionally proposed objective function for SVMs.  They do not involve any heuristics such as choosing a learning rate or deciding which variables to update at each iteration.  They can be used to adjust all the quadratic programming variables in parallel with a guarantee of improvement at each iteration.  We analyze the asymptotic convergence of the updates and show that the coefficients of non-support vectors decay geometrically to zero at a rate that depends on their margins.  In practice, the updates converge very rapidly to good classifiers. 
Multiplicative Updates for Classification by Mixture Models| Abstract We investigate a learning algorithm for the classification of nonnegative data by mixture models.  Multiplicative update rules are derived that directly optimize the performance of these models as classifiers.  The update rules have a simple closed form and an intuitive appeal.  Our algorithm retains the main virtues of the Expectation-Maximization (EM) algorithm---its guarantee of monotonic improvement, and its absence of tuning parameters---with the added advantage of optimizing a discriminative objective function.  The algorithm reduces as a
Learning Semitic Vocalizations with Hidden Markov Models| Abstract Semitic languages present a special problem for natural language processing in that most of the vowels are omitted from written prose.  Thus a natural and often necessary preprocessing step for Semitic text is vocalization, or "pointing", of the text: filling in the vowels and diacritical marks.  Unvocalized Hebrew contains many more ambiguities than English text; conversely, vocalized Hebrew is considerably less ambiguous than English.  The pointed text could then be used directly or fed into parsers, translators, or text-to-speech engines.  This paper demonstrates that hidden Markov models may be a useful tool for automatic vocalizations of Semitic texts. 
Statistical Signal Processing with Nonnegativity Constraints| Abstract Nonnegativity constraints arise frequently in statistical learning and pattern recognition.  Multiplicative updates provide natural solutions to optimizations involving these constraints.  One well known set of multiplicative updates is given by the ExpectationMaximization algorithm for hidden Markov models, as used in automatic speech recognition.  Recently, we have derived similar algorithms for nonnegative deconvolution and nonnegative quadratic programming.  These algorithms have applications to low-level problems in voice processing, such as fundamental frequency estimation, as well as high-level problems, such as the training of large margin classifiers.  In this paper, we describe these algorithms and the ideas that connect them. 
Unsupervised Learning by Convex and Conic Coding| Abstract Unsupervised learning algorithms based on convex and conic encoders are proposed.  The encoders find the closest convex or conic combination of basis vectors to the input.  The learning algorithms produce basis vectors that minimize the reconstruction error of the encoders.  The convex algorithm develops locally linear models of the input, while the conic algorithm discovers features.  Both algorithms are used to model handwritten digits and compared with vector quantization and principal component analysis.  The neural network implementations involve feedback connections that project a reconstruction back to the input layer. 
The Autapse: A Simple Illustration of Short-Term Analog Memory Storage by Tuned Synaptic Feedback| Abstract.  According to a popular hypothesis, short-term memories are stored as persistent neural activity maintained by synaptic feedback loops.  This hypothesis has been formulated mathematically in a number of recurrent network models.  Here we study an abstraction of these models, a single neuron with a synapse onto itself, or autapse.  This abstraction cannot simulate the way in which persistent activity patterns are distributed over neural populations in the brain.  However, with proper tuning of parameters, it does reproduce the continuously graded, or analog, nature of many examples of persistent activity.  The conditions for tuning are derived for the dynamics of a conductance-based model neuron with a slow excitatory autapse.  The derivation uses the method of averaging to approximate the spiking model with a nonspiking, reduced model.  Short-term analog memory storage is possible if the reduced model is approximately linear and if its feedforward bias and autapse strength are precisely tuned. 
The Rectified Gaussian Distribution| Abstract A simple but powerful modification of the standard Gaussian distribution is studied.  The variables of the rectified Gaussian are constrained to be nonnegative, enabling the use of nonconvex energy functions.  Two multimodal examples, the competitive and cooperative distributions, illustrate the representational power of the rectified Gaussian.  Since the cooperative distribution can represent the translations of a pattern, it demonstrates the potential of the rectified Gaussian for modeling pattern manifolds. 
Real Time Voice Processing with Audiovisual Feedback: Toward Autonomous Agents with Perfect Pitch| Abstract We have implemented a real time front end for detecting voiced speech and estimating its fundamental frequency.  The front end performs the signal processing for voice-driven agents that attend to the pitch contours of human speech and provide continuous audiovisual feedback.  The algorithm we use for pitch tracking has several distinguishing features: it makes no use of FFTs or autocorrelation at the pitch period; it updates the pitch incrementally on a sample-by-sample basis; it avoids peak picking and does not require interpolation in time or frequency to obtain high resolution estimates; and it works reliably over a four octave range, in real time, without the need for postprocessing to produce smooth contours.  The algorithm is based on two simple ideas in neural computation: the introduction of a purposeful nonlinearity, and the error signal of a least squares fit.  The pitch tracker is used in two real time multimedia applications: a voice-to-MIDI player that synthesizes electronic music from vocalized melodies, and an audiovisual Karaoke machine with multimodal feedback.  Both applications run on a laptop and display the user's pitch scrolling across the screen as he or she sings into the computer. 
Beyond Gaussian Processes: On the Distributions of Infinite Networks| Abstract A general analysis of the limiting distribution of neural networks is performed, with emphasis on non-Gaussian limits.  We show that with i. i. d.  symmetric stable output weights, the neural functions converge in distribution to symmetric stable processes.  Conditions are also investigated under which Gaussian limits do occur when the weights are noni. i. d.  We discuss some simple classes of stable distributions, and the possibility of learning with such processes. 
The TIGR Gene Indices: analysis of gene transcript sequences in highly sampled eukaryotic species| ABSTRACT While genome sequencing projects are advancing rapidly, EST sequencing and analysis remains a primary research tool for the identification and categorization of gene sequences in a wide variety of species and an important resource for annotation of genomic sequence.  The TIGR Gene Indices (
Dynamic Quality of Service Mapping Framework for Relative Service Differentiation-Aware Media Streaming| Abstract We investigate the source domain's scheme of dynamically and intelligently pre-marking the streaming media packets before entering a DS-domain providing a relative differentiated service.  The pre-marking scheme takes into account the packet content, the price limit for the transport of streaming media, and the trac conditioning agreement.  In this scheme, the sender cooperates with what we call media gateway (MG), which is a special node on the boundaries of the DS-domain.  MG is responsible for meeting the trac conditioning agreement while fully utilizing the received di#erentiated services for the quality of the streaming media.  Our proposed QoS control scheme includes the following components: 1) the relative priority based indexing and categorization of streaming videocontent at the sender and 2) the dynamic feedforward QoS mapping of categorized index to DS grade at the proposed MG.  With the proposed scheme, enhanced quality of streaming media applications is demonstrated. 
Semisupervised alignment of manifolds| Abstract In this paper, we study a family of semisupervised learning algorithms for "aligning" different data sets that are characterized by the same underlying manifold.  The optimizations of these algorithms are based on graphs that provide a discretized approximation to the manifold.  Partial alignments of the data sets---obtained from prior knowledge of their manifold structure or from pairwise correspondences of subsets of labeled examples--are completed by integrating supervised signals with unsupervised frameworks for manifold learning.  As an illustration of this semisupervised setting, we show how to learn mappings between different data sets of images that are parameterized by the same underlying modes of variability (e. g. , pose and viewing angle).  The curse of dimensionality in these problems is overcome by exploiting the low dimensional structure of image manifolds. 
A Neural Network Based Head Tracking System| Abstract We have constructed an inexpensive, video-based, motorized tracking system that learns to track a head.  It uses real time graphical user inputs or an auxiliary infrared detector as supervisory signals to train a convolutional neural network.  The inputs to the neural network consist of normalized luminance and chrominance images and motion information from frame differences.  Subsampled images are also used to provide scale invariance.  During the online training phase, the neural network rapidly adjusts the input weights depending upon the reliability of the different channels in the surrounding environment.  This quick adaptation allows the system to robustly track a head even when other objects are moving within a cluttered background. 
The Nonnegative Boltzmann Machine| Abstract The nonnegative Boltzmann machine (NNBM) is a recurrent neural network model that can describe multimodal nonnegative data.  Application of maximum likelihood estimation to this model gives a learning rule that is analogous to the binary Boltzmann machine.  We examine the utility of the mean field approximation for the NNBM, and describe how Monte Carlo sampling techniques can be used to learn its parameters.  Reflective slice sampling is particularly well-suited for this distribution, and can efficiently be implemented to sample the distribution.  We illustrate learning of the NNBM on a translationally invariant distribution, as well as on a generative model for images of human faces. 
NONNEGATIVE DECONVOLUTION FOR TIME OF ARRIVAL ESTIMATION| ABSTRACT The interaural time difference (ITD) of arrival is a primary cue for acoustic sound source localization.  Traditional estimation techniques for ITD based upon cross-correlation are related to maximum-likelihood estimation of a simple generative model.  We generalize the time difference estimation into a deconvolution problem with nonnegativity constraints.  The resulting nonnegative least squares optimization can be efficiently solved using a novel iterative algorithm with guaranteed global convergence properties.  We illustrate the utility of this algorithm using simulations and experimental results from a robot platform. 
Max--Planck--Institut f ur biologische Kybernetik Max Planck Institute for Biological Cybernetics Technical Report No| TR-110 A kernel view of the dimensionality reduction of manifolds.  Abstract We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods.  Isomap, graph Laplacian eigenmap, and locally linear embedding (LLE) all utilize local neighborhood information to construct a global embedding of the manifold.  We show how all three algorithms can be described as kernel PCA on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples. 
Multiplicative Updates for Large Margin Classifiers| Abstract.  Various problems in nonnegative quadratic programming arise in the training of large margin classifiers.  We derive multiplicative updates for these problems that converge monotonically to the desired solutions for hard and soft margin classifiers.  The updates differ strikingly in form from other multiplicative updates used in machine learning.  In this paper, we provide complete proofs of convergence for these updates and extend previous work to incorporate sum and box constraints in addition to nonnegativity. 
A Network Pump|
Enhanced Fixed and Dynamic Code Assignment Policies for OVSF-CDMA Systems|
A kernel view of the dimensionality reduction of manifolds|
JPEG 2000: Overview, Architecture, and Applications|
VML - the vector markup language|
Learning a Continuous Hidden Variable Model for Binary Data|
