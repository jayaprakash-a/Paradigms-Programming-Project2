A Mixture of Experts Model Exhibiting Prosopagnosia| Abstract A considerable body of evidence from prosopagnosia, a deficit in face recognition dissociable from nonface object recognition, indicates that the visual system devotes a specialized functional area to mechanisms appropriate for face processing.  We present a modular neural network composed of two "expert" networks and one mediating "gate" network with the task of learning to recognize the faces of 12 individuals and classifying 36 nonface objects as members of one of three classes.  While learning the task, the network tends to divide labor between the two expert modules, with one expert specializing in face processing and the other specializing in nonface object processing.  After training, we observe the network's performance on a test set as one of the experts is progressively damaged.  The results roughly agree with data reported for prosopagnosic patients: as damage to the "face" expert increases, the network's face recognition performance decreases dramatically while its object classification performance drops slowly.  We conclude that data-driven competitive learning between two unbiased functional units can give rise to localized face processing, and that selective damage in such a system could underlie prosopagnosia. 
Selective attention in the acquisition of the past tense| Abstract It is well known that children generally exhibit a "Ushaped" pattern of development in the process of acquiring the past tense.  Plunkett & Marchman (
In Search Of Articulated Attractors| Abstract Recurrent attractor networks offer many advantagesover feed
Acquiring the mapping from meaning to sounds| Abstract One of the fundamental difficulties facing a child trying to acquire a language is that the association between meanings and sounds is for the most part an arbitrary one.  In this work, we model this process using a recurrent neural network that is trained to map a set of plan vectors, representing meaning, to associated sequences of phonemes, representing the phonological structure of the surface forms.  We evaluate the role of the similarity structure of the target forms (the adult vocabulary) and the similarity structure of the input forms (the semantic structure) on the evolution of the network's vocabulary.  The model's performance offers a principled account of various phenomena associated with children's early vocabulary development including the difficulty of acquiring synonyms, the appearance of idiosyncratic forms and over-extension errors.  The model makes several unexplored predictions for the developmental profiles of young children acquiring morphology. 
Visual Expertise is a General Skill| Abstract The fusiform face area (FFA) in the ventral temporal lobe has been shown through fMRI studies to selectively respond with high activation to face stimuli, and has been identified as a face specific processing area.  Studies of brain-lesioned subjects with face recognition or object recognition deficits also have often been cited as evidence for face specific processing.  Recent studies, however, have shown evidence that the FFA also responds with high activation to a wide variety of non-face objects if the level of discrimination and the level of expertise are controlled.  Based on these recent results, we hypothesized that the features of faces that the FFA respond to can be useful for discriminating other classes of visually homogeneous stimuli with some tuning through experience.  To test our hypothesis, we trained two groups of feed-forward neural networks on visual classification tasks.  The first group was pretrained on basic level classification of four stimulus classes, including faces.  The second group was pretrained on subordinate level classification on one of the stimulus classes and basic level classification on the other three.  In two experiments that used different criteria to stop pretraining, we show that networks that fully acquire the skill of subordinate level classification consistently show an advantage in learning the new task. 
Learning to Retrieve Information| Abstract Information retrieval differs significantly from function approximation in that the goal is for the system to achieve the same ranking function of documents relative to queries as the user: the outputs of the system relative to one another must be in the proper order.  We hypothesize that a particular rank-order statistic, Guttman's point alienation, is the proper objective function for such a system, and demonstrate its efficacy by using it to find the optimal combination of retrieval experts.  In application to a commercial retrieval system, the combination performs 47% better than any single expert. 
Neighborhood and Position Effects Interact in Naming Latency| Abstract Naming latency studies have recently shown a position-ofirregularity effect (words with early irregularities seem slowed compared to those with late irregularities), for which DualRoute models of reading can account.  Milostan & Cottrell (1998) showed that the initial studies contained a confound between irregularity position and friend/enemy ratio, and that the statistical confound could be captured by connectionist networks which then show the supposed position effect.  This paper presents work to disentangle the position/regularity confound through a subject study and additional connectionist explorations.  The latency data show that, once friend/enemy ratios are controlled for, the supposed position effect is driven entirely by high-enemy words in the first position.  Further, connectionist network simulations show that network error at the first phoneme position only is a better match for naming latency, while overall network error produces a better match to subject error counts. 
Automatic Combination of Multiple Ranked Retrieval Systems| Abstract Retrieval performance can often be improved significantly by using a number of different retrieval algorithms and combining the results, in contrast to using just a single retrieval algorithm.  This is because different retrieval algorithms, or retrieval experts, often emphasize different document and query features when determining relevance and therefore retrieve different sets of documents.  However, it is unclear how the different experts are to be combined, in general, to yield a superior overall estimate.  We propose a method by which the relevance estimates made by different experts can be automatically combined to result in superior retrieval performance.  We apply the method to two expert combination tasks.  The applications demonstrate that the method can identify high performance combinations of experts and also is a novel means for determining the combined effectiveness of experts. 
Learning Mackey-Glass from 25 Examples, Plus or Minus 2| Abstract We apply active exemplar selection (Plutowski & White, 1991; 1993) to predicting a chaotic time series.  Given a fixed set of examples, the method chooses a concise subset for training.  Fitting these exemplars results in the entire set being fit as well as desired.  The algorithm incorporates a method for regulating network complexity, automatically adding exemplars and hidden units as needed.  Fitting examples generated from the Mackey-Glass equation with fractal dimension 2. 1 to an rmse of 0. 01 required about 25 exemplars and 3 to 6 hidden units.  The method requires an order of magnitude fewer floating point operations than training on the entire set of examples, is significantly cheaper than two contending exemplar selection techniques, and suggests a simpler active selection technique that performs comparably. 
SOLVING THE VISUAL EXPERTISE MYSTERY| Through brain imaging studies and studies of brain-lesioned patients with face or object recognition deficits, the fusiform face area (FFA) has been identified as a face-specific processing area.  Recent work, however, illustrates that the FFA is also responsive to a wide variety of non-face objects if levels of discrimination and expertise are controlled.  The mystery is why an expertise area, whose initial domain of expertise is presumably faces, would be recruited for these other domains.  Here we show that features tuned for fine-level discrimination within one visually homogeneous class have high-variance responses across that class.  This variability generalizes to other homogenous classes, providing a foothold for learning. 
Categorical Perception in Facial Emotion Classification| Abstract We present an automated emotion recognition system that is capable of identifying six basic emotions (happy,
Predicting the Performance of Linearly Combined IR Systems| Abstract We introduce a new technique for analyzing combination models.  The technique allows us to make qualitative conclusions about which IR systems should be combined.  We achieve this by using a linear regression to accurately (r 2 = 0:98) predict the performance of the combined system based on quantitative measurements of individual component systems taken from TREC5.  When applied to a linear model (weighted sum of relevance scores), the technique supports several previously suggested hypotheses: one should maximize both the individual systems' performances and the overlap of relevant documents between systems, while minimizing the overlap of nonrelevant documents.  It also suggests new conclusions: both systems should distribute scores similarly, but not rank relevant documents similarly.  It furthermore suggests that the linear model is only able to exploit a fraction of the benefit possible from combination.  The technique is general in nature and capable of pointing out the strengths and weaknesses of any given combination approach. 
Organization of face and object recognition in modular neural network models| Abstract There is strong evidence that face processing in the brain is localized.  The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent neural mechanisms.  In this paper, we use computational models to show how the face processing specialization apparently underlying prosopagnosia and visual object agnosia could be attributed to (1) a relatively simple competitive selection mechanism that, during development, devotes neural resources to the tasks they are best at performing, (2) the developing infant's need to perform subordinate classification (identification) of faces early on, and (3) the infant's low visual acuity at birth. 
Do Expression and Identity Need Separate Representations?| Abstract Recent work has shown that expression
Analysis of Oscillations in a Reciprocally Inhibitory Network with Synaptic Depression| Abstract We present and analyze a model of a two-cell reciprocally inhibitory network that oscillates.  The principal mechanism of oscillation is short-term synaptic depression.  Using a simple model of depression, and analyzing the system in certain limits, we can derive analytical expressions for various features of the oscillation, including the parameter regime in which stable oscillations occur as well as the period and amplitude of these oscillations.  These expressions are functions of three parameters: the time constant of depression, the synaptic strengths, and the amount of tonic excitation the cells receive.  We compare our analytical results with the output of numerical simulations, and obtain good agreement between the two.  Based on our analysis, we conclude that the oscillations in our network are qualitatively different from those in networks which oscillate due to postinhibitory rebound, spike-frequency adaptation, or other intrinsic (rather than synaptic) adaptational mechanisms.  In particular, our network can only oscillate via the synaptic escape mode of Skinner, Kopell and Marder (1994). 
Principled Methods for Advising Reinforcement Learning Agents| Abstract An important issue in reinforcement learning is how to incorporate expert knowledge in a principled manner, especially as we scale up to real-world tasks.  In this paper, we present a method for incorporating arbitrary advice into the reward structure of a reinforcement learning agent without altering the optimal policy.  This method extends the potentialbased shaping method proposed by Ng et al.  (1999) to the case of shaping functions based on both states and actions.  This allows for much more specific information to guide the agent -- which action to choose -- without requiring the agent to discover this from the rewards on states alone.  We develop two qualitatively different methods for converting a potential function into advice for the agent.  We also provide theoretical and experimental justifications for choosing between these advice-giving algorithms based on the properties of the potential function. 
Fusion Via Linear Combination for the Routing Problem| Abstract A linear combination of scores from two different IR systems is used
Individual Differences in Exemplar-Based Interference During Instructed Category Learning| Abstract Instructed category learning studies have shown that
Hybrid Neural Systems| Preface The aim of this book is to present a broad spectrum of current research in hybrid neural systems, and advance the state of the art in neural networks and artificial intelligence.  Hybrid neural systems are computational systems which are based mainly on artificial neural networks but whichalsoallowasymbolic interpretation or interaction with symbolic components.  This book focuses on the following issues related to different types of representation: How does neural representation contribute to the success of hybrid systems? Howdoessymbolic representation supplement neural representation? How can these types of representation be combined? How can we utilize their interaction and synergy? Howcanwe develop neural and hybrid systems for new domains? What are the strengths and weaknesses of hybrid neural techniques? Are current principles and methodologies in hybrid neural systems useful? How can they be extended? What will be the impact of hybrid and neural techniques in the future? In order to bring together new and different approaches, we organized an international workshop.  This workshop on hybrid neural systems, organized by Stefan Wermter and Ron Sun, was held during December4{5,1998inDenver.  In this well-attended workshop, 27 papers were presented.  Overall, the workshop was wide-ranging in scope, covering the essential aspects and strands of hybrid neural systems research, and successfully addressed many importantissues of hybrid neural systems research.  The best and most appropriate paper contributions were selected and revised twice.  This book contains the best revised papers, some of which are presented as state-of-the-art surveys, to cover the various research areas of the collection.  This selection of contributions is a representative snapshot of the state of the art in current approaches to hybrid neural systems.  This is an extremely active area of research that is growing in interest and popularity.  We hope that this collection will be stimulating and useful for all those interested in the area of hybrid neural systems. 
The Early Word Catches the Weights| Abstract The strong correlation between the frequency of words and their naming latency has been well documented.  However, as early as 1973, the Age of Acquisition (AoA) of a word was alleged to be the actual variable of interest, but these studies seem to have been ignored in most of the literature.  Recently, there has been a resurgence of interest in AoA.  While some studies have shown that frequency has no effect when AoA is controlled for, more recent studies have found independent contributions of frequency and AoA.  Connectionist models have repeatedly shown strong effects of frequency, but little attention has been paid to whether they can also show AoA effects.  Indeed, several researchers have explicitly claimed that they cannot show AoA effects.  In this work, we explore these claims using a simple feed forward neural network.  We find a significant contribution of AoA to naming latency, as well as conditions under which frequency provides an independent contribution.  1 Background Naming latency is the time between the presentation of a picture or written word and the beginning of the correct utterance of that word.  It is undisputed that there are significant differences in the naming latency of many words, even when controlling word length, syllabic complexity, and other structural variants.  The cause of differences in naming latency has been the subject of numerous studies.  Earlier studies found that the frequency with which a word appears in spoken English is the best determinant of its naming latency (Oldfield & Wingfield, 1965).  More recent psychological studies, however, show that the age at which a word is learned, or its Age of Acquisition (AoA), may be a better predictor of naming latency.  Further, in many multiple regression analyses, frequency is not found to be significant when AoA is controlled for (Brown & Watson, 1987; Carroll & White, 1973; Morrison et al.  1992; Morrison & Ellis, 1995).  These studies show that frequency and AoA are highly correlated (typically r = -. 6) explaining the confound of older studies on frequency.  However, still more recent studies question this finding and find that both AoA and frequency are significant and contribute independently to naming latency (Ellis & Morrison, 1998; Gerhand & Barry, 1998,1999).  Much like their psychological counterparts, connectionist networks also show very strong frequency effects.  However, the ability of a connectionist network to show AoA effects has been doubted (Gerhand & Barry, 1998; Morrison & Ellis, 1995).  Most of these claims are based on the well known fact that connectionist networks exhibit "destructive interference" in which later presented stimuli, in order to be learned, force early learned inputs to become less well represented, effectively increasing their associated errors.  However, these effects only occur when training ceases on the early patterns.  Continued training on all the patterns mitigates the effects of interference from later patterns.  Recently, Ellis & Lambon-Ralph (in press) have shown that when pattern presentation is staged, with one set of patterns initially trained, and a second set added into the training set later, strong AoA effects are found.  They show that this result is due to a loss of plasticity in the network units, which tend to get out of the linear range with more training.  While this result is not surprising, it is a good model of the fact that some words may not come into existence until late in life, such as "email" for baby boomers.  However, they explicitly claim that it is important to stage the learning in this way, and offer no explanation of what happens during early word acquisition, when the surrounding vocabulary is relatively constant, or why and when frequency and AoA show independent effects.  In this paper, we present an abstract feed-forward computational model of word acquisition that does not stage inputs.  We use this model to examine the effects of frequency and AoA on sum squared error, the usual variable used to model reaction time.  We find a consistent contribution of AoA to naming latency, as well as the conditions under which there is an independent contribution from frequency in some tasks.  2 Experiment 1: Do networks show AoA effects? Our first goal was to show that AoA effects could be observed in a connectionist network using the simplest possible model.  First, we need to define AoA in a network.  We did this is such a way that staging the inputs was not necessary: we defined a threshold for the error, after which we would say a pattern has been "acquired. " The AoA is defined to be the epoch during which this threshold is crossed.  Since error for a particular pattern may occasionally go up again during online learning, we also measured the last epoch that the pattern went below the threshold for final time.  We analyzed our networks using both definitions of acquisition (which we call first acquisition and final acquisition), and have found that the results vary little between these definitions.  In what follows, we use first acquisition for simplicity.  2. 1 The Model The simplest possible model is an autoencoder network.  Using a network architecture of 20-15-20, we trained the network to autoencode 200 patterns of random bits (each bit had a 50% probability of being on or off).  We initialized weights randomly with a flat distribution of values between 0. 1 and -0. 1, used a learning rate of 0. 001 and momentum of 0. 9.  For this experiment, we chose the AoA threshold to be 2, indicating an average squared error of . 1 per input bit, yielding outputs much closer to the correct output than any other.  We calculated Euclidean distances between all outputs and patterns to verify that the input was mapped most closely to the correct output.  Training on the entire corpus continued until 98% of all patterns fell below this threshold.  2. 2 Results After the network had learned the input corpus, we investigated the relationship between the epoch at which the input vector had been learned and the final sum squared error (equivalent, for us, to "adult" naming latency) for that input vector.  These results are presented in Figure 1.  The relationship between the age of acquisition of the input vector and its
Seeing Blobs as Faces or Letters: Modeling Effects on Discrimination| Abstract What is the difference between processing faces and other objects such as letters? What makes humans face experts, and what makes this expertise different from other identification skills? It is well known that people are very sensitive to the configural information in faces.  How does the sensitivity to face configuration compare to sensitivity to configurations of other stimuli? To investigate these issues, Nishimura et al.  (2004) designed a test to contrast two types of processing using the same stimuli.  They primed subjects to see four blobs as either a "Y" or as a face.  Then they asked the subjects to discriminate pairs of these stimuli that differed only in small shifts in the blob locations.  Although the stimuli were exactly the same, subjects were more accurate in the face condition than the "Y" condition.  With Nishimura et al. , we assumed that the subjects were relying on their letter recognition networks in the "Y" condition and their face recognition networks in the face condition to perform the task.  We therefore trained two networks, a face recognition network and a letter recognition network that were otherwise identical in structure, and show here that the internal representations in the letter network for the blobs were less differentiated than the internal representations for the blobs in the face network.  We argue that this is a natural consequence of the requirements of the two tasks. 
Phase-Space learning for recurrent networks| Abstract We study the problem of learning nonstatic attractors in recurrent networks.  With concepts from dynamical systems theory, we show that this problem can be reduced to three sub-problems, (a) that of embedding the temporal trajectory in phase space, (b) approximating the local vector field, and (c) function approximation using feedforward networks.  This general framework overcomes problems with traditional methods by providing more appropriate error gradients and enforcing stability explicitly.  We describe an online version of our method we call ARTISTE, that can learn periodic attractors without teach-forcing. 
Regularities in a Random Mapping from Orthography to Semantics| Abstract In this paper we investigate representational and methodological issues in a attractor network model of the mapping from orthography to semantics based on [Plaut, 1995]. 
A Six-Unit Network is All You Need to Discover Happiness| Abstract In this paper, we build upon previous results to show that our facial expression recognition system, an extremely simple neural network containing six units, trained by backpropagation, is a surprisingly good
Tau Net A neural network for modeling temporal variability| Abstract The ability to handle temporal variation is important when dealing with real-world dynamic signals.  In many
Content and Cluster Analysis: Assessing Representational Similarity in Neural Systems| Abstract If Connectionism is to be an adequate theory of mind, we must have a theory of representation for neural networks that allows for individual differences in weighting and architecture while preserving sameness, or at least similarity, of content.  In this paper we propose a procedure for measuring sameness of content of neural representations.  We argue that the correct way to compare neural representations is through analysis of the distances between neural activations, and we present a method for doing so.  We then use the technique to demonstrate empirically that different artificial neural networks trained by backpropagation on the same categorization task, even with different representational encodings of the input patterns and different numbers of hidden units, reach states in which representations at the hidden units are similar.  We discuss how this work provides a rebuttal to Fodor & Lepore's critique of Paul Churchland's state space semantics. 
When Holistic Processing is Not Enough: Local Features Save the Day| Abstract Is configural information or featural information more important for facial identity recognition? How are the skills for processing these types of information developed? To investigate these issues, Mondloch et al.  designed three sets of face images based on a single face, "Jane", to measure featural, configural, and contour processing.  These stimuli were tested on human subjects of dierent ages in a same/dierent task.  We test our model [Dailey et al. , 2002] of face processing on these stimuli.  We find that our model is overly holistic: It finds the configural dierences the easiest to detect, while adult human subjects find featural changes the easiest to detect.  We then introduce a representation of the important parts of the face (eyes and mouth) to our holistic model.  We find that only a relatively small amount of holistic representation, compared to parts representations, is necessary to account for the data. 
Representing Documents Using an Explicit Model of Their Similarities| Abstract A method is proposed for creating vector space representations of documents based on modeling target inter-document similarity values.  The target
A model of the leech segmental swim central pattern generator| Abstract We present a model of the single-ganglion oscillator of the leech swim central pattern generator (CPG).  The model is based on the known neuronal architecture of this circuit.  Free parameters in the model were "tted to produce membrane potential oscillations matching those seen during swimming.  However, the oscillations produced are not robust to small ($5%) changes in the parameters.  We propose that this may be due to the large di!erence between the passive time constant of our model cells and the period of the swim oscillation.  We discuss possible ways the real circuit achieves robustness. 
Phase-Space Learning| Abstract Existing recurrent net learning algorithms are inadequate.  We introduce the conceptual framework of viewing recurrent training as matching vector fields of dynamical systems in phase space.  Phasespace reconstruction techniques make the hidden states explicit, reducing temporal learning to a feed--forward problem.  In short, we propose viewing iterated prediction [LF88] as the best way of training recurrent networks on deterministic signals.  Using this framework, we can train multiple trajectories, insure their stability, and design arbitrary dynamical systems. 
Modeling Interference Effects In Instructed Category Learning| Abstract Category learning is often seen as a process of inductive generalization from a set of class-labeled exemplars.  Human learners, however, often receive direct instruction concerning the structure of a category before being presented with examples.  Such explicit knowledge may often be smoothly integrated with knowledge garnered by exposure to instances, but some interference effects have been observed. 
A Connectionist Simulation of the Empirical Acquisition of Grammatical Relations| In contrast to this approach, we propose that grammatical relations emerge rather late in the language-learning process.  Our theoretical proposal is based on two observations.  First, early production of childhood speech is formulaic and becomes systematic in a progressive fashion.  Second, grammatical relations themselves are family-resemblance categories that cannot be described by a single parameter.  This leads to the notion that grammatical relations are learned in a bottom up fashion.  Combining this theoretical position with the notion that the main purpose of language is communication, we demonstrate the emergence of the notion of "subject" in a simple recurrent network that learns to map from sentences to semantic roles.  We analyze the hidden layer representations of the emergent subject, and demonstrate that these representations correspond to a radially--structured category.  We also claim that the pattern of generalization and undergeneralization demonstrated by the network conforms to what we expect from the data on children's generalizations. 
EMPATH: A Neural Network that Categorizes Facial Expressions| Abstract There are two competing theories of facial expression recognition.  Some researchers have suggested that facial expression recognition is an example of categorical perception. Inthisview,expression categories are considered to be discrete entities with sharp boundaries between them, and discrimination of similar pairs of expressive faces is enhanced when the faces are near those boundaries.  Other researchers, however, suggest that facial expression perception is more graded and that facial expressions are best thought of as points in a continuous, low-dimensional space, where, for example, "Surprise" expressions are between "Happiness" and "Fear" expressions, due to their perceived similarity.  In this paper, we show that a simple yet biologically plausible neural network model, trained to classify facial expressions into six basic emotions, can fit data used to support both theories.  Without any attempt to fit the model to the data, the model matches a variety of psychological data on categorization, similarity, reaction times, discrimination, and recognition difficulty, both qualitatively and quantitatively.  We thus explain many of the seemingly complex psychological phenomena related to facial expression perception as natural consequences of the task's implementation in the brain. 
Interactions between Frequency Effects and Age of Acquisition Effects in a Connectionist Network| Abstract The performance of a connectionist network, in which some resources are absent or damaged is examined as a function of various learning parameters.  A learning environment is created by generating a set of random "prototypes" and clusters of exemplar vectors surrounding each prototype.  An autoencoder is trained on the patterns.  The robustness of each learned item is measured as a function of the time at which it was "acquired" by the network and its overall frequency in the environment.  Both factors are shown to influence robustness under several learning conditions. 
Latent Semantic Indexing is an Optimal Special Case of Multidimensional Scaling| Abstract Latent Semantic Indexing (LSI) is a technique for representing documents, queries, and terms as vectors in a multidimensional real-valued space.  The representations are approximations to the original term space encoding, and are found using the matrix technique of Singular Value Decomposition.  In comparison, Multidimensional Scaling (MDS) is a class of data analysis techniques for representing data points as points in a multidimensional real-valued space.  The objects are represented so that inter-point similarities in the space match inter-object similarity information provided by the researcher.  We illustrate how the document representations given by LSI are equivalent to the optimal representations found when solving a particular MDS problem in which the given inter-object similarity information is provided by the inner product similarities between the documents themselves.  We further analyze a more general MDS problem in which the interdocument similarity information, although still in inner product form, is arbitrary with respect to the vector space encoding of the documents. 
A Simple Neural Network Models Categorical Perception of Facial Expressions| Abstract The performance of a neural network that categorizes facial expressions is compared with human subjects over a set of experiments using interpolated imagery.  The experiments for both the human subjects and neural networks make use of interpolations of facial expressions from the Pictures of Facial Affect Database [Ekman and Friesen, 1976].  The only difference in materials between those used in the human subjects experiments [Young et al. , 1997] and our materials are the manner in which the interpolated images are constructed -image-quality morphs versus pixel averages.  Nevertheless, the neural network accurately captures the categorical nature of the human responses, showing sharp transitions in labeling of images along the interpolated sequence.  Crucially for a demonstration of categorical perception [Harnad, 1987
Optimizing Parameters in a Ranked Retrieval System Using Multi-Query Relevance Feedback| Abstract A method is proposed by which parameters in ranked-output text retrieval systems can be automatically optimized to improve retrieval performance.  A ranked-output text retrieval system implements a ranking function which orders documents, placing documents estimated to be more relevant to the user's query before less relevant ones.  The proposed method is to adjust system parameters to maximize the match between the system's document ordering and the user's desired ordering, given by relevance feedback.  The utility of the approach is demonstrated by estimating the similarity measure in a vector space model of information retrieval.  The approach automatically finds a similarity measure which performs equivalent to or better than all "classic" similarity measures studied.  It also performs within 1% of an estimated theoretically optimal measure. 
Facial Memory Is Kernel Density Estimation (Almost)| Abstract We compare the ability of three exemplar-based memory models, each using three different face stimulus representations, to account for the probability a human subject responded "old" in an old/new facial memory experiment.  The models are 1) the Generalized Context Model, 2) SimSample, a probabilistic sampling model, and 3) MMOM, a novel model related to kernel density estimation that explicitly encodes stimulus distinctiveness.  The representations are 1) positions of stimuli in MDS "face space," 2) projections of test faces onto the "eigenfaces" of the study set, and 3) a representation based on response to a grid of Gabor filter jets.  Of the 9 model/representation combinations, only the distinctiveness model in MDS space predicts the observed "morph familiarity inversion" effect, in which the subjects' false alarm rate for morphs between similar faces is higher than their hit rate for many of the studied faces.  This evidence is consistent with the hypothesis that human memory for faces is a kernel density estimation task, with the caveat that distinctive faces require larger kernels than do typical faces.  1 Background Studying the errors subjects make during face recognition memory tasks aids our understanding of the mechanisms and representations underlying memory, face processing, and visual perception.  One way of evoking such errors is by testing subjects' recognition of new faces created from studied faces that have been combined in some way (e. g.  Solso and McCarthy, 1981; Reinitz, Lammers, and Cochran 1992).  Busey and Tunnicliff (submitted) have recently examined the extent to which image-quality morphs between unfamiliar faces affect subjects' tendency to make recognition errors.  Their experiments used facial images of bald males and morphs between these images (see Figure 1: Three normalized morphs from the database.  Figure 1) as stimuli.  In one study, Busey (in press) had subjects rate the similarity of all pairs in a large set of faces and morphs, then performed a multidimensional scaling (MDS) of these similarity ratings to derive a 6-dimensional "face space" (Valentine and Endo, 1992).  In another study, "Experiment 3" (Busey and Tunnicliff, submitted), 179 subjects studied 68 facial images, including 8 similar pairs and 8 dissimilar pairs, as determined in a pilot study.  These pairs were included in order to study how morphs between similar faces and dissimilar faces evoke false alarms.  We call the pair of images from which a morph are derived its "parents," and the morph itself as their "child. " In the experiment's test phase, the subjects were asked to make new/old judgments in response to 8 of the 16 morphs, 20 completely new distractor faces, the 36 non-parent targets and one of the parents of each of the 8 morphs.  The results were that, for many of the morph/parent pairs, subjects responded "old" to the unstudied morph more often than to its studied parent.  However, this effect (a morph familiarity inversion) only occurred for the morphs with similar parents.  It seems that the similar parents are so similar to their "child" morphs that they both contribute toward an "old" (false alarm) response to the morph.  Researchers have proposed many models to account for data from explicit memory experiments.  Although we have applied other types of models to Busey and Tunnicliff's data with largely negative results (Dailey et al. , 1998), in this paper, we limit discussion to exemplar-based models, such as the Generalized Context Model (Nosofsky, 1986) and SAM (Gillund and Shiffrin, 1984).  These models rely on the assumption that subjects explicitly store representations of each of the stimuli they study.  Busey and Tunnicliff applied several exemplar-based models to the Experiment 3 data, but none of these models have been able to fully account for the observed similar morph familiarity inversion without positing that the similar parents are explicitly blended in memory, producing prototypes near the morphs.  We extend Busey and Tunnicliff's (submitted) work by applying two of their exemplar models to additional image-based face stimulus representations, and we propose a novel exemplar model that accounts for the similar morphs' familiarity inversion.  The results are consistent with the hypothesis that facial memory is a kernel density estimation (Bishop, 1995) task, except that distinctive exemplars require larger kernels.  Also, on the basis of our model, we can predict that distinctiveness with respect to the study set is the critical factor influencing kernel size, as opposed to a context-free notion of distinctiveness.  We can easily test this prediction empirically. 
A Taxonomy of Computational and Social Learning| Abstract This paper presents a first attempt at explaining the
User Lenses -- Achieving 100% Precision on Frequently Asked Questions| degrading test data performance, and that larger lenses result in nearly perfect performance on the training set.  The lens provides a mechanism for automatically capturing long-term, user-specific information about an improved representation scheme for document vectors. 
A model of scan paths applied to face recognition| Abstract We develop a model of scan path generation based on the output of low level filters.  The highest variance of Gabor jet filters computed over orientations are used as the object of attention.  These points are held in a feature map which is inhibited as attention points are visited, creating a new attention point elsewhere.  Scan paths generated this way can be used for recognition purposes where "single-shot" methods, such as PCA, would fail because the image is not registered. 
Serial Order in Reading Aloud: Connectionist Models and Neighborhood Structure| Abstract Dual-Route and Connectionist Single-Route models of reading have been at odds over claims as to the correct explanation of the reading process.  Recent Dual-Route models predict that subjects should show an increased naming latency for irregular words when the irregularity is earlier in the word (e. g.  chef is slower than glow) - a prediction that has been confirmed in human experiments.  Since this would appear to be an effect of the left-to-right reading process, Coltheart & Rastle (1994) claim that Single-Route parallel connectionist models cannot account for it.  A refutation of this claim is presented here, consisting of network models which do show the interaction, along with orthographic neighborhood statistics that explain the effect. 
Representing Face Images for Emotion Classification| Abstract We compare the generalization performance of three distinct representation schemes for facial emotions using a single classification strategy (neural network).  The face images presented to the classifiers are represented as: full face projections of the dataset onto their eigenvectors (eigenfaces); a similar projection constrained to eye and mouth areas (eigenfeatures); and finally a projection of the eye and mouth areas onto the eigenvectors obtained from 32x32 random image patches from the dataset.  The latter system achieves 86% generalization on novel face images (individuals the networks were not trained on) drawn from a database in which human subjects consistently identify a single emotion for the face. 
Optimizing Similarity Using Multi-Query Relevance Feedback| Abstract We propose a novel method for automatically adjusting parameters in ranked-output text retrieval systems to improve retrieval performance.  A ranked-output text retrieval system implements a ranking function which orders documents, placing documents
Age of Acquisition in Connectionist Networks| Abstract Recently, there has been a resurgence of interest in the role of the Age of Acquisition (AoA) of an item in determining subjects' reaction time in naming words, objects, and faces.  Using the number of epochs required to learn an item as a direct measure of AoA in connectionist networks, Smith, Cottrell & Anderson (in press) have shown that AoA is a stronger predictor of final Sum Squared Error than frequency.  In this paper, we replicate Smith et al. 
Developmental Embodied Cognition| The objective of this workshop was to bring together researchers from cognitive science, psychology, robotics, artificial intelligence, philosophy, and related fields to discuss the role of developmental and embodied views of cognition, and in particular, their mutual relationship.  The ultimate goal of this approach is to understand the emergence of high-level cognition in organisms based on their interactions with their environment over extended periods of time. 
Non-Linear Dimensionality Reduction|
Fusion Via a Linear Combination of Scores|
Image compression by back propagation: an example of extensional programming|
in press)| The early word catches the weights. 
Automatic Combination of Multiple Ranked Retrieval Systems|
Connectionist models of face processing: A survey|
Learning simple arithmetic procedures,|
Learning internal representations from grayscale images: An example of extensional programming|
Face recognition using unsupervised feature extraction",|
Face, gender and emotion recognition using holons|
Identifying Emotion in Static Images|
EMPATH: Face, Emotion, and Gender Recognition Using Holons|
Using Relevance to Train a Linear Mixture of Experts|
A Connectionist Approach to Word Sense Disambiguation|
A connectionist model of instruction following|
Visual expertise is a general skill|
Connectionist parsing|
The role of input and target similarity in assimilation|,. 
A connectionist perspective on prosodic structure|
Learning the past tense in a recurrent network: acquiring the mapping from meaning to sounds|
A connectionist scheme for modelling word sense disambiguation|
EMPATH: Face, Gender and Emotion Recognition Using Holons|
Grounding Meaning in Perception|
Advances in neural information processing systems|
Using a recurrent net to learn the past tense|
Learning simple arithmetic procedures|
Dissociation of algorithmic and heuristic processes in language comprehension: Evidence from aphasia|
Optimizing parameters in a ranked retrieval system using mutli-query relevance feedback|
Extracting features from faces using compression networks: Face, identity, emotion and gender recognition using holons",|
Identifying emotion in static images, Proc| 2. 
Task and Spatial Frequency Effects on Face Specialization|
Is all face processing holistic? The view from UCSD|
Do expression and identity need separate representations?|
Modeling individual differences in the specialization of an explicit rule|
Latent semantic indexing is an optimal case of multidimensional scaling| SIGIR'92. 
A neural network that categorizes facial expressions|
A connectionist Approach to Word Sense Disambiguation,|
A Model of Lexical Access of Ambiguous Words|
Image compression by backpropagation: and example of extensional programming|
Design Considerations and Operational Results of a GPS Attitude Determination Unit, Proceedings of The Seventh International Technical Meeting of the Satellite Division of The Institute of Navigation,|
Some experiments on learning stable network oscillations|
"A Model of Symbol Grounding in a Temporal Environment,|
Analysis of image compression by back propagation|
Towards instructable connectionist systems|
Categorical perception of emotional facial expressions: Computer models and human performance|
Organization of face and object recognition in modular neural networks|
Experience with selecting exemplars from clean data|
Viewing parsing as word sense discrimination: A connectionist approach|
Visual expertise depends on how you slice the space|
Connectionist perspective on prosodic structure|
Time-delay neural networks: Representation and induction of finite state machines|
Representation and Induction of Finite State Machines using Time-Delay Neural Networks|
Toward Connectionist Parsing|
Tau net: The way to do is to be|
Dynamic rate adaptation|
A Connectionist Approach to Rate Adaptation|
From symbols to neurons: Are we yet there?|
Early lateralization and orientation tuning for face, word and object processing in the visual cortex|
Topology-modifying neural network algorithms|
Eigenfaces for familiarity|
PCA = Gabor for expression recognition|
The role of statistical regularities in reading and connectionist modeling|
Grounding Meaning in Perception|
Principal components analysis of images via back propagation|
