On-Line EM Reinforcement Learning| Abstract--- In this article, we propose a new reinforcement learning (RL) method for a system having continuous state and action spaces.  Our RL method has an architecture like the actorcritic model.  The critic tries to approximate the Q-function, which is the expected future return for the current state-action pair.  The actor tries to approximate a stochastic soft-max policy defined by the Q-function.  The soft-max policy is more likely to select an action that has a higher Q-function value.  The on-line EM algorithm is used to train the critic and the actor.  We apply this method to two control problems.  Computer simulations show that our method is able to acquire fairly good control in the two tasks after a few learning trials. 
A network of chaotic elements for information processing| Abstract A Globally Coupled Map (GCM) model is a network of chaotic elements that are globally coupled with each other.  In this paper, first, a modified GCM model called the "Globally Coupled Map using the Symmetric map (S-GCM)" is proposed.  The SGCM is designed for information-processing applications.  The S-GCM has attractors called "cluster frozen attractors," each of which is taken to represent information.  This paper also describes the following characteristics of the S-GCM which are important to information-processing applications: (a) The S-GCM falls into one of the cluster frozen attractors over a wide range of parameters.  This means that the information representation is stable over parameters; (b) Represented information can be preserved or broken by controlling parameters; (c) The cluster partitioning is restricted, i. e. , the representation of information has a limitation.  Finally, our techniques for applying the S-GCM to information processing are shown, considering these characteristics.  Two associative memory systems are proposed and their performance is compared with that of the Hopfield network. 
Associative memory based on parametrically coupled chaotic elements| Abstract In this paper, we propose an associative memory system based on parametrically coupled chaotic elements.  The proposed system is obtained by adding a new parameter control to our previously proposed system.  A chaotic activity in an early association stage makes an efficient association over the memories that are stored by means of autocorrelational learning.  When the system successfully recalls the target memory, the system's motion is dominated by a spatially coherent oscillation, while unstable motions remain when the system fails to make the association.  In addition, the system has a large memory capacity.  A comparison between the proposed system and an approach with a nonmonotonic transfer function is also shown. 
-Opt Neural Approaches to Quadratic Assignment Problems| Abstract In this paper, we propose new analog neural approaches to combinatorial optimization problems, in particular, quadratic assignment problems (QAPs).  Our proposed methods are based on an analog version of the -opt heuristics, which simultaneously changes assignments for elements in a permutation.  Since we can take a relatively large value, our new methods can achieve a middle-range search over possible solutions, and this helps the system neglect shallow local minima and escape from local minima.  In experiments, we have applied our methods to relatively large-scale (N = 80 150) QAPs.  Results have shown that our new methods are comparable to the present champion algorithms; for two benchmark problems, they are able to obtain better solutions than the previous champion algorithms. 
Reinforcement Learning Based on On-Line EM Algorithm| Abstract In this article, we propose a new reinforcement learning (RL) method based on an actor-critic architecture.  The actor and the critic are approximated by Normalized Gaussian Networks (NGnet), which are networks of local linear regression units.  The NGnet is trained by the on-line EM algorithm proposed in our previous paper.  We apply our RL method to the task of swinging-up and stabilizing a single pendulum and the task of balancing a double pendulum near the upright position.  The experimental results show that our RL method can be applied to optimal control problems having continuous state/action spaces and that the method achieves good control with a small number of trial-and-errors. 
Control of exploitation-exploration meta-parameter in reinforcement learning| Abstract In reinforcement learning, the duality between exploitation and exploration has long been an important issue.  This paper presents a new method that controls the balance between exploitation and exploration.  Our learning scheme is based on model-based reinforcement learning, in which the Bayes inference with forgetting effect estimates the state-transition probability of the environment.  The balance parameter, which corresponds to the randomness in action selection, is controlled based on variation of action results and perception of environmental change.  When applied to maze tasks, our method successfully obtains good controls by adapting to environmental changes.  Recently, Usher et al.  [60] has suggested that noradrenergic neurons in the locus coeruleus may control the exploitation-exploration balance in a real brain and that the balance may correspond to the level of animal's selective attention.  According to this scenario, we also discuss a possible implementation in the brain. 
Bifurcations in mean-field-theory annealing| Abstract In this paper, we investigate bifurcation processes for the mean field theory (MFT) annealing applied to traveling salesman problems (TSPs).  Due to the symmetries of the TSP free energy function, some special bifurcations occur: cyclic symmetry breaking bifurcations and reverse symmetry breaking bifurcations.  Saddle-node bifurcations also occur.  Which type of bifurcations occurs depends on the symmetry of the eigenvector that corresponds to the zero eigenvalue mode of the free energy curvature matrix at the bifurcation point.  In the MFT annealing process, a sequence of bifurcations occurs and the bifurcation structure affects the quality of the annealing solution.  It is shown that the annealing solution in this process is not unique in general, and it is not always the optimal solution.  Our approach can also be applied to the Potts spin model and its bifurcation structure is almost the same as that of the MFT.  The practical implications of our results are also discussed. 
Eliminating spurious memories in a network of chaotic elements| Abstract A Globally Coupled Map (GCM) model is a network of chaotic elements that are globally coupled with each other.  We have previously proposed an associative memory system based on GCM, which has a better ability than the Hopfield network.  This result indicates that the dynamics of our system is more efficient than that of the Hopfield network.  However, even in our system, spurious memories, i. e. , system's equilibria that do not correspond to any of proper memories, do exist.  In this paper, we propose a modified associative memory system, in which spurious memories are noticeably reduced.  This is achieved by modifying the chaotic dynamics of the system.  With this improvement, our system's memory capacity and basin volumes are expanded a great deal.  Some experimental results in comparison with those of a neural network employing a nonmonotonic output function are also shown. 
Chaotic Potts spin model for combinatorial optimization problems| Abstract In this paper, first, we show some of the bifurcation properties of Potts mean-fieldtheory annealing applied to traveling salesman problems.  Due to these bifurcation properties, this approach, in general, produces non-optimal and non-unique solutions.  As an alternative approach, we propose a nonequilibrium version of the Potts spin neural network, called Chaotic Potts Spin (CPS).  CPS has several parameters, and bifurcations over each parameter are investigated.  Next, experimental results are shown comparing CPS with several related approaches.  CPS is good at obtaining optimal solutions for small-scale problems and semi-optimal solutions for relatively large-scale problems.  We also describe a couple of CPS modifications: CPS with a heuristic method and CPS with a "chaotic annealing" method.  These modified algorithms can produce even better CPS solutions. 
Application of reinforcement learning to balancing of acrobot| ABSTRACT The acrobot is a two-link robot, actuated only at the joint between the two links.  It is one of difficult tasks in reinforcement learning (RL) to control the acrobot because it has nonlinear dynamics and continuous state and action spaces.  In this article, we discuss applying the RL to the task of balancing control of the acrobot.  Our RL method has an architecture similar to the actor-critic.  The actor and the critic are approximated by normalized Gaussian networks, which are trained by an on-line EM algorithm.  We also introduce eligibility traces for our actorcritic architecture.  Our computer simulation shows that our method is able to achieve fairly good control with a small number of trials. 
Gaussian Process Approach to Spiking Neurons for Inhomogeneous Poisson Inputs| Abstract This article presents a new theoretical framework to consider the dynamics of a stochastic spiking neuron model with general membrane response to input spike.  We assume that the input spikes obey an inhomogeneous Poisson process.  The stochastic process of the membrane potential then becomes a Gaussian process.  When a general type of the membrane response is assumed, the stochastic process becomes a Markov-Gaussian process.  We present a calculation method for the membrane potential density and the firing probability density.  Our new formulation is the extension of the existing formulation based on diffusion approximation.  Although the single Markov assumption of the diffusion approximation simplifies the stochastic process analysis, the calculation is inaccurate when the stochastic process involves a multiple Markov property.  We find that the variation of the shape of the membrane response, which has often been ignored in existing stochastic process studies, significantly affects the firing probability.  Our approach can consider the reset effect, which has been difficult to be dealt with by analysis based on the first passage time density. 
On-line EM Algorithm for the Normalized Gaussian Network|
Reinforcement Learning for Biped Locomotion|
Doubly constrained network for combinatorial optimization|
A multi-agent reinforcement learning method for a partially-observable competitive game|
Multi-Agent Reinforcement Learning: An Approach Based on the Other Agent's Internal Model|
Strategy acquisition for the game "Othello" based on reinforcement learning|
