Learning Informative Statistics: A Nonparametric Approach| Abstract We discuss an information theoretic approach for categorizing and modeling dynamic processes.  The approach can learn a compact and informative statistic which summarizes past states to predict future observations.  Furthermore, the uncertainty of the prediction is characterized nonparametrically by a joint density over the learned statistic and present observation.  We discuss the application of the technique to both noise driven dynamical systems and random processes sampled from a density which is conditioned on the past.  In the first case we show results in which both the dynamics of random walk and the statistics of the driving noise are captured.  In the second case we present results in which a summarizing statistic is learned on noisy random telegraph waves with differing dependencies on past states.  In both cases the algorithm yields a principled approach for discriminating processes with differing dynamics and/or dependencies.  The method is grounded in ideas from information theory and nonparametric statistics. 
NONPARAMETRIC ESTIMATORS FOR ONLINE SIGNATURE AUTHENTICATION| ABSTRACT We present extensions to our previous work in modelling dynamical processes.  The approach uses an information theoretic criterion for searching over subspaces of the past observations, combined with a nonparametric density characterizing its relation to one-step-ahead prediction and uncertainty.  We use this methodology to model handwriting stroke data, specifically signatures, as a dynamical system and show that it is possible to learn a model capturing their dynamics for use either in synthesizing realistic signatures and in discriminating between signatures and forgeries even though no forgeries have been used in constructing the model.  This novel approach yields promising results even for small training sets. 
Nonparametric Belief Propagation| Abstract In many applications of graphical models arising in computer vision, the hidden variables of interest are most naturally specified by continuous, non-Gaussian distributions.  There exist inference algorithms for discrete approximations to these continuous distributions, but for the highdimensional variables typically of interest, discrete inference becomes infeasible.  Stochastic methods such as particle filters provide an appealing alternative.  However, existing techniques fail to exploit the rich structure of the graphical models describing many vision problems.  Drawing on ideas from regularized particle filters and belief propagation (BP), this paper develops a nonparametric belief propagation (NBP) algorithm applicable to general graphs.  Each NBP iteration uses an efficient sampling procedure to update kernel-based approximations to the true, continuous likelihoods.  The algorithm can accomodate an extremely broad class of potential functions, including nonparametric representations.  Thus, NBP extends particle filtering methods to the more general vision problems that graphical models can describe.  We apply the NBP algorithm to infer component interrelationships in a partsbased face model, allowing location and reconstruction of occluded features. 
Nonparametric Hypothesis Tests for Statistical Dependency| Abstract---Determining the structure of dependencies among a set of variables is a common task in many signal and image processing applications, including multitarget tracking and computer vision.  In this paper, we present an information-theoretic, machine learning approach to problems of this type.  We cast this problem as a hypothesis test between factorizations of variables into mutually independent subsets.  We show that the likelihood ratio can be written as sums of two sets of Kullback--Leibler (KL) divergence terms.  The first set captures the structure of the statistical dependencies within each hypothesis, whereas the second set measures the details of model differences between hypotheses.  We then consider the case when the signal prior models are unknown, so that the distributions of interest must be estimated directly from data, showing that the second set of terms is (asymptotically) negligible and quantifying the loss in hypothesis separability when the models are completely unknown.  We demonstrate the utility of nonparametric estimation methods for such problems, providing a general framework for determining and distinguishing between dependency structures in highly uncertain environments.  Additionally, we develop a machine learning approach for estimating lower bounds on KL divergence and mutual information from samples of high-dimensional random variables for which direct density estimation is infeasible.  We present empirical results in the context of three prototypical applications: association of signals generated by sources possessing harmonic behavior, scene correspondence using video imagery, and detection of coherent behavior among sets of moving objects. 
Nonparametric Belief Propagation for Self-Calibration in Sensor Networks| ABSTRACT Automatic self-calibration of ad-hoc sensor networks is a critical need for their use in military or civilian applications.  In general, self-calibration involves the combination of absolute location information (e. g.  GPS) with relative calibration information (e. g.  time delay or received signal strength between sensors) over regions of the network.  Furthermore, it is generally desirable to distribute the computational burden across the network and minimize the amount of inter-sensor communication.  We demonstrate that the information used for sensor calibration is fundamentally local with regard to the network topology and use this observation to reformulate the problem within a graphical model framework.  We then demonstrate the utility of nonparametric belief propagation (NBP), a recent generalization of particle filtering, for both estimating sensor locations and representing location uncertainties.  NBP has the advantage that it is easily implemented in a distributed fashion, admits a wide variety of statistical models, and can represent multi-modal uncertainty.  We illustrate the performance of NBP on several example networks while comparing to a previously published nonlinear least squares method. 
Graphical Models for Statistical Inference and Data Assimilation| Abstract In data assimilation for a system which evolves in time, one combines past and current observations with a model of the dynamics of and observations on the system, in order to improve the simulation of the system, as well as any future predictions about it.  From a statistical point of view, this process can be regarded as estimating many random variables, which are related both spatially and temporally: given observations of some of these variables, typically corresponding to times past, we require estimates of several others, typically corresponding to future times.  Graphical models have emerged as an eective formalism for assisting in these types of inference tasks, particularly for large numbers of variables.  Graphical models provide a means of representing statistical structure among the variables, and can provide both intuition and eciency in estimation and other inference computations.  We provide an overview and introduction to graphical models, and describe how they can be used to represent statistical dependency and how the resulting structure can be used to organize computation.  The relation between statistical inference using graphical models and optimal sequential estimation algorithms such as Kalman filtering is discussed.  We then give several additional examples of how graphical models can be applied to climate dynamics, specifically estimation using multi-resolution models of large--scale data sets such as satellite imagery, and learning hidden Markov models to capture rainfall patterns in space and time. 
Hypothesis Testing over Factorizations for Data Association| Empirical results of the approximate approach are presented. 
