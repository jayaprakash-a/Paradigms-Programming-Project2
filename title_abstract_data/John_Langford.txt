Microchoice Bounds and Self Bounding Learning Algorithms| Abstract We prove adaptive bounds for learning algorithms that operate by making a sequence of choices.  These adaptive bounds, which we call Microchoice bounds, can be used to make these algorithms self-bounding in the style of Freund [Fre98].  Furthermore, we can combine these bounds with Freund's more sophisticated query-tree approach, producing a modified query-tree structure that yields similar bounds to those in [Fre98] but that permits a much more efficient algorithmic approximation. 
An iterative method for multi-class cost-sensitive learning| ABSTRACT Cost-sensitive learning addresses the issue of classification in the presence of varying costs associated with different types of misclassification.  In this paper, we present a method for solving multi-class cost-sensitive learning problems using any binary classification algorithm.  This algorithm is derived using three key ideas: 1) iterative weighting; 2) expanding data space; and 3) gradient boosting with stochastic ensembles.  We establish some theoretical guarantees concerning the performance of this method.  In particular, we show that a certain variant possesses the boosting property, given a form of weak learning assumption on the component binary classifier.  We also empirically evaluate the performance of the proposed method using benchmark data sets and verify that our method generally achieves better results than representative methods for cost-sensitive learning, in terms of predictive performance (cost minimization) and, in many cases, computational e)ciency. 
A Simple Method for Cost-Sensitive Learning| Abstract A folk theorem implies a simple reduction which allows anyone to turn an arbitrary cost-insensitive classi#cation algorithm into a cost-sensitive classification algorithm.  The reduction works using a particular reweighting of the examples which can be satis#ed either by feeding the weights to the classification algorithm (as often done in boosting), or by resampling.  Naive methods of resampling often result in drastically poor performance due to a strong tendency to over#t.  The overfitting is analyzed and rejection sampling is used in a technique we call \costing", which provably avoids resampling-based overfitting and results in superior performance. 
On Learning Monotone Boolean Functions| Abstract We consider the problem of learning monotone Boolean functions over f0; 1g n under the uniform distribution.  Specifically, given a polynomial number of uniform random samples for an unknown monotone Boolean function f , and given polynomial computing time, we would like to approximate f as well as possible.  We describe a simple algorithm that we prove achieves error at most 1=2 \Gamma \Omega(1= p n), improving on the previous best bound of 1=2 \Gamma \Omega((log 2 n)=n).  We also prove that no algorithm, given a polynomial number of samples, can guarantee error 1=2 \Gamma !((log n)= p n), improving on the previous best hardness bound of O(1= p n).  These lower bounds hold even if the learning algorithm is allowed membership queries.  Thus this paper settles to an O(log n) factor the question of the best achievable error for learning the class of monotone Boolean functions with respect to the uniform distribution. 
Bounds for Averaging Classifiers| Abstract We present a generalized PAC bound for averaging classifiers which applies to base hypotheses with a bounded real valued output.  In addition, we discuss several methods for quantitatively tightening the bound.  In the process, a tightened version of the PAC-Bayes bound [5] is proved. 
Probabilistic Planning in the Graphplan Framework| Abstract.  The Graphplan planner has enjoyed considerable success as a planning algorithm for classical STRIPS domains.  In this paper we explore the extent to which its representation can be used for probabilistic planning.  In particular, we consider an MDP-style framework in which the state of the world is known but actions are probabilistic, and the objective is to produce a finite horizon contingent plan with highest probability of success within the horizon.  We describe two extensions of Graphplan in this direction.  The first, PGraphplan, produces an optimal contingent plan.  It typically suffers a performance hit compared to Graphplan but still appears to be fast compared with other approaches to probabilistic planning problems.  The second, TGraphplan, runs at essentially the same speed as Graphplan, but produces potentially sub-optimal policies: TGraphplan's policy selects the first action on the highest probability trajectory from its current state to the goal.  Ideally, we would like an optimal planner for probabilistic domains with the same speed that Graphplan would have if the domain were made deterministic.  By comparing the speed and quality of these two planners to each other and to other existing planners, we are able to estimate how far off we are from our ideal.  PGraphplan is based on a forward-chaining search, unlike the backwardchaining search of the standard Graphplan algorithm.  Thus, one focus of this paper is exploring the extent to which Graphplan's representation can be used to speed up forward search in addition to the backward search for which it was originally intended. 
Reductions Between Classification Tasks| Abstract.  A reduction converts a solver for one task into a solver for another task.  We introduce a notion of reduction and analyze reductions between different classification tasks. 
FeatureBoost: A Meta-Learning Algorithm that Improves Model Robustness| Abstract Most machine learning algorithms are lazy: they extract from the training set the minimum information needed to predict its labels.  Unfortunately, this often leads to models that are not robust when features are removed or obscured in future test data.  For example, a backprop net trained to steer a car typically learns to recognize the edges of the road, but does not learn to recognize other features such as the stripes painted on the road which could be useful when road edges disappear in tunnels or are obscured by passing trucks.  The net learns the minimum necessary to steer on the training set.  In contrast, human driving is remarkably robust as features become obscured.  Motivated by this, we propose a framework for robust learning that biases induction to learn many different models from the same inputs.  We present a meta algorithm for robust learning called FeatureBoost, and demonstrate it on several problems using backprop nets, k-nearest neighbor, and decision trees.  1.  Motivation Consider a backprop net learning to steer a car.  In the ALVINN system (Pomerleau, 1993) the principal internal features learned by ALVINN nets detect the left and right edges of the road.  Typically, ALVINN nets do not learn internal features that detect other road phenomena that could be useful for steering such as road centerlines, roadway signs, trees, other traffic, people, etc.  This creates a problem when the left or right edges of the road are obstructed by passing vehicles, or are missing as on bridges and in tunnels.  Yet human steering is remarkably robust to the loss of these features.  Human drivers can fall back on a number of alternate features as different subsets of road features come in and out of view.  Backprop nets can learn to steer better if they learn to recognize other road features such as centerlines (Caruana, 1997).  How can we force backprop nets to learn to use a variety of road features when learning to steer? A related problem arises in health care (Cooper et al. , 1997).  Basic inputs such as age, gender, and blood pressure are available for most patients before they enter the hospital.  Other measurements such as RBC counts, oxygenation, and Albumin become available after patients are hospitalized.  As you would expect, models trained to predict patient risk from both the pre and in-hospital features usually outperform models trained to predict risk from only the prehospital inputs.  But these models perform poorly on patients not yet admitted to the hospital when one marginalizes over the missing in-hospital features.  Models that use only the pre-hospital inputs are more accurate for patients not yet admitted to the hospital than marginalized models trained on all the features.  How can we force learning to learn models that make better predictions when some input features (such as the in-hospital attributes) are missing for some test cases? If the edges of the road, or the in-hospital features are always available, models learned the usual way perform well.  In the ALVINN and health care problems above, the difficulty arises when features are missing or obscured in the test cases.  Boosting algorithms such as AdaBoost are one way to make learned models more robust to feature obscuration.  If the main features such as the edges of the road are obscured or missing from a few training cases, boosting places more emphasis on these cases because they are predicted poorly.  This emphasis forces the learning algorithm to use other features such as road centerlines for these cases.  Unfortunately, boosting learns about centerlines by strongly emphasizing the cases that are missing road edges, even though centerlines may be visible in all images.  Boosting could learn about other features better if it used all of the training data containing those features to learn about them.  How can we make boosting take full advantage of all the redundant information in the training set? This paper introduces a general framework for induction called robust learning, which is motivated by our desire to model situations where features may be corrupted or missing in ways not adequately represented in the training set.  Guided by the framework, we devise a meta-learning algorithm called FeatureBoost, that trains models to use different subsets of features.  Because the final prediction from FeatureBoost combines the predictions of models that depend on different (often overlapping) subsets of features, it is more robust to missing or obscured features.  We develop the paper as follows: 1 Present a general framework for robust learning.  2 Examine a specialization of this framework that suggests one way to improve robustness.  3 Develop a meta-learning algorithm (FeatureBoost) inspired by this model.  4 Test FeatureBoost on a variety of learning problems and machine learning algorithms. 
Non-Parametric Fault Identification for Space Rovers| Abstract Autonomous fault detection is prerequisite for autonomous system repair which is of great value for spacecraft where human intervention is expensive, slow, unreliable, and occasionally impossible.  We present a method which successfully achieves autonomous fault detection in simulation.  The approach uses a nonparametric estimate of the system state updated based upon sensor measurements.  Our system does state estimation using a decision-theoretic generalization of particle filters which takes into account the difference in utility of fault detection vs.  fault nondetection. 
Beating the Hold-Out: Bounds for K-fold and Progressive Cross-Validation| Abstract The empirical error on a test set, the hold-out estimate, often is a more reliable estimate of generalization error than the observed error on the training set, the training estimate.  K-fold cross validation is used in practice with the hope of being more accurate than the hold-out estimate without reducing the number of training examples.  We argue that the k-fold estimate does in fact achieve this goal.  Specifically, we show that for any nontrivial learning problem and learning algorithm that is insensitive to example ordering, the k-fold estimate is strictly more accurate than a single hold-out estimate on 1/k of the data, for 2 ! k ! n (k = n is leave-one-out), based on its variance and all higher moments.  Previous bounds were termed sanitycheck because they compared the k-fold estimate to the training estimate and, further, restricted the VC dimension and required a notion of hypothesis stability [2].  In order to avoid these dependencies, we consider a k-fold hypothesis that is a randomized combination or average of the k individualhypotheses.  We introduce progressive validationas another possible improvement on the hold-out estimate.  This estimate of the generalization error is, in many ways, as good as that of a single hold-out, but it uses an average of half as many examples for testing.  The procedure also involves a hold-out set, but after an example has been tested, it is added to the training set and the learning algorithm is rerun. 
CAPTCHA: Using Hard AI Problems for Security| Abstract.  We introduce captcha, an automated test that humans can pass, but current computer programs can't pass: any program that has high success over a captcha can be used to solve a hard, unsolved Artificial Intelligence (AI) problem. 
Provably Secure Steganography| Abstract Informally, steganography is the process of sending a secret message from Alice to Bob in such a way that an eavesdropper (who listens to all communications) cannot even tell that a secret message is being sent.  In this work, we initiate the study of steganography from a complexity-theoretic point of view.  We introduce definitions based on computational indistinguishability and we prove that the existence of one-way functions implies the existence of secure steganographic protocols. 
An Improved Predictive Accuracy Bound for Averaging Classifiers| Abstract We present an improved bound on the difference between training and test errors for voting classifiers.  This improved averaging bound provides a theoretical justi#cation for popular averaging techniques such as Bayesian classification, Maximum Entropy discrimination, Winnow and Bayes point machines and has implications for learning algorithm design. 
PAC-MDL Bounds| Abstract.  We point out that a number of standard sample complexity bounds (VC-dimension, PAC-Bayes, and others) are all related to the number of bits required to communicate the labels given the unlabeled data for a natural communication game.  Motivated by this observation, we give a general sample complexity bound based on this game that allows us to unify these different bounds in one common framework. 
Correlated equilibria in graphical games| ABSTRACT We examine correlated equilibria in the recently introduced formalism of graphical games, a succinct representation for multiplayer games.  We establish a natural and powerful relationship between the graphical structure of a multiplayer game and a certain Markov network representing distributions over joint actions.  Our first main result establishes that this Markov network succinctly represents all correlated equilibria of the graphical game up to expected payoff equivalence.  Our second main result provides a general algorithm for computing correlated equilibria in a graphical game based on its associated Markov network.  For a special class of graphical games that includes trees, this algorithm runs in time polynomial in the graphical game representation (which is polynomial in the number of players and exponential in the graph degree). 
Exploration in Metric State Spaces| Abstract We present metric-4 , a provably near-optimal algorithm for reinforcement learning in Markov decision processes in which there is a natural metric on the state space that allows the construction of accurate local models.  The algorithm is a generalization of the he algorithm of Kearns and Singh, and assumes a black box for approximate planning.  Unlike the originalri , metricme finds a near optimal policy in an amount of time that does not directly depend on the size of the state space, but instead depends on the covering number of the state space.  Informally, the covering number is the number of neighborhoods required for accurate local modeling. 
PAC-Bayes & Margins| Abstract We show two related things: (1) Given a classifier which consists of a weighted sum of features with a large margin, we can construct a stochastic classifier with negligibly larger training error rate.  The stochastic classifier has a future error rate bound that depends on the margin distribution and is independent of the size of the base hypothesis class.  (2) A new true error bound for classifiers with a margin which is simpler, functionally tighter, and more data-dependent than all previous bounds. 
Computable Shell Decomposition Bounds| Abstract Haussler, Kearns, Seung and Tishby introduced the notion of a shell decomposition of the union bound as a means of understanding certain empirical phenomena in learning curves such as phase transitions.  Here we use a variant of their ideas to derive an upper bound on the generalization error of a hypothesis computable from its training error and the histogram of training errors for the hypotheses in the class.  In most cases this new bound is significantly tighter than traditional bounds computed from the training error and the cardinality or VC dimension of the class.  Our results can also be viewed as providing PAC theoretical foundations for a model selection algorithm proposed by Scheffer and Joachims. 
Competitive Analysis of the Explore/Exploit Tradeoff| Abstract We investigate the explore/exploit trade-off in reinforcement learning using competitive analysis applied to an abstract model.  We state and prove lower and upper bounds on the competitive ratio.  The essential conclusion of our analysis is that optimizing the explore/exploit trade-off is much easier with a few pieces of extra knowledge such as the stopping time or upper and lower bounds on the value of the optimal exploitation policy. 
Approximately Optimal Approximate Reinforcement Learning| Abstract In order to solve realistic reinforcement learning problems, it is critical that approximate algorithms be used.  In this paper, we present the conservative policy iteration algorithm which finds an #approximately# optimal policy, given access to a restart distribution (which draws the next state from a particular distribution) and an approximate greedy policy chooser.  Crudely, the greedy policy chooser outputs a policy that usually chooses actions with the largest state-action values of the current policy, ie it outputs an #approximate# greedy policy.  This greedy policy chooser can be implemented using standard value function approximation techniques.  Under these assumptions, our algorithm: (1) is guaranteed to improve a performance metric (2) is guaranteed to terminate in a #small# number of timesteps and (3) returns an #approximately# optimal policy.  The quantifled statements of (2) and (3) depend on the quality of the greedy policy chooser, but not explicitly on the the size of the state space. 
Risk Sensitive Particle Filters| Abstract We propose a new particle filter that incorporates a model of costs when generating particles.  The approach is motivated by the observation that the costs of accidentally not tracking hypotheses might be significant in some areas of state space, and irrelevant in others.  By incorporating a cost model into particle filtering, states that are more critical to the system performance are more likely to be tracked.  Automatic calculation of the cost model is implemented using an MDP value function calculation that estimates the value of tracking a particular state.  Experiments in two mobile robot domains illustrate the appropriateness of the approach. 
(Not) Bounding the True Error| Abstract We present a new approach to bounding the true error rate of a continuous valued classifier based upon PAC-Bayes bounds.  The method first constructs a distribution over classifiers by determining how sensitive each parameter in the model is to noise.  The true error rate of the stochastic classifier found with the sensitivity analysis can then be tightly bounded using a PAC-Bayes bound.  In this paper we demonstrate the method on artificial neural networks with results of a 2 3 order of magnitude improvement vs.  the best deterministic neural net bounds. 
Monte Carlo Hidden Markov Models: Learning Non-Parametric Models of Partially Observable Stochastic Processes|
Cost-Sensitive Learning by Cost-Proportionate Example Weighting|
Reducing T-step reinforcement learning to classification|
Telling humans and computers apart automatically|
Tutorial on practical prediction theory for classification|
Beating the Hold-Out: Bounds for K-fold and Progressive Cross-Validation|
"Microchoice and self-bounding algorithms",|
An objective evaluation criterion for clustering|
Combining Trainig Set and Test Set Bounds|
Quantitatively Tight Sample Complexity Bounds#,|
