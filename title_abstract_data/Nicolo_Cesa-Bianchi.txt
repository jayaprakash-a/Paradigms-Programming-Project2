Gambling in a rigged casino: The adversarial multi-armed bandit problem| Abstract In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. 
On-line Prediction and Conversion Strategies| Abstract We study the problem of deterministically predicting boolean values by combining the boolean predictions of several experts.  Previous online algorithms for this problem predict with the weighted majority of the experts' predictions.  These algorithms give each expert an exponential weight fi m where fi is a constant in [0; 1) and m is the number of mistakes made by the expert in the past.  We show that it is better to use sums of binomials as weights.  In particular, we present a deterministic algorithm using binomial weights that has a better worst case mistake bound than the best deterministic algorithm using exponential weights.  The binomial weights naturally arise from a version space argument.  We also show how both exponential and binomial weighting schemes can be used to make prediction algorithms robust against noise. 
Worst-case Bounds for the Logarithmic Loss of Predictors| Using Shtarkov's theorem and tools from empirical process theory, we prove a general upper bound on the best possible (minimax) regret.  The bound depends on certain metric properties of the class of predictors.  We apply the bound to both parametric and nonparametric classes of predictors.  Finally, we point out a suboptimal behavior of the popular Bayesian weighted average algorithm. 
Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms| Abstract We provide a worst-case analysis of selective sampling algorithms for learning linear threshold functions.  The algorithms considered in this paper are Perceptron-like algorithms, i. e. , algorithms which can be efficiently run in any reproducing kernel Hilbert space.  Our algorithms exploit a simple margin-based randomized rule to decide whether to query the current label.  We obtain selective sampling algorithms achieving on average the same bounds as those proven for their deterministic counterparts, but using much fewer labels.  We complement our theoretical findings with an empirical comparison on two text categorization tasks.  The outcome of these experiments is largely predicted by our theoretical results: Our selective sampling algorithms tend to perform as good as the algorithms receiving the true label after each classification, while observing in practice substantially fewer labels. 
The Nonstochastic Multiarmed Bandit Problem| Abstract.  In the multiarmed
Bounds on approximate steepest descent for likelihood maximization in exponential families| Abstract An approximate steepest descent strategy converging, in families of regular exponential densities, to maximum likelihood estimates of density functions is described.  These density estimates are also obtained by an application of the principle of minimum relative entropy subject to empirical constraints.  We prove tight bounds on the increase of the log-likelihood at each iteration of our strategy for families of exponential densities whose log-densities are spanned by a set of bounded basis functions. 
Adaptive and Self-Confident On-Line Learning Algorithms| Abstract Most of the performance bounds for on-line learning algorithms are proven assuming a constant learning rate.  To optimize these bounds, the learning rate must be tuned based on quantities that are generally unknown, as they depend on the whole sequence of examples.  In this paper we show that essentially the same optimized bounds can be obtained when the algorithms adaptively tune their learning rates as the examples in the sequence are progressively revealed.  Our adaptive learning rates apply to a wide class of on-line algorithms, including p-norm algorithms for generalized linear regression and Weighted Majority for linear regression with absolute loss.  We emphasize that our adaptive tunings are radically different from previous techniques, such as the so-called doubling trick.  Whereas the doubling trick restarts the on-line algorithm several times using a constant learning rate for each run, our methods save information by changing the value of the learning rate very smoothly.  In fact, for Weighted Majority over a finite set of experts our analysis provides a better leading constant than the doubling trick. 
Finite-time Analysis of the Multiarmed Bandit Problem| Abstract Reinforcement learning policies face the exploration versus exploitation dilemma, i. e.  the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible.  A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times.  One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem.  Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays.  Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others.  In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and ecient policies, and for all reward distributions with bounded support. 
Analysis of Two Gradient-based Algorithms for On-line Regression| Abstract In this paper we present a new analysis of two algorithms, Gradient Descent and Exponentiated Gradient, for solving regression problems in the on-line framework.  Both these algorithms compute a prediction that depends linearly on the current instance, and then update the coefficients of this linear combination according to the gradient of the loss function.  However, the two algorithms have distinctive ways of using the gradient information for updating the coefficients.  For each algorithm, we show general regression bounds for any convex loss function.  Furthermore, we show special bounds for the absolute and the square loss functions, thus extending previous results by Kivinen and Warmuth.  In the nonlinear regression case, we show general bounds for pairs of transfer and loss functions satisfying a certain condition.  We apply this result to the Hellinger loss and the entropic loss in case of logistic regression (similar results, but only for the entropic loss, were also obtained by Helmbold et al.  using a different analysis. ) Finally, we describe the connection between our approach and a general family of gradient-based algorithms proposed by Warmuth et al.  in recent works. 
Margin-Based Algorithms for Information Filtering| Abstract In this work, we study an information filtering model where the relevance labels associated to a sequence of feature vectors are realizations of an unknown probabilistic linear function.  Building on the analysis of a restricted version of our model, we derive a general filtering rule based on the margin of a ridge regression estimator.  While our rule may observe the label of a vector only by classfying the vector as relevant, experiments on a real-world document filtering problem show that the performance of our rule is close to that of the on-line classifier which is allowed to observe all labels.  These empirical results are complemented by a theoretical analysis where we consider a randomized variant of our rule and prove that its expected number of mistakes is never much larger than that of the optimal filtering rule which knows the hidden linear model. 
Worst-Case Bounds for the Logarithmic Loss of Predictors| Abstract We investigate on-line prediction of individual sequences.  Given a class of predictors, the goal is to predict as well as the best predictor in the class, where the loss is measured by the self information (logarithmic) loss function.  The excess loss (regret) is closely related to the redundancy of the associated lossless universal code.  Using Shtarkov's theorem and tools from empirical process theory, we prove a general upper bound on the best possible (minimax) regret.  The bound depends on certain metric properties of the class of predictors.  We apply the bound to both parametric and nonparametric classes of predictors.  Finally, we point out a suboptimal behavior of the popular Bayesian weighted average algorithm. 
Worst-Case Analysis of the Bandit Problem| Abstract The multi-armed bandit is a classical problem in the area of sequential decision theory and has been studied under a variety of statistical assumptions.  In this work we investigate the bandit problem from a purely worst-case standpoint.  We present a randomized algorithm with an expected total reward of G\Gamma O(G 4=5 K 6=5 ) (disregarding log factors), where K is the number of arms and G is the (unknown) total reward of the best arm.  Our analysis holds with no assumptions whatsoever on the way rewards are generated, other than being independent of the algorithm's randomization.  Our results can also be interpreted as a novel extension of the on-line prediction model, an intensively studied framework in learning theory. 
Worst-case Quadratic Loss Bounds for Prediction Using Linear Functions and Gradient Descent| Abstract In this paper we study the performance of gradient descent when applied to the problem of on-line linear prediction in arbitrary inner product spaces.  We show worst-case bounds on the sum of the squared prediction errors under various assumptions concerning the amount of a priori information about the sequence to predict.  The algorithms we use are variants and extensions of on-line gradient descent.  Whereas our algorithms always predict using linear functions as hypotheses, none of our results requires the data to be linearly related.  In fact, the bounds proved on the total prediction loss are typically expressed as a function of the total loss of the best fixed linear predictor with bounded norm.  All the upper bounds are tight to within constants.  Matching lower bounds are provided in some cases.  Finally, we apply our results to the problem of on-line prediction for classes of smooth functions.  Keywords: prediction, Widrow-Hoff algorithm, gradient descent, adaptive linear filter theory, smoothing, inner product spaces, computational learning theory, on-line learning, linear systems, worst-case loss bounds. 
Multilayer Perceptrons and Learning| Abstract In this paper we present a survey on some interesting contributions offered by theoretical computer science to the area of supervised learning.  In the first part, we discuss the computing capabilities of multilayer preceptrons with binary inputs and outputs and we describe design techniques for some classes of simple boolean functions.  Finally, we show the application of communication complexity to obtain separations between complexity classes related to multilayer preceptrons.  In the second part, we look at the learnability of these computing models within the PAC learning framework and some of its variants.  The hardness of polynomial time prediction for the class of multilayer perceptrons is shown under cryptographical assumptions.  We conclude by presenting a recently developed technique for boosting the accuracy of PAC learning algorithms. 
Characterizations of Learnability for Classes of| Abstract We investigate the PAC learnability of classes of f0; : : : ; ng-valued functions (n ! 1).  For n = 1 it is known that the finiteness of the Vapnik-Chervonenkis dimension is necessary and sufficient for learning.  For n ? 1 several generalizations of the VC-dimension, each yielding a distinct characterization of learnability, have been proposed by a number of researchers.  In this paper we present a general scheme for extending the VC-dimension to the case n ? 1.  Our scheme defines a wide variety of notions of dimension in which all these variants of the VC-dimension, previously introduced in the context of learning, appear as special cases.  Our main result is a simple condition characterizing the set of notions of dimension whose finiteness is necessary and sufficient for learning.  This provides a variety of new tools for determining the learnability of a class of multi-valued functions.  Our characterization is also shown to hold in the "robust" variant of PAC model and for any "reasonable" loss function. 
Potential-Based Algorithms in On-Line Prediction and Game Theory| Abstract In this paper we show that several known algorithms for sequential prediction problems (including the quasi-additive family of Grove et al.  and Littlestone and Warmuth's Weighted Majority), for playing iterated games (including Freund and Schapire's Hedge and MW, as well as the #strategies of Hart and Mas-Colell), and for boosting (including AdaBoost) are special cases of a general decision strategy based on the notion of potential.  By analyzing this strategy we derive known performance bounds, as well as new bounds, as simple corollaries of a single general theorem.  Besides offering a new and unified view on a large family of algorithms, we establish a connection between potential-based analysis in learning and their counterparts independently developed in game theory.  By exploiting this connection, we show that certain learning problems are instances of more general game-theoretic problems.  In particular, we describe a notion of generalized regret and show its applications in learning theory. 
Regret Minimization Under Partial Monitoring| Abstract We consider repeated games in which the player, instead of observing the action chosen by the opponent in each game round, receives a feedback generated by the combined choice of the two players.  We study Hannan consistent players for these games, that is, randomized playing strategies whose per-round regret vanishes with probability one as the number n of game rounds goes to infinity.  We prove a general lower bound of #(n- 1/3 ) for the convergence rate of the regret, and exhibit a specific strategy that attains this rate for any game for which a Hannan consistent player exists. 
On the Generalization Ability of On-Line Learning Algorithms| Abstract---In this paper, it is shown how to extract a hypothesis with small risk from the ensemble of hypotheses generated by an arbitrary on-line learning algorithm run on an independent and identically distributed (i. i. d. ) sample of data.  Using a simple large deviation argument, we prove tight data-dependent bounds for the risk of this hypothesis in terms of an easily computable statistic associated with the on-line performance of the ensemble.  Via sharp pointwise bounds on , we then obtain risk tail bounds for kernel Perceptron algorithms in terms of the spectrum of the empirical kernel matrix.  These bounds reveal that the linear hypotheses found via our approach achieve optimal tradeoffs between hinge loss and margin size over the class of all linear functions, an issue that was left open by previous results.  A distinctive feature of our approach is that the key tools for our analysis come from the model of prediction of individual sequences; i. e. , a model making no probabilistic assumptions on the source generating the data.  In fact, these tools turn out to be so powerful that we only need very elementary statistical facts to obtain our final risk bounds. 
Randomized Hypotheses and Minimum Disagreement Hypotheses for Learning with Noise| Abstract In this paper we prove various results about PAC learning in the presence of malicious and random classification noise.  Our main theme is the use of randomized hypotheses for learning with small sample sizes and high malicious noise rates.  We show an algorithm that PAC learns any target class of VC-dimension d using randomized hypotheses and order of d=" training examples (up to logarithmic factors) while tolerating malicious noise rates even slightly larger than the information-theoretic bound ''=(1 + '') for deterministic hypotheses.  Combined with previous results, this implies that a lower bound d=\Delta + ''=\Delta 2 on the sample size, where j = ''=(1 + '')\Gamma \Delta is the malicious noise rate, applies only when using deterministic hypotheses.  We then show that the information-theoretic upper bound on the noise rate for deterministic hypotheses can be replaced by 2"=(1 + 2") if randomized hypotheses are used.  Investigating further the use of randomized hypotheses, we show a strategy for learning the powerset of d elements using an optimal sample size of order d"=\Delta 2 (up to logarithmic factors) and tolerating a noise rate j = 2"=(1 +2") \Gamma \Delta.  We complement this result by proving that this sample size is also necessary for any class C of VC-dimension d.  We then discuss the performance of the minimum disagreement strategy under both malicious and random classification noise models.  For malicious noise we show an algorithm that, using deterministic hypotheses, learns unions of d intervals on the continuous domain [0; 1) using a sample size significantly smaller than that needed by the minimum disagreement strategy.  For classification noise we show, generalizing a result by Laird, that order of d=("\Delta 2 ) training examples suffice (up to logarithmic factors) to learn by minimizing disagreements any target class of VC-dimension d tolerating random classification noise rate j = 1=2 \Gamma \Delta.  Using a lower bound by Simon, we also prove that this sample size bound cannot be significantly improved. 
On Bayes Methods for On-Line Boolean Prediction| Abstract This paper proposes a general framework, based on weighting schemes, within which the Bayes method applied to on-line Boolean prediction can be studied.  By applying standard tools in Bayes theory we propose an improved variant of the Weighted Majority algorithm for deterministic prediction.  The mistake bound of our variant is asymptotically equal to the mistake bound of Weighted Majority when the latter has additional side information to optimally tune its update factor.  We also show general bounds on the number of prediction mistakes made by conservative versions of Bayesian algorithms.  Specific instances of our bounds match bounds previously shown for different on-line prediction algorithms proposed in the past.  Finally, we study a generalization of these methods to randomized predictions. 
Minimizing Regret with Label Efficient Prediction| Abstract--- We investigate label efficient prediction, a variant, proposed by Helmbold and Panizza, of the problem of prediction with expert advice.  In this variant the forecaster, after guessing the next element of the sequence to be predicted, does not observe its true value unless he asks for it, which he cannot do too often.  We determine matching upper and lower bounds for the best possible excess prediction error, with respect to the best possible constant predictor, when the number of allowed queries is fixed.  We also prove that Hannan consistency, a fundamental property in game-theoretic prediction models, can be achieved by a forecaster issuing a number of queries growing to infinity at a rate just slightly faster than logarithmic in the number of prediction rounds. 
On-line Learning with Malicious Noise and the Closure Algorithm| Abstract We investigate a variant of the on-line learning model for classes of f0; 1gvalued functions (concepts) in which the labels of a certain amount of the input instances are corrupted by adversarial noise.  We propose an extension of a general learning strategy, known as "Closure Algorithm", to this noise model, and show a worst-case mistake bound of m+ (d + 1)K for learning an arbitrary intersection-closed concept class C, where K is the number of noisy labels, d is a combinatorial parameter measuring C's complexity, and m is the worst-case mistake bound of the Closure Algorithm for learning C in the noise-free model.  For several concept classes our extended Closure Algorithm is efficient and can tolerate a noise rate up to the information-theoretic upper bound.  Finally, we show how to efficiently turn any algorithm for the on-line noise model into a learning algorithm for the PAC model with malicious noise. 
On Prediction of Individual Sequences \Lambda| Abstract Sequential randomized prediction of an arbitrary binary sequence is investigated.  No assumption is made on the mechanism of generating the bit sequence.  The goal of the predictor is to minimize its relative loss, i. e. , to make (almost) as few mistakes as the best "expert" in a fixed, possibly infinite, set of experts.  We point out a surprising connection between this prediction problem and empirical process theory.  First, in the special case of static (memoryless) experts, we completely characterize the minimax relative loss in terms of the maximum of an associated Rademacher process.  Then we show general upper and lower bounds on the minimax relative loss in terms of the geometry of the class of experts.  As main examples, we determine the exact order of magnitude of the minimax relative loss for the class of autoregressive linear predictors and for the class of Markov experts. 
How to use expert advice|
Minimax values and entropy bounds for portfolio selection problems|
How to use expert advice|
Worst-case quadratic loss bounds for on-line prediction of linear functions by gradient descent|
Analysis of two gradientbased algorithms for on-line reression|
Finite-Time Regret Bounds for the Multiarmed Bandit Problem|
Minimax Regret Under log Loss for General Classes of Experts|
A Second-Order Perceptron Algorithm|
Improved second-order bounds for prediction with expert advice|
Characterizations of learnability for classes of f0; : : : ; ng-valued functions|
Noisetolerant learning near the informationn-theoretic bound|
Diagnosis of epilepsy via backpropagation,|
Noise-Tolerant Learning Near the Information-Theoretic Bound|
Worst-Case Quadratic Loss Bounds for a Generalization of the Widrow-Hoff Rule|
in:|
On Bayes methods for on-line boolean prediction|
On prediction of individual sequences|
Sample-Efficient Strategies for Learning in the Presence of Noise|
How to use expert advise?|
Scale-sensitive Dimensions, Uniform Convergence, and Learnability," pages 292--301|
Models of learning with noise|
Worst-case quadratic bounds for on-line prediction of linear functions by gradient descent|
Bianchi On-Line Learning with Malicious Noise and the Closure Algorithm|
Learning Probabilistic Linear-Threshold Classifiers via Selective Sampling|
Characterizations of Learnability for Classes of {0, |. . , n}-Valued Functions. 
The effect of nicotine and cytisine on 3 H-acetylcholine release from cortical slices of guinea-pig brain|
Kernal method for document filtering|
A Graph-theoretic Generalization of the Sauer-Shelah Lemma|
Analysis of Large Scale Econometric Models Using Supercomputer Techniques|
Kernel Methods for Document Filtering|
