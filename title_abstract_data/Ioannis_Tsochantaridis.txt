Efficient Methods for Computing Investment Strategies for Multi-Market Commodity Trading| Abstract The focus of this work is the computation of ecient strategies for commodity trading in a multi-market environment.  In today's \global economy" commodities are often bought in one location and then sold (right away, or after some storage period) in different markets.  Thus, a trading decision in one location must be based on expectations about future price curves in all other relevant markets, and on current and future storage and transportation costs.  Investors try to compute a strategy that maximizes expected return, usually with some limitations on assumed risk.  With standard stochastic assumptions on commodity price fluctuations, computing an optimal strategy can be modeled as a Markov decision process (MDP).  However, in general such a formulation does not lead to ecient algorithms.  In this work we propose a model for representing the multi-market trading problem and show how to obtain ecient structured algorithms for computing optimal strategies for a number of commonly used trading objective functions (Expected NPV, Mean-Variance, and Value at Risk). 
Support Vector Machines for Multiple-Instance Learning| Abstract This paper presents two new formulations of multiple-instance learning as a maximum margin problem.  The proposed extensions of the Support Vector Machine (SVM) learning approach lead to mixed integer quadratic programs that can be solved heuristically.  Our generalization of SVMs makes a state-of-the-art classification technique, including non-linear classification via kernels, available to an area that up to now has been largely dominated by special purpose methods.  We present experimental results on a pharmaceutical data set and on applications in automated image indexing and document categorization. 
Support vector machine learning for interdependent and structured output spaces| Abstract Learning general functional dependencies is one of the main goals in machine learning.  Recent progress in kernel-based methods has focused on designing flexible and powerful input representations.  This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces.  We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs.  The resulting optimization problem is solved eciently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem.  We demonstrate the versatility and eectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment. 
Computing Global Strategies for Multi-Market Commodity Trading| Abstract The focus of this work is the computation of ecient strategies for commodity trading in a multi-market environment.  In today's \global economy" commodities are often bought in one location and then sold (right away, or after some storage period) in different markets.  Thus, a trading decision in one location must be based on expectations about future price curves in all other relevant markets, and on current and future storage and transportation costs.  Investors try to compute a strategy that maximizes expected return, usually with some limitations on assumed risk.  With standard stochastic assumptions on commodity price fluctuations, computing an optimal strategy can be modeled as a Markov decision process (MDP).  However, in general such a formulation does not lead to ecient algorithms.  In this work we propose a model for representing the multi-market trading problem and show how to obtain ecient structured algorithms for computing optimal strategies for a number of commonly used trading objective functions (Expected NPV, Mean-Variance, and Value at Risk). 
Brownian Motion on a Smash Line| Abstract Brownian motion on a smash line algebra (a smash or braided version of the algebra resulting by tensoring the real line and the generalized paragrassmann line algebras), is constructed by means of its Hopf algebraic structure.  Further, statistical moments, non stationary generalizations and its diffusion limit are also studied.  The ensuing diffusion equation possesses triangular matrix realizations. 
Hidden Markov Support Vector Machines| Abstract This paper presents a novel discriminative learning technique for label sequences based on a combination of the two most
Topic-based document segmentation with probabilistic latent semantic analysis| ABSTRACT This paper presents a new method for topic-based document segmentation, i. e. , the identification of boundaries between parts of a document that bear on different topics.  The method combines the use of the Probabilistic Latent Semantic Analysis (PLSA) model with the method of selecting segmentation points based on the similarity values between pairs of adjacent blocks.  The use of PLSA allows for a better representation of sparse information in a text block, such as a sentence or a sequence of sentences.  Furthermore, segmentation performance is improved by combining different instantiations of the same model, either using different random initializations or different numbers of latent classes.  Results on commonly available data sets are significantly better than those of other state-of-the-art systems. 
Learning over structured output spaces via joint kernel functions|
Hiddem markov support vector machines|
