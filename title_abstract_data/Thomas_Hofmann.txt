Probabilistic Latent Semantic Analysis| Abstract Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data.  Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{speci#c synonymy as well as with polysemous words.  In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model.  Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methodsaswell as over LSI.  In particular, the combination of models with different dimensionalities has proven to be advantageous. 
To appear in: AI-based Mobile Robots: Case studies of successful robot systems| Abstract This chapter surveys basic methods for
Support Vector Machines for Multiple-Instance Learning| Abstract This paper presents two new formulations of multiple-instance learning as a maximum margin problem.  The proposed extensions of the Support Vector Machine (SVM) learning approach lead to mixed integer quadratic programs that can be solved heuristically.  Our generalization of SVMs makes a state-of-the-art classification technique, including non-linear classification via kernels, available to an area that up to now has been largely dominated by special purpose methods.  We present experimental results on a pharmaceutical data set and on applications in automated image indexing and document categorization. 
areas| Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of. 
A theory of proximity based clustering: structure detection by optimization| Abstract In this paper, a systematic optimization approach for clustering proximity or similarity data is developed.  Starting from fundamental invariance and robustness properties, a set of axioms is proposed and discussed to distinguish different cluster compactness and separation criteria.  The approach covers the case of sparse proximity matrices, and is extended to nested partitionings for hierarchical data clustering.  To solve the associated optimization problems, a rigorous mathematical framework for deterministic annealing and mean--field approximation is presented.  Efficient optimization heuristics are derived in a canonical way, which also clarifies the relation to stochastic optimization by Gibbs sampling.  Similarity-based clustering techniques have a broad range of possible applications in computer vision, pattern recognition, and data analysis.  As a major practical application we present a novel approach to the problem of unsupervised texture segmentation, which relies on statistical tests as a measure of homogeneity.  The quality of the algorithms is empirically evaluated on a large collection of Brodatz--like micro-texture Mondrians and on a set of real--word images.  To demonstrate the broad usefulness of the theory of proximity based clustering the performances of different criteria and algorithms are compared on an information retrieval task for a document database.  The superiority of optimization algorithms for clustering is supported by extensive experiments. 
Support vector machine learning for interdependent and structured output spaces| Abstract Learning general functional dependencies is one of the main goals in machine learning.  Recent progress in kernel-based methods has focused on designing flexible and powerful input representations.  This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces.  We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs.  The resulting optimization problem is solved eciently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem.  We demonstrate the versatility and eectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment. 
ROBUST VECTOR QUANTIZATION BY COMPETITIVE LEARNING| ABSTRACT Competitive neural networks can be used to efficiently quantize image and video data.  We discuss a novel class of vector quantizers which perform noise robust data compression.  The vector quantizers are trained to simultaneously compensate channel noise and code vector elimination noise.  The training algorithm to estimate code vectors is derived by the maximum entropy principle in the spirit of deterministic annealing.  We demonstrate the performance of noise robust codebooks with compression results for a teleconferencing system on the basis of a wavelet image representation. 
Large Margin Methods for Label Sequence Learning| Abstract Label sequence learning is the problem of inferring a state sequence from an observation sequence, where the state sequence may encode a labeling, annotation or segmentation of the sequence.  In this paper we give an overview of discriminative methods developed for this problem.  Special emphasis is put on large margin methods by generalizing multiclass Support Vector Machines and AdaBoost to the case of label sequences.  An experimental evaluation demonstrates the advantages over classical approaches like Hidden Markov Models and the competitiveness with methods like Conditional Random Fields. 
Mixture Models for Co-occurrence and Histogram Data \Lambda| Abstract Modeling and predicting co-occurrences of events is a fundamental problem of unsupervised learning.  In this contribution, we develop a general statistical framework for analyzing co-occurrence data based on probabilistic clustering by mixture models.  More specifically, we discuss three models which pursue different modeling goals and which differ in the way they define the probabilistic partitioning of the observations.  Adopting the maximum likelihood principle, annealed EM algorithms are derived for parameter estimation.  From the class of potential applications in pattern recognition and data analysis, we have chosen document retrieval, language modeling, and unsupervised texture segmentation to test and evaluate the proposed algorithms. 
The Missing Link - A Probabilistic Model of Document Content and Hypertext Connectivity| Abstract We describe a joint probabilistic model for modeling the contents and inter-connectivity of document collections such as sets of web pages or research paper archives.  The model is based on a probabilistic factor decomposition and allows identifying principal topics of the collection as well as authoritative documents within those topics.  Furthermore, the relationships between topics is mapped out in order to build a predictive model of link content.  Among the many applications of this approach are information retrieval and search,
Histogram Clustering for Unsupervised Image Segmentation| Abstract This paper introduces a novel statistical mixture model for probabilistic grouping of distributional (histogram) data.  Adopting the Bayesian framework, we propose to perform annealed maximum a posteriori estimation to compute optimal clustering solutions.  In order to accelerate the optimization process, an efficient multiscale formulation is developed.  We present a prototypical application of this method for the unsupervised segmentation of textured images based on local distributions of Gabor coefficients.  Benchmark results indicate superior performance compared to K--means clustering and proximity-based algorithms. 
An Object-Oriented Framework for Configurable Coordination of Heterogeneous Agents Diploma Thesis of the Faculty of Sciences University of Berne| Neubruckstrasse 10 CH-3012 Bern Switzerland mailto:hofmann@iam. unibe. ch http://www. iam. unibe. 
Overview of the field measurement campaign in Hyytiala, August 2001 in the framework of the EU project OSOA| Abstract.  As part of the OSOA (Origin and formation of Secondary Organic Aerosols) project, two intensive field campaigns were conducted in Melpitz, Germany and Hyytiala, Finland.  This paper gives an overview of the measurements made during the Hyytiala campaign, which was held between 1 and 16 August 2001.  Various instrumental techniques were used to achieve physical and chemical characterisation of aerosols and to investigate possible precursor gases.  During the OSOA campaign in Hyytiala, particle formation was observed on three consecutive days at the beginning of the campaign (1 to 3 August 2001) and on three days later on.  The investigation of the meteorological situation divided the campaign into two parts.  During the first three days of August, relatively cold and clean air masses from northwest passed over the station (condensation sink -- CS: <0. 002 s- 1 , NO x : <0. 5 ppb).  Daily particle bursts of one fraction of the nucleation mode aerosols (3--10 nm) with number concentrations between 600--1200 particles cm- 3 were observed.  After this period, warmer and more polluted air from south-west to south-east arrived at the station (CS: 0. 002--0. 01 s - 1 , NO x : 0. 5--4 ppb) and during these 13 days only three events were observed.  These events were not as apparent as those that occurred during the earlier period of the campaign.  The chemical analyses from different institutes of PM 2 , PM 2. 5 and PM 10 particles confirmed the assumption that organic matCorrespondence to: M.  Boy (michael. boy@helsinki. fi) ter from the oxidation of various terpenes contributed to the formation of secondary organic aerosols (SOA).  Concerning these conclusions among others, the ratio between formic (oxidation product of isoprene and monoterpenes by ozone) and acetic acid (increased by anthropogenic emissions) (ratio=1 to 1. 5) and concentration of different carboxylic acids (up to 62 ng m - 3 ) were investigated.  Gas/particle partitioning of five photo-oxidation products from #- and #-pinene resulted in higher concentrations of pinonic, nor pinonic and pinic acids in the particle phase than in the gas phase, which indicates a preference to the particle phase for these compounds.  The average growth factors (GF) from 100 nm particles in water vapour gave a diurnal pattern with a maximum during daytime and values between 1. 2 and 1. 7.  On average, the amount of secondary organic carbon reached values around 19% of the sampled aerosols and we speculate that formation of SOA with the influence of photooxidation products from terpenes was the reason for the observed particle bursts during the campaign.  However, correlations between the precursor gases or the favourable condensing species with the monitored nucleation mode particles were not found.  For the investigated time period other factors like the condensation sink of newly formed particles to the pre-existing aerosols, temperature and solar irradiance seem to be more important steering parameters for the production of new aerosols.  European Geosciences Union 2004 Another open question concerns the vertical distribution of the formation of SOA.  For this reason measurements were conducted at different altitudes using a tethered balloon platform with particle sampling and particle counting equipment.  They were incorporated with eddy covariance (EC) flux measurements made at 23 m above ground level.  The results give first indications that production of new aerosols happens throughout the planetary boundary layer (PBL), whereby different parameters e. g.  temperature, CS, solar irradiance or concentration of monoterpenes are responsible for the location of the vertical maximum. 
Learning Curved Multinomial Subfamilies for Natural Language Processing and Information Retrieval| Abstract Many problems in natural language learning and information retrieval involve estimating probabilities in very large discrete state spaces.  Dimension reduction as well as clustering techniques in various flavors have been popular choices to deal with the problem of data sparseness.  In this paper, we present a general framework for dimension reduction based on curved multinomial subfamilies.  The investigated class of models include different geometries as well as various objective functions and algorithms for model fitting.  The pursued goal is twofold { to achieve a systematic understanding of the differences and similarities between various models and to empirically investigate their generalization performance on a number of representative data sets. 
Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences| Abstract Discriminative models have been of interest in the NLP community in recent years.  Previous research has shown that they are advantageous over generative models.  In this paper, we investigate how different objective functions and optimization methods affect the performance of the classifiers in the discriminative learning framework.  We focus on the sequence labelling problem, particularly POS tagging and NER tasks.  Our experiments show that changing the objective function is not as effective as changing the features included in the model. 
Deterministic Annealing: Fast Physical Heuristics for Real--Time Optimization of Large Systems| ABSTRACT This paper systematically investigates the heuristical optimization technique known as deterministic annealing.  This method is applicable to a large class of assignment and partitioning problems.  Moreover, the established theoretical results, as well as the general algorithmic solution scheme, are largely independent of the objective functions under consideration.  Deterministic annealing is derived from strict minimization principles, including a rigorous convergence analysis.  We stress the close relation to homotopy methods, and discuss some of the most important strengths and weaknesses in this framework.  Optimization results for unsupervised texture segmentation are presented for an autonomous robotics application. 
Non-parametric Similarity Measures for Unsupervised Texture Segmentation and Image Retrieval| Abstract In this paper we propose and examine non--parametric statistical tests to define similarity and homogeneity measures for textures.  The statistical tests are applied to the coefficients of images filtered by a multi--scale Gabor filter bank.  We will demonstrate that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer an unified approach to these closely related tasks.  We present results on Brodatz--like micro--textures and a collection of real--word images. 
TOPIC-BASED LANGUAGE MODELS USING EM| ABSTRACT In this paper, we propose a novel statistical language model to capture topic-related long-range dependencies.  Topics are modeled in a latent variable framework in which we also derive an EM algorithm to perform a topic factor decomposition based on a segmented training corpus.  The topic model is combined with a standard language model to be used for on-line word prediction.  Perplexity results indicate an improvement over previously proposed topic models, which unfortunately has not translated into lower word error. 
Multiple-Instance Learning via Disjunctive Programming Boosting| Abstract Learning from ambiguous training data is highly relevant in many applications.  We present a new learning algorithm for classification problems where labels are associated with sets of pattern instead of individual patterns.  This encompasses multiple instance learning as a special case.  Our approach is based on a generalization of linear programming boosting and uses results from disjunctive programming to generate successively stronger linear relaxations of a discrete non-convex problem. 
A Hierarchical Probabilistic Model for Novelty Detection in Text| Abstract Topic Detection and Tracking (TDT) is a variant of classification in which the set of classes grows over time.  This paper describes a new approach to TDT based on probabilistic, generative models.  Strong statistical techniques address the many challenges: hierarchical shrinkage for sparse data, statistical \garbage collection" for new event detection, clustering in time to separate the different events of a common topic, and deterministic annealing to create the hierarchy.  Preliminary experimental results show promise. 
INTERNATIONAL COMPUTER SCIENCE INSTITUTE| Abstract Dyadic data refers to a domain with two finite sets of objects in which observations are made for dyads, i. e. , pairs with one element from either set.  This includes event co-occurrences, histogram data, and single stimulus preference data as special cases.  Dyadic data arises naturally in many applications ranging from computational linguistics and information retrieval to preference analysis and computer vision.  In this paper, we present a systematic, domain-independent framework for unsupervised learning from dyadic data by statistical mixture models.  Our approach covers different models with flat and hierarchical latent class structures and unifies probabilistic modeling and structure discovery.  Mixture models provide both, a parsimonious yet flexible parameterization of probability distributions with good generalization performance on sparse data, as well as structural information about data-inherent grouping structure.  We propose an annealed version of the standard Expectation Maximization algorithm for model fitting which is empirically evaluated on a variety of data sets from different domains. 
Exponential Families for Conditional Random Fields| Abstract In this paper we define conditional random fields in reproducing kernel Hilbert spaces and show connections to Gaussian Process classification.  More specifically, we prove decomposition results for undirected graphical models and we give constructions for kernels.  Finally we present efficient means of solving the optimization problem using reduced rank decompositions and we show how stationarity can be exploited efficiently in the optimization process. 
Learning with Taxonomies: Classi#ng Documents and Words| Abstract Automatically extracting semantic information about word meaning and document topic from text typically involves an extensive number of classes.  Such classes may represent predefined word senses, topics or document categories and are often organized in a taxonomy.  The latter encodes important information, which should be exploited in learning classifiers from labeled training data.  To that extent, this paper presents an extension of multiclass Support Vector Machine learning which can incorporate prior knowledge about class relationships.  The latter can be encoded in the form of class attributes, similarities between classes or even a kernel function defined over the set of classes.  The paper also discusses how to specify and optimize meaningful loss functions based on the relative position of classes in the taxonomy.  We include experimental results for text categorization and for word sense classification. 
A joint framework for collaborative and content filtering| ABSTRACT This paper proposes a novel, unified, and systematic approach to combine collaborative and content-based filtering for ranking and user preference prediction.  The framework incorporates all available information by coupling together multiple learning problems and using a suitable kernel or similarity function between user-item pairs.  We propose and evaluate an on-line algorithm (JRank) that generalizes perceptron learning using this framework and shows significant improvement over other approaches. 
Unsupervised Texture Segmentation in a Deterministic Annealing Framework| Abstract We present a novel optimization framework for unsupervised texture segmentation that relies on statistical tests as a measure of homogeneity.  Texture segmentation is formulated as a data clustering problem based on sparse proximity data.  Dissimilarities of pairs of textured regions are computed from a multi{scale Gabor filter image representation.  We discuss and compare a class of clustering objective functions which is systematically derived from invariance principles.  As a general optimization framework we propose deterministic annealing based on a mean{#eld approximation.  The canonical way to derive clustering algorithms within this framework as well as an efficient implementation of mean{#eld annealing and the closely related Gibbs sampler are presented.  We apply both annealing variants to Brodatz{like micro{texture mixtures and real{word images. 
Pairwise Data Clustering by Deterministic Annealing| Abstract---Partitioning a data set and extracting hidden structure from the data arises in different application areas of pattern recognition, speech and image processing.  Pairwise data clustering is a combinatorial optimization method for data grouping which extracts hidden structure from proximity data.  We describe a deterministic annealing approach to pairwise clustering which shares the robustness properties of maximum entropy inference.  The resulting Gibbs probability distributions are estimated by mean--field approximation.  A new structure-preserving algorithm to cluster dissimilarity data and to simultaneously embed these data in a Euclidian vector space is discussed which can be used for dimensionality reduction and data visualization.  The suggested embedding algorithm which outperforms conventional approaches has been implemented to analyze dissimilarity data from protein analysis and from linguistics.  The algorithm for pairwise data clustering is used to segment textured images. 
Hidden Markov Support Vector Machines| Abstract This paper presents a novel discriminative learning technique for label sequences based on a combination of the two most
Discriminative Learning for Label Sequences via Boosting| Abstract This paper investigates a boosting approach to discriminative learning of label sequences based on a sequence rank loss function.  The proposed method combines many of the advantages of boosting schemes with the eciency of dynamic programming methods and is attractive both, conceptually and computationally.  In addition, we also discuss alternative approaches based on the Hamming loss for label sequences.  The sequence boosting algorithm offers an interesting alternative to methods based on HMMs and the more recently proposed Conditional Random Fields.  Applications areas for the presented technique range from natural language processing and information extraction to computational biology.  We include experiments on named entity recognition and part-of-speech tagging which demonstrate the validity and competitiveness of our approach. 
Mining of ad-hoc business processes with TeamLog| The design of workflows is a complicated task.  In practice, the actual workflow processes will often differ from the processes as perceived by the management.  Process mining supports the design and improvement of processes using transaction logs, which contain information about the actual process executions.  This paper introduces basics about process mining, a common workflow log format and it gives an example: mining ad-hoc processes of Caramba--aprocess-aware collaboration system.  It is discussed how Caramba-specific process information is converted to a common format using an application called TeamLog.  Then EMiT--aprocess mining tool -- mines the converted process information. 
Semi-supervised Learning on Directed Graphs| Abstract Given a directed graph in which some of the nodes are labeled, we investigate the question of how to exploit the link structure of the graph to infer the labels of the remaining unlabeled nodes.  To that extent we propose a regularization framework for functions defined over nodes of a directed graph that forces the classification function to change slowly on densely linked subgraphs.  A powerful, yet computationally simple classification algorithm is derived within the proposed framework.  The experimental evaluation on real-world Web classification problems demonstrates encouraging results that validate our approach. 
Inferring Hierarchical Clustering Structures by Deterministic Annealing| Abstract The unsupervised detection of hierarchical structures is a major topic in unsupervised learning and one of the key questions in data analysis and representation.  We propose a novel algorithm for the problem of learning decision trees for data clustering and related problems.  In contrast to many other methods based on successive tree growing and pruning, we propose an objective function for tree evaluation and we derive a non--greedy technique for tree growing.  Applying the principles of maximum entropy and minimum cross entropy, a deterministic annealing algorithm is derived in a meanfield approximation.  This technique allows us to canonically superimpose tree structures and to fit parameters to averaged or `fuzzified' trees. 
Learning with Taxonomies: Classifying Documents and Words| Abstract Automatically extracting semantic information about word meaning and document topic from text typically involves an extensive number of classes.  Such classes may represent predefined word senses, topics or document categories and are often organized in a taxonomy.  The latter encodes important information, which should be exploited in learning classifiers from labeled training data.  To that extent, this paper presents an extension of multiclass Support Vector Machine learning which can incorporate prior knowledge about class relationships.  The latter can be encoded in the form of class attributes, similarities between classes or even a kernel function defined over the set of classes.  The paper also discusses how to specify and optimize meaningful loss functions based on the relative position of classes in the taxonomy.  We include experimental results for text categorization and for word sense classification. 
Unsupervised Texture Segmentation on the Basis of Scale Space Features| Abstract A novel approach to unsupervised texture segmentation is presented, which is formulated as a combinatorial optimization problem known as sparse pairwise data clustering.  Pairwise dissimilarities between texture blocks are measured by scale space features, i. e. , multi-resolution edges.  These scale space features are computed by a Gabor filter bank tuned to spatial frequencies.  To solve the data clustering problem a deterministic annealing technique is applied.  This approach is examined from the viewpoint of scale space theory.  Based on a meanfield approximation an efficient algorithm is derived.  We present an application of the proposed algorithm to Brodatz-like microtexture collages. 
Gaussian process classification for segmenting and annotating sequences| Abstract Multiclass classification refers to the problem of assigning labels to instances where labels belong to some finite set of elements.  Often, however, the instances to be labeled do not occur in isolation, but rather in observation sequences.  One is then interested in predicting the joint label configuration, i. e.  the sequence of labels, using models that take possible interdependencies between label variables into account.  This scenario subsumes problems of sequence segmentation and annotation.  In this paper, we investigate the use of Gaussian Process (GP) classification for label sequences. 
The Mobile Robot RHINO| Abstract--- Rhinowas the University of Bonn's entry in the 1994 AAAI mobile robot competition.  Rhino is a mobile robot designed for indoor navigation and manipulation tasks.  The general scientific goal of the Rhino project is the development and the analysis of autonomous and complex learning systems.  This paper briefly describes the major components of the Rhino control software, as they were exhibited at the competition.  It also sketches the basic philosophy of the Rhino architecture, and discusses some of the lessons that we learned during the competition.  I.  GENERAL OVERVIEW Rhino, shown in Figure 1, is a B21 mobile robot platform manufactured by Real World Interface Inc.  It is equipped with 24 sonar proximity sensors, a dual color camera system mounted on a pan/tilt unit, and two on-board i486 computers.  Sonar information is obtained at a rate of 1. 3 Hertz, and camera images are processed at a rate of 0. 7 Hertz.  Rhino communicates with external computers (two SUN Sparc stations) via a tetherless Ethernet link.  The Rhino project is generally concerned with the design of autonomous and complex learning systems [8].  The AAAI competition ended an initial six month period of software design.  Key features of Rhino's control software, as exhibited at the competition, are: ffl Autonomy.  Rhino operates completely autonomously.  It has been repeatedly operated for durations of up to one hour in populated office environments without human intervention.  ffl Learning.  To increase the flexibility of the software, learning mechanisms support the adaptation of the robot to its sensors and the environment.  For example, neural network learning is employed to interpret sonar measurements.  ffl Real-time operation.  In order to act continuously in real-time, any-time solutions [2] are employed wherever possible.  Any-time algorithms are able to make decisions regardless of the time spent for computation.  The more time is available, however, the better are the results.  ffl Reactive control and deliberation.  Rhino's navigation system integrates a fast, reactive on-board obstacle avoidance routine with knowledge- and computationintense map building and planning algorithms.  Rhino's software consists of a dozen different modules.  The interface modules (a base/sonar sensor interface, a camera interface and a speech interface) control the basic communication to and from the hardware components of the robot.  On top of these, a fast obstacle avoidance routine analyzes sonar measurements to avoid collisions with obstacles and walls at a speed of up to 90cm per second.  Global metric and topological maps are constructed on-the-fly using a neural network-based approach, combined with a database of maps showing typical rooms, doors and hallways.  Rhino employs a dynamic programming planner to explore unknown terrain and to navigate to arbitrary target locations.  It locates itself by continuously analyzing sonar information.  In addition, a fast vision module segments images from two color cameras, in order to find target objects and obstacles that block the path of the robot.  Rhino's control flow is monitored by an integrated task planner and a central user interface.  The integration of a dozen different software modules, which all exhibit different timing and response characteristics, requires a flexible scheme for the flow and synchronization of information.  The key principles for the design of Rhino's software are: Figure 1: The Rhino robot of
Non-Redundant Data Clustering| Abstract Data clustering is a popular approach for automatically finding classes, concepts, or groups of patterns.  In practice this discovery process should avoid redundancies with existing knowledge about class structures or groupings, and reveal novel, previously unknown aspects of the data.  In order to deal with this problem, we present an extension of the information bottleneck framework, called coordinated conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score subject to constraints.  Algorithmically, one can apply an alternating optimization scheme that can be used in conjunction with different types of numeric and non-numeric attributes.  We present experimental results for applications in text mining and computer vision. 
Conditional Information Bottleneck Clustering| Abstract We present an extension of the well-known information bottleneck framework, called conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score.  This general approach can be utilized in a data mining context to extract relevant information that is at the same time novel relative to known properties or structures of the data.  We present possible applications of the conditional information bottleneck in information retrieval and text mining for recovering non-redundant clustering solutions, including experimental results on the WebKB data set which validate the approach. 
Map Learning and High-Speed Navigation in RHINO| Abstract This chapter surveys basic methods for
Statistical Models for Co-occurrence Data| Abstract Modeling and predicting co-occurrences of events is a fundamental problem of unsupervised learning.  In this contribution we develop a statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets.  The main challenge for statistical models in this context is to overcome the inherent data sparseness and to estimate the probabilities for pairs whichwere rarely observed or even unobserved in a given sample set.  Moreover, it is often of considerable interest to extract grouping structure or to find a hierarchical data organization. Anovel family of mixturemodels is proposed which explain the observed data bya finite number of shared aspects or clusters.  This provides a common framework for statistical inference and structure discovery and also includes several recently proposed models as special cases.  Adopting the maximum likelihood principle, EM algorithms are derived to fit the model parameters.  We develop improved versions of EM which largely avoid overfitting problems and overcome the inherent localityof EM{based optimization.  Among the broad variety of possible applications, e. g. , in information retrieval, natural language processing, data mining, and computer vision, wehavechosen document retrieval, the statistical analysis of noun/adjective co-occurrence and the unsupervised segmentation of textured images to test and evaluate the proposed algorithms. 
Text categorization by boosting automatically extracted concepts| ABSTRACT Term-based representations of documents have found widespread use in information retrieval.  However, one of the main shortcomings of such methods is that they largely disregard lexical semantics and, as a consequence, are not sufficiently robust with respect to variations in word usage.  In this paper we investigate the use of concept-based document representations to supplement word- or phrase-based features.  The utilized concepts are automatically extracted from documents via probabilistic latent semantic analysis.  We propose to use AdaBoost to optimally combine weak hypotheses based on both types of features.  Experimental results on standard benchmarks confirm the validity of our approach, showing that AdaBoost achieves consistent improvements by including additional semantic features in the learned ensemble. 
Probabilistic Latent Semantic Indexing| Abstract Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data.  Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{speci#c synonymy as well as with polysemous words.  In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model.  Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methodsaswell as over LSI.  In particular, the combination of models with different dimensionalities has proven to be advantageous. 
Unifying collaborative and content-based filtering| Abstract Collaborative and content-based filtering are two paradigms that have been applied in the context of recommender systems and user preference prediction.  This paper proposes a novel, unified approach that systematically integrates all available training information such as past user-item ratings as well as attributes of items or users to learn a prediction function.  The key ingredient of our method is the design of a suitable kernel or similarity function between user-item pairs that allows simultaneous generalization across the user and item dimensions.  We propose an on-line algorithm (JRank) that generalizes perceptron learning.  Experimental results on the EachMovie data set show significant improvements over standard approaches. 
Learning from Dyadic Data|
Learning What People (Don't) Want|
Learning over structured output spaces via joint kernel functions|
Probabilistic Topic Maps: Navigating through Large Text Collections|
A deterministic annealing framework for textured image segmentation|
Deterministic Annealing for Unsupervised Texture Segmentation|
Learning the Similarity of Documents: An Information-Geometric Approach to Document Retrieval and Categorization|
Unsupervised Learning by Probabilistic Latent Semantic Analysis|
A hierarchical probabilistic model for novelty detection in text| Technical report, Just Research. 
Statistical models for cooccurence data,|
Latent Class Models for Collaborative Filtering|
Central and Pairwise Data Clustering by Competitive Neural Networks|
The Cluster-Abstraction Model: Unsupervised Learning of Topic Hierarchies from Text Data|
Pairwise Data Clustering by Deterministic Annealing",|
Learning probabilistic models of the Web|
Competitive learning algorithms for robust vector quantization|
Pairwise data clustering by deterministic annealing|
Active Data Clustering|
Multidimensional Scaling and Data Clustering|
Latent semantic models for collaborative filtering|
Mapping Applications onto Reconfigurable Kress Arrays|
A deterministic annealing framework for unsupervised texture segmentation|
Discrete Mixture Models for Unsupervised Image Segmentation|
Pairwise Data Clustering by Deterministic Annealing'|
Unsupervised Segmentation of Textured Images by Pairwise Data Clustering,|
A maximum entropy approach to pairwise data clustering|
OpenSpaces: An Object-Oriented Framework for Reconfigurable Coordination Spaces|
Disjunctive programming boosting|
\Topic-based Language Modeling Using EM,|
A hierarchical probabilistic model for novelty detection in text|
ProbMap - A probabilistic approach for mapping large document collections|
Hiddem markov support vector machines|
Hierarchical document categorization with support vector machines|
An Optimization Approach to Unsupervised Hierarchical Texture Segmentation|
Mixture models for cooccurrence data|
An Annealed ``Neural Gas'' Network for Robust Vector Quantization|
Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences|
