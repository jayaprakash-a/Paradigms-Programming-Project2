Variations on Incremental Interpretation| Abstract The strict competence hypothesis has sparked a small dialogue among several researchers attempting to understand its ramifications for human sentence processing and incremental interpretation in particular.  In this paper, we review the dialogue, reconstructing the arguments in an attempt to make them more uniform and crisper, and provide our own analyses of certain of the issues that arise.  We argue that strict competence, because it requires a synchronous computation mechanism, may actually lead to more complex, rather than simpler, models of incremental interpretation.  Asynchronous computation, which is arguably both psychologically more plausible and conceptually more basic, allows for incremental interpretation to fall out naturally, without additional machinery for interpreting partial constituents.  We show that this is true regardless of whether the presumed interpretation mechanism is top-down or bottomup, contra previous conclusions in the literature, and propose a particular implementation of some of these ideas using a novel representation based on tree-adjoining grammars. 
Specialization of Neural Mechanisms Underlying Face Recognition in Human Infants| Abstract & Newborn infants respond preferentially to simple face-like patterns, raising the possibility that the face-specific regions identified in the adult cortex are functioning from birth.  We sought to evaluate this hypothesis by characterizing the specificity of infants' electrocortical responses to faces in two ways: (1) comparing responses to faces of humans with those to faces of nonhuman primates; and 2) comparing responses to upright and inverted faces.  Adults' face-responsive N170 event-related potential (ERP) component showed specificity to upright human faces that was not observable at any point in the ERPs of infants.  A putative "infant N170" did show sensitivity to the species of the face, but the orientation of the face did not influence processing until a later stage.  These findings suggest a process of gradual specialization of cortical face processing systems during postnatal development.  &
DITHER-BASED SECURE IMAGE HASHING USING DISTRIBUTED CODING| ABSTRACT We propose an image hashing algorithm that is based on distributed compression principles.  The algorithm assumes the availability of a robust feature vector extracted from the image.  Then a suitable dither sequence is added to this feature vector, and the resulting dithered feature vector is compressed using distributed compression principles.  We prove that the dither sequence can be used to guarantee information-theoretic security.  Applications of our proposed secure image hashing scheme include video watermarking, image authentication, and image database management. 
AN IMPROVED MODEL FOR RECOGNIZING DISFLUENCIES IN CONVERSATIONAL SPEECH| ABSTRACT This paper presents a novel metadata extraction (MDE) system for automatically detecting edited words, fillers, and self-interruption points in conversational speech.  Our edit word detection sub-system combines a Tree Adjoining Grammar (TAG) noisy channel model, a statistical syntactic language model, and a MaxEnt reranker.  Hand-built, deterministic rules are used to detect fillers.  Self-interruption points are explicitly determined by detected fillers and edited words.  We have evaluated our system for these three tasks on two types of input: manually annotated words and automatically recognized speech-to-text tokens.  In all six cases, our system has improved the state-of-the-art, as measured in a recent blind evaluation. 
Squibs and Discussions The DOP Estimation Method Is Biased and Inconsistent| A data-oriented parsing or DOP model for statistical parsing associates fragments of linguistic representations with numerical weights, where these weights are estimated by normalizing the empirical frequency of each fragment in a training corpus (see Bod [1998] and references cited therein).  This note observes that this estimation method is biased and inconsistent; that is, the estimated distribution does not in general converge on the true distribution as the size of the training corpus increases. 
Secondary Trading Costs in the Municipal Bond Market| ABSTRACT Using new econometric methods, we separately estimate average transaction costs for over 167,000 bonds from a one-year sample of all U. S.  municipal bond trades.  Municipal bond transaction costs decrease with trade size and do not depend significantly on trade frequency.  Also, municipal bond trades are substantia lly more expensive than similarsized equity trades.  We attribute these results to the lack of bond market price transparency.  Additional cross-sectional analyses show that bond trading costs increase with credit risk, instrument complexity, time to maturity, and time since issuance.  Investors, and perhaps ultimately issuers, might benefit if issuers issued simpler bonds. 
A Resource Sensitive Interpretation of Lexical Functional Grammar| Abstract.  This paper investigates whether the fundamental linguistic insights and intuitions of Lexical Functional Grammar (LFG), which is usually presented as a ``constraint-based" linguistic theory, can be reformulated in a "resource sensitive" framework using a substructural modal logic.  In the approach investigated here, LFG's f-descriptions are replaced with expressions from a multi-modal propositional logic (with permutation and possibly limited contraction).  In effect, the feature structure "unification" basis of LFG's f-structures is replaced with a very different resource based mechanism.  It turns out that some linguistic analyses that required non-monotonic devices in LFG (such as the "constraint equations" in the Andrews (1982) analysis of Icelandic) can be straightforwardly expressed in the framework presented here.  Moreover, a Curry-Howard correspondence between proofs in this logic and -terms provides a semantic interpretation as a by-product of the process of showing syntactic well-formedness. 
Unsupervised learning of multi-word verbs| Abstract Collocation is a linguistic phenomenon that is dicult to define and harder to explain; it has been largely overlooked in the field of computational linguistics due to its diculty.  Although standard techniques exist for finding collocations, they tend to be rather noisy and suffer from sparse data problems.  In this paper, we demonstrate that by utilising parsed input to concentrate on one very specific type of collocation|in this case, verbs with particles, a subset of the so-called \multi-word" verbs|and applying an algorithm to promote those collocations in which we have more confidence, the problems with statistically learning collocations can be overcome. 
A SHEAF-THEORETIC VIEW OF LOOP SPACES| ABSTRACT.  The context of enriched sheaf theory introduced in the author's thesis provides a convenient viewpoint for models of the stable homotopy category as well as categories of finite loop spaces.  Also, the languages of algebraic geometry and algebraic topology have been interacting quite heavily in recent years, primarily due to the work of Voevodsky and that of Hopkins.  Thus, the language of Grothendieck topologies is becoming a necessary tool for the algebraic topologist.  The current article is intended to give a somewhat relaxed introduction to this language of sheaves in a topological context, using familiar examples such as n-fold loop spaces and pointed G-spaces.  This language also includes the diagram categories of spectra from [19] as well as spectra in the sense of [17], which will be discussed in some detail. 
Proceedings of the 43rd Annual Meeting of the ACL,| Abstract Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000).  A discriminative reranker requires a source of candidate parses for each sentence.  This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).  This method generates 50-best lists that are of substantially higher quality than previously obtainable.  We used these parses as the input to a MaxEnt reranker (Johnson et al. , 1999; Riezler et al. , 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91. 0% on sentences of length 100 or less. 
Discriminative Language Modeling with Conditional Random Fields and the Perceptron Algorithm| Abstract This paper describes discriminative language modeling for a large vocabulary speech recognition task.  We contrast two parameter estimation methods: the perceptron algorithm, and a method based on conditional random fields (CRFs).  The models are encoded as deterministic weighted finite state automata, and are applied by intersecting the automata with word-lattices that are the output from a baseline recognizer.  The perceptron algorithm has the benefit of automatically selecting a relatively small feature set in just a couple of passes over the training data.  However, using the feature set output from the perceptron algorithm (initialized with their weights), CRF training provides an additional 0. 5% reduction in word error rate, for a total 1. 8% absolute reduction from the baseline of 39. 2%. 
Explaining away ambiguity: Learning verb selectional preference with Bayesian networks| Abstract This paper presents a Bayesian model for unsupervised learning of verb selectional preferences.  For each verb the model creates a Bayesian network whose architecture is determined by the lexical hierarchy of Wordnet and whose parameters are estimated from a list of verb-object pairs found from a corpus.  \Explaining away", a wellknown property of Bayesian networks, helps dealing with word sense ambiguity in the training data in a natural fashion.  On a word sense disambiguation test our model performed better than other state of the art systems for unsupervised learning of selectional preferences.  Computational complexity problems, ways of improving this approach and methods for implementing \explaining away" in other graphical frameworks are discussed.  1 Selectional preference and sense ambiguity Semantic regularities about verb arguments (subject, object, and direct object) are called selectional preferences (Katz and Fodor, 1964; Chomsky, 1965; Johnson-Laird, 1983) (SP).  They express the preferences of the verb
A Simple Pattern-matching Algorithm for Recovering Empty Nodes and their Antecedents| Abstract This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.  The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.  This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.  Evaluating the algorithm on the output of Charniak's parser (Charniak, 2000) and the Penn treebank (Marcus et al. , 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity. 
Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences| Abstract Discriminative models have been of interest in the NLP community in recent years.  Previous research has shown that they are advantageous over generative models.  In this paper, we investigate how different objective functions and optimization methods affect the performance of the classifiers in the discriminative learning framework.  We focus on the sequence labelling problem, particularly POS tagging and NER tasks.  Our experiments show that changing the objective function is not as effective as changing the features included in the model. 
Fast Nearest Neighbor Search of Entropy-Constrained Vector Quantization| Abstract--Entropy-constrained vector quantization (ECVQ) [3] offers substantially improved image quality over vector quantization (VQ) at the cost of additional encoding complexity.  We extend results in the literature for fast nearest neighbor search of VQ to ECVQ.  We use a new, easily computed distance that successfully eliminates most codewords from consideration. 
Exploiting auxiliary distributions in stochastic unification-based grammars| Abstract This paper describes a method for estimating conditional probability distributions over the parses of "unification-based" grammars which can utilize auxiliary distributions that are estimated by other means.  We show how this can be used to incorporate information about lexical selectional preferences gathered from other sources into Stochastic "Unificationbased" Grammars (SUBGs).  While we apply this estimator to a Stochastic LexicalFunctional Grammar, the method is general, and should be applicable to stochastic versions of HPSGs, categorial grammars and transformational grammars. 
LANGUAGE MODELING USING EFFICIENT BEST-FIRST BOTTOM-UP PARSING| ABSTRACT In this paper we present a two-stage best-first bottom-up word-lattice parser which we use as a language model for speech recognition.  The parser works by using a "Figure of Merit" that selects lattice paths while simultaneously selecting syntactic category edges for parsing.  Additionally, we introduce a modified version of the Inside-Outside algorithm used as a pruning stage between syntactic context-free parsing and lexicalized context-dependent parsing.  We report our results in terms of Word Error Rate on the HUB--1 word-lattices and compare these results to other syntactic language modeling techniques. 
The DOP Estimation Method Is Biased and Inconsistent| A "Data-Oriented Parsing" or DOP model for statistical parsing associates fragments of linguistic representations with numerical weights, where these weights are estimated by normalizing the empirical frequency of each fragment in a training corpus (see Bod (1998) and references cited therein).  This note observes that this estimation method is biased and inconsistent; i. e. , that the estimated distribution does not in general converge on the true distribution as the size of the training corpus increases. 
Optimal Selection of Supply Voltages and Level Conversions During Data Path Scheduling Under Resource Constraints| Abstract In this paper we will consider how to select an optimal set of supply voltages and account for level conversion costs when optimizing the schedule of a resource dominated data path for minimum energy dissipation.  An integer linear program (ILP) is presented for minimum energy schedules under latency, supply voltage, and resource constraints.  The supply voltage assignment for each resource is modeled as fixed for all time.  Schedules were generated for a variety of data path structures, resource and latency constraints.  Resource constraints tended to limit the use of reduced supply voltages.  With latency constraints loosened to 1:5\Theta minimum latency, unlimited resources, and two power supplies, energy savings ranged from 53% to 70% compared to 5V operation.  When resource constraints were applied, savings dropped to a range of 46% to 58%.  Loosened latency constraints resulted in increased use of lower supply voltages.  With resource constraints unchanged and latency constraints of 2\Theta minimum latency, energy savings increased to a range of 64% to 75%.  In no case did three supplies decrease energy by more than 5% compared to two supplies. 
Proceedings of the IBM Austin Center for Advanced Studies 5th Annual Austin CAS Conference,| Abstract Grouping users automatically based on their system usage can be beneficial in an autonomic computing environment.  Clustering algorithms can generate meaningful user groups that provide important insights to system administrators about user profiles and group policies.  In particular, if a small amount of supervision is provided by the administrator to the clustering process, semi-supervised clustering algorithms can use this supervision to generate clusters which are more useful for user management.  In this work, we demonstrate the utility of semisupervised clustering in intelligent user management.  We collect publicly available system usage data of users in a university computing environment, and cluster the users using semi-supervised hierarchical agglomerative clustering based on the profile of the processes they run.  Initial supervision is provided in the form of a few users running a specific process.  Semi-supervised clustering gives us more meaningful clusters than unsupervised clustering in this domain, demonstrating that our technique can find interesting and useful groups in data with minimal user intervention. 
Parsing and Dis#uency Placement| Abstract It has been suggested that some forms of speech disfluencies, most notable interjections and parentheticals, tend to occur disproportionally at major clause boundaries [6] and thus might serve to aid parsers in establishing these boundaries.  Wehave tested a current statistical parser [1] on Switchboard text with and without interjections and parentheticals and found that the parser performed better when not faced with these extra phenomena.  This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process. 
A CASE STUDY IN EXPERIMENTAL DESIGN APPLIED TO GENETIC ALGORITHMS WITH APPLICATIONS TO DNA SEQUENCE ASSEMBLY| Synoptic Abstract Experimental design and response surface methodology is applied to tuning the parameters of an optimization program employing genetic algorithms.  Attention is directed to the combinatorially challenging DNA sequence assembly problem.  Fine tuning of a 10K size test problem leads to a considerably improved solution to a 35K problem of sequence assembly that is of significant biological interest. 
DNA Sequence Assembly and Genetic Algorithms - New Results and Puzzling Insights| Abstract Applying genetic algorithms to DNA sequence assembly is not a straightforward process.  Significantly
Electromagnetic Exposure Safety of the Carstens Articulograph AG100| Abstract Extremely strong magnetic fields at the frequencies used in an electromagnetic articulometer (EMA) system may pose a risk to the health of a subject.  To avoid such risks, the field strengths produced by any EMA system should be measured, and compared to published permissible exposure standards.  This letter reports measurements of the 2-50kHz magnetic field strength of the Carstens Articulograph AG100.  The measured field strength (35T at a distance of 7. 5cm) is permissible under standards in Austria, Germany, the USA, and the UK, but is not permissible in Canada or Massachusetts, or under the 1995 European Community Prestandard.  I.  Motivation Electromagnetic Midsagittal Articulography (EMA) is a technique for obtaining real-time data about the motion of points on the surface of the tongue and other articulators using relatively low-cost, lightweight, and non-invasive equipment (Schonle, 1987, Perkell, 1992).  EMA relies on alternating magnetic fields to measure the distance between fixed transmitter coils and movable receiver coils fixed to the surfaces of the articulators.  The Carstens Articulograph AG100 is, at the time of this writing, the only commercially available EMA system capable of correcting for small misalignments of the receiver coils using a redundant third transmitter (Hoole and Nguyen, 1996).  Because of its light weight and relative low cost, the Articulograph offers small laboratories a unique opportunity to collect large amounts of articulatory data.  Alternating magnetic fields generate electric current in any conducting medium, including human bones and blood.  Fields of moderate strength at the frequencies used in the Articulograph (10-20 kHz) have not been conclusively linked to any health risk, but caution dictates that unnecessary exposure should be minimized.  In particular, the American National Standards Institute has endorsed a standard which limits exposure to magnetic fields at frequencies above 3kHz (IEEE, 1992).  The purpose of this article is to very briefly review the relevant safety considerations, and to describe measurements which show that the Articulograph AG100 meets the maximum permissible exposure standards endorsed by the American
When Are Two Protocols the Same?| Abstract.  A number of protocols based on the formal dialogue games of philosophy have recently been proposed for interactions between autonomous agents.  Several of these proposals purport to assist agents engaged in the same types of interactions, such as persuasions and negotiations, and are superficially different.  How are we to determine whether or not these proposals are substantially different? This chapter considers this question and explores several alternative definitions of equivalence of protocols. 
Multi-Component Word Sense Disambiguation| Abstract This paper describes the system MC-WSD presented for the English Lexical Sample task.  The system is based on a multicomponent architecture.  It consists of one classifier with two components.  One is trained on the data provided for the task.  The second is trained on this data and, additionally, on an external training set extracted from the Wordnet glosses.  The goal of the additional component is to lessen sparse data problems by exploiting the information encoded in the ontology. 
On Compressing Encrypted Data without the Encryption Key| Abstract.  When it is desired to transmit redundant data over an insecure and bandwidth-constrained channel, it is customary to first compress the redundant data and then encrypt it for security reasons.  In this paper, we investigate the novelty of reversing the order of these steps, i. e.  first encrypting and then compressing.  Although counter-intuitive, we show surprisingly that through the use of coding with side information principles, this reversal in order is indeed possible.  In fact, for lossless compression, we show that the theoretical compression gain is unchanged by performing encryption before compression.  We show that the cryptographic security of the reversed system is directly related to the strength of the key generator. 
Supersense Tagging of Unknown Nouns in WordNet| Abstract We present a new framework for classifying common nouns that extends namedentity classification.  We used a fixed set of 26 semantic labels, which we called supersenses.  These are the labels used by lexicographers developing WordNet.  This framework has a number of practical advantages.  We show how information contained in the dictionary can be used as additional training data that improves accuracy in learning new nouns.  We also define a more realistic evaluation procedure than cross-validation. 
In Proceedings of the 1st Meeting of the North American Chapter of the ACL| Abstract This paper describes a method for estimating conditional probability distributions over the parses of iunication-basedj grammars which can utilize auxiliary distributions that are estimated by other means.  We show how this can be used to incorporate information about lexical selectional preferences gathered from other sources into Stochastic iUnicationbasedj Grammars (SUBGs).  While we apply this estimator to a Stochastic Lexical-Functional Grammar, the method is general, and should be applicable to stochastic versions of HPSGs, categorial grammars and transformational grammars. 
Dynamic programming for parsing and estimation of stochastic unification-based grammars| Abstract Stochastic unification-based grammars (SUBGs) define exponential distributions over the parses generated by a unificationbased grammar (UBG).  Existing algorithms for parsing and estimation require the enumeration of all of the parses of a string in order to determine the most likely one, or in order to calculate the statistics needed to estimate a grammar from a training corpus.  This paper describes a graph-based dynamic programming algorithm for calculating these statistics from the packed UBG parse representations of Maxwell and Kaplan (1995) which does not require enumerating all parses.  Like many graphical algorithms, the dynamic programming algorithm's complexity is worst-case exponential, but is often polynomial.  The key observation is that by using Maxwell and Kaplan packed representations, the required statistics can be rewritten as either the max or the sum of a product of functions.  This is exactly the kind of problem which can be solved by dynamic programming over graphical models. 
Datapath scheduling with multiple supply voltages and level converters| We present an algorithm called MOVER (Multiple Operating Voltage Energy Reduction) to minimize datapath energy dissipation through use of multiple supply voltages.  In a single voltage design, the critical path length, clock period, and number of control steps limit minimization of voltage and power.  Multiple supply voltages permit localized voltage reductions to take up remaining schedule slack.  MOVER initially finds one minimum voltage for an entire datapath.  It then determines a second voltage for operations where there is still schedule slack.  New voltages can be introduced and minimized until no schedule slack remains.  MOVER was exercised for a variety of DSP datapath examples.  Energy savings ranged from 0% to 50% when comparing dual to single voltage results.  The benefit of going from two to three voltages never exceeded 15%.  Power supply costs are not reflected in these savings, but a simple analysis shows that energy savings can be achieved even with relatively inefficient DC-DC converters.  Datapath resource requirements were found to vary greatly with respect to number of supplies.  Area penalties ranged from 0% to 170%.  Implications of multiple voltage design for IC layout and power supply requirements are discussed. 
Scheduling and Optimal Voltage Selection For Low Power Multi-Voltage DSP Datapaths| Abstract--- We present an algorithm called MOVER (Multiple Operating Voltage Energy Reduction) to minimize datapath energy dissipation through use of multiple supply voltages.  In a single voltage design, the critical path length, clock period, and number of control steps limit minimization of voltage and power.  Multiple supply voltages permit localized voltage reductions to take up remaining schedule slack.  MOVER initially finds one minimum voltage for an entire datapath.  It then determines a second voltage for operations where there is still schedule slack.  New voltages can be introduced and minimized until no schedule slack remains.  MOVER was exercised for a variety of DSP datapath examples.  Energy savings of up to 50% were observed when comparing dual to single voltage results.  The benefit of going from two to three voltages never exceeded 15%.  Circuit resource requirements for multiple voltages varied greatly.  In some cases requirements changed very little with respect to number of voltages, but area penalties up to 150% were observed.  Implications for IC layout are discussed. 
Attention Shifting for Parsing Speech| Abstract We present a technique that improves the efficiency of word-lattice parsing as used in speech recognition language modeling.  Our technique applies a probabilistic parser iteratively where on each iteration it focuses on a different subset of the wordlattice.  The parser's attention is shifted towards word-lattice subsets for which there are few or no syntactic analyses posited.  This attention-shifting technique provides a six-times increase in speed (measured as the number of parser analyses evaluated) while performing equivalently when used as the first-stage of a multi-stage parsing-based language model. 
We Are Live Creatures: Embodiment, American Pragmatism, and the Cognitive Organism| Abstract The philosophical tradition mistakenly asks how the inside (i. e.  thoughts, ideas, concepts) can represent the outside (i. e. , the world).  This trap is a consequence of the view that mind and body must be two ontologically different entities.  On this view the problem of meaning is to explain how disembodied " internal" ideas can represent " external" physical objects and events.  Several centuries have shown that given a radical mind-body dichotomy, there is no way to bridge the gap between the inner and the outer.  When " mind" and " body" are regarded as two fundamentally different kinds, no third mediating thing can exist that possesses both the metaphysical character of inner, mental things and simultaneously possesses the character of the outer, physical things.  Embodied Realism, in contrast to Representationalist theories, rejects the notion that mind and body are two ontologically distinct kinds, and it therefore rejects the attendant view that cognition and language are based on symbolic representations inside the mind of an organism that refer to some physical thing in an outside world.  Instead, the terms " body" and " mind" are simply convenient shorthand ways of identifying aspects of ongoing organismenvironment interactions---and so cognition and language must be understood as arising from organic processes.  We trace the rejection of this mind-body dualism from the philosopherpsychologists known as the early American pragmatists (James and Dewey) forward through recent cognitive science (such as Varela, Maturana, Edelman, Hutchins, Lakoff, Johnson, Brooks).  We argue that embodied realism requires a radical reevaluation of the classical dualistic metaphysics and epistemology---especially the classical Representationalist theory of mind---and we conclude by investigating the implications for future investigations for a new, pragmatically-centered cognitive science. 
ACOUSTIC SEGMENTATION USING SWITCHING STATE KALMAN FILTER| ABSTRACT Segmenting the acoustic signal in the TIMIT database by a switching state Kalman filter model is reported in this paper.  According to the assumption that the high dimensional acoustic feature vector of the LSF (Line Spectrum Frequency) of the speech signal is probably embedded in a low dimensional space, a two dimensional vector is used to represent the continuous state vector in this model.  The parameters of the model are initialized by PPCA (probabilistic principle component analysis) and first order vector auto-regression, and are re-estimated by the EM algorithm.  We show that this model can be used to classify vowels, nasals, frication and silence by an approximate Viterbi inference. 
Semisupervised Clustering for Intelligent User Management| Abstract Grouping users automatically based on their system usage can be beneficial in an autonomic computing environment.  Clustering algorithms can generate meaningful user groups that provide important insights to system administrators about user profiles and group policies.  In particular, if a small amount of supervision is provided by the administrator to the clustering process, semi-supervised clustering algorithms can use this supervision to generate clusters which are more useful for user management.  In this work, we demonstrate the utility of semisupervised clustering in intelligent user management.  We collect publicly available system usage data of users in a university computing environment, and cluster the users using semi-supervised hierarchical agglomerative clustering based on the profile of the processes they run.  Initial supervision is provided in the form of a few users running a specific process.  Semi-supervised clustering gives us more meaningful clusters than unsupervised clustering in this domain, demonstrating that our technique can find interesting and useful groups in data with minimal user intervention. 
Estimators for Stochastic ``Unification-Based'' Grammars| Abstract Log-linear models provide a statistically sound framework for Stochastic "Unification-Based" Grammars (SUBGs) and stochastic versions of other kinds of grammars.  We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of LexicalFunctional Grammar. 
Interpolating Between Types and Tokens by Estimating Power-Law Generators| Abstract Standard statistical models of language fail to capture one of the most striking properties of natural languages: the power-law distribution in the frequencies of word tokens.  We present a framework for developing statistical models that generically produce power-laws, augmenting standard generative models with an adaptor that produces the appropriate pattern of token frequencies.  We show that taking a particular stochastic process -- the Pitman-Yor process -- as an adaptor justifies the appearance of type frequencies in formal analyses of natural language, and improves the performance of a model for unsupervised learning of morphology. 
MENTAL STATE DETECTION OF DIALOGUE SYSTEM USERS VIA SPOKEN LANGUAGE| ABSTRACT This paper presents an approach to simulate the mental activities of children during their interaction with computers through their spoken language.  The mental activities are categorized into three states: confidence, confusion and frustration.  Two knowledge sources are used in the detection.  One is prosody, which indicates utterance type and user's attitude.  The other is embedded key words/phrases which help interpret the utterances.  Moreover, it is found that children's speech exhibits very different acoustic characteristics from adults.  Given the uniqueness of children's speech, this paper applies a vocal-tract-length-normalization (VTLN)-based technique to compensate for both inter-speaker variability and intraspeaker variability in children's speech.  The detected key words/phrases are then integrated with prosodic information as the cues for the MAP decision of mental states.  Tests on a set of 50 utterances collected from the project experiment showed the classification accuracy was 74%. 
Discriminative Learning for Label Sequences via Boosting| Abstract This paper investigates a boosting approach to discriminative learning of label sequences based on a sequence rank loss function.  The proposed method combines many of the advantages of boosting schemes with the eciency of dynamic programming methods and is attractive both, conceptually and computationally.  In addition, we also discuss alternative approaches based on the Hamming loss for label sequences.  The sequence boosting algorithm offers an interesting alternative to methods based on HMMs and the more recently proposed Conditional Random Fields.  Applications areas for the presented technique range from natural language processing and information extraction to computational biology.  We include experiments on named entity recognition and part-of-speech tagging which demonstrate the validity and competitiveness of our approach. 
When are two protocols the same?| ABSTRACT A number of protocols based on the formal dialogue games of philosophy have recently been proposed for interactions between autonomous agents.  Several of these proposals purport to assist agents engaged in the same types of interactions, such as persuasions and negotiations, and are superficially different.  How are we to determine whether or not these proposals are substantially different? This paper considers this question and explores several alternative definitions of equivalence of protocols. 
Joint and Conditional Estimation of Tagging and Parsing Models| Abstract This paper compares two different ways of estimating statistical language models.  Many statistical NLP tagging and parsing models are estimated by maximizing the (joint) likelihood of the fully-observed training data.  However, since these applications only require the conditional probability distributions, these distributions can in principle be learnt by maximizing the conditional likelihood of the training data.  Perhaps somewhat surprisingly, models estimated by maximizing the joint were superior to models estimated by maximizing the conditional, even though some of the latter models intuitively had access to "more information". 
DEVELOPMENT AND APPLICATION OF NON-TRADITIONAL VERTEBRATE MODELS TO INVESTIGATE TERRESTRIAL ECOLOGICAL RISK TO 2| __________________________________
A TAG-based noisy-channel model of speech repairs| Abstract This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.  A syntactic parser is used as the source model, and a novel type of TAG-based transducer is the channel model.  The use of TAG is motivated by the intuition that the reparandum is a "rough copy" of the repair.  The model is trained and tested on the Switchboard disfluency-annotated corpus. 
Estimators for Stochastic iUnication-Basedj Grammars| Abstract Log-linear models provide a statistically sound framework for Stochastic iUnication-Basedj Grammars (SUBGs) and stochastic versions of other kinds of grammars.  We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of LexicalFunctional Grammar. 
On Compressing Encrypted Data| Abstract When it is desired to transmit redundant data over an insecure and bandwidth-constrained channel, it is customary to first compress the data and then encrypt it.  In this paper, we investigate the novelty of reversing the order of these steps, i. e. , first encrypting and then compressing, without compromising either the compression efficiency or the information-theoretic security.  Although counter-intuitive, we show surprisingly that, through the use of coding with side information principles, this reversal of order is indeed possible in some settings of interest without loss of either optimal coding efficiency or perfect secrecy.  We show that in certain scenarios our scheme requires no more randomness in the encryption key than the conventional system where compression precedes encryption.  In addition to proving the theoretical feasibility of this reversal of operations, we also describe a system which implements compression of encrypted data. 
DIMACS Series in Discrete Mathematics and Theoretical Computer Science Nearest Neighbor Search for Data Compression| Abstract.  Vector Quantization is a lossy data compression method whose running time is dominated by a series of nearest neighbor searches.  In this paper, we empirically compare six nearest neighbor search algorithms for performing vector quantization.  Three of these algorithms were designed specifically for vector quantization.  One is the traditional k-d tree algorithm.  The other two are new algorithms based on the idea of principal component partitioning. 
Edit Detection and Parsing for Transcribed Speech| Abstract We present a simple architecture for parsing transcribed speech in which an edited-word detector first removes such words from the sentence string, and then a standard statistical parser trained on transcribed speech parses the remaining words.  The edit detector achieves a misclassification rate on edited words of 2. 2%.  (The NULL-model, which marks everything as not edited, has an error rate of 5. 9%. ) To evaluate our parsing results we introduce a new evaluation metric, the purpose of which is to make evaluation of a parse tree relatively indifferent to the exact tree position of EDITED nodes.  By this metric the parser achieves 85. 3% precision and 86. 5% recall. 
CTMRedit: A Case Study in Human-Computer Interface Design| Abstract CTMRedit (affectionately known as MRCAT, or 'Mr.  Cat") is a software tool for displaying, editing, and three-dimensional reconstruction of MR and CT images.  This paper describes the incremental evolution of MRCAT during a period in which it was used regularly by the two software designers, and by two medical experts naive with respect to the software design.  Three methods were found to be useful for suggesting changes to the software: use of the software, and conversations with other users, were helpful for identifying useful new functionality, while direct observation of naive users was most useful for identifying problems with the existing user interface.  As expected, naive users are generally most efficient when presented with a familiar-looking user interface, e. g.  radiologists are familiar with film, so images on screen should be smoothly interpolated so that they look like film.  An unexpected finding is that not all of the software implementation details should be hidden.  Implementation details which the user must know, e. g.  organization of an image database, should be displayed prominently in the user interface, so that they will quickly become familiar to the user. 
Priors in Bayesian Learning of Phonological Rules| Abstract This paper describes a Bayesian procedure for unsupervised learning of phonological rules from an unlabeled corpus of training data.  Like Goldsmith's Linguistica program (Goldsmith, 2004b), whose output is taken as the starting point of this procedure, our learner returns a grammar that consists of a set of signatures, each of which consists of a set of stems and a set of suffixes.  Our grammars differ from Linguistica's in that they also contain a set of phonological rules, specifically insertion, deletion and substitution rules, which permit our grammars to collapse far more words into a signature than Linguistica can.  Interestingly, the choice of Bayesian prior turns out to be crucial for obtaining a learner that makes linguistically appropriate generalizations through a range of different sized training corpora. 
Source Separation using Particle Filters| Abstract Our goal is to study the statistical methods for source separation based on temporal and frequency specific features by using particle filtering.  Particle filtering is an advanced state-space Bayesian estimation technique that supports non-Gaussian and nonlinear models along with time-varying noise, allowing for a more accurate model of the underlying system dynamics.  We present a system that combines standard speech processing techniques in a novel method to separate two noisy speech sources.  The system models the pitch and amplitude over time separately, and adopts particle filtering to reduce complexity by generating a discrete distribution that approximates well the desired continuous distribution.  Preliminary results that demonstrate the separation of two noisy sources using this system are presented. 
A Discovery Procedure For Certain Phonological Rules|
A 2|5 V CMOS Delay Locked Loop for an 18 Mbit, 500 Mbyte/s DRAM,' IEEE Journal of Solid State Circuits,. 
Optimal two- and three-stage production schedules with setup times included,|
PCFG Models of Linguistic Tree Representations|
Finite-state Approximation of Constraint-based Grammars using Left-corner Grammar Transforms|
Model enforcement: A unified feature transformation framework for classification and recognition,|
Stochastic Lexical-Functional Grammar|
Memoization in Constraint Logic Programming|
A Variable Delay Line PLL for CPU-Coprocessor Synchronization|
Logic and Feature Structures|
Type-driven semantic interpretation and feature dependencies in R-LFG|
Broad coverage predictive parsing| Presented at the 12th Annual CUNY Conference on Human Sentence. 
An Investigation of Phase-Distribution Moment-Matching Algorithms for Use in Queueing Models|
A Graphical Investigation of Error Bounds for Moment-Based Queueing Approximations|
A symmetric CMOS NOR gate for high-speed applications,|
Memoization of Coroutined Constraints|
A 2|5 V CMOS delay-locked loop for 18 Mbit, 500 megabyte/s DRAM,. 
Proof Nets and the Complexity of Processing Center-Embedded Constructions|
Compact non-left-recursive grammars using the selective left-corner transform and factoring|
A Variable Delay Line Phase Locked Loop for CPUCoprocessor Synchronization|
BLLIP 1987--89 wsj corpus release 1|
Best-first edgebased chart parsing|
Income, Wealth and the Theory of Consumption"|
On the foundations of the theory of thin elastic shells,|
A theory for the surface Atlantic response to thermohaline variability|
Dynamic plasticity influences the emergence of function in a simple cortical array|
Parsing with Discontinuous Constituents|
\A walking tour of java beans,"|
PCFG models of linguistic tree|
Improved genetic algorithm-based protein structure comparisons: pairwise and multiple superpositions|
Discourse, Anaphora and Parsing|
Efficient probabilistic top-down and left-corner parsing|
WavesWorld: A Testbed for Three Dimensional Semi-Autonomous Animated Characters|
Estimating the Value of Community College: Evidence from Quebec's CEGEPs," mimeo,|
Localization of abrupt change in the North Atlantic thermohaline circulation|
Residue-residue contact substitution probabilities derived from aligned three-dimensional structures and the identification of common folds|
Expressing Disjunctive and Negative Feature Constraints with Classical First-Order Logic|
Memory requirements and local ambiguities for parsing strategies|
Design and Optimization of Low Voltage High Performance Dual Threshold CMOS Circuits|
A Beginner's Guide to Enterprise JavaBeans|" Java World 3,. 
Estimation of standby leakage power in CMOS circuits considering accurate modeling of transistor stacks|
Optimal selection of supply voltages and level conversions during low power data path scheduling,|
"SIMON HOMEPAGE: Welcome to SIMON," University of London, available via World Wide Web at|
"Prototype Educational Software for Integrating the Engineering Curriculum," Session 6B4,|
Stability of explosives in environmental water and soil samples|
Features as Resources in R-LFG|
Memoization of Top Down Parsing|
Repetitive segmental structure of the transducin b-subunit--- homology with the CDC4 gene and identification of related messenger-RNAs|
Left corner transforms and finite state approximations|
The development of visual attention: a cognitive neuroscience perspective|
A GPSG account of VP structure in German|
Leakage Control with Efficient Use of Transistor Stacks in Single Threshold CMOS|
Computing with Features as Formulae|
Ubv photometry of bright stars,|
The use of knowledge of language|
The production of human insulin using recombinant DNA technology and a new chain recombination procedure|
Semantic Abstraction and Anaphora|
Parsing and Empty Nodes|
Context-sensitivity and stochastic "unification-based" grammars|
Adaptive flutter suppression, analysis and test|
Functional brain development in humans|
Woodcock--Johnson tests of cognitive ability---revised|
JOY: protein sequence-structure representation and analysis|
Determination and characterization of a cannabinoid receptor in rat brain|
Features and agreement in lambek categorial grammar|
Modeling evapotranspiration and soil moisture|
Time-Frequency Distribution of Partial Phonetic Information Measured Using Mutual Information",|
An analysis of arctic sea ice fluctuations,|
Software design for low power| In Low Power Design in Deep Submicron Electronics. 
Deadline Scheduling for a Real-Time Multiprocessor|
Features and Formulae|
Build-a-dude: Action selection networks for computational autonomous agents|
Modulation of human nerve growth factor promoter activity by interleukin1beta and interferon-gamma|
Random Phase Approximation Spin-Isospin Nuclear Response in the Deep Inelastic Region|
An investigation of the gate control theory of pain by ramping-off the experimental pain stimulus of potassium iontophoresis|
The origin of freckles in unidirectionally solidified castings|
A 1-Mbit CMOS Dynamic RAM with a Divided Bitline Matrix Architecture|
Analysis of National Toxicology Program rodent bioassays for anticarcinogenic effects|
"Feature as Resources in R-LFG"|
ASTROS-A Multidisciplinary Automated Design Tool,"|
A GPSG account of VP fronting|
Estimators for Stochastic|
A GPSG account of VP fronting in|
An LFG description of the double infinitive construction in Dutch and German,|
Nonlinear optimization using the algorithm of Hooke and Jeeves;|
Coarse-to-fine n-best parsing and maxent discriminative reranking|
Data Compression for Low Bit Rate Transmission of Marine Imagery|
Lecture Notes for Course taught at the LSA|
A declarative formulation of Discourse Representation Theory| Paper presented at the summer meeting of the Association for Symbolic Logic,. 
Sentence-Internal Prosody Does not Help Parsing the Way Punctuation Does|
Effective use of prosody in parsing conversational speech|
"Community Income, Intergovernmental Grants, and Local School District Fiscal Behavior,"|
Stochastic crew motion modeling|
for a survey see,|
Imprinting and the development of face recognition: From chick to man|
The effect of alternative tree representations on tree bank grammars|
Novel routes for the preparation of a range of germanium containing zeolites,|
"The Impact of Antitakeover Amendments on Corporate Financial Performance,|
