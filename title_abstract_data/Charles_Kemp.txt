Shoes as a Platform for Vision| Abstract We explore the use of a shoe-mounted camera as a sensory system for wearable computing.  We demonstrate tools useful for gait analysis, obstacle detection, and context recognition.  Using only visual information, we detect periods of stability and motion during walking.  In the stable phase, the foot can be assumed to be parallel to the ground plane.  In this condition, the floor dominates the lower part of the camera's view, and we show that it can be segmented out from the remainder of the scene, leaving walls and obstacles.  We also demonstrate floor surface recognition for context awareness. 
Discovering Latent Classes in Relational Data| We present a framework for learning abstract relational knowledge with the aim of explaining how people acquire intuitive theories of physical, biological, or social systems.  Our approach is based on a generative relational model with latent classes, and simultaneously determines the kinds of entities that exist in a domain, the number of these latent classes, and the relations between classes that are possible or likely.  This model goes beyond previous psychological models of category learning, which consider attributes associated with individual categories but not relationships between categories.  We apply this domain-general framework to two specific problems: learning the structure of kinship systems and learning causal theories. 
SENSING AND MANIPULATING BUILT-FOR-HUMAN ENVIRONMENTS| We report on a dynamically balancing robot with a dexterous arm designed to operate in built-for-human environments.  Our initial target task has been for the robot to navigate, identify doors, open them, and proceed through them. 
Alternative Essences of Intelligence| Abstract We present a novel methodology for building humanlike artificially intelligent systems.  We take as a model the only existing systems which are universally accepted as intelligent: humans.  We emphasize building intelligent systems which are not masters of a single domain, but, like humans, are adept at performing a variety of complex tasks in the real world.  Using evidence from cognitive science and neuroscience, we suggest alternative "essences of intelligence" to those held by classical AI: the parallel themes of development, social interaction, embodiment, and integration.  Following a methodology based on these themes, we have built a physical humanoid robot.  In this paper we present our methodology and the insights it affords for facilitating learning, simplifying the computation underlying rich behavior, and building systems that can scale to more complex tasks in more challenging environments. 
Semi-Supervised Learning with Trees| Abstract We describe a nonparametric Bayesian approach to generalizing from few labeled examples, guided by a larger set of unlabeled objects and the assumption of a latent tree-structure to the domain.  The tree (or a distribution over trees) may be inferred using the unlabeled data.  A prior over concepts generated by a mutation process on the inferred tree(s) allows efficient computation of the optimal Bayesian classification function from the labeled examples.  We test our approach on eight real-world datasets. 
The Whole World in Your Hand: Active and Interactive Segmentation| Abstract Object segmentation is a fundamental problem in computer vision and a powerful resource for development.  This paper presents three embodied approaches to the visual segmentation of objects.  Each approach to segmentation is aided by the presence of a hand or arm in the proximity of the object to be segmented.  The first approach is suitable for a robotic system, where the robot can use its arm to evoke object motion.  The second method operates on a wearable system, viewing the world from a human's perspective, with instrumentation to help detect and segment objects that are held in the wearer's hand.  The third method operates when observing a human teacher, locating periodic motion (finger/arm/object waving or tapping) and using it as a seed for segmentation.  We show that object segmentation can serve as a key resource for development by demonstrating methods that exploit high-quality object segmentations to develop both low-level vision capabilities (specialized feature detectors) and high-level vision capabilities (object recognition and localization). 
Learning Domain Structures| Psychologists have argued that cognition in different domains draws on qualitatively different mental representations.  Tree structures appear well-suited to representing relationships between animal species [1, 2, 10], while a one-dimensional structure (the liberalconservative spectrum) seems better for representing people's political views.  The possibility of different structures raises a fundamental question: how do people learn what kind of structure is appropriate in each domain? The standard approach to this question is to reject one of its assumptions.  Nativists deny that core structures are learned, at least for evolutionarily important domains like folkbiology.  Instead, infants come equipped with innate knowledge about which structures are appropriate for which domains.  Atran [1], for example, argues that folkbiology is a core domain of human knowledge, and that the tendency to group living kinds into hierarchies reflects an "innately determined cognitive structure. " More generally, Keil [8] has argued that ontological knowledge obeys an innate "M-constraint", requiring the extensions of predicates to conform to rigidly treestructured hierarchies of objects.  Alternatively, empiricists generally deny that structured representations are present at all.  Domain-specific representations are merely emergent properties of unstructured, domain-general associative learning architectures.  McClelland and Rogers [12], for example, have recently suggested that the acquisition of semantic knowledge in domains such as intuitive biology can be explained as learning in a generic connectionist network.  Their architecture never explicitly represents any tree structure, although with repeated training, its hidden unit representations may implicitly come to approximate the taxonomic relations between biological species.  This paper proposes an alternative approach -- structure learning -- that combines important insights from both of these traditions.  Our key contribution is to show how structured domain representations can be acquired within a domain-general framework for Bayesian inference.  Like nativists, we suggest that different domains are represented with qualitatively different structures, and we show how these structured representations serve as critical constraints on inductive generalization.  Like empiricists, though, we emphasize the importance of learning, and attempt to show how domain structures can be acquired through domain-general statistical inference.  This is not only more parsimonious than the nativist position, but allows us to explain the origin of structured representations in novel domains, where the prior existence of domain-specific innate structure is highly implausible.  After describing our structure learning framework, we present two empirical tests of its performance.  First, we show that it chooses the appropriate domain structure for both synthetic and real-world data sets.  It correctly chooses a tree structure for a biological domain (animal feature judgments), and a linear structure for a political domain (US Supreme Court decisions).  Second, we model two classic data sets of inductive judgments in biology [13] and show that our framework performs better than an unstructured connectionist approach.  Bayesian structure learning Our proposal takes the form of a rational analysis.  We aim to demonstrate the computational plausibility and explanatory value of Bayesian structure learning, but leave for future work the question of how these computations might be implemented or approximated by cognitive processes.  Assume the learner's data consist of a binary-valued object-feature matrix D specifying the features of each object in a given domain.  In biology, for instance, the rows of D might correspond to species, and the columns to anatomical and behavioral attributes.  The entry in row i and column j would then specify the value of feature j for species i.  Structurelearning includes computational problems at two levels.  First, which structure class is most appropriate for the domain? Second, given a structure class, which structure in that class provides the best account of the data? For instance, suppose that a learner exposed to biological data ends up organizing animal species into a taxonomic tree.  The first problem asks how she knew to use a tree rather than some other kind of structure.  The second problem asks why she settled on one specific tree instead of the many other trees she might have chosen.  Our focus here is on the first problem -- the problem of inferring the right structure class for a domain.  A solution to the second problem, however, falls out of our probabilistic approach.  We assume that learners come to a domain equipped with a hypothesis space of structure classes, either constructed from innate primitives or based on analogies with previously learned domains.  For simplicity, this paper considers a hypothesis space of just three canonical classes: taxonomic trees, one-dimensional (linear) spaces, and independent feature models.  People surely have access to other classes, including higherdimensional spaces, flat (non-hierarchical) clusterings, and causal networks.  We leave it to future work to characterize the full range of structure classes accessible to human cognition.  In particular, it is an open question whether this space is small enough to be explicitly enumerated as we do here, or is so large (perhaps infinite or uncountable) that it can be specified only implicitly through some generating mechanism.  Future work should also consider the possibility that multiple structures may apply within a single domain.  Given a set of probabilistic models, Bayesian techniques can be used to evaluate which of the models is most likely to have generated some data [7].  Before these techniques can be applied to inferring domain structures, we need to associate each structure class in our hypothesis space with a probabilistic generative model for the features of objects.  The next section defines these models, but here we show how Bayesian inference can be used to choose between them.  Let D be an object-feature matrix generated from one of several structure classes.  The posterior probability of each class C i is proportional to the product of the likelihood p(D|C i ) and the prior probability p(C i ).  If we assign equal prior probabilities to each class (as we do throughout this paper), the best class is the class that makes the data most likely.  Computing the likelihood p(D|C i ) requires integrating over all structures S belonging to structure class C i : p(D|C i ) = Z p(D|S, C i )p(S|C i )dS, (1) Intuitively, this means that a structure class C i provides a good account of object-feature data D if the data are highly probable under a range of structures S in class C i , and if these structures themselves have high prior probability within C i .  The following section explains how the fit of each structure to the data, p(D|S, C i ), is computed for several structure classes.  We estimate the integral in Equation 1 using stochastic approximations.  First we run a Markov chain Monte Carlo simulation to draw a sample of m structures, {S j }, from the distribution p(S|D, C i ).  We then approximate p(D|C i ) by the harmonic mean estimator [7]: p(D|C i ) = 0 @ 1 m m X j=1 1 p(D|S j , C i ) 1 A1 1 .  (2) This estimator does not satisfy a central limit theorem, and can be thrown off by a sample with very low likelihood.  Despite its limitations, it is often sufficient to identify a model that is very much better than its competitors.  In future work we plan to estimate these integrals more accurately using path sampling [4].  From structures to probabilistic models We will work with three probabilistic models, each appropriate for a different structure class, and show how to compute the likelihoods p(D|S, C i ) for structures in each class.  For simplicity we assume here that all features are binary, but our framework extends naturally to multi-valued or continuous features.  C T : Taxonomic trees Class C T is the set of taxonomic trees --- rooted trees with the objects in D as their leaves.  This is a natural representation when the objects are the outcome of an evolutionary process.  We restrict ourselves to ultrametric trees --- trees where each leaf node is at the same distance from the root.  Assume that each feature is generated by a mutation process over the tree.  We formalize the mutation process using a simple biological model [11].  Suppose that a feature F is defined at every point along every branch, not just at the leaf nodes where the data points lie.  Imagine F spreading out over the tree from root to leaves --- it starts out at the root with some value and could switch values at any point along any branch.  Whenever a branch splits, both lower branches inherit the value of F at the point immediately before the split.  Figure 1(a) shows one mutation history for a binary feature on a tree with four objects.  A B C D (a) A B C D (b) Figure 1: (a) A tree with four objects (A, B, C and D) and three internal nodes.  A mutation history for a single feature is shown.  The feature is off at the root, but switches on at two places in the tree.  Shaded nodes have value 1, clear nodes have value 0, and crosses indicate mutations.  (b) A line with four objects.  We formalize this model of mutation using a Poisson arrival process.  Under this process, the probability that
A Wearable System that Learns a Kinematic Model and Finds Structure in Everyday Manipulation by using Absolute Orientation Sensors and a Camera| Abstract This thesis presents Duo, the first wearable system to autonomously learn a kinematic model of the wearer via body-mounted absolute orientation sensors and a head-mounted camera.  With Duo, we demonstrate the significant benefits of endowing a wearable system with the ability to sense the kinematic configuration of the wearer's body.  We also show that a kinematic model can be autonomously estimated offline from less than an hour of recorded video and orientation data from a wearer performing unconstrained, unscripted, household activities within a real, unaltered, home environment.  We demonstrate that our system for autonomously estimating this kinematic model places very few constraints on the wearer's body, the placement of the sensors, and the appearance of the hand, which, for example, allows it to automatically discover a left-handed kinematic model for a left-handed wearer, and to automatically compensate for distinct camera mounts, and sensor configurations.  Furthermore, we show that this learned kinematic model efficiently and robustly predicts the location of the dominant hand within video from the head-mounted camera even in situations where vision-based hand detectors would be likely to fail.  Additionally, we show ways in which the learned kinematic model can facilitate highly efficient processing of large databases of first person experience.  Finally, we show that the kinematic model can e#ciently direct visual processing so as to acquire a large number of high quality segments of the wearer's hand and the manipulated objects.  Within the course of justifying these claims, we present methods for estimating global image motion, segmenting foreground motion, segmenting manipulation events, finding and representing significant hand postures, segmenting visual regions, and detecting visual points of interest with associated shape descriptors.  We also describe our architecture and user-level application for machine augmented annotation and browsing of first person video and absolute orientations.  Additionally, we present a real-time application in which the human and wearable cooperate through tightly integrated behaviors coordinated by the wearable's kinematic perception, and together acquire high-quality visual segments of manipulable objects that interest the wearable. 
Alternative Esences of Intelligence,|
Alternate Essences of Intelligence|
Thesis Proposal: Humans as Robots|
Long-Term Learning for Web Search Engines|
Alternative Essences of Intelligence, in `Proceedings of the American Association of Artificial Intelligence'|
Humans as robots|
