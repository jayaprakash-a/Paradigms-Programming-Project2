CPG Design using Inhibitory Networks| Abstract -- We describe in detail the behavior of an inhibitory Central Pattern Generator (CPG) network for robot control.  A four-neuron, mutual inhibitory network forms the basic coordinating pattern for locomotion.  This network then inhibits an eight-neuron network used to drive patterned movement.  We show that we can get predictable control of important relationships such as the phase of the hip and the knee by adjusting tonic parameters.  We demonstrate the basic concept both in a simulation that is used to drive a trotting bipedal robot as well as an aVLSI CPG chip that generates spiking burst patterns.  Our results indicate that an inhibitory framework can generate simple, understandable and flexible networks for legged robot control that can be implemented in custom VLSI circuits. 
Entrainment of Silicon Central Pattern Generators for Legged Locomotory Control| Abstract We have constructed a second generation CPG chip capable of generating the necessary timing to control the leg of a walking machine.  We demonstrate improvements over a previous chip by moving toward a significantly more versatile device.  This includes a larger number of silicon neurons, more sophisticated neurons including voltage dependent charging and relative and absolute refractory periods, and enhanced programmability of neural networks.  This chip builds on the basic results achieved on a previous chip and expands its versatility to get closer to a self-contained locomotion controller for walking robots. 
A Vision Chip for Color Segmentation and Pattern Matching| A 128(H) 64(V) RGB CMOS imager is integrated with region-of-interest selection, RGB-to-HSI transformation, HSI-based pixel segmentation, (36bins 12bits)-HSI histogramming, and sum-of-absolute-di#erence (SAD) template matching.  Thirty-two learned color templates are stored and compared to each image.  The chip captures the R, G, and B images using in-pixel storage before passing the pixel content to a multiplying digital-to-analog converter (DAC) for white balancing.  The DAC can also be used to pipe in images for a PC.  The color processing uses a biologically inspired color opponent representation and an analog lookup table to determine the Hue (H) of each pixel.  Saturation (S) is computed using a loser-take-all circuit.  Intensity (I) is given by the sum of the color components.  A histogram of the segments of the image, constructed by counting the number of pixels falling into 36 Hue intervals of 10 degrees, is stored on a chip and compared against the histograms of new segments using SAD comparisons.  We demonstrate color-based image segmentation and object recognition with this chip.  Running at 30 fps, it uses 1 mW.  To our knowledge, this is the first chip that integrates imaging, color segmentation, and color-based object recognition at the focal plane. 
VLSI Implementation of Motion Centroid Localization for Autonomous Navigation| Abstract A circuit for fast, compact and low-power focal-plane motion centroid localization is presented.  This chip, which uses mixed signal CMOS components to implement photodetection, edge detection, ON-set detection and centroid localization, models the retina and superior colliculus.  The centroid localization circuit uses time-windowed asynchronously triggered row and column address events and two linear resistive grids to provide the analog coordinates of the motion centroid.  This VLSI chip is used to realize fast lightweight autonavigating vehicles.  The obstacle avoiding line-following algorithm is discussed. 
Saliency-Driven Image Acuity Modulation on a Reconfigurable Silicon Array of Spiking Neurons| Abstract We have constructed a system that uses an array of 9,600 spiking silicon neurons, a fast microcontroller, and digital memory, to implement a reconfigurable network of integrate-and-fire neurons.  The system is designed for rapid prototyping of spiking neural networks that require high-throughput communication with external address-event hardware.  Arbitrary network topologies can be implemented by selectively routing address-events to specific internal or external targets according to a memory-based projective field mapping.  The utility and versatility of the system is demonstrated by configuring it as a three-stage network that accepts input from an address-event imager, detects salient regions of the image, and performs spatial acuity modulation around a high-resolution fovea that is centered on the location of highest salience. 
VLSI Model of Primate Visual Smooth Pursuit|
Toward Biomorphic Control Using Custom aVLSI CPG Chips|
Control of a Robot Leg with an Adaptive aVLSI CPG Chip," presented at Computational Neuroscience Meeting 2000|
A Programmable Array of Silicon Neurons for the Control of Legged Locomotion, invited paper on the special session on Spiking Neural Networks,|
Neuromorphic visual motion detection in VLSI,|
