The Complexity of Approximating the Entropy| Abstract We consider the problem of approximating the entropy of a discrete distribution under several different models of oracle access to the distribution.  In the evaluation oracle model, the algorithm is given access to the explicit array of probabilities specifying the distribution.  In this model, linear time in the size of the domain is both necessary and sufficient for approximating the entropy.  In the generation oracle model, the algorithm has access only to independent samples from the distribution.  In this case, we show that a #-multiplicative approximation to the entropy can be obtained in O # n (1+#)/# 2 log n # time for distributions with entropy #(#/#), where n is the size of the domain of the distribution and # is an arbitrarily small positive constant.  We show that this model does not permit a multiplicative approximation to the entropy in general.  For the class of distributions to which our upper bound applies, we obtain a lower bound of # # n 1/(2# 2 ) # .  We next consider a combined oracle model in which the algorithm has access to both the generation and the evaluation oracles of the distribution.  In this model, significantly greater efficiency can be achieved: a #-multiplicative approximation to the entropy can be obtained in O # # 2 log 2 n h 2 (#- 1) 2 # time for distributions with entropy #(h); for such distributions, we also show a lower bound of # # log n h(# 2 - 1)+# 2 # .  Finally, we consider two special families of distributions: those in which the probabilities of the elements decrease monotonically with respect to a known ordering of the domain, and those that are uniform over a subset of the domain.  In each case, we give more efficient algorithms for approximating the entropy. 
A Generalization of Principal Components Analysis to the Exponential Family| Abstract Principal component analysis (PCA) is a commonly applied technique for dimensionality reduction.  PCA implicitly minimizes a squared loss function, which may be inappropriate for data that is not real-valued, such as binary-valued data.  This paper draws on ideas from the Exponential family, Generalized linear models, and Bregman distances, to give a generalization of PCA to loss functions that we argue are better suited to other data types.  We describe algorithms for minimizing the loss functions, and give examples on simulated data. 
An Efficient PAC Algorithm for Reconstructing a Mixture of Lines| Abstract.  In this paper we study the learnability of a mixture of lines model which is of great importance in machine vision, computer graphics, and computer aided design applications.  The mixture of lines is a partially-probabilistic model for an image composed of line-segments.  Observations are generated by choosing one of the lines at random and picking a point at random from the chosen line.  Each point is contaminated with some noise whose distribution is unknown, but which is bounded in magnitude.  Our goal is to discover eciently and rather accurately the line-segments that generated the noisy observations.  We describe and analyze an ecient probably approximately correct (PAC) algorithm for solving the problem.  Our algorithm combines techniques from planar geometry with simple large deviation tools and is simple to implement. 
Analysis of a greedy active learning strategy| Abstract We abstract out the core search problem of active learning schemes, to better understand the extent to which adaptive labeling can improve sample complexity.  We give various upper and lower bounds on the number of labels which need to be queried, and we prove that a popular greedy active learning rule is approximately as good as any other strategy for minimizing this number of labels. 
An Iterative Improvement Procedure for Hierarchical Clustering| Abstract We describe a procedure which finds a hierarchical clustering by hillclimbing.  The cost function we use is a hierarchical extension of the k-means cost; our local moves are tree restructurings and node reorderings.  We show these can be accomplished efficiently, by exploiting special properties of squared Euclidean distances and by using techniques from scheduling algorithms. 
Analysis of perceptron-based active learning| Abstract.  We start by showing that in an active learning setting, the Perceptron algorithm needs #(
A Theoretical Analysis of Query Selection for Collaborative Filtering| Abstract.  We consider the problem of determining which of a set of experts has tastes most similar to a given user by asking the user questions about his likes and dislikes.  We describe a simple algorithm for generating queries for a theoretical model of this problem.  We show that the algorithm requires at most opt(F )(ln(jF j=opt(F )) + 1) + 1 queries to find the correct expert, where opt(F ) is the optimal worst-case bound on the number of queries for learning arbitrary elements of the set of experts F .  The algorithm runs in time polynomial in jF j and jXj (where X is the domain) and we prove that no polynomial-time algorithm can have a significantly better bound on the number of queries unless all problems in NP have n O(log log n) time algorithms.  We also study a more general case where the user ratings come from a finite set Y and there is an integer-valued loss function ` on Y that is used to measure the distance between the ratings.  Assuming that the loss function is a metric and that there is an expert within a distance # from the user, we give a polynomial-time algorithm that is guaranteed to find such an expert after at most 2opt(F; #) ln jF j 1+deg(F;#) + 2(# + 1)(1 + deg(F; #)) queries, where deg(F; #) is the largest number of experts in F that are within a distance 2# of any f 2 F . 
CHDStd - application support for reusable hierarchical interconnect timing views| ABSTRACT This paper describes an important new facility for timing-driven design applications within the new CHDStd standard for a SEMATECH design system for large complex chips.  We first review EDA requirements for CHDStd hierarchy for large complex leading edge chips and current EDA problems in accurately and efficiently handling complex interconnect.  We then describe our approach for fully-reusable hierarchical interconnect timing views in support of timing driven design for 0. 25u technologies and below.  The result is a method which builds on SEMATECH's new controlled error parasitic timing calculation capability for deep submicron, providing means for compactly storing and reusing accurate hierarchical timing views for 28M to 100M transistor chip designs. 
INTERNATIONAL COMPUTER SCIENCE INSTITUTE| Abstract The Johnson-Lindenstrauss lemma shows that a set of n points in high dimensional Euclidean space can be mapped down into an O(log n=ffl 2 ) dimensional Euclidean space such that the distance between any two points changes by only a factor of (1 \Sigma ffl).  In this note, we prove this lemma using elementary probabilistic techniques. 
Performance Guarantees for Hierarchical Clustering| Abstract We show that for any data set in any metric space, it is possible to construct a hierarchical clustering with the guarantee that for every k, the induced k-clustering has cost at most eight times that of the optimal k-clustering.  Here the cost of a clustering is taken to be the maximum radius of its clusters.  Our algorithm is similar in simplicity and eciency to popular agglomerative heuristics for hierarchical clustering, and we show that these heuristics have unbounded approximation factors. 
Learning Mixtures of Gaussians|
An elementary proof of the Johnson-Lindenstrauss lemma|
A Two-Round Variant of EM for Gaussian Mixtures|
Experiments with Random Projection|
Optimum rules for classification into two multivariate normal populations with the same covariance matrix,|
Averaging analysis of local stability of a real constant modulus algorithm adaptive filter,|
Transversals of additive Latin squares,|
Off-Policy Temporal Difference Learning with Function Approximation|
Kharitonov's theorem revisited,|
III: `Diffusion of Gases in Polymers', to be submitted;|
Hierarchy - A CHDStd Tool for the Coming Deep Submicron Complex Design Crisis|
Chip hierarchical design system (CHDS): a foundation for timing-driven physical design into the 21st century|
Improved Newton-Type Algorithm for Adaptive Implementation of Pisarenko's Harmonic Retrieval Method and Its Convergence Analysis,"|
Environmental regulation and development: A cross-country empirical analysis, Policy Research Working Paper 1448,|
Guaranteed convergence in a class of Hopfield networks,"|
Learning Polytrees|
A model of clocked micro-architectures for firmware engineering and design automation applications|
\Lyapunov functions for uncertain systems with applications to the stability of time varying systems,|
b) In the simulations we used a dynamics step of 0|001 ps, an NPT dynamics mass prefactor of 0. 125, and a Nos'e relaxation time constant of 0. 25 ps; see c) and d). 
The sample complexity of learning Bayesian nets|
Bending the Rules: Discretionary Pollution Control in China,|
Surviving Success: Policy Reform and the Future of Industrial Pollution in China,|
Citizen Complaints As Environmental Indicators: Evidence From China," World Bank Policy Research Department Working Paper,|
Water Pollution Abatement by Chinese Industry: Cost Estimates and Policy Implications,|
Confronting the Environmental Kuznets Curve,|
Easily testable sufficient conditions for the robust stability of systems with uncertain multilinear parameter dependence,|
Optimum subband coding of cyclostationary signals,|
Conditions for designing strictly positive real transfer functions for adaptive output error identification|
Robust strict positive realness: Characterization and construction|
Noise cancellation with improved residuals|
PAC Generalization Bounds for Co-training|
The Sample Complexity of Learning Fixed-Structure Bayesian Networks|
Long and short run memory|
Electoral Goals and Centre-State Transfers in India", processed, Indian Statistical Institute,|
Contractual incompleteness and the optimality of equity joint ventures|". 
Interfacial force field characterization in a constrained vapor bubble thermosyphon,|
Molecular dynamics for very large systems on massively parallel computers: The MPSim program|
Taylor S and Goddard W A III 1997 Molecular dynamics for very large systems on massively parallel computers: the MPSim program|
Frequency domain conditions for the robust stability of linear and nonlinear dynamical systems|
Intergenerational equity and e$cient allocation of exhaustible Resources|
Small Manufacturing Plants, Pollution and Poverty: New Evidence from Brazil and Mexico," World Bank Development Research Group Working Paper,|
Capital Market Responses to Environmental Performance in Developing Countries," World Bank Development Research Group Working Paper,|
Geological framework of the Indo-Burmese convergent margin with special reference to ophiolitic emplacement|
Pesticide use in Brazil in the era of agroindustrialization and globalization|
"Integrated Hierarchical Forward Timing Driven Electrical and Physical Design Requirements for 0|25-micron Chip Design,. 
T^x# D o/oor+#|
What improves environmental performance? Evidence from Mexican industry, Development Research Group Working Paper 1877,|
An elementary proof of the Johnson-Lindenstrauss Lemma| International Computer Science Institute,. 
'On the welfare significance of national product for economic growth and sustainable develpment',|
Personal Communication,|
Noise{proof equilibria in signaling games|
Small-world properties of the Indian railway network"|
Electoral goals and center-state transfers: A theoretical model and empirical evidence from India,|
Policy reform, economic growth, and the digital divide: An econometric analysis," Aavailable at|
Adaptive estimation of eigenspaces|
`On the Use of Dispersion Measures from NAPM Surveys in Business Cycle Forecasting',|
`A comparative study of altenrative methods of quantifying qualitative survey responses using napm data',|
Persistent Excitation in Bilinear Systems,|
\Parametric Lyapunov function for uncertain system: the multiplier approach,|
Noise-Proof Equilibria in Two-Action Signalling Games|
Learning a mixture of gaussians|
What Improves Environmental Compliance? Evidence from Mexican Industry,|
Managing Procurement Auctions|
What Improves Environmental Performance? Evidence from Mexico in the Economics of Industrial Pollution Control in Developing Countries (RPO 680-20)|
Auctions with cross-shareholdings|
Intertemporal equity and Hartwicks rule in an exhaustible resource model|
Robust relative stability of time invariant and time varying lattice filters,|
Adaptive estimation of eigensubspace,|
"Molecular Dynamics for Very Large Systems on Massively Parallel Computers: The MPSim Program|". 
Deep structure and tectonics of the Burmese arc: constraints from earthquake and gravity data|
Accounting for toxicity risks in pollution control: Does it matter?|
Exponential convergence of a gradient descent algorithm for a class of recurrent neural networks|
Testing the hypothesis law of design: the case of the Britannia bridge|
Effect of data compression of ERP sign preprocessed by FWT algorithm upon a neural network classifier|
February| "Classification of ERP signals using neural networks. 
Effect of using peak amplitudes of ERP signals for a class of neural network classification|
A 2-round variant of EM for Gaussian mixtures,|
A detailed model for the decomposition of nitramines: RDX and HMX|
The mechanism for unimolecular decomposition of RDX, an ab initio study|
Mechanism for unimoecular decomposition of HMX (|
Experiments with random projections|
