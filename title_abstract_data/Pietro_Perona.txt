CNS/EE 248 Sensory Information Processing Laboratory| Abstract The present lab assignment has the objective of familiarize the students with problems in speech recognition/verification and to expose them to the theory and applications of Hidden Markov Models. 
A Bayesian Approach to Unsupervised One-Shot Learning of Object Categories| Abstract Learning visual models of object categories notoriously requires thousands of training examples; this is due to the diversity and richness of object appearance which requires models containing hundreds of parameters.  We present a method for learning object categories from just a few images ( # #).  It is based on incorporating "generic" knowledge which may be obtained from previously learnt models of unrelated categories.  We operate in a variational Bayesian framework: object categories are represented by probabilistic models, and "prior" knowledge is represented as a probability density function on the parameters of these models.  The "posterior" model for an object category is obtained by updating the prior in the light of one or more observations.  Our ideas are demonstrated on four diverse categories (human faces, airplanes, motorcycles, spotted cats).  Initially three categories are learnt from hundreds of training examples, and a "prior" is estimated from these.  Then the model of the fourth category is learnt from 1 to 5 training examples, and is used for detecting new exemplars a set of test images. 
Hybrid Models for Human Motion Recognition| Abstract Probabilistic models have been previously shown to be efficient and effective for modeling and recognition of human motion.  In particular we focus on methods which represent the human motion model as a triangulated graph.  Previous approaches learned models based just on positions and velocities of the body parts while ignoring their appearance.  Moreover, a heuristic approach was commonly used to obtain translation invariance.  In this paper we suggest an improved approach for learning such models and using them for human motion recognition.  The suggested approach combines multiple cues, i. e. , positions, velocities and appearance into both the learning and detection phases.  Furthermore, we introduce global variables in the model, which can represent global properties such as translation, scale or view-point.  The model is learned in an unsupervised manner from unlabelled data.  We show that the suggested hybrid probabilistic model (which combines global variables, like translation, with local variables, like relative positions and appearances of body parts), leads to: (i) faster convergence of learning phase, (ii) robustness to occlusions, and, (iii) higher recognition rate. 
CLASSIFICATION OF HUMAN ACTIONS INTO DYNAMICS BASED PRIMITIVES WITH APPLICATION TO DRAWING TASKS| Abstract We develop the study of primitives of human motion, which we refer to as movemes.  The idea is to understand human motion by decomposing it into a sequence of elementary building blocks that belong to a known alphabet of dynamical systems.  How can we construct an alphabet of movemes from human data? In this paper we address this issue by introducing the notion of well-posednes.  Using examples from human drawing data, we show that the well-posedness notion can be applied in practice so to establish if sets of actions, viewed as signals in time, can define movemes. 
Towards Automatic Discovery of Object Categories| Abstract We propose a method to learn heterogeneous models of object classes for visual recognition.  The training images contain a preponderance of clutter and learning is unsupervised.  Our models represent objects as probabilistic constellations of rigid parts (features).  The variability within a class is represented by a joint probability density function on the shape of the constellation and the appearance of the parts.  Our method automatically identifies distinctive features in the training set.  The set of model parameters is then learned using expectation maximization (see the companion paper [11] for details).  When trained on different, unlabeled and unsegmented views of a class of objects, each component of the mixture model can adapt to represent a subset of the views.  Similarly, different component models can also "specialize" on sub-classes of an object class.  Experiments on images of human heads, leaves from different species of trees, and motor-cars demonstrate that the method works well over a wide variety of objects. 
Real Time Motion Detection System and Scene Segmentation| Abstract We address two issues in this report.  One is the real time implementation of feature tracking and motion estimation.  As a fundamental problem in vision field, feature tracking needs to be implemented in real time so that researchers can do further analysis on motion such as building real time visual navigation system etc. .  Our implementation of the algorithm on the C4x board with parallel processors and its performance are described.  Another part of the paper represents a 3D motion segmentation scheme.  We propose an EM approach combined with the modified separation matrix scheme to perform 3D motion segmentation of the image sequence that contains multiple moving objects.  We observe that, given the detected features and their 2D optical flow, in most cases the objects or their flow are separated very well from each other in space.  The separation matrix method modified by using normalized cuts achieves expected grouping results for these cases.  However, when the objects are overlapped spatially but undergoing independent motions, such as Ullman's co-axial transparent cylinder demonstration, there will be no proper affinity to perform segmentation by that way.  Pure underlying 3D motion becomes the only cue to segment the scene.  We exploit the EM algorithm to deal with such difficult cases.  The scheme is tested on vast number of synthetic image sequences.  Results with real image sequence are also given. 
Unsupervised Learning of Models for Visual Object Class Recognition| Abstract We present a method to learn object class models for the purpose of object recognition.  We focus on a particular type of model where objects are represented as constellations of rigid features (parts).  The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of feature detectors.  The pdf may be estimated from training data once a model structure (type and number of features) has been specified.  The method automatically identifies distinctive features in the training set and learns the statistical shape model.  It is assumed that a set of generic feature detectors is available for the learning algorithm to choose from.  The entire set of model parameters is learned using expectation maximization. 
Camera Calibration from Points and Lines in Dual-Space Geometry| Abstract Camera calibration is essential to many computer vision applications.  Most existing calibration algorithms in the literature consist of estimating both intrinsic and extrinsic camera parameters through non-linear iterative minimizations using only point features.  We show that using lines and planes in a consistant framework allows to first entirely decouple intrinsic and extrinsic camera parameters, and then extract closed form solutions for them making optimal use of the geometrical constraints existing in the scene.  We introduce a new formalism, which we call `dual space', that allows one to represent cleanly and intuitively many useful geometrical relashionships between planes, lines and points in space, and lines and points on the image plane.  Calibration results are presented on real images retrieved from a standard image database. 
Monocular Perception of Biological Motion - Detection and Labeling| Abstract Computer perception of biological motion is key to developing convenient and powerful human-computer interfaces.  Successful body tracking algorithms have been developed; however, initialization is done by hand.  We propose a method for detecting a moving human body and for labeling its parts automatically.  It is based on maximizing the joint probability density function (PDF) of the position and velocity of the body parts.  The PDF is estimated from training data.  Dynamic programming is used for calculating efficiently the best global labeling on an approximation of the PDF.  The computational cost is on the order of N 4 where N is the number of features detected.  We explore the performance of our method with experiments carried on a variety of periodic and non-periodic body motions viewed monocularly for a total of approximately 30,000 frames.  Point-markers were strapped to the joints of the subject for facilitating image analysis.  We find an average of 2. 3% labeling error; the experiments also suggest a high degree of viewpoint-invariance. 
Decomposition of Human Motion into Dynamics Based Primitives with Application to Drawing Tasks| Abstract Using tools from dynamical systems and systems identification we develop a framework for the study of primitives for human motion, which we refer to as movemes.  The objective is understanding human motion by decomposing it into a sequence of elementary building blocks that belong to a known alphabet of dynamical systems.  In this work we define conditions under which a class of dynamical models is able to represent a given collection of trajectories as dierent movemes, and we refer to these conditions as well-posedness.  Based on the assumption of well-posedness, we develop segmentation and classification algorithms in order to reduce a complex activity into the sequence of movemes that have generated it.  Using examples we show that the definition of well-posedness can be applied in practice and show analytically that the proposed algorithms are robust with respect to noise and model uncertainty.  We test our ideas on data sampled from five human subjects who were drawing figures using a computer mouse.  Our experiments show that we are able to distinguish between movemes and recognize them even when they take place in activities containing more than one moveme at a time. 
Viewpoint-Invariant Learning and Detection of Human Heads| Abstract We present a method to learn models of human heads for the purpose of detection from different viewing angles.  We focus on a model where objects are represented as constellations of rigid features (parts).  Variability is represented by a joint probability density function (pdf) on the shape of the constellation.  In a first stage, the method automatically identifies distinctive features in the training set using an interest operator followed by vector quantization.  The set of model parameters, including the shape pdf, is then learned using expectation maximization.  Experiments show good generalization performance to novel viewpoints and unseen faces.  Performance is above ### % correct with less than # s computation time per image. 
Scene Segmentation from 3D Motion| Abstract We propose an EM approach combined with the modified separation matrix scheme to perform 3D motion segmentation of the image sequence which contains multiple moving objects.  We observe that, given the detected features and their 2D optical flow, in most cases the objects or their flow are separated very well from each other in space.  The separation matrix method modified by using normalized cuts achieves expected grouping results for these cases.  However, when the objects are overlapped spatially but undergoing independent motions, such as Ullman's co-axial transparent cylinder demonstration, there will be no proper affinity to perform segmentation by that way.  Pure underlying 3D motion becomes the only cue to segment the scene.  We exploit the EM algorithm to deal with such difficult cases.  The scheme is tested on vast number of synthetic image sequences.  Results with real image sequence are also given. 
Probabilistic Affine Invariants for Recognition| Abstract Under a weak perspective camera model, the image plane coordinates in different views of a planar object are related by an affine transformation.  Because of this property, researchers have attempted to use affine invariants for recognition.  However, there are two problems with this approach: (1) objects or object classes with inherent variability cannot be adequately treated using invariants; and (2) in practice the calculated affine invariants can be quite sensitive to errors in the image plane measurements.  In this paper we use probability distributions to address both of these difficulties.  Under the assumption that the feature positions of a planar object can be modeled using a jointly Gaussian density, we have derived the joint density over the corresponding set of affine coordinates.  Even when the assumptions of a planar object and a weak perspective camera model do not strictly hold, the results are useful because deviations from the ideal can be treated as deformability in the underlying object model. 
Rotation Invariant Texture Recognition Using a Steerable Pyramid| Abstract A rotation-invariant texture recognition system is presented.  A steerable oriented pyramid is used to extract representative features for the input textures.  The steerability of the filter set allows a shift to an invariant representation via aDFT-encoding step.  Supervised classification follows.  State-of-the-art recognition results are presented on a 30 texture database with a comparison across the performance of the K-nn, Back-Propagation and Rule-Based classifiers.  In addition, high accuracy estimation of the input rotation angle is demonstrated. 
Self-Tuning Spectral Clustering| Abstract Spectral clustering has been theoretically analyzed and empirically proven useful.  Still, there are some open issues which have not been addressed properly: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups.  In this paper we address all the above issues.  We first suggest an automatic way to incorporate the local scale for each data point into the point-to-point distance estimation.  We show that this local scaling leads to better clustering performance especially when the data includes multiple scales and when the clusters are placed within a cluttered background.  We further suggest a scheme which exploits the structure of the eigenvectors to automatically infer the number of groups.  This scheme turns out to lead to a new spectral clustering algorithm which requires less user intervention. 
Overcomplete Steerable Pyramid Filters and Rotation Invariance| Abstract A given (overcomplete) discrete oriented pyramid may be converted into a steerable pyramid by interpolation.  We present a technique for deriving the optimal interpolation functions (otherwise called steering coefficients).  The proposed scheme is demonstrated on a computationally efficient oriented pyramid, which is a variation on the Burt and Adelson pyramid.  We apply the generated steerable pyramid to orientation-invarianttexture analysis to demonstrate its excellent rotational isotropy.  High classification rates and precise rotation identification are demonstrated. 
3D photography on your desk \Lambda| Experimental results are presented on three different scenes demonstrating that the error in reconstructing the surface is less than 1%. 
Viewpoint-Invariant Learning and Detection of Human Heads| Abstract We present a method to learn models of human heads for the purpose of detection from different viewing angles.  We focus on a model where objects are represented as constellations of rigid features (parts).  Variability is represented by a joint probability density function (pdf) on the shape of the constellation.  In a first stage, the method automatically identifies distinctive features in the training set using an interest operator followed by vector quantization.  The set of model parameters, including the shape pdf, is then learned using expectation maximization.  Experiments show good generalization performance to novel viewpoints and unseen faces.  Performance is above 90% correct with less than 1s computation time per image. 
An Improved Scheme for Detection and Labelling in Johansson Displays| Abstract Consider a number of moving points, where each point is attached to a joint of the human body and projected onto an image plane.  Johannson showed that humans can eortlessly detect and recognize the presence of other humans from such displays.  This is true even when some of the body points are missing (e. g.  because of occlusion) and unrelated clutter points are added to the display.  We are interested in replicating this ability in a machine.  To this end, we present a labelling and detection scheme in a probabilistic framework.  Our method is based on representing the joint probability density of positions and velocities of body points with a graphical model, and using Loopy Belief Propagation to calculate a likely interpretation of the scene.  Furthermore, we introduce a global variable representing the body's centroid.  Experiments on one motion-captured sequence suggest that our scheme improves on the accuracy of a previous approach based on triangulated graphical models, especially when very few parts are visible.  The improvement is due both to the more general graph structure we use and, more significantly, to the introduction of the centroid variable. 
Discriminative Distance Measures for Object Detection| Abstract The reliable detection of an object of interest in an input image with arbitrary background clutter and occlusion has to a large extent remained an elusive goal in computer vision.  Traditional model-based approaches are inappropriate for a multi-class object detection task primarily due to difficulties in modeling arbitrary object classes.  Instead, we develop a detection framework whose core component is a nearest neighbor search over object parts.  The performance of the overall system is critically dependent on the distance measure used in the nearest neighbor search.  A distance measure that minimizes the mis-classification risk for the 1-nearest neighbor search can be shown to be the probability that a pair of input measurements belong to different classes.  This pair-wise probability is not in general a metric distance measure.  Furthermore, it can out-perform any metric distance, approaching even the Bayes optimal performance.  In practice, we seek a model for the optimal distance measure that combines the discriminative powers of more elementary distance measures associated with a collection of simple feature spaces that are easy and efficient to implement; in our work, we use histograms of various feature types like color, texture and local shape properties.  We use a linear logistic model combining such elementary distance measures that is supported by observations of actual data for a representative discrimination task.  For performing efficient nearest neighbor search over large training sets, the linear model was extended to discretized distance measures that combines distance measures associated with discriminators organized in a treelike structure.  The discrete model was combined with the continuous model to yield a hierarchical distance model that is both fast and accurate.  Finally, the nearest neighbor search over object parts was integrated into a whole object detection system and evaluated against both an indoor detection task as well as a face recognition task yielding promising results. 
Sampling Methods for Unsupervised Learning| Abstract We present an algorithm to overcome the local maxima problem in estimating the parameters of mixture models.  It combines existing approaches from both EM and a robust fitting algorithm, RANSAC, to give a data-driven stochastic learning scheme.  Minimal subsets of data points, sufficient to constrain the parameters of the model, are drawn from proposal densities to discover new regions of high likelihood.  The proposal densities are learnt using EM and bias the sampling toward promising solutions, giving an efficient algorithm.  We compare it with alternative methods, including EM and RANSAC, on both challenging synthetic data and real visual data from Google's image search. 
A Sparse Object Category Model for Efficient Learning and Exhaustive Recognition| Abstract We present a "parts and structure" model for object category recognition that can be learnt efficiently and in a semisupervised manner: the model is learnt from example images containing category instances, without requiring segmentation from background clutter.  The model is a sparse representation of the object, and consists of a star topology configuration of parts modeling the output of a variety of feature detectors.  The optimal choice of feature types (whose repertoire includes interest points, curves and regions) is made automatically.  In recognition, the model may be applied efficiently in an exhaustive manner, bypassing the need for feature detectors, to give the globally optimal match within a query image.  The approach is demonstrated on a wide variety of categories, and delivers both successful classification and localization of the object within the image. 
A Computational Model for Motion Detection and Direction Discrimination in Humans| Abstract Seeing biological motion is very important for both humans and computers.  Psychophysics experiments show that the ability of our visual system for biological motion detection and direction discrimination is different from that for simple translation [4].  But the existing quantitative models of motion perception can not explain these findings.  We propose a computational model, which uses learning and statistical inference based on the joint probability density function (PDF) of the position and motion of the body, on stimuli similar to [4].  Our results are consistent with the psychophysics indicating that our model is consistent with human motion perception, accounting for both biological motion and pure translation. 
Object Class Recognition by Unsupervised Scale-Invariant Learning| Abstract We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner.  Objects are modeled as flexible constellations of parts.  A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale.  An entropy-based feature detector is used to select regions and their scale within the image.  In learning the parameters of the scale-invariant object model are estimated.  This is done using expectation-maximization in a maximum-likelihood setting.  In recognition, this model is used in a Bayesian manner to classify images.  The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e. g.  faces, cars) and flexible objects (such as animals). 
Motion from Points, Lines and P-Lines on N views| Abstract We study the problem of 3D motion analysis based on points and lines correspondence across any number of images.  An intuitive geometric approach is provided, leading to precise algebraic relations.  We reach the statement that on N views, one point and one line correspondences respectively provide 2N \Gamma 3 and 2N \Gamma 4 independent constraints and show how those constraints can be effectively constructed.  In the specific case of points on three views, we derive in a consistent fashion both bilinear and trilinear constraints, and show that there are exactly 3 independent equations per point correspondence.  We illustrate the influence of the choice of constraints through two specific degenerate cases for three views.  Finally, as an extension to points and lines, we derive the motion constraints for a new type of hybrid feature that we call P-Line defined to be a line going through a point in space.  This work is mostly inspired from Hartley's work on lines and points in three views, with a complete geometric interpretation.  The algebraic formalism is in part inspired by Faugeras and provides an intuitive geometric understanding of lines and points on multiple views. 
Unsupervised Learning of Human Motion Models| Abstract This paper presents an unsupervised learning algorithm that can derive the probabilistic dependence structure of parts of an object (a moving human body in our examples) automatically from unlabeled data.  The
What do reflections tell us about the shape of a mirror?| Abstract Three-dimensional shape may be perceived from static images.  Contours, shading, texture gradients, perspective and occlusion are well-studied cues to this percept.  When looking at a picture of a specular object, such as a silver vase, one additional cue is potentially available: a deformed picture of the reflected environment is seen in the surface of the object and the amount and type of deformation depend on its shape.  Can specular reflections be used as a visual cue for shape perception? Our experiments show that our subjects are very poor at judging the shape of mirror surfaces in absence of other visual cues.  However, for a considerable subset of the stimuli, subjects are highly consistent in their (most often wrong) perception.  This observation leads us to the hypothesis that our subjects rather than `computing' a percept from each image based on geometrical considerations, may be associating a shape to each pattern in a stereotypical way, akin to pattern-matching.  This behavior is reasonable since, as suggested by our ideal observer analysis, the information available from specular reflections is ambiguous when the surrounding world is (partially) unknown. 
3D PHOTOGRAPHY USING SHADOWS| ABSTRACT A simple and inexpensive approach for extracting the threedimensional shape of objects is presented.  It is based on `weak structured lighting;' and requires little hardware besides the camera: a light source (a desk-lamp or the sun), a stick and a checkerboard.  The object, illuminated by the light source, is placed on a stage composed of a ground plane and a back plane; the camera faces the object.  The user moves the stick in front of the light source, casting a moving shadow on the scene.  The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow.  Experimental results are presented on three different scenes (indoor with a desk lamp and outdoor with the sun) demonstrating that the error in reconstructing the surface is less than 0:5% of the size of the object. 
Segmentation of Human Motion into Dynamics Based Primitives with Application to Drawing Tasks| Abstract Using tools from dynamical systems and systems identification we develop a framework for the study of decomposition of human motion.  The objective is understanding human motion by decomposing it into a sequence of elementary building blocks, which we refer to as movemes, which belong to a known alphabet of dynamical systems.  We develop classification and segmentation algorithms with error analysis and we test them on human drawing data. 
A Digital Antennal Lobe for Pattern Equalization: Analysis and Design| Abstract Re-mapping patterns in order to equalize their distribution may greatly simplify both the structure and the training of classifiers.  Here, the properties of one such map obtained by running a few steps of discrete-time dynamical system are explored.  The system is called 'Digital Antennal Lobe' (DAL) because it is inspired by recent studies of the antennal lobe, a structure in the olfactory system of the grasshopper.  The pattern-spreading properties of the DAL as well as its average behavior as a function of its (few) design parameters are analyzed by extending previous results of Van Vreeswijk and Sompolinsky.  Furthermore, a technique for adapting the parameters of the initial design in order to obtain opportune noise-rejection behavior is suggested.  Our results are demonstrated with a number of simulations. 
Grouping and dimensionality reduction by locally linear embedding| Abstract Locally Linear Embedding (LLE) is an elegant nonlinear dimensionality-reduction technique recently introduced by Roweis and Saul [2].  It fails when the data is divided into separate groups.  We study a variant of LLE that can simultaneously group the data and calculate local embedding of each group.  An estimate for the upper bound on the intrinsic dimension of the data set is obtained automatically. 
Is Bottom-Up Attention Useful for Object Recognition?| Abstract A key problem in learning multiple objects from unlabeled images is that it is a priori impossible to tell which part of the image corresponds to each individual object, and which part is irrelevant clutter which is not associated to the objects.  We investigate empirically to what extent pure bottom-up attention can extract useful information about the location, size and shape of objects from images and demonstrate how this information can be utilized to enable unsupervised learning of objects from unlabeled images.  Our experiments demonstrate that the proposed approach to using bottom-up attention is indeed useful for a variety of applications. 
A Factorization Approach to Grouping| Abstract The foreground group in a scene may be `discovered' and computed as a factorized approximation to the pairwise affinity of the elements in the scene.  A pointwise approximation of the pairwise affinity information may in fact be interpreted as a `saliency' index, and the foreground of the scene may be obtained by thresholding it.  An algorithm called `affinity factorization' is thus obtained whichmay be used for grouping.  The affinity factorization algorithm is demonstrated on displays com- posed of points, of lines and of brightness values.  Its relationship to the Shi-Malik normalized cuts algorithms is explored both analytically and experimentally.  The affinity factorization algorithm is shown to be com- putationally efficient (O(n) floating-point operations for a scene com- posed of n elements) and to perform well on displays where the back- ground is unstructured.  Generalizations to solve more complex problems are also discussed. 
Visual Input for Pen-Based Computers| More than 100 subjects have used the system and have provided a large and heterogeneous set of examples showing that the system is both convenient and accurate. 
Towards Detection of Human Motion| Abstract Detecting humans in images is a useful application of computer vision.  Loose and textured clothing, occlusion and scene clutter make it a difficult problem because bottom-up segmentation and grouping do not always work.  We address the problem of detecting humans from their motion pattern in monocular image sequences; extraneous motions and occlusion may be present.  We assume that we may not rely on segmentation, nor grouping and that the vision front-end is limited to observing the motion of key points and textured patches in between pairs of frames.  We do not assume that we are able to track features for more than two frames.  Our method is based on learning an approximate probabilistic model of the joint position and velocity of different body features.  Detection is performed by hypothesis testing on the maximum a posteriori estimate of the pose and motion of the body.  Our experiments on a dozen of walking sequences indicate that our algorithm is accurate and efficient. 
Online Terrain Parameter Estimation for Wheeled Mobile Robots With Application to Planetary Rovers|
Unsupervised Learning of Models for Recognition| Abstract.  We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition.  We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features).  The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors.  In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator.  It then learns the statistical shape model using expectation maximization.  The method achieves very good classification results on human faces and rear views of cars. 
Pruning Training Sets for Learning of Object Categories| Abstract Training datasets for learning of object categories are often contaminated or imperfect.  We explore an approach to automatically identify examples that are noisy or troublesome for learning and exclude them from the training set.  The problem is relevant to learning in semi-supervised or unsupervised setting, as well as to learning when the training data is contaminated with wrongly labeled examples or when correctly labeled, but hard to learn examples, are present.  We propose a fully automatic mechanism for noise cleaning, called 'data pruning', and demonstrate its success on learning of human faces.  It is not assumed that the data or the noise can be modeled or that additional training examples are available.  Our experiments show that data pruning can improve on generalization performance for algorithms with various robustness to noise.  It outperforms methods with regularization properties and is superior to commonly applied aggregation methods, such as bagging. 
On the usefulness of attention for object recognition| Abstract Today's object recognition systems have become very good at learning and recognizing isolated objects or objects in images with little clutter.  However, unsupervised learning and recognition in highly cluttered scenes or in scenes with multiple objects are still problematic.  Faced with the same issue, the brain employs selective visual attention to select relevant parts of the image and to serialize the perception of individual objects.  In this paper we demonstrate the use of a computational model of bottom-up visual attention for object recognition in machine vision.  By comparing the performance of David Lowe's recognition algorithm with and without attention, we quantify the usefulness of attention for learning and recognizing multiple objects from complex scenes, and for learning and recognizing objects in scenes with large amounts of clutter. 
Reducing "Structure From Motion": A General Framework for Dynamic Vision Part 1: Modeling| Abstract A number of methods have been proposed in the literature for estimating scenestructure and ego-motion from a sequence of images using dynamical models.  Despite the fact that all methods may be derived from a "natural" dynamical model within a unified framework, from an engineering perspective there are a number of trade-offs that lead to different strategies depending upon the applications and the goals one is targeting.  We want to characterize and compare the properties of each model such that the engineer may choose the one best suited to the specific application.  We analyze the properties of filters derived from each dynamical model under a variety of experimental conditions, assess the accuracy of the estimates, their robustness to measurement noise, sensitivity to initial conditions and visual angle, effects of the bas-relief ambiguity and occlusions, dependence upon the number of image measurements and their sampling rate. 
Visual Identification by Signature Tracking| Abstract We propose a new camera-based biometric: visual signature identification.  We discuss the importance of the parameterization of the signatures in order to achieve good classification results, independently of variations in the position of the camera with respect to the writing surface.  We show that ane arc-length parameterization performs better than conventional time and Euclidean arc-length ones.  We find that the system verification performance is better than 4 % error on skilled forgeries and 1 % error on random forgeries, and that its recognition performance is better than 1 % error rate, comparable to the best camera-based biometrics. 
PRIMITIVES FOR HUMAN MOTION: A DYNAMICAL APPROACH| Abstract: Using tools from dynamical systems theory and systems identification theory we develop the study of primitives for human motion which we refer to as movemes.  We introduce basic definitions of dynamical independence of linear time-invariant dynamical systems (LTI) and segmentability of signals and we develop classification and segmentation algorithms for two dimensional motions.  We test our ideas on data sampled from four human subjects who were engaged in a simple real-life activity including two movemes.  Our experiments show that we are able to distinguish between the two movemes and recognize them even when they take place in an activity containing more than one moveme. 
3D Photography on Your Desk| Abstract A simple and inexpensive approach for extracting the threedimensional shape of objects is presented.  It is based on `weak structured lighting'; it differs from other conventional structured lighting approaches in that it requires very little hardware besides the camera: a desk-lamp, a pencil and a checkerboard.  The camera faces the object, which is illuminated by the desk-lamp.  The user moves a pencil in front of the light source casting a moving shadow on the object.  The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow.  Experimental results are presented on three different scenes demonstrating that the error in reconstructing the surface is less than 1%. 
What Do Planar Shadows Tell About Scene Geometry?| Abstract A method for reconstructing 3D scene geometry from a set of projected shadows is presented.  It is composed of two stages.  First, the scene geometry is retrieved up to three scalar unknowns using only the information contained in the observed shadow edges on the image plane.  Then, the three remaining unknowns are computed making use of the known depths at three points.  This technique improves upon previous results [2] in that it does not require the presence of a reference plane in the background.  A mathematical analysis is presented using dual-space geometry, a formalism that provides adequate tools to carry out all the derivations in a compact and intuitive manner.  A linear algorithm based on singular value decomposition (SVD) is presented leading to a closed form solution for reconstruction. 
A Variational Framework for Image Segmentation Combining Motion Estimation and Shape Regularization| Abstract Based on a geometric interpretation of the optic flow constraint equation, we propose a conditional probability on the spatio-temporal image gradient.  We consistently derive a variational approach for the segmentation of the image domain into regions of homogeneous motion.  The proposed energy functional extends the MumfordShah functional from gray value segmentation to motion segmentation.  It depends on the spatio-temporal image gradient calculated from only two consecutive images of an image sequence.  Moreover, it depends on motion vectors for a set of regions and a boundary separating these regions.  In contrast to most alternative approaches, the problems of motion estimation and motion segmentation are jointly solved by minimizing a single functional.  Numerical evaluation with both explicit and implicit (level set based) representations of the boundary shows the strengths and limitations of our approach. 
Continuous Dynamic Time Warping for Translation-Invariant Curve Alignment with Applications to Signature Verification| Abstract The problem of establishing correspondence and measuring the similarity of a pair of planar curves arises in many applications in computer vision and pattern recognition.  This paper presents a new method for comparing planar curves and for performing matching at sub-sampling resolution.  The analysis of the algorithm as well as its structural properties are described.  The performance of the new technique applied to the problem of signature verification is shown and compared with the performance of the well-known Dynamic Time Warping algorithm. 
Selective visual attention enables learning and recognition of multiple objects in cluttered scenes| Abstract A key problem in learning representations of multiple objects from unlabeled images is that it is a priori impossible to tell which part of the image corresponds to each individual object, and which part is irrelevant clutter.  Distinguishing individual objects in a scene would allow unsupervised learning of multiple objects from unlabeled images.  There is psychophysical and neurophysiological evidence that the brain employs visual attention to select relevant parts of the image and to serialize the perception of individual objects.  We propose a method for the selection of salient regions likely to contain objects, based on bottom-up visual attention.  By comparing the performance of David Lowe#s recognition algorithm with and without attention, we demonstrate in our experiments that the proposed approach can enable one-shot learning of multiple objects from complex scenes, and that it can strongly improve learning and recognition performance in the presence of large amounts of clutter.  # 2005 Elsevier Inc.  All rights reserved. 
Squaring the Circle in Panoramas| Abstract Pictures taken by a rotating camera cover the viewing sphere surrounding the center of rotation.  Having a set of images registered and blended on the sphere what is left to be done, in order to obtain a flat panorama, is projecting the spherical image onto a picture plane.  This step is unfortunately not obvious -- the surface of the sphere may not be flattened onto a page without some form of distortion.  The objective of this paper is discussing the difficulties and opportunities that are connected to the projection from viewing sphere to image plane.  We first explore a number of alternatives to the commonly used linear perspective projection.  These are `global' projections and do not depend on image content.  We then show that multiple projections may coexist successfully in the same mosaic: these projections are chosen locally and depend on what is present in the pictures.  We show that such multi-view projections can produce more compelling results than the global projections. 
Scale-Space and Edge Detection Using Anisotropic Diffusion|
Monocular Tracking of the Human Arm in 3D|
Motion estimation via dynamic vision|
Preattentive texture discrimination with early vision mechanisms|
Steerable-scalable kernels for edge detection and junction analysis|
Detecting and localizing edges composed of steps, peaks and roofs|
Face localization via shape statistics|
Where is the sun?|
Finding Faces in Cluttered Scenes Using Labeled Random Graph Matching|
Monocular perception of biological motion in johansson displays|
Structure-independent visual motion control on the essential manifold|
Real-Time 2-D Feature Detection on a Reconfigurable Computer|
Deformable Kernels for Early Vision|
Common-frame model for object recognition|
A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry|
Reach Out and Touch Space (Motion Learning)|
Automating the hunt for volcanos on venus|
Rapid natural scene categorization in the near absence of attention|
Why does natural scene categorization require little attention? Exploring attentional requirements for natural and synthetic stimuli|
Anisotropic diffusion|
Visual-based ID verification by signature tracking|
Camera-Based ID Verification by Signature Tracking|
Dynamic Rigid Motion Estimation from Weak Perspective|
Recognition by Probabilistic Hypothesis Construction|
Orientation diffusion|
Orientation diffusions|
Learning to Recognize Volcanoes on Venus|
Motion Estimation on the Essential Manifold|
Local Analysis for 3D Reconstruction of Specular Surfaces|
Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth|
MWeber, and MWelling| Unsupervised learning of object classes from natural scenes. 
Anisotropic diffusion| In B Romeny, editor, Geometrydriven diffusion in computer vision,. 
Three dimensional transparent structure segmentation and multiple 3d motion estimation from monocular perspective image sequences|
Unsupervised Learning of Human Motion|
Recursive motion estimation on the essential manifold|
Efficient deformable filter banks,|
Is attention useful for object recognition?|
Monocular perception of biological motion - clutter and partial occlusion|
Recursive 3-d visual motion estimation using subspace constraints|
Reducing "structure from motion" 1: modeling|
Structure from visual motion as a nonlinear observation problem|
Finding boundaries in images|
Early computation of shape and reflectance in the visual system,|
A computational model of texture perception|
Towards detection of humans,"|
Using Hierarchical Shape Models to Spot Keywords in Cursive Handwriting Data|
Dynamic Visual Motion Estimation from Subspace Constraints|
On the exact linearization of structure from motion|
A Bayesian hierarchical model for learning natural scene categories|
D photography on your desk,|
Unsupervised learning of object models for recognition|
Finite representation of deformable functions|
Mutual Boosting for Contextual Inference|
"Computing centroids in current-mode technique,|
Recursive Estimation of Camera Motion from Uncalibrated Image Sequences|
Face localisation via shape statistics|
Shadow Carving|
Automating the hunt for volcanoes on Venus|
Bayesian reasoning on qualitative descriptions from images and speech|
Pyramidal implementation of deformable kernels|
Baysian Reasoning on Qualitative Descriptions from Images and Speech|
Beyond pairwise clustering|
A network for multiscale image segmentation,|
X-y separable pyramid steerable scalable kernels|
Apparatus and method for tracking handwriting from visual input|
Geometry-Driven Diffusion in Computer Vision,|
Detecting human faces in cluttered dynamic scenes| Computation and Neural Systems In Preparation,. 
3D Photography Using Shadows in Dual-Space Geometry|
"A Network for Edge Detection and Scale-Space",|
Visual navigation by controlling apparent shape|
Preattentive Perception of Elementary Three-Dimensional Shapes|
What do planar shadows tell us about scene geometry?",|
Trainable cataloging for digital image libraries with application to volcano detection| Technical Report Computation and Neural Systems,. 
A visual odometer and gyroscope|
Object segmentation and 3d structure from motion|
Recovering Local Shape of a Mirror Surface from Reflection of a Regular Grid|
Can we see the shape of a mirror?|
3d visual mtion estimation using subspace constraints|
Motion estimation via dynamic vision|
Inferring Ground Truth from Subjective Labelling of Venus Images|
Image recognition: Visual grouping, recognition and learning|
IEEE Trans| Pattern Analysis and. 
Learning to catalog science images|
Motion from fixation|
Steerable-2 -4170 e kernels for edge detection and junction analysis|
Modeling Subjective Uncertainty in Image Annotation|
On the trajectory method for the reconstruction of differential equations from time series,|
3D photography using shadow in dual space geometry|
1994 "Rotation invariant texture recognition using steerable pyramids|
Locating small volcanoes on venus using a scientisttrainable analysis system|
Two grocery e-tailers to exit markets|
in press)| Knowledge discovery in large image databases: Dealing with uncertainties in ground truth. 
Slippre: Face localization by shape likelihood plus part responses|
Reducing "structure from motion" part 1: modeling|
Recognition of Planer Class Objects',|
Time Motion Detection System and Scene Segmentation",|
