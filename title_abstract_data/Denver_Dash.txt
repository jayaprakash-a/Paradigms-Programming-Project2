A method for evaluating elicitation schemes for probabilistic models| Abstract We present an objective approach for evaluating probability elicitation methods in probabilistic models.  Our method draws on ideas from research on learning Bayesian networks: if we assume that the expert's knowledge is manifested essentially as a database of records that have been collected in the course of the expert's experience, and if this database of records were available to us, then the structure and parameters of the expert's beliefs could be reliably constructed using techniques for Bayesian learning from data.  This learned model could, in turn, be compared to elicited models to judge the effectiveness of the elicitation process.  We describe a general procedure by which it is possible to capture the data corresponding to the expert's beliefs, and we present a simple experiment in which we utilize this technique to compare three methods for eliciting discrete probabilities: (1) direct numerical assessment, (2) the probability wheel, and (3) the scaled probability bar.  We show that for our domain, the scaled probability bar is the most effective tool for probability elicitation. 
Model Averaging with Discrete Bayesian Network Classifiers| Abstract This paper considers the problem of performing classification by model-averaging over a class of discrete Bayesian network structures consistent with a partial ordering and with bounded in-degree k.  We show that for N nodes this class contains in the worst-case at least -( N/2 k N/2 ) distinct network structures, but we show that this summation can be performed in O( N k N) time.  We use this fact to show that it is possible to eciently construct a single directed acyclic graph (DAG) whose predictions approximate those of exact model-averaging over this class, allowing approximate model-averaged predictions to be performed in O(N) time.  We evaluate the procedure in a supervised classification context, and show empirically that this technique can be beneficial for classification even when the generating distribution is not a member of the class being averaged over, and we characterize the performance over several parameters on simulated and real-world data. 
"Lazy evaluation of symmetric Bayesian decision problems," in Proc| 15th Conf.  Uncertainty in Artificial.  Intelligence, 1999, pp.  382--390.  [10] R.  D.  Shachter, "An ordered examination of influence diagrams," Networks, vol.  20, no.  5, pp.  535--563, 1990.  [11] P.  P.  Shenoy, "Valuation network representation and solution of asymmetric decision problems," Eur.  J.  Oper. 
In Proceedings of the Fifteenth Annual Conference on Uncertainty in Artificial Intelligence| Abstract We present a hybrid constraintbased/Bayesian algorithm for learning causal networks in the presence of sparse data.  The algorithm searches the space of equivalence classes of models (essential graphs) using a heuristic based on conventional constraintbased techniques.  Each essential graph is then converted into a directed acyclic graph and scored using a Bayesian scoring metric.  Two variants of the algorithm are developed and tested using data from randomly generated networks of sizes from 15 to 45 nodes with data sizes ranging from 250 to 2000 records.  Both variations are compared to, and found to consistently outperform two variations of greedy search with restarts. 
Caveats for Causal Reasoning with Equilibrium Models|
Exact model averaging with naive Bayesian classifiers|
Model Averaging for Prediction with Discrete Bayesian Networks|
An inconsistency between formalisms for causal discovery and causal reasoning|
Testing of diagnostic models based on bayesian networks|
