A Mixed-State CONDENSATION Tracker with Automatic Model-Switching| The Bayesian mixed-state framework is described in its generality, and the example of a bouncing ball is used to demonstrate that a mixed-state model can significantly improve tracking performance in heavy clutter.  The relevance of the approach to the problem of gesture recognition is then investigated using a tracker which is able to follow the natural drawing action of a hand holding a pen, and switches state according to the hand's motion. 
ICONDENSATION: Unifying Low-Level and High-Level Tracking in a Stochastic Framework| Abstract.  Tracking research has diverged into two camps; low-level approaches which are typically fast and robust but provide little fine-scale information, and high-level approaches which track complex deformations in high-dimensional spaces but must trade off speed against robustness.  Real-time high-level systems perform poorly in clutter and initialisation for most high-level systems is either performed manually or by a separate module.  This paper presents a new technique to combine low- and high-level information in a consistent probabilistic framework, using the statistical technique of importance sampling combined with the Condensation algorithm.  The general framework, which we term Icondensation, is described, and a hand tracker is demonstrated which combines colour blob-tracking with a contour model.  The resulting tracker is robust to rapid motion, heavy clutter and hand-coloured distractors, and re-initialises automatically.  The system runs comfortably in real time on an entry-level desktop workstation. 
Bayesian Correlation| Abstract Cross-correlation is a commonly used principle for intensity-based object localization and consists of two conceptual components, one very effective and the other rather weak.  The effective component is the inner-product score for matching.  The weak component is exhaustive search, inefficient in two dimensions, and infeasible in the higher dimensioned configuration spaces needed for matching object models.  The Bayesian framework for correlation, developed here, replaces exhaustive search with constrained, random hypothesis generation.  Achieving a synthesis of cross-correlation, which is deterministic, with probabilistic sampling has required several developments.  The first is the interpretation of correlation matching functions, in probabilistic terms, by constructing an observation likelihood.  Second, a response-learning algorithm is developed for the distributions of filter-bank responses.  Inescapably, response-learning demands statistical modelling of background intensities, and there are unexpected links here with image coding and Independent Component Analysis.  Lastly, multi-scale processing is well known to be an important component of conventional correlation.  In the Bayesian context it is achieved by means of a new algorithm, termed layered sampling, for which asymptotic properties are derived.  Bayesian correlation has the considerable advantage that, thanks to the response-learning, image-feature tuning and selection are automatic.  Combined with random sampling to deal with ambiguity, response-learning makes for excellent handling of image clutter, and this is demonstrated.  Furthermore, the output of Bayesian correlation is not simply an estimate of location but an entire probability distribution.  This allows sequential inference --- propagation from coarse to fine scale, and also propagation over time, illustrated here by examples of image-sequence analysis. 
Object Localization by Bayesian Correlation| Abstract Maximisation of cross-correlation is a commonly used principle for intensity-based object localization that gives a single estimate of location.  However, to facilitate sequential inference (eg over time or scale) and to allow the representation of ambiguity, it is desirable to represent an entire probability distribution for object location.  Although the crosscorrelation itself (or some function of it) has sometimes been treated as a probability distribution, this is not generally justifiable.  Bayesian correlation achieves a consistent probabilistic treatment by combining several developments.  The first is the interpretation of correlation matching functions in probabilistic terms, as observation likelihoods.  Second, probability distributions of filter-bank responses are learned from training examples.  Inescapably, response-learning also demands statistical modelling of background intensities, and there are links here with image coding and Independent Component Analysis.  Lastly, multi-scale processing is achieved, in a Bayesian context, by means of a new algorithm, layered sampling, for which asymptotic properties are derived. 
Tracking Loose-Limbed People| Abstract We pose the problem of 3D human tracking as one of inference in a graphical model.  Unlike traditional kinematic tree representations, our model of the body is a collection of loosely-connected limbs.  Conditional probabilities relating the 3D pose of connected limbs are learned from motioncaptured training data.  Similarly, we learn probabilistic models for the temporal evolution of each limb (forward and backward in time).  Human pose and motion estimation is then solved with non-parametric belief propagation using a variation of particle filtering that can be applied over a general loopy graph.  The loose-limbed model and decentralized graph structure facilitate the use of low-level visual cues.  We adopt simple limb and head detectors to provide "bottom-up" information that is incorporated into the inference process at every time-step; these detectors permit automatic initialization and aid recovery from transient tracking failures.  We illustrate the method by automatically tracking a walking person in video imagery using four calibrated cameras.  Our experimental apparatus includes a marker-based motion capture system aligned with the coordinate frame of the calibrated cameras with which we quantitatively evaluate the accuracy of our 3D person tracker. 
Hand tracking for vision-based drawing| Abstract This report should be regarded as an appendix to our paper [9].  It provides technical details on the hand tracking system described there, and on the vision-based drawing package developed to demonstrate its use in applications.  1 The hand tracker This section describes the implementation of a robust and accurate hand tracker using ICondensation [5] and partitioned sampling [9].  1. 1 State space A second-order state-space is used to represent the hand, giving X t = ` x t x t\Gamma 1 ' where x
A Cooperative Internet Backup Scheme| Abstract We present a novel peer-to-peer backup technique that allows computers connected to the Internet to back up their data cooperatively: Each computer has a set of partner computers, which collectively hold its backup data.  In return, it holds a part of each partner's backup data.  By adding redundancy and distributing the backup data across many partners, a highly-reliable backup can be obtained in spite of the low reliability of the average Internet machine.  Because our scheme requires cooperation, it is potentially vulnerable to several novel attacks involving free riding (e. g. , holding a partner's data is costly, which tempts cheating) or disruption.  We defend against these attacks using a number of new methods, including the use of periodic random challenges to ensure partners continue to hold data and the use of disk-space wasting to make cheating unprofitable.  Results from an initial prototype show that our technique is feasible and very inexpensive: it appears to be one to two orders of magnitude cheaper than existing Internet backup services. 
3D Human Limb Detection using Space Carving and Multi-view Eigen Models| Abstract In this paper, we integrate space carving and eigen detection methods to develop a bottom-up 3D human limb detector.  We model the body in terms of its constituent body parts; here we focus on the head, lower arms, upper arms and calves.  For each body part, we build a multi-view eigen model that combines image views from multiple calibrated cameras.  This approach is much more constraining than the conventional multiple single-view eigen models and provides coarse 3D pose information.  We use ideas from space carving using multiple silhouette images to constrain the volume of our search for the body part locations.  We have applied the method to detect the body parts of a subject in long test sequences.  The approach provides bottom-up information that supports the automatic initialization of a full 3D human body model. 
Object localization by Bayesian correlation| Abstract This paper is based on the article [2]
Contour Tracking by Stochastic Propagation of Conditional Density| The problem of tracking curves in dense visual clutter is a challenging one.  Trackers based on Kalman filters are of limited use; because they are based on Gaussian densities which are unimodal, they cannot represent simultaneous alternative hypotheses.  Extensions to the Kalman filter to handle multiple data associations work satisfactorily in the simple case of point targets, but do not extend naturally to continuous curves.  A new, stochastic algorithm is proposed here, the Condensation algorithm --- Conditional Density Propagation over time.  It uses `factored sampling', a method previously applied to interpretation of static images, in which the distribution of possible interpretations is represented by a randomly generated set of representatives.  The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time.  The result is highly robust tracking of agile motion in clutter, markedly superior to what has previously been attainable from Kalman filtering.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  1 The problem of tracking curves in clutter The purpose of this paper is to establish a stochastic framework for tracking curves in visual clutter, and to propose a powerful new technique --- the Condensation algorithm.  The new approach is rooted in strands from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our framework aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models must be pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost [17, 26, 18].  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally [20], especially if motion is modelled as well as shape [12, 16].  One important facility is the modelling of curve segments which interact with images [29] or image sequences [19].  This is more general than modelling entire objects but more clutter-resistant than applying signal-processing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric Bspline curves [3] tracking over image sequences [8].  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space [28, 5], or more generally allowing a linear space of non-rigid motion [9].  Finally, probability densities p(x) can be defined over the class of curves [9], and also over their motions [27, 5], and this constitutes a powerful facility for tracking.  Reasonable default functions can be chosen for those densities.  However, it is obviously more satisfactory to measure the actual densities or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this assuming Gaussian densities are known in the control-theory literature [13] and have been applied in computer vision [6, 7, 4].  1. 2 Sampling methods A standard problem in statistical pattern recognition is to find an object parameterised as x with prior p(x), using data z from a single image.  (This is a simplified, static form of the image sequence problem addressed in this paper. ) In order to estimate x from z, some information is needed about the conditional distribution p(zjx) which measures the likelihood that a hypothetical object configuration x should give rise to the image data z that has just been observed.  The data z could either be an entire grey-level array or a set of sparse features such as corners or, as in this paper, curve fragments obtained by edge detection.  The posterior density p(xjz) represents all the knowledge about x that is deducible from the data.  It can be evaluated in principle by applying Bayes' rule to obtain p(xjz) = kp(zjx)p(x) (1) where k is a normalisation constant that is independent of x.  In the general case that p(zjx) is multi-modal p(xjz) cannot be evaluated simply in closed form: instead iterative sampling techniques can be used.  The first use of such an iterative solution was proposed by Geman and Geman [11] for restoration of an image represented by mixed variables, both continuous (pixels) and discrete (the `line process').  Sampling methods for recovery of a parametric curve x by sampling [24, 14, 25] have generally used spatial Markov processes as the underlying probabilistic model p(x).  The basic method is factored sampling [14].  It is useful when the conditional observation probability p(zjx) can be evaluated pointwise and sampling it is not feasible and when, conversely, the prior p(x) can be sampled but not evaluated.  The algorithm
Condensation --- conditional density propagation for visual tracking| ABSTRACT The problem of tracking curves in dense visual clutter is challenging.  Kalman filtering is inadequate because it is based on Gaussian densities which, being unimodal, cannot represent simultaneous alternative hypotheses.  The Condensation algorithm uses "factored sampling", previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set.  Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time.  The result is highly robust tracking of agile motion.  Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.  Contents 1 Tracking curves in clutter 2 2 Discrete-time propagation of state density 3 3 Factored sampling 6 4 The Condensation algorithm 8 5 Stochastic dynamical models for curve motion 10 6 Observation model 13 7 Applying the Condensation algorithm to video-streams 17 8 Conclusions 26 A Non-linear filtering 31 B Derivation of the sampling rule 33 C Asymptotic correctness of the Condensation Algorithm 34 1 Tracking curves in clutter The purpose of this paper 1 is to establish a stochastic framework for tracking curves in visual clutter, using a sampling algorithm.  The approach is rooted in ideas from statistics, control theory and computer vision.  The problem is to track outlines and features of foreground objects, modelled as curves, as they move in substantial clutter, and to do it at, or close to, video frame-rate.  This is challenging because elements in the background clutter may mimic parts of foreground features.  In the most severe case of camouflage, the background may consist of objects similar to the foreground object, for instance when a person is moving past a crowd.  Our approach aims to dissolve the resulting ambiguity by applying probabilistic models of object shape and motion to analyse the video-stream.  The degree of generality of these models is pitched carefully: sufficiently specific for effective disambiguation but sufficiently general to be broadly applicable over entire classes of foreground objects.  1. 1 Modelling shape and motion Effective methods have arisen in computer vision for modelling shape and motion.  When suitable geometric models of a moving object are available, they can be matched effectively to image data, though usually at considerable computational cost (Hogg, 1983; Lowe, 1991; Sullivan, 1992; Huttenlocher et al. , 1993).  Once an object has been located approximately, tracking it in subsequent images becomes more efficient computationally (Lowe, 1992), especially if motion is modelled as well as shape (Gennery, 1992; Harris, 1992).  One important facility is the modelling of curve segments which interact with images (Fischler and Elschlager, 1973; Yuille and Hallinan, 1992) or image sequences (Kass et al. , 1987; Dickmanns and Graefe, 1988).  This is more general than modelling entire objects but more clutter-resistant than applying signalprocessing to low-level corners or edges.  The methods to be discussed here have been applied at this level, to segments of parametric B-spline curves (Bartels et al. , 1987) tracking over image sequences (Menet et al. , 1990; Cipolla and Blake, 1990).  The B-spline curves could, in theory, be parameterised by their control points.  In practice this allows too many degrees of freedom for stable tracking and it is necessary to restrict the curve to a low-dimensional parameter x, for example over an affine space (Koenderink and Van Doorn, 1991; Ullman and Basri, 1991; Blake et al. , 1993), or more generally allowing a "shape-space" of non-rigid motion (Cootes et al. , 1993).  Finally, prior probability densities can be defined over the curves (Cootes et al. , 1993) represented by appropriate parameter vectors x, and also over their motions (Terzopoulos and Metaxas, 1991; Blake et al. , 1993), and this constitutes a powerful facility for tracking.  Reasonable defaults can be chosen for those densities.  However, it is obviously more satisfactory to measure or estimate them from data-sequences (x 1 ; x 2 ; : : :).  Algorithms to do this, assuming Gaussian densities, are known in the control-theory literature (Goodwin and Sin, 1984) and have been applied in computer vision (Blake and Isard, 1994; Baumberg and Hogg, 1995).  Given the prior, and an observation density that characterises the statistical variability of image data z given a curve state x, a posterior distribution can, in principle, be estimated for x t given z t at successive times t.  1 This paper has appeared in short form (Isard and Blake, 1996) as joint winner of the prize of the European Conference on Computer Vision, 1996. 
A Smoothing Filter for CONDENSATION| Abstract.  Condensation, recently introduced in the computer vision literature, is a particle filtering algorithm which represents a tracked object's state using an entire probability distribution.  Clutter can cause the distribution to split temporarily into multiple peaks, each representing a different hypothesis about the object configuration.  When measurements become unambiguous again, all but one peak, corresponding to the true object position, die out.  While several peaks persist estimating the object position is problematic.  "Smoothing" in this context is the statistical technique of conditioning the state distribution on both past and future measurements once tracking is complete.  After smoothing, peaks corresponding to clutter are reduced, since their trajectories eventually die out.  The result can be a much improved state-estimate during ambiguous time-steps.  This paper implements two algorithms to smooth the output of a Condensation filter.  The techniques are derived from the work of Kitagawa, reinterpreted in the Condensation framework, and considerably simplified. 
B y| The analysis of visual motion against dense background clutter is a challenging problem.  Uncertainty in the positions of visually sensed features and ambiguity of feature correspondence call for a probabilistic treatment, capable of maintaining not simply a single estimate of position and shape but an entire distribution.  Exact representation of the evolving distribution is possible when the distributions are Gaussian and this yields some powerful approaches.  However normal distributions are limited when clutter is present: because of their unimodality, they cannot be used to represent simultaneous alternative hypotheses.  One powerful methodology for maintaining non-Gaussian distributions is based on random sampling techniques.  The effectiveness of "factored sampling" and ``Markov chain Monte Carlo" for interpretation of static images is widely accepted.  More recently, factored sampling has been combined with learned dynamical models to propagate probability distributions for object position and shape.  Progress in several areas is reported here.  First a new observational model is described that takes object opacity into account.  Secondly, complex shape models to represent combined rigid and nonrigid motion have been developed, together with a new algorithm to decompose rigid from nonrigid.  Lastly, more powerful dynamical prior models have been constructed by appending suitable discrete labels to a continuous system state; this may also have applications to gesture recognition. 
Bayesian Object Localisation in Images| Abstract A Bayesian approach to intensity-based object localisation is presented that employs a learned probabilistic model of image filter-bank output, applied via Monte Carlo methods, to escape the inefficiency of exhaustive search.  An adequate probabilistic account of image data requires intensities both in the foreground (ie over the object), and in the background, to be modelled.  Some previous approaches to object localisation by Monte Carlo methods have used models which, we claim, do not fully address the issue of the statistical independence of image intensities.  It is addressed here by applying to each image a bank of filters whose outputs are approximately statistically independent. 
Learning Multi-Class Dynamics| Abstract Standard techniques (eg.  Yule-Walker) are available for learning Auto-Regressive process models of simple, directly observable, dynamical processes.  When sensor noise means that dynamics are observed only approximately, learning can still been achieved via Expectation-Maximisation (EM) together with Kalman Filtering.  However, this does not handle more complex dynamics, involving multiple classes of motion.  For that problem, we show here how EM can be combined with the Condensation algorithm, which is based on propagation of random sample-sets.  Experiments have been performed with visually observed juggling, and plausible dynamical models are found to emerge from the learning process. 
Attractive People: Assembling Loose-Limbed Models using Non-parametric Belief Propagation| Abstract The detection and pose estimation of people in images and video is made challenging by the variability of human appearance, the complexity of natural scenes, and the high dimensionality of articulated body models.  To cope with these problems we represent the 3D human body as a graphical model in which the relationships between the body parts are represented by conditional probability distributions.  We formulate the pose estimation problem as one of probabilistic inference over a graphical model where the random variables correspond to the individual limb parameters (position and orientation).  Because the limbs are described by 6-dimensional vectors encoding pose in 3-space, discretization is impractical and the random variables in our model must be continuousvalued.  To approximate belief propagation in such a graph we exploit a recently introduced generalization of the particle filter.  This framework facilitates the automatic initialization of the body-model from low level cues and is robust to occlusion of body parts and scene clutter. 
Learning and Classification of Complex Dynamics|
Partitioned Sampling, Articulated Objects, and Interface-Quality Hand Tracking|
Learning to Track the Visual Motion of Contours|
Condensation - conditional density propogation for visual tracking|
Contour tracking by sotchastic propagation of conditional density|
BraMBLe: A Bayesian Multiple-Blob Tracker|
D position, attitude and shape input using video tracking of hands and lips|
Active contours: The application of techniques from graphics, vision, control theory and statistics to visual tracking of shapes in motion,|
Contour tracking by stochastic propogation of conditional density|
Statistical models of visual shape and motion|
Contour tracking by stochatic propagation of conditional density|
PAMPAS: Real-Valued Graphical Models for Computer Vision|
Visual Motion Analysis by Probabilistic Propagation of Conditional Density|
Object localisation by bayesian correlation|
Learning multiclass dynamics, in `Advances in Neural Information Processing Systems',|
Algorithmic issues in modeling motion|
Learnung multi-class dynamics|
Contour tracking by stochastic propagation of condition density," pp| 343-356. 
Bramble: A Bayesian multiple-blob tracker,|
BRAMBLE: A Bayesian multi-blob tracker|
