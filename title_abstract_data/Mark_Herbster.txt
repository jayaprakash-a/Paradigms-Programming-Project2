Tracking the Best Linear Predictor| Abstract In most on-line learning research the total on-line loss of the algorithm is compared to the total loss of the best off-line predictor u from a comparison class of predictors.  We call such bounds static bounds.  The interesting feature of these bounds is that they hold for an arbitrary sequence of examples.  Recently some work has been done where the predictor u t at each trial t is allowed to change with time, and the total on-line loss of the algorithm is compared to the sum of the losses of u t at each trial plus the total \cost" for shifting to successive predictors.  This is to model situations in which the examples change over time, and different predictors from the comparison class are best for different segments of the sequence of examples.  We call such bounds shifting bounds.  They hold for arbitrary sequences of examples and arbitrary sequences of predictors.  Naturally shifting bounds are much harder to prove.  The only known bounds are for the case when the comparison class consists of a sequences of experts or boolean disjunctions.  In this paper we develop the methodology for lifting known static bounds to the shifting case.  In particular we obtain bounds when the comparison class consists of linear neurons (linear combinations of experts).  Our essential technique is to project the hypothesis of the static algorithm at the end of each trial into a suitably chosen convex region.  This keeps the hypothesis of the algorithm well-behaved and the static bounds can be converted to shifting bounds. 
Tracking the Best Regressor \Lambda| Abstract In most of the on-line learning research the total on-line loss of the algorithm is compared to the total loss of the best off-line predictor u from a comparison class of predictors.  We call such bounds static bounds.  The interesting feature of these bounds is that they hold for an arbitrary sequence of examples.  Recently some work has been done where the comparison vector u t at each trial t is allowed to change with time, and the total online loss of the algorithm is compared to the sum of the losses of u t at each trial plus the total "cost" for shifting to successive comparison vectors.  This is to model situations in which the examples change over time and different predictors from the comparison class are best for different segments of the sequence of examples.  We call such bounds shifting bounds.  Shifting bounds still hold for arbitrary sequences of examples and also for arbitrary partitions.  The algorithm does not know the offline partition and the sequence of predictors that its performance is compared against.  Naturally shifting bounds are much harder to prove.  The only known bounds are for the case when the comparison class consists of a finite sets of experts or boolean disjunctions.  In this paper we develop the methodology for lifting known static bounds to the shifting case.  In particular we obtain bounds when the comparison class consists of linear neurons (linear combinations of experts).  Our essential technique consists of the following.  At the end of each trial we project the hypothesis of the static algorithm into a suitably chosen convex region.  This keeps the hypothesis of the algorithm well-behaved and the static bounds can be converted to shifting bounds so that the cost for shifting remains reasonable.  \Lambda The authors were supported by the NSF grant CCR-9700201. 
RNA Modeling Using Gibbs Sampling and Stochastic Context Free Grammars| Abstract A new method of discovering the common secondary structure of a family of homologous RNA sequences using Gibbs sampling and stochastic context-free grammars is proposed.  Given an unaligned set of sequences, a Gibbs sampling step simultaneously estimates the secondary structure of each sequence and a set of statistical parameters describing the common secondary structure of the set as a whole.  These parameters describe a statistical model of the family.  After the Gibbs sampling has produced a crude statistical model for the family, this model is translated into a stochastic context-free grammar, which is then refined by an Expectation Maximization (EM) procedure to produce a more complete model.  A prototype implementation of the method is tested on tRNA, pieces of 16S rRNA and on U5 snRNA with good results. 
Tracking the Best Expert|
Learning Additive Models Online with Fast Evaluating Kernels|
Tracking the Best Regressor|
