Variable Word Rate N-grams| ABSTRACT The rate of occurrence of words is not uniform but varies from document to document.  Despite this observation, parameters for conventional n-gram language models are usually derived using the assumption of a constant word rate.  In this paper we investigate the use of variable word rate assumption, modelled by a Poisson distribution or a continuous mixture of Poissons.  We present an approach to estimating the relative frequencies of words or ngrams taking prior information of their occurrences into account.  Discounting and smoothing schemes are also considered.  Using the Broadcast News task, the approach demonstrates a reduction of perplexity up to 10%. 
DYNAMIC BAYESIAN NETWORKS FOR MEETING STRUCTURING| ABSTRACT This paper is about the automatic structuring of multiparty meetings using audio information.  We have used a corpus of 53 meetings, recorded using a microphone array and lapel microphones for each participant.  The task was to segment meetings into a sequence of meeting actions, or phases.  We have adopted a statistical approach using dynamic Bayesian networks (DBNs).  Two DBN architectures were investigated: a two-level hidden Markov model (HMM) in which the acoustic observations were concatenated; and a multistream DBN in which two separate observation sequences were modelled.  Additionally we have also explored the use of counter variables to constrain the number of action transitions.  Experimental results indicate that the DBN architectures are an improvement over a simple baseline HMM, with the multistream DBN with counter constraints producing an action error rate of 6%. 
CONNECTIONIST PROBABILITY ESTIMATION IN THE DECIPHER SPEECH RECOGNITION SYSTEM| ABSTRACT Previously, we have demonstrated that feed-forward networks may be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems.  Here these connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker independent DARPA RM database.  Our results indicate that: .  connectionist probability estimation can improve performance of a context independent maximum likelihood trained HMM system, .  performance of the connectionist system is close to what can be achieved using (context dependent) HMM systems of much higher complexity, and .  mixing connectionist and maximum likelihood estimates can improve the performance of a state-of-theart context dependent HMM system. 
Evaluation of Extractive Voicemail Summarization| Abstract This paper is about the evaluation of a system that generates short text summaries of voicemail messages, suitable for transmission as text messages.  Our approach to summarization is based on a speech-recognized transcript of the voicemail message, from which a set of summary words is extracted.  The system uses a classifier to identify the summary words, with each word being identified by a vector of lexical and prosodic features.  The features are selected using Parcel, an ROC-based algorithm.  Our evaluations of the system, using a slot error rate metric, have compared manual and automatic summarization, and manual and automatic recognition (using two different recognizers).  We also report on two subjective evaluations using mean opinion score of summaries, and a set of comprehension tests.  The main results from these experiments were that the perceived difference in quality of summarization was affected more by errors resulting from automatic transcription, than by the automatic summarization process. 
MAXIMUM ENTROPY SEGMENTATION OF BROADCAST NEWS| ABSTRACT This paper presents an automatic system for structuring and preparing a news broadcast for applications such as speech summarization, browsing, archiving and information retrieval.  This process comprises transcribing the audio using an automatic speech recognizer and subsequently segmenting the text into utterances and topics.  A maximum entropy approach is used to build statistical models for both utterance and topic segmentation.  The experimental work addresses the effect on performance of the topic boundary detector of three factors: the information sources used, the quality of the ASR transcripts, and the quality of the utterance boundary detector.  The results show that the topic segmentation is not affected severely by transcripts errors, whereas errors in the utterance segmentation are more devastating. 
CONFIDENCE MEASURES FROM LOCAL POSTERIOR PROBABILITY ESTIMATES| Abstract In this paper we introduce a set of related confidence measures for large vocabulary continuous speech recognition (LVCSR) based on local phone posterior probability estimates output by an acceptor HMM acoustic model.  In addition to their computational efficiency, these confidence measures are attractive as they may be applied at the state-, phone-, word- or utterance-levels, potentially enabling discrimination between different causes of low confidence recognizer output, such as unclear acoustics or mismatched pronunciation models.  We have evaluated these confidence measures for utterance verification using a number of different metrics.  Experiments reveal several trends in `profitability of rejection', as measured by the unconditional error rate of a hypothesis test.  These trends suggest that crude pronunciation models can mask the relatively subtle reductions in confidence caused by out-of-vocabulary (OOV) words and disfluencies, but not the gross model mismatches elicited by non-speech sounds.  The observation that a purely acoustic confidence measure can provide improved performance over a measure based upon both acoustic and language model information for data drawn from the Broadcast News corpus, but not for data drawn from the North American Business News corpus suggests that the quality of model fit offered by a trigram language model is reduced for Broadcast News data.  We also argue that acoustic confidence measures may be used to inform the search for improved pronunciation models. 
EFFICIENT EVALUATION OF THE LVCSR SEARCH SPACE USING THE NOWAY DECODER| ABSTRACT This work further develops and analyses the large vocabulary continuous speech recognition (LVCSR) search strategy reported at ICASSP-95 [1].  In particular, the posteriorbased phone deactivation pruning approach has been extended to include phone-dependent thresholds and an improved estimate of the least upper bound on the utterance log-probability has been developed.  Analysis of the pruning procedures and of the search's interaction with the language model has also been performed.  Experiments were carried out using the ARPA North American Business News task with a 20,000 word vocabulary and a trigram language model.  As a result of these improvements and analyses, the computational cost of the recognition process performed by the noway decoder has been substantially reduced. 
Experimental Evaluation of Latent Variable Models for Dimensionality Reduction| Abstract We use electropalatographic (EPG) data as a test bed for dimensionality reduction methods based in latent variable modelling, in which an underlying lower dimension representation is inferred directly from the data.  Several models (and mixtures of them) are investigated, including factor analysis and the generative topographic mapping (GTM).  Experiments indicate that nonlinear latent variable modelling reveals a low-dimensional structure in the data inaccessible to the investigated linear models. 
TRANSCRIPTION AND SUMMARIZATION OF VOICEMAIL SPEECH| ABSTRACT This paper describes the development of a system to transcribe and summarize voicemail messages.  The results of the research presented in this paper are two-fold.  First, a hybrid connectionist approach to the Voicemail transcription task shows that competitive performance can be achieved using a context-independent system with fewer parameters than those based on mixtures of Gaussian likelihoods.  Second, an effective and robust combination of statistical with prior knowledge sources for term weighting is used to extract information from the decoder's output in order to deliver summaries to the message recipients via a GSM Short Message Service (SMS) gateway. 
Transcription of Conference Room Meetings: an Investigation| Abstract The automatic processing of speech collected in conference style meetings has attracted considerable interest with several large scale projects devoted to this area.  In this paper we explore the use of various meeting corpora for the purpose of automatic speech recognition.  In particular we investigate the similarity of these resources and how to efficiently use them in the construction of a meeting transcription system.  The analysis shows distinctive features for each resource.  However the benefit in pooling data and hence the similarity seems sufficient to speak of a generic "conference meeting domain".  In this context this paper also presents work on development for the AMI meeting transcription system, a joint effort by seven sites working on the AMI (augmented multi-party interaction) project. 
IMPROVING STATISTICAL SPEECH RECOGNITION| ABSTRACT In this paper we summarise the theory underlying our hybrid connectionist/HMM continuous speech recognition systems and report some recent experimental results and further theoretical developments.  Highlights include: 1.  Experimental results indicating that our connectionist methods can significantly improve the performance of a context independent HMM system (to a performance close to that of state of the art context dependent systems of much higher complexity); 2.  Experimental results demonstrating that a state of the art context dependent HMM system (SRI's DECIPHER) can be significantly improved by interpolating context independent connectionist probability estimates; 3.  The development of a principled network decomposition method that allows the efficient and parsimonious modelling of context-dependent phones, with no independence assumptions. 
PROBABILITY ESTIMATION BY FEED-FORWARD NETWORKS IN CONTINUOUS SPEECH RECOGNITION| Abstract: We review the use of feed-forward networks as estimators of probability densities in hidden Markov modelling.  In this paper we are mostly concerned with radial basis functions (RBF) networks.  We note the isomorphism of RBF networks to tied mixture density estimators; additionally we note that RBF networks are trained to estimate posteriors rather than the likelihoods estimated by tied mixture density estimators.  We show how the neural network training should be modified to resolve this mismatch.  We also discuss problems with discriminative training, particularly the problem of dealing with unlabelled training data and the mismatch between model and data priors. 
Automatic summarization of voicemail messages using lexical and prosodic features| Abstract This paper presents trainable methods for extracting principal content words from voicemail messages.  The short text summaries generated are suitable for mobile messaging applications.  The system uses a set of classifiers to identify the summary words, with each word being identified by a vector of lexical and prosodic features.  We use an ROC-based algorithm, Parcel, to select input features (and classifiers).  We have performed a series of objective and subjective evaluations using unseen data from two different speech recognition systems, as well as human transcriptions of voicemail speech. 
ACOUSTIC SPACE DIMENSIONALITY SELECTION AND COMBINATION USING THE MAXIMUM ENTROPY PRINCIPLE| ABSTRACT In this paper we propose a discriminative approach to acoustic space dimensionality selection based on maximum entropy modelling.  We form a set of constraints by composing the acoustic space with the space of phone classes, and use a continuous feature formulation of maximum entropy modelling to select an optimal feature set.  The suggested approach has two steps: (1) the selection of the best acoustic space that efficiently and economically represents the acoustic data and its variability; (2) the combination of selected acoustic features in the maximum entropy framework to estimate the posterior probabilities over the phonetic labels given the acoustic input.  Specific contributions of this paper include a parameter estimation algorithm (generalized improved iterative scaling) that enables the use of negative features, the parameterization of constraint functions using Gaussian mixture models, and experimental results using the TIMIT database. 
Information Extraction from Broadcast News| This paper discusses the development of trainable statistical models for extracting content from television and radio news broadcasts.  In particular we concentrate on statistical finite state models for identifying proper names and other named entities in broadcast speech.  Two models are presented: the first models name class information as a word attribute; the second explicitly models both word-word and class-class transitions.  A common n-gram based formulation is used for both models.  The task of named entity identification is characterized by relatively sparse training data and issues related to smoothing are discussed.  Experiments are reported using the DARPA/NIST Hub--4E evaluation for North American Broadcast News. 
RECENT IMPROVEMENTS TO THE ABBOT LARGE VOCABULARY CSR SYSTEM| ABSTRACT ABBOT is the hybrid connectionist-hidden Markov model (HMM) large-vocabulary continuous speech recognition (CSR) system developed at Cambridge University.  This system uses a recurrent network to estimate the acoustic observation probabilities within an HMM framework.  A major advantage of this approach is that good performance is achieved using context-independent acoustic models and requiring many fewer parameters than comparable HMM systems.  This paper presents substantial performance improvements gained from new approaches to connectionist model combination and phone-duration modeling.  Additional capability has also been achieved by extending the decoder to handle larger vocabulary tasks (20,000 words and greater) with a trigram language model.  This paper describes the recent modifications to the system and experimental results are reported for various test and development sets from the November 1992, 1993, and 1994 ARPA evaluations of spoken language systems. 
INTERNATIONAL COMPUTER SCIENCE INSTITUTE| Abstract We review the use of feed-forward networks as estimators of probability densities in hidden Markov modelling.  In this paper we are mostly concerned with radial basis functions (RBF) networks.  We note the isomorphism of RBF networks to tied mixture density estimators; additionally we note that RBF networks are trained to estimate posteriors rather than the likelihoods estimated by tied mixture density estimators.  We show how the neural network training should be modified to resolve this mismatch.  We also discuss problems with discriminative training, particularly the problem of dealing with unlabelled training data and the mismatch between model and data priors. 
THE THISL SYSTEM FOR INDEXING AND RETRIEVAL OF BROADCAST NEWS| Abstract - This paper describes the THISL news retrieval system which maintains an archive of BBC radio and television news recordings.  The system uses the Abbot large vocabulary continuous speech recognition system to transcribe news broadcasts, and the thislIR text retrieval system to index and access the transcripts.  Decoding and indexing is performed automatically, and the archive is updated with three hours of new material every day.  A web-based interface to the retrieval system has been devised to facilitate access to the archive. 
Start-Synchronous Search for Large Vocabulary Continuous Speech Recognition| Abstract In this paper, we present a novel, efficient search strategy for large vocabulary continuous speech recognition.  The search algorithm, based on a stack decoder framework, utilizes phone-level posterior probability estimates (produced by a connectionist/HMM acoustic model) as a basis for phone deactivation pruning --- a highly efficient method of reducing the required computation.  The single-pass algorithm is naturally factored into the time-asynchronous processing of the word sequence and the timesynchronous processing of the HMM state sequence.  This enables the search to be decoupled from the language model while still maintaining the computational benefits of time-synchronous processing.  The incorporation of the language model in the search is discussed and computationally cheap approximations to the full language model are introduced.  Experiments were performed on the North American Business News task using a 60,000 word vocabulary and a trigram language model.  Results indicate that the computational cost of the search may be reduced by more than a factor of 40 with a relative search error of less than 2% using the techniques discussed in the paper. 
A LATENT VARIABLE MODELLING APPROACH TO THE ACOUSTIC-TO-ARTICULATORY MAPPING PROBLEM| 2 2 #############################%########&#####(
ASR SYSTEM MODELING FOR AUTOMATIC EVALUATION AND OPTIMIZATION OF DIALOGUE SYSTEMS| ABSTRACT Though the field of spoken dialogue systems has developed quickly in the last decade, rapid design of dialogue strategies remains uneasy.  Several approaches to the problem of automatic strategy learning have been proposed and the use of Reinforcement Learning introduced by Levin and Pieraccini is becoming part of the state of the art in this area.  However, the quality of the strategy learned by the system depends on the definition of the optimization criterion and on the accuracy of the environment model.  In this paper, we propose to bring a model of an ASR system in the simulated environment in order to enhance the learned strategy.  To do so, we introduced recognition error rates and confidence levels produced by ASR systems in the optimization criterion. 
Multi-Stream Segmentation of Meetings| Abstract--- This paper investigates the automatic segmentation of meetings into a sequence of group actions or phases.  Our work is based on a corpus of multiparty meetings collected in a meeting room instrumented with video cameras, lapel microphones and a microphone array.  We have extracted a set of feature streams, in this case extracted from the audio data, based on speaker turns, prosody and a transcript of what was spoken.  We have related these signals to the higher level semantic categories via a multistream statistical model based on dynamic Bayesian networks (DBNs).  We report on a set of experiments in which different DBN architectures are compared, together with the different feature streams.  The resultant system has an action error rate of 9%. 
To appear: Proceedings of IEEE ICASSP, San| ABSTRACT Previously, we have demonstrated that feed-forward networks may be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems.  Here these connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker independent DARPA RM database.  Our results indicate that: .  connectionist probability estimation can improve performance of a context independent maximum likelihood trained HMM system, .  performance of the connectionist system is close to what can be achieved using (context dependent) HMM systems of much higher complexity, and .  mixing connectionist and maximum likelihood estimates can improve the performance of a state-of-theart context dependent HMM system. 
CONFIDENCE MEASURES FOR HYBRID HMM/ANN SPEECH RECOGNITION| ABSTRACT In this paper we introduce four acoustic confidence measures which are derived from the output of a hybrid HMM/ANN large vocabulary continuous speech recognition system.  These confidence measures, based on local posterior probability estimates computed by an ANN, are evaluated at both phone and word levels, using the North American Business News corpus. 
Multistream Dynamic Bayesian Network for Meeting Segmentation| Abstract.  This paper investigates the automatic analysis and segmentation of meetings.  A meeting is analysed in terms of individual behaviours and group interactions, in order to decompose each meeting in a sequence of relevant phases, named meeting actions.  Three feature families are extracted from multimodal recordings: prosody from individual lapel microphone signals, speaker activity from microphone array data and lexical features from textual transcripts.  A statistical approach is then used to relate low-level features with a set of abstract categories.  In order to provide a flexible and powerful framework, we have employed a dynamic Bayesian network based model, characterized by multiple stream processing and flexible state duration modelling.  Experimental results demonstrate the strength of this system, providing a meeting action error rate of 9%. 
Topic-Based Mixture Language Modelling| Abstract This paper describes an approach for constructing a mixture of language models based on simple statistical notions of semantics using probabilistic models developed for information retrieval.  The approach encapsulates corpus-derived semantic information and is able to model varying styles of text.  Using such information, the corpus texts are clustered in an unsupervised manner and a mixture of topic-specific language models is automatically created.  The principal contribution of this work is to characterise the document space resulting from information retrieval techniques and to demonstrate the approach for mixture language modelling.  A comparison is made between manual and automatic clustering in order to elucidate how the global content information is expressed in the space.  We also compare (in terms of association with manual clustering and language modelling accuracy) alternative term-weighting schemes and the effect of singular value decomposition dimension reduction (latent semantic analysis).  Test set perplexity results using the British National Corpus indicate that the approach can improve the potential of statistical language modelling.  Using an adaptive procedure, the conventional model may be tuned to track text data with a slight increase in computational cost. 
Speaker verification using sequence discriminant support vector machines| Abstract--- This paper presents a text-independent speaker verification system using support vector machines (SVMs) with score-space kernels.  Score-space kernels generalize Fisher kernels and are based on underlying generative models such as Gaussian mixture models (GMMs).  This approach provides direct discrimination between whole sequences, in contrast with the frame-level approaches at the heart of most current systems.  The resultant SVMs have a very high dimensionality since it is related to the number of parameters in the underlying generative model.  To address problems that arise in the resultant optimization we introduce a technique called spherical normalization that preconditions the Hessian matrix.  We have performed speaker verification experiments using the PolyVar database.  The SVM system presented here reduces the relative error rates by 34% compared to a GMM likelihood ratio system. 
INTEGRATED TRANSCRIPTION AND IDENTIFICATION OF NAMED ENTITIES IN BROADCAST SPEECH| ABSTRACT This paper presents an approach to integrating functions for both transcription and named entity (NE) identification into a large vocabulary continuous speech recognition system.  It builds on NE tagged language modelling approach, which was recently applied for development of the statistical NE annotation system.  We also present results for proper name identification experiment using the Hub-4 evaluation data. 
A LATENT VARIABLE MODELLING APPROACH TO THE ACOUSTIC-TO-ARTICULATORY MAPPING PROBLEM| ABSTRACT We present a latent variable approach to the acoustic-toarticulatory mapping problem, where different vocal tract configurations can give rise to the same acoustics.  In latent variable modelling, the combined acoustic and articulatory data are assumed to have been generated by an underlying low-dimensional process.  A parametric probabilistic model is estimated and mappings are derived from the respective conditional distributions.  This has the advantage over other methods, such as articulatory codebooks or neural networks, of directly addressing the nonuniqueness problem.  We demonstrate our approach with electropalatographic and acoustic data from the ACCOR database. 
THE 1994 ABBOT HYBRID CONNECTIONIST-HMM LARGE-VOCABULARY RECOGNITION SYSTEM| ABSTRACT ABBOT is the hybrid connectionist-hidden Markov model largevocabulary speech recognition system developed at Cambridge University.  In this system, a recurrent network maps each acoustic vector to an estimate of the posterior probabilities of the phone classes.  The maximum likelihood word string is then extracted using Markov models.  As in traditional hidden Markov models, the Markov process is used to model the lexical and language model constraints.  This paper describes the system which participated in the November 1994 ARPA evaluation of continuous speech recognition systems.  The emphasis of the paper is on the differences between the 1993 and 1994 versions of the ABBOT system.  This includes the utilization of a larger training corpus (SI284 versus SI84), the extension of the lexicon from 5,000 words to 65,000 words, the application of a trigram language model, and the development of a near-realtime single-pass decoder well suited for the hybrid approach.  Experimental results are reported for various test and development sets from the November 1992, 1993 and 1994 ARPA benchmark tests. 
SVMSVM: SUPPORT VECTOR MACHINE SPEAKER VERIFICATION METHODOLOGY| ABSTRACT Support vector machines with the Fisher and score-space kernels are used for text independent speaker verification to provide direct discrimination between complete utterances.  This is unlike approaches such as discriminatively trained Gaussian mixture models or other discriminative classifiers that discriminate at the frame-level only.  Using the sequence-level discrimination approach we are able to achieve error-rates that are significantly better than the current state-of-the-art on the PolyVar database. 
SPEAKER-ADAPTATION FOR HYBRID HMM-ANN CONTINUOUS SPEECH RECOGNITION SYSTEM| ABSTRACT It is well known that recognition performance degrades significantly when moving from a speakerdependent to a speaker-independent system.  Traditional hidden Markov model (HMM) systems have successfully applied speaker-adaptation approaches to reduce this degradation.  In this paper we presentandevaluate some techniques for speaker-adaptation of a hybrid HMM-artificial neural network (ANN) continuous speech recognition system.  These techniques are applied to a well trained, speaker-independent, hybrid HMM-ANN system and the recognizer parameters are adapted to a new speaker through off-line procedures.  The techniques are evaluated on the DARPA RM corpus using varying amounts of adaptation material and different ANN architectures.  The results showthat speaker-adaptation within the hybrid framework can substantially improve system performance. 
Sentence Boundary Detection in Broadcast Speech Transcripts| ABSTRACT This paper presents an approach to identifying sentence boundaries in broadcast speech transcripts.  We describe finite state models that extract sentence boundary information statistically from text and audio sources.  An # -gram language model is constructed from a collection of British English news broadcasts and scripts.  An alternative model is estimated from pause duration information in speech recogniser outputs aligned with their programme script counterparts.  Experimental results show that the pause duration model alone outperforms the language modelling approach and that, by combining these two models, it can be improved further and precision and recall scores of over 70% were attained for the task. 
ARE EXTRACTIVE TEXT SUMMARISATION TECHNIQUES PORTABLE TO BROADCAST NEWS?| ABSTRACT In this paper we report on a series of experiments which compare the effect of individual features on both text and speech summarisation, the effect of basing the speech summaries on automatic speech recognition transcripts with varying word error rates, and the effect of summarisation approach and transcript source on summary quality.  We show that classical text summarisation features (based on stylistic and content information) are portable to broadcast news.  However, the quality of the speech transcripts as well as the difference in information structure between broadcast and newspaper news affect the usability of the individual features. 
DECODER TECHNOLOGY FOR CONNECTIONIST LARGE VOCABULARY SPEECH RECOGNITION| Abstract The search problem in large vocabulary continuous speech recognition (LVCSR) is to locate the most probable string of words for a spoken utterance given the acoustic signal and a set of sentence models.  Searching the space of possible utterances is difficult because of the large vocabulary size and the complexity imposed when long-span language models are used.  This report describes an efficient search procedure and its software embodiment in a decoder, NOWAY, which has been incorporated in ABBOT, a hybrid connectionist/ hidden Markov model (HMM) LVCSR system [15].  The search algorithm is based on stack decoding and uses both likelihood- and posterior-based pruning.  The use of the posterior-based phone deactivation pruning techniques is well-suited to hybrid connectionist/HMM systems because posterior phone probabilities are directly computed by the connectionist acoustic model.  The single-pass decoder has been evaluate on the large vocabulary North American Business News task using a 20,000 word vocabulary and a trigram language model.  These results indicate that phone deactivation pruning increased the search speed by an order of magnitude while incurring 2% or less relative search error.  Using a pentium-based PC system, evaluation quality decoding (less than 3% relative search error) was available with execution speeds 2--5 times slower than realtime, and realtime decoding was available at the cost of 4--12% relative search error. 
NAMED ENTITY TAGGED LANGUAGE MODELS| ABSTRACT We introduce Named Entity (NE) Language Modelling, a stochastic finite state machine approach to identifying both words and NE categories from a stream of spoken data.  We provide an overview of our approach to NE tagged language model (LM) generation together with results of the application of such a LM to the task of out-of-vocabulary (OOV) word reduction in large vocabulary speech recognition.  Using the Wall Street Journal and Broadcast News corpora, it is shown that the tagged LM was able to reduce the overall word error rate by 14%, detecting up to 70% of previously OOV words.  We also describe an example of the direct tagging of spoken data with NE categories. 
BAYESIAN REGULARISATION METHODS IN A HYBRID MLP--HMM SYSTEM| ABSTRACT We have applied Bayesian regularisation methods to multi-layer perceptron (MLP) training in the context of a hybrid MLP-HMM (hidden Markov model) continuous speech recognition system.  The Bayesian framework adopted here allows an objective setting of the regularisation parameters, according to the training data.  Experiments were carried out on the ARPA Resource Management database. 
CONFIDENCE MEASURES FOR EVALUATING PRONUNCIATION MODELS| ABSTRACT In this paper, we investigate the use of confidence measures for the evaluation of pronunciation models and the employment of these evaluations in an automatic baseform learning process.  The confidence measures and
Retrieval Of Broadcast News Documents With the THISL System| ABSTRACT This paper describes a spoken document retrieval system, combining the ABBOT large vocabulary continuous speech recognition (LVCSR) system developed by Cambridge University, Sheffield University and SoftSound, and the PRISE information retrieval engine developed by NIST.  The system was constructed to enable us to participate in the TREC 6 Spoken Document Retrieval experimental evaluation.  Our key aims in this work were to produce a complete system for the SDR task, to investigate the effect of a word error rate of 30-50% on retrieval performance and to investigate the integration of LVCSR and word spotting in a retrieval task. 
Speech and Crosstalk Detection in Multichannel Audio| Abstract---The analysis of scenarios in which a number of microphones record the activity of speakers, such as in a round-table meeting, presents a number of computational challenges.  For example, if each participant wears a microphone, speech from both the microphone's wearer (local speech) and from other participants (crosstalk) is received.  The recorded audio can be broadly classified in four ways: local speech, crosstalk plus local speech, crosstalk alone and silence.  We describe two experiments related to the automatic classification of audio into these four classes.  The first experiment attempted to optimize a set of acoustic features for use with a Gaussian mixture model (GMM) classifier.  A large set of potential acoustic features were considered, some of which have been employed in previous studies.  The best-performing features were found to be kurtosis, "fundamentalness," and cross-correlation metrics.  The second experiment used these features to train an ergodic hidden Markov model classifier.  Tests performed on a large corpus of recorded meetings show classification accuracies of up to 96%, and automatic speech recognition performance close to that obtained using ground truth segmentation. 
Evaluating Automatic Summaries of Meeting Recordings| Abstract The research below explores schemes for evaluating automatic summaries of business meetings, using the ICSI Meeting Corpus (Janin et al. , 2003).  Both automatic and subjective evaluations were carried out, with a central interest being whether or not the two types of evaluations correlate with each other.  The evaluation metrics were used to compare and contrast differing approaches to automatic summarization, the deterioration of summary quality on ASR output versus manual transcripts, and to determine whether manual extracts are rated significantly higher than automatic extracts. 
Dimensionality Reduction of Electropalatographic Data Using Latent Variable Models| Abstract We consider the problem of obtaining a reduced dimension representation of electropalatographic (EPG) data.  An unsupervised learning approach based on latent variable modelling is adopted, in which an underlying lower dimension representation is inferred directly from the data.  Several latent variable models are investigated, including factor analysis and the generative topographic mapping (GTM).  Experiments were carried out using a subset of the EUR-ACCOR database, and the results indicate that these automatic methods capture important, adaptive structure in the EPG data.  Nonlinear latent variable modelling clearly outperforms the investigated linear models in terms of loglikelihood and reconstruction error and suggests a substantially smaller intrinsic dimensionality for the EPG data than that claimed by previous studies.  A two-dimensional representation is produced with applications to speech therapy, language learning and articulatory dynamics. 
EXPLORING THE STYLE-TECHNIQUE INTERACTION IN EXTRACTIVE SUMMARIZATION OF BROADCAST NEWS| ABSTRACT In this paper we seek to explore the interaction between the style of a broadcast news story and its summarization technique.  We report the performance of three different summarization techniques on broadcast news stories, which are split into planned speech and spontaneous speech.  The initial results indicate that some summarization techniques work better for the documents with spontaneous speech than for those with planned speech.  Even for human beings some documents are inherently difficult to summarize.  We observe this correlation between degree of difficulty in summarizing and performance of the three automatic summarizers.  Given the high frequency of named entities in broadcast news and even greater number of references to these named entities, we also gauge the effect of named entity and coreference resolution in a news story, on the performance of these summarizers. 
USING GAMMA FILTERS TO MODEL TEMPORAL DEPENDENCIES IN SPEECH| ABSTRACT Hybrid systems which use connectionist networks to estimate the output probabilities of a hidden Markov model represent time both at the network level and the Markov chain level.  In this paper we discuss modelling time in connectionist networks, and introduce local recurrences in a feed-forward network in the form of an adaptive gamma filter.  Using the Resource Management (RM) database, we have performed continuous speech recognition experiments comparing a gamma filtered input representation to a delay line.  We have also performed speaker adaptation experiments using the speaker-dependent RM database.  Our results have not indicated that gamma filters offer an appreciable modelling advantage on this task.  However, the baseline speaker adaptation experiments have indicated that supervised adaptation over 100 sentences reduced the word error by an average of 40%. 
EFFICIENT SEARCH USING POSTERIOR PHONE PROBABILITY ESTIMATES| ABSTRACT In this paper we present a novel, efficient search strategy for large vocabulary continuous speech recognition (LVCSR).  The search algorithm, based on stack decoding, uses posterior phone probability estimates to substantially increase its efficiency with minimal effect on accuracy.  In particular, the search space is dramatically reduced by phone deactivation pruning where phones with a small local posterior probability are deactivated.  This approach is particularly well-suited to hybrid connectionist/hidden Markov model systems because posterior phone probabilities are directly computed by the acoustic model.  On large vocabulary tasks, using a trigram language model, this increased the search speed by an order of magnitude, with 2% or less relative search error.  Results from a hybrid system are presented using the Wall Street Journal LVCSR database for a 20,000 word task using a backed-off trigram languagemodel.  For this task, our single-pass decodertook around 15realtime on an HP735 workstation.  At the cost of 7% relative search error, decoding time can be speeded up to approximately realtime. 
(will be inserted by the editor) Accessing the Spoken Word| conversations.  The collection, access and preservation of such data is stimulated by political, economic, cultural and educational needs.  This paper outlines the major issues in the field, reviews the current state of technology, examines the rapidly changing policy issues relating to privacy and copyright, and presents issues relating to the collection and preservation of spoken audio content. 
The THISL SDR System At TREC-8| ABSTRACT This paper describes the participation of the THISL group at the TREC-8 Spoken Document Retrieval (SDR) track.  The THISL SDR system consists of the realtime version of the ABBOT large vocabulary speech recognition system and the THISLIR text retrieval system.  The TREC-8 evaluation assessed SDR performance on a corpus of 500 hours of broadcast news material collected over a five month period.  The main test condition involved retrieval of stories defined by manual segmentation of the corpus in which non-news material, such as commercials, were excluded.  An optional test condition required required retrieval of the same stories from the unsegmented audio stream.  The THISL SDR system participated at both test conditions.  The results show that a system such as THISL can produce respectable information retrieval performance on a realistically-sized corpus of unsegmented audio material. 
An Advanced Integrated Architecture for Wireless Voicemail Data Retrieval| Abstract This paper describes an alternative architecture for voicemail data retrieval on the move.  It is comprised of three distinct components: a speech recognizer, a text summarizer and a WAP Push Service initiator, enabling mobile users to receive text summaries of their voicemail in realtime without an explicit request.  Our approach overcomes the cost and usability limitations of the conventional voicemail retrieval paradigm which requires a connection establishment in order to listen to spoken messages.  We report performance results on all different components of the system that has been trained and tested on a database containing 1843 North American English messages as well as on the duration of the corresponding data path.  The proposed architecture can be further customized to meet the requirements of a complete voicemail value-added service. 
The Role of Prosody in a Voicemail Summarization System| Abstract When a speaker leaves a voicemail message there are prosodic cues that emphasize the important points in the message, in addition to lexical content.  In this paper we compare and visualize the relative contribution of these two types of features within a voicemail summarization system.  We describe the system's ability to generate summaries of two test sets, having trained and validated using 700 messages from the IBM Voicemail corpus.  Results measuring the quality of summary artifacts show that combined lexical and prosodic features are at least as robust as combined lexical features alone across all operating conditions. 
The THISL Spoken Document Retrieval Project| ABSTRACT THISL is an ESPRIT Long Term Research Project focused the development and construction of a system to items from an archive of television and radio news broadcasts.  In this paper we outline our spoken document retrieval system based on the ABBOT speech recognizer and a text retrieval system based on Okapi term-weighting .  The system has been evaluated as part of the TREC-6 and TREC-7 spoken document retrieval evaluations and we report on the results of the TREC-7 evaluation based on a document collection of 100 hours of North American broadcast news. 
Applying Vocal Tract Length Normalization to Meeting Recordings| Abstract Vocal Tract Length Normalisation (VTLN) is a commonly used technique to normalise for inter-speaker variability.  It is based on the speaker-specific warping of the frequency axis, parameterised by a scalar warp factor.  This factor is typically estimated using maximum likelihood.  We discuss how VTLN may be applied to multiparty conversations, reporting a substantial decrease in word error rate in experiments using the ICSI meetings corpus.  We investigate the behaviour of the VTLN warping factor and show that a stable estimate is not obtained.  Instead it appears to be influenced by the context of the meeting, in particular the current conversational partner.  These results are consistent with predictions made by the psycholinguistic interactive alignment account of dialogue, when applied at the acoustic and phonological levels. 
STATISTICAL ANNOTATION OF NAMED ENTITIES IN SPOKEN AUDIO| ABSTRACT In this paper we describe stochastic finite state model for named entity (NE) identification, based on explicit word-level n-gram relations.  NE categories are incorporated in the model as word attributes.  We present an overview of the approach, describing how the extensible vocabulary model may be used for NE identification.  We report development and evaluation results on a North American Broadcast News task.  This approach resulted in average precision and recall scores of around 83% on hand transcribed data, and 73% on the SPRACH recogniser output.  We also present an error analysis and a comparison of our approach with an alternative statistical approach. 
EVALUATION OF KERNEL METHODS FOR SPEAKER VERIFICATION AND IDENTIFICATION| ABSTRACT Support vector machines are evaluated on speaker verification and speaker identification tasks.  We compare the polynomial kernel, the Fisher kernel, a likelihood ratio kernel and the pair hidden Markov model kernel with baseline systems based on a discriminative polynomial classifier and generative Gaussian mixture model classifiers.  Simulations were carried out on the YOHO database and some promising results were obtained. 
Extractive Summarization of Voicemail using Lexical and Prosodic Feature Subset Selection| Abstract This paper presents a novel data-driven approach to summarizing spoken audio transcripts utilizing lexical and prosodic features.  The former are obtained from a speech recognizer and the latter are extracted automatically from speech waveforms.  We employ a feature subset selection algorithm, based on ROC curves, which examines different combinations of features at different target operating conditions.  The approach is evaluated on the IBM Voicemail corpus, demonstrating that it is possible and desirable to avoid complete commitment to a single best classifier or feature set. 
A Hybrid MaxEnt/HMM based ASR System| Abstract The aim of this work is to develop a practical framework, which extends the classical Hidden Markov Models (HMM) for continuous speech recognition based on the Maximum Entropy (MaxEnt) principle.  The MaxEnt models can estimate the posterior probabilities directly as with Hybrid NN/HMM connectionist speech recognition systems.  In particular, a new acoustic modelling based on discriminative MaxEnt models is formulated and is being developed to replace the generative Gaussian Mixture Models (GMM) commonly used to model acoustic variability.  Initial experimental results using the TIMIT phone task are reported. 
Indexing and retrieval of broadcast news| Precision and recall results using the Text Retrieval Conference (TREC) SDR evaluation infrastructure are reported throughout the paper, and we discuss the application of these developments to a large scale SDR task based on an archive of British English broadcast news.  2000 Elsevier Science B. V.  All rights reserved. 
Phone deactivation pruning in large vocabulary continuous speech recognition| Abstract In this letter we introduce a new pruning strategy for large vocabulary continuous speech recognition based on direct estimates of local posterior phone probabilities.  This approach is well suited to hybrid connectionist/hidden Markov model systems.  Experiments on the Wall Street Journal task using a 20,000 word vocabulary and a trigram language model have demonstrated that phone deactivation pruning can increase the speed of recognition-time search by up to a factor of 10, with a relative increase in error rate of less than 2%. 
) indicating how well an input acoustic signal matches a speech model of the hypothesised utterance| A fundamental problem in speech recognition is how this score may be computed, 159. 
Practical Identifiability of Finite Mixtures of Multivariate Bernoulli Distributions| Abstract The class of finite mixtures of multivariate Bernoulli distributions is known to be
DOCUMENT SPACE MODELS USING LATENT SEMANTIC ANALYSIS| ABSTRACT In this paper, an approach for constructing mixture language models (LMs) based on some notion of semantics is discussed.  To this end, a technique known as latent semantic analysis (LSA) is used.  The approach encapsulates corpus-derived semantic information and is able to model the varying style of the text.  Using such information, the corpus texts are clustered in an unsupervised manner and mixture LMs are automatically created.  This work builds on previous work in the field of information retrieval which was recently applied by Bellegarda et.  al.  to the problem of clustering words by semantic categories.  The principal contribution of this work is to characterize the document space resulting from the LSA modeling and to demonstrate the approach for mixture LM application.  Comparison is made between manual and automatic clustering in order to elucidate how the semantic information is expressed in the space.  It is shown that, using semantic information, mixture LMs performs better than a conventional single LM with slight increase of computational cost. 
CONFIDENCE MEASURES DERIVED FROM AN ACCEPTOR HMM| ABSTRACT In this paper we define a number of confidence measures derived from an acceptor HMM and evaluate their performance for the task of utterance verification using the North American Business News (NAB) and Broadcast News (BN) corpora.  Results are presented for decodings made at both the word and phone level which show the relative profitability of rejection provided by the diverse set of confidence measures.  The results indicate that language model dependent confidence measures have reduced performance on BN data relative to that for the more grammatically constrained NAB data.  An explanation linking the observations that rejection is more profitable for noisy acoustics, for a reduced vocabulary and at the phone level is also given. 
THE 1995 ABBOT LVCSR SYSTEM FOR MULTIPLE UNKNOWN MICROPHONES| ABSTRACT ABBOT is the hybrid connectionist-hidden Markov model largevocabulary speech recognition system developed at Cambridge University.  In this system, a recurrent network maps each acoustic vector to an estimate of the posterior probabilities of the phone classes, which are used as observation probabilities within an HMM.  This paper describes the system which participated in the November 1995 ARPA Hub-3 Multiple Unknown Microphones (MUM) evaluation of continuous speech recognition systems, under the guise of the CU-CON system.  The emphasis of the paper is on the changes made to the 1994 ABBOT system, specifically to accomodate the H3 task.  This includes improved acoustic modelling using limited word-internal context-dependentmodels, training on the Wall Street Journal secondary channel database, and using the linear input network for speaker and environmental adaptation.  Experimental results are reported for various test and development sets from the November 1994 and 1995 ARPA benchmark tests. 
Extractive Summarization of Meeting Recordings| Abstract Several approaches to automatic speech summarization are discussed below, using the ICSI Meetings corpus.  We contrast feature-based approaches using prosodic and lexical features with maximal marginal relevance and latent semantic analysis approaches to summarization.  While the latter two techniques are borrowed directly from the field of text summarization, feature-based approaches using prosodic information are able to utilize characteristics unique to speech data.  We also investigate how the summarization results might deteriorate when carried out on ASR output as opposed to manual transcripts.  All of the summaries are of an extractive variety, and are compared using the software ROUGE. 
An Overview of the SPRACH System for the Transcription of Broadcast News| ABSTRACT This paper describes the SPRACH system developed for the 1998 Hub-4E broadcast news evaluation.  The system is based on the connectionist-HMM framework and uses both recurrent neural network and multi-layer perceptron acoustic models.  We describe both a system designed for the primary transcription hub, and a system for the less-than 10 times real-time spoke.  We then describe recent developments to CHRONOS, a time-first stack decoder.  We show how these developments have simplified the evaluation system, and led to significant reductions in the error rate of the 10x real-time system.  We also present a system designed to operate in real-time with negligible search error. 
Connectionist Probability Estimators in HMM Speech Recognition| Resource Management database.  In conclusion, we show that a connectionist component improves a state-of-the-art HMM system. 
The use of recurrent networks in continuous speech recognition|
and Herv'e Bourlard| Probability estimation by feed-forward networks in continuous speech recognition. 
A Neural Network Based, Speaker Independent, Large Vocabulary, Continuous Speech Recognition System:|
THISL spoken document retrieval|
The use of recurrent neural networks in continuous speech recognition|
Training recurrent networks|
Radial basis function network for speech pattern classification,|
Connectionist speech recognition|
The SPRACH system for the transcription of broadcast news,|
A British English speech corpus for large vocabulary continuous speech recognition,|
Connectionist model combination for large vocabulary speech recognition,|
Large vocabulary continuous speech recognition using a hybrid connectionist--HMM system|
IPA: Improved phone modelling with recurrent neural networks|
Learning Temporal Dependencies in Connectionist Speech Recognition|
A study of network dynamics|
Information Extraction from Broadcast News| Philosophical Transactions of the Royal Society of London, Series A: Mathematical,. 
Connectionist Probability Estimation in HMM Speech Recognition|
A comparative study of continuous speech recognition using neural networks and hidden Markov models|
CDNN: a context dependent neural network for continuous speech recognition,|
Connectionist Optimisation of Tied Mixture Hidden Markov Models|
Phoneme Classification Experiments Using Radial Basis Functions|
ABBOT: The CUED Hybrid ConnectionistHMM Large-Vocabulary Recognition System, in `Spoken Language Systems Technology Workshop',|
Hybrid Neural Network/Hidden Markov Model Systems for Continuous Speech Recognition|
Efficient Evaluation of the LVCSR Search Space Using|
The THISL Spoken Document Retrieval System|
Confidence measures from local posterior estimate",|
Herv#e|
Chaos in Neural Networks|
Information Extraction from Broadcast News|
Connectionist speech recognition: Status and prospects|
The 1995 ABBOT LVCSR System|
Audio information access from meeting rooms,|
The 1995 Hybrid Connectionist-HMM Large-Vocabulary Recognition System|
ABBOT LVCSR System for Multiple Unknown Microphones|
Noway's manual page| University of Cambridge. 
Estimation of Global Posteriors and Forward-Backward Training of Hybrid Systems,|
Neural nets and hidden markov models: Review and generalizations,|
An investigation into transcription of conference room meetings,|
Baseline IE-|
The 1994 ABBOT Hybrid Connectionist-HMM Large Vocabulary Recognition System,Spoken Language Systems Technology Wokshop,|
Named entity tagged language models for LVCSR|
Start-Synchronous Search for LVCSR,|
Automatic Speech and Speaker recognition--Advanced Topics, ch| The use of recurrent networks in continuous speech recognition, chapter 10,. 
Sentence Boundary Detection in Broadcast Speech Transcripts| 2000. 
Recognition, Indexing and Retrieval of British Broadcast News with the THISL System|
Bayesian Regularisation Methods in a Hybrid MLP-|
The use of recurrent networks in continuos speech reognition|
Retrieval of Broadcast News with the THISL System',|
From Text Summarisation to Style-Specific Summarisation for Broadcast News|
