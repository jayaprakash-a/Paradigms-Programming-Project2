Face recognition using a hybrid supervised/unsupervised neural network| Abstract A system for automatic face recognition is presented.  It consists of several steps; Automatic detection of the eyes and mouth is followed by a spatial normalization of the images.  The classification of the normalized images is carried out by a hybrid (supervised and unsupervised) Neural Network.  Two methods for reducing the overfitting -- a common problem in high dimensional classification schemes -- are presented, and the superiority of their combination is demonstrated. 
Receptive Field Formation in Natural Scene Environments: Comparison of Single Cell Learning Rules| Abstract We study several statistically and biologically motivated learning rules using the same
Towards structural systematicity in distributed, statically bound visual representations| Abstract The problem of representing the spatial structure of images, which arises in visual object processing,
A SPECIAL SKELETONIZATION ALGORITHM FOR CURSIVE WORDS| We present a novel approach for finding a pseudo-skeleton of a cursive word's image.  This pseudo-skeleton preserves all the necessary components of a cursive word such as: loops, curves, junctions, end-points etc.  It is expected to be useful for cursive word recognition. 
3D Object Recognition Using Unsupervised Feature Extraction| Abstract Intrator (1990) proposed a feature extraction method that is related to recent statistical theory (Huber, 1985; Friedman, 1987), and is based on a biologically motivated model of neuronal plasticity (Bienenstock et al. , 1982).  This method has been recently applied to feature extraction in the context of recognizing 3D objects from single 2D views (Intrator and Gold, 1991).  Here we describe experiments designed to analyze the nature of the extracted features, and their relevance to the theory and psychophysics of object recognition. 
Computational models of perceptual learning| Abstract In visual perception, learning is a pervasive phenomenon, which, when properly studied, may offer valuable insights into the inner workings of the brain.  We outline a theoretical framework for the computational study of perceptual learning, aiming to make the relationships among the existing models more readily apparent, and to identify promising directions for future research. 
Learning as extraction of low-dimensional representations| Abstract Psychophysical findings accumulated over the past several decades indicate that perceptual
Face Detection by Direct Convexity Estimation| Abstract We suggest a novel attentional mechanism for detection of smooth convex and concave objects based on direct processing of intensity values.  The operator detects the regions of the eyes and hair in a facial image, and thus allows us to infer the face location and scale.  Our operator is robust to variations in illumination, scale, and face orientation.  Invariance to a large family of functions, serving for lighting improvement in images, is proved.  An extensive comparison with edge-based methods is delineated. 
A Productive, Systematic Framework for the Representation of Visual Structure| Abstract We describe a unified framework for the understanding of structure representation in primate vision.  A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common "middle-scale" parts, represented as image fragments.  The model addresses the same concerns as previous work on compositional representation through the use of what+where receptive fields and attentional gain modulation.  It does not require prior exposure to the individual parts, and avoids the need for abstract symbolic binding.  1 The problem of structure representation The focus of theoretical discussion in visual object processing has recently started to shift from problems of recognition and categorization to the representation of object structure.  Although view- or appearance-based solutions for these problems proved effective on a variety of object classes [1], the "holistic" nature of this approach -- the lack of explicit representation of relational structure -- limits its appeal as a general framework for visual representation [2].  The main challenges in the processing of structure are productivity and systematicity, two traits commonly attributed to human cognition.  A visual system is productive if it is openended, that is, if it can deal effectively with a potentially infinite set of objects.  A visual representation is systematic if a well-defined change in the spatial configuration of the object (e. g. , swapping top and bottom parts) causes a principled change in the representation (e. g. , the interchange of the representations of top and bottom parts [3, 2]).  A solution commonly offered to the twin problems of productivity and systematicity is compositional representation, in which symbols standing for generic parts drawn from a small repertoire are bound together by categorical symbolically coded relations [4].  2 The Chorus of Fragments In visual representation, the need for symbolic binding may be alleviated by using location in the visual field in lieu of the abstract frame that encodes object structure.  Intuitively, the constituents of the object are then bound to each other by virtue of residing in their proper places in the visual field; this can be thought of as a pegboard, whose spatial structure supports the arrangement of parts suspended from its pegs.  This scheme exhibits shallow compositionality, which can be enhanced by allowing the "pegboard" mechanism to operate at different spatial scales, yielding effective systematicity across levels of resolution.  Coarse coding the constituents (e. g. , representing each object fragment in terms of its similarities to some basis shapes) will render the scheme productive.  We call this approach to the representation of structure the Chorus of Fragments (CoF; [5]). 
Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI| Abstract Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal fibers delineation.  Here we show a modification for DT-MRI that allows delineation of neuronal fibers which are infiltrated by edema.  We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and fits it to the signal attenuation with a variational regularization mechanism.  In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment.  The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions.  By using the variational framework we were able to overcome the highly ill posed fitting.  The results show that we were able to find fibers that were not found by DT-MRI. 
Receptive field formation in natural scene environments: comparison of kurtosis, skewness, and the quadratic form of BCM| Abstract We study several statistically and biologically motivated learning rules using the same visual environment and neuronal architecture.  This allows us to concentrate on the feature extraction and neuronal coding properties of these rules.  We find that the quadratic form of the BCM rule behaves in a manner similar to a kurtosis maximization rule when the distribution contains kurtotic directions, although the BCM modification equations are computationally simpler. 
Unsupervised Learning of Visual Structure| acquisition of spatially localized features that can support systematic treatment of structured objects [1].  1 A paradox and some ways of resolving it It is logically impossible to form a principled structural description of a visual scene without prior knowledge of related scenes.  Adapting an observation made by R.  A.  Fisher, such knowledge must, in the first instance, be statistical.  Several recent studies indeed showed that subjects are capable of unsupervised acquisition of statistical regularities (e. g. , conditional probabilities of constituents) that can support structural interpretation of novel scenes composed of a few simple objects [2, 3].  Theoretical understanding of unsupervised statistical learning is, however, hindered by a paradox perceived as "monstrous and unmeaning" already in the Socratic epistemology: statistics can only be computed over a set of candidate primitive descriptors if these are identified in advance, yet the identification of the candidates requires prior statistical data (cf.  [4]).  1 Figure 1 illustrates the paradox at hand in the context of scene interpretation.  To decide whether the image on the left is better seen as containing horses (and riders) rather than centaurs requires tracking the representational utility of horse over a sequence of images.  But for that one must have already acquired the notion of horse --- an undertaking that we aimed to alleviate in the first place, by running statistics over multiple stimuli.  In what follows, we describe a way of breaking out of this vicious circle, suggested by computational and neurobiological considerations.  Fig.  1.  An intuitive illustration of the fundamental problem of unsupervised discovery of the structural units best suited for describing a visual scene (cf.  Left).  Is the being in the forefront of this picture integral or composite? The visual system of the Native Americans, who in their first encounter reportedly perceived mounted Spaniards as centaur-like creatures (cf.  [5], p. 127), presumably acted on a principle that prescribes an integral interpretation, in the absence of evidence to the contrary.  A sophisticated visual system should perceive such evidence in the appearance of certain candidate units in multiple contexts (cf.  Middle, where the conquistadors are seen dismounted).  Units should not have to appear in isolation (Right) to be seen as independent.  1. 1 Computational considerations The choice of primitives or features in terms of which composite objects and their structure are to be described is the central issue at the intersection of high-level vision and computational learning theory.  Studies of unsupervised feature extraction (see e. g.  [6] for a review) typically concentrate on the need for supporting recognition, that is, telling objects apart.  Here, we are concerned with the complementary need --- seeking to capture commonalities between objects --which stems from the coupled constraints of making explicit object structure, as per the principle of systematicity [1], and maintaining representational economy, as per the Minimum Description Length (MDL) principle [7].  One biologically relevant representational framework that aims for systematicity while observing parsimony is the Chorus of Fragments (CoF [8, 1]).  In the CoF model, the graded responses of "what+where" cells [9, 10] coarsely tuned both to shape and to location form a distributed representation of stimulus structure.  In this paper, we describe a method for unsupervised acquisition of "what+where" receptive fields from examples. 
Skew Detection via Principal Components Analysis| Abstract Skew detection via principal components is proposed as an effective method for images which contain other parts than text.  It is shown that the negative of the image leads to much more robust results, and that the computation time involved is still practical.  This method is also shown to be effective for single word skew detection. 
Unsupervised statistical learning in vision: computational principles, biological evidence| Abstract Unsupervised statistical learning is the standard setting for the development of the only advanced visual system that is both highly sophisticated and versatile, and extensively studied: that of monkeys and humans.  In this extended abstract, we invoke philosophical observations, computational arguments, behavioral data and neurobiological findings to explain why computer vision researchers should care about (1) unsupervised learning, (2) statistical inference, and (3) the visual brain.  We then outline a neuromorphic approach to structural primitive learning motivated by these considerations, survey a range of neurobiological findings and behavioral data consistent with it, and conclude by mentioning some of the more challenging directions for future research.  1 Why computer vision should care about unsupervised learning As the goals of computer vision grow more ambitious, the importance of learning becomes more difficult to deny: nobody wants to have to enter object and scene representations into his or her system by hand.  But why should we insist that such learning be, in the first instance, unsupervised? Because we should not trust our analytical intuitions about the ontology of visual objects.  Although the increasing availability of annotated image databases encourages the development of highly sophisticated supervised learning methods that combine linguistic and visual information (Duygulu et al. , 2002), the success of such methods is limited by the poverty of the annotations, usually lexical labels.  Indeed, a label (such as {cat, forest, grass, tiger}, shown in the work just cited) attached to a picture is both ontologically deficient in that it leaves out a host of possible complementary or alternative labels (Akins, 1996; Smith, 2001), and descriptively deficient in that it falls far short of providing a listener with a clear notion of the scene depicted (Kitcher and Varzi, 2000; Edelman, 2002). 
Global Optimization of RBF Networks| Abstract Several modifications to parameter estimation in a Radial Basis Functions network are introduced.  These include a better initializing clustering algorithm and a full gradient descent on centers and weights after weights were found via a matrix inversion.  Performance comparison with other RBF algorithms is given on several data-sets.  It is found that The proposed method was found superior to Bishop's EM training algorithm, to Orr's method [1] for as well as a conventional implementation. 
OFF-LINE CURSIVE SCRIPT WORD RECOGNITION -A SURVEY| Abstract We review the field of off-line cursive word recognition.  We mainly deal with the various methods that were proposed to realize the core of recognition in a word recognition system.  These methods are discussed in view of the two most important properties of such a system: the size and nature of the lexicon involved, and whether or not a segmentation stage is present.  We classify the field to three categories.  Segmentationfree methods, which compare a sequence of observations derived from a word image with similar references of words in the lexicon.  Segmentation-based methods, that look for the best match between consecutive sequences of primitive segments and letters of a possible word.  Perception-oriented approach, that relates to methods that perform a human-like reading technique, in which anchor features found all-over the word are used to boot-strap a few candidates for a final evaluation phase. 
Optimal Ensemble Averaging of Neural Networks| Abstract Based on an observation about the different effect of ensemble averaging on the bias and variance portion of the prediction error, we discuss training methodologies for ensembles of networks.  We demonstrate the effect of variance reduction and present a method of extrapolation to the limit of an infinite ensemble.  A significant reduction of variance is obtained by averaging just over initial conditions of the neural networks, without varying architectures or training sets.  The minimum of the ensemble prediction error is reached later than that of a single network.  In the vicinity of the minimum, the ensemble prediction error appears to be flatter than that of the single network, thus simplifying optimal stopping decision.  The results are demonstrated on the sunspots data, where the predictions are among the best obtained, and on the 1993 energy prediction competition data-set B. 
Probabilistic principles in unsupervised learning of visual structure: human data and a model| Abstract To find out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the conditional probabilities of the constituent fragments, and (2) the value of Barlow's criterion of "suspicious coincidence" (the ratio of joint probability to the product of marginals).  We then compared the part verification response times for various probe/target combinations before and after the exposure.  For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not.  This effect was modulated by the significance of their co-occurrence as estimated by Barlow's criterion.  For lone-fragment probes, the speedup in all conditions was generally lower than for composites.  These results shed light on the brain's strategies for unsupervised acquisition of structural information in vision.  1 Motivation How does the human visual system decide for which objects it should maintain distinct and persistent internal representations of the kind typically postulated by theories of object recognition? Consider, for example, the image shown in Figure 1, left.  This image can be represented as a monolithic hieroglyph, a pair of Chinese characters (which we shall refer to as A and B), a set of strokes, or, trivially, as a collection of pixels.  Note that the second option is only available to a system previously exposed to various combinations of Chinese characters.  Indeed, a principled decision whether to represent this image as fABg, fA; Bg or otherwise can only be made on the basis of prior exposure to related images.  According to Barlow's [1] insight, one useful principle is tallying suspicious coincidences: two candidate fragments A and B should be combined into a composite object AB if the probability of their joint appearance P (A; B) is much higher than P (A)P (B), which is the probability expected in the case of their statistical independence.  This criterion may be compared to the Minimum Description Length (MDL) principle, which has been previously discussed in the context of object representation [2, 3].  In a simplified form [4], MDL calls for representing AB explicitly as a whole if P (A; B) # P (A)P (B), just as the principle of suspicious coincidences does.  While the Barlow/MDL criterion r : = P (A; B)= (P (A)P (B)) certainly indicates a suspicious coincidence, there are additional probabilistic considerations that may be used in setting the degree of association between A and B.  One example is the possible perfect predictability of A from B and vice versa, as measured by minCP : = min fP (AjB); P (BjA)g.  If minCP = 1, then A and B are perfectly predictive of each other and should really be coded by a single symbol, whereas the MDL criterion may suggest merely that some association between the representation of A and that of B be established.  In comparison, if A and B are not perfectly predictive of each other (minCP < 1), there is a case to be made in favor of coding them separately to allow for a maximally expressive representation, whereas MDL may actually suggest a high degree of association (if r = P (A; B)= (P (A)P (B)) # 1).  In this study we investigated whether the human visual system uses a criterion based on minCP alongside MDL while learning (in an unsupervised manner) to represent composite objects.  AB Figure 1: Left: how many objects are contained in image AB? Without prior knowledge, a reasonable answer, which embodies a holistic bias, should be "one" (Gestalt effects, which would suggest two convex "blobs" [5], are beyond the scope of the present discussion).  Right: in this set of ten images, AB appears five times as a whole; the other five times a fragment wholly contained in AB appears in isolation.  This statistical fact provides grounds for considering AB to be composite, consisting of two fragments (call the upper one A and the lower one B), because P (AjB) = 1, but P (BjA) = 0:5 < 1.  To date, psychophysical explorations of the sensitivity of human subjects to stimulus statistics tended to concentrate on means (and sometimes variances) of the frequency of various stimuli (e. g. , [6].  One recent and notable exception is the work of Saffran et al.  [7], who showed that infants (and adults) can distinguish between "words" (stable pairs of syllables that recur in a continuous auditory stimulus stream) and non-words (syllables accidentally paired with each other, the first of which comes from one "word" and the second -- from the following one).  Thus, subjects can sense (and act upon) differences in transition probabilities between successive auditory stimuli.  This finding has been recently replicated, with infants as young as 2 months, in the visual sequence domain, using successive presentation of simple geometric shapes with controlled transition probabilities [8].  Also in the visual domain, Fiser and Aslin [9] presented subjects with geometrical shapes in various spatial configurations, and found effects of conditional probabilities of shape co-occurrences, in a task that required the subjects to decide in each trial which of two simultaneously presented shapes was more familiar.  The present study was undertaken to investigate the relevance of the various notions of statistical independence to the unsupervised learning of complex visual stimuli by human subjects.  Our experimental approach differs from that of [9] in several respects.  First, instead of explicitly judging shape familiarity, our subjects had to verify the presence of a probe shape embedded in a target.  This objective task, which produces a pattern of response times, is arguably better suited to the investigation of internal representations involved in object recognition than subjective judgment.  Second, the estimation of familiarity requires the subject to access in each trial the representations of all the objects seen in the
Three-dimensional object recognition of gray level images: The usefulness of distinguishing features|
Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions|
Combining Exploratory Projection Pursuit and Projection Pursuit Regression|
Using neural networks for interpretation of nonlinear models|
Coarse Coding of Shape Fragments) + (Retinotopy)|
Variance reduction via noise and bias constraints, in Combining artificial neural nets,|
Feature extraction using an unsupervised neural network|
Offline cursive script word recognition - a survey|
Bootstrapping with Noise: An Effective Regularization Technique|
Trees and splines in survival analysis|
Learning low dimensional representations of visual objects with extensive use of prior knowledge|
How to make a low-dimensional representation suitable for diverse tasks|
Complex cells and object recognition|
On the Use of Projection Pursuit Constraints for Training Neural Networks|
Bootstrapping with noise: An effective regularisation technique|
Analysis of a temporal sequence learning network based on the property of LTP induction|
Boosting Regression Estimators|
Classification of seismic signals by integrating ensembles of neural networks,|
Boosted Mixture Of Experts: An Ensemble Learning Scheme|
Classifying Seismic Signals by Integrating Ensembles of Neural Networks,|
Blurred Face Recognition via a Hybrid Network Architecture|
Unsupervised splitting rules for neural tree classifiers|
A framework for object representation that is shallowly structural, recursively compositional, and effectively systematic|
A Neural Network for Feature Extraction|
A Hybrid Projection Based and Radial Basis Function Architecture|
Feature Extraction Using an Exploratory Projection Pursuit Neural Network|
Exploratory Feature Extraction in Speech Signals|
A hierarchical model for 3D object recognition based on 2D visual representation|
Supervised and unsupervised feature extraction from a cochlear model for speech recognition|
Three-dimensional object recognition using an unsupervised neural network: understanding the distinguishing features|
Making a Low-dimensional Representation Suitable for Diverse Tasks|
Learning as formation of low-dimensional representation spaces|
An integrated approach to the study of object features in visual recognition|
Hidden loop recovery for handwriting recognition",|
Face detection by convexity estimation",|
Extending small and limited word recognition methods for large lexicons|
Improving recognition via reconstruction,|
