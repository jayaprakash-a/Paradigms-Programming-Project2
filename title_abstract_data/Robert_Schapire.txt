The Annals of Statistics, to appear| Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods.  Abstract.  One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero.  In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label.  We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error.  We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples.  Finally, we compare our explanation to those based on the bias-variance decomposition. 
Modeling Auction Price Uncertainty Using Boosting-based Conditional Density Estimation| Abstract In complicated, interacting auctions, a fundamental problem is the prediction of prices of goods in the auctions, and more broadly, the modeling of uncertainty regarding these prices.  In this paper, we present a machine-learning approach to this problem.  The technique is based on a new and general boosting-based algorithm for conditional density estimation problems of this kind, i. e. , supervised learning problems in which the goal is to estimate the entire conditional distribution of the real-valued label.  This algorithm, which we present in detail, is at the heart of ATTac2001, a top-scoring agent in the recent Trading Agent Competition (TAC-01).  We describe how ATTac-2001 works, the results of the competition, and controlled experiments evaluating the effectiveness of price prediction in auctions. 
Predicting Nearly as Well as the Best Pruning of a Decision Tree| Abstract.  Many algorithms for inferring a decision tree from data involve a two-phase process: First, a very large decision tree is grown which typically ends up "over-fitting" the data.  To reduce over-fitting, in the second phase, the tree is pruned using one of a number of available methods.  The final tree is then output and used for classification on test data.  In this paper, we suggest an alternative approach to the pruning phase.  Using a given unpruned decision tree, we present a new method of making predictions on test data, and we prove that our algorithm's performance will not be "much worse" (in a precise technical sense) than the predictions made by the best reasonably small pruning of the given decision tree.  Thus, our procedure is guaranteed to be competitive (in terms of the quality of its predictions) with any pruning algorithm.  We prove that our procedure is very efficient and highly robust.  Our method can be viewed as a synthesis of two previously studied techniques.  First, we apply Cesa-Bianchi et al. 's [4] results on predicting using "expert advice" (where we view each pruning as an "expert") to obtain an algorithm that has provably low prediction loss, but that is computationally infeasible.  Next, we generalize and apply a method developed by Buntine [3], [2] and Willems, Shtarkov and Tjalkens [20], [21] to derive a very efficient implementation of this procedure. 
Gambling in a rigged casino: The adversarial multi-armed bandit problem| Abstract In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. 
Agent Mediated Electronic Commerce IV: Designing Mechanisms and#Systems, Springer Verlag| This approach is fully implemented as ATTac-2001, a top-scoring agent in the second Trading Agent Competition (TAC-01).  ATTac-2001 uses boosting techniques to learn conditional distributions of auction clearing prices.  We present experiments demonstrating the effectiveness of this predictor relative to several reasonable alternatives. 
A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting| Abstract In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework.  The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting.  We show that the multiplicative weightupdate rule of Littlestone and Warmuth [20] can be adapted to this model yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems.  We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games and prediction of points in R n .  In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm.  This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm.  We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line. 
Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers| Abstract We present a unifying framework for studying the solution of multiclass categorization problems by reducing them to multiple binary problems that are then solved using a margin-based binary learning algorithm.  The proposed
An Efficient Boosting Algorithm for Combining Preferences| Abstract.  The problem of combining preferences arises in several applications, such as combining the results of different search engines.  This work describes an efficient algorithm for combining multiple preferences.  We first give a formal framework for the problem.  We then describe and analyze a new boosting algorithm for combining preferences called RankBoost.  We also describe an efficient implementation of the algorithm for a restricted case.  We discuss two experiments we carried out to assess the performance of RankBoost.  In the first experiment, we used the algorithm to combine different WWW search strategies, each of which is a query expansion for a given domain.  For this task, we compare the performance of RankBoost to the individual search strategies.  The second experiment is a collaborative-filtering task for making movie recommendations.  Here, we present results comparing RankBoost to nearest-neighbor and regression algorithms. 
Learning Theory and Language Modeling| Abstract We consider some of our recent work on Good-Turing estimators in the larger context of learning theory and language modeling.  The Good-Turing estimators have played a significant role in natural language modeling for the past twenty years.  We have recently shown that these particular leave-one-out estimators converge rapidly.  We present these results and consider possible consequences for language modeling in general.  In particular, other leave-one-out estimators, such as for the cross entropy of various forms of language models, might also be shown to be rapidly converging using proof methods similar to those used for the Good-Turing estimators.  This could have broad ramification in the analysis and development of language modeling methods.  We suggest that, in language modeling at least, leave-one-out estimation may be more significant than Occam's razor. 
Margin-Based Ranking Meets Boosting in the Middle| AdaBoost and RankBoost will produce the same result, explaining the empirical observations. 
A Generalization of Principal Components Analysis to the Exponential Family| Abstract Principal component analysis (PCA) is a commonly applied technique for dimensionality reduction.  PCA implicitly minimizes a squared loss function, which may be inappropriate for data that is not real-valued, such as binary-valued data.  This paper draws on ideas from the Exponential family, Generalized linear models, and Bregman distances, to give a generalization of PCA to loss functions that we argue are better suited to other data types.  We describe algorithms for minimizing the loss functions, and give examples on simulated data. 
Boosting with Prior Knowledge for Call Classification| Abstract--The use of boosting for call classification in spoken language understanding is described in this paper.  An extension to the AdaBoost algorithm is presented that permits the incorporation of prior knowledge of the application as a means of compensating for the large dependence on training data.  We give a convergence result for the algorithm, and we describe experiments on four datasets showing that prior knowledge can substantially improve classification performance. 
Convergence and Consistency of Regularized Boosting Algorithms with Stationary -Mixing Observations| Abstract We study the statistical convergence and consistency of regularized Boosting methods, where the samples are not independent and identically distributed (i. i. d. ) but come from empirical processes of stationary -mixing sequences.  Utilizing a technique that constructs a sequence of independent blocks close in distribution to the original samples, we prove the consistency of the composite classifiers resulting from a regularization achieved by restricting the 1-norm of the base classifiers' weights.  When compared to the i. i. d.  case, the nature of sampling manifests in the consistency result only through generalization of the original condition on the growth of the regularization parameter. 
Learning to Order Things| Abstract There are many applications in which it is desirable to order rather than classify instances.  Here we consider the problem of learning how to order instances given feedback in the form of preference judgments, i. e. , statements to the effect that one instance should be ranked ahead of another.  We outline a two-stage approach in which one first learns by conventional means a binary preference function indicating whether it is advisable to rank one instance before another.  Here we consider an on-line algorithm for learning preference functions that is based on Freund and Schapire's "Hedge" algorithm.  In the second stage, new instances are ordered so as to maximize agreement with the learned preference function.  We show that the problem of finding the ordering that agrees best with a learned preference function is NP-complete.  Nevertheless, we describe simple greedy algorithms that are guaranteed to find a good approximation.  Finally, we show how metasearch can be formulated as an ordering problem, and present experimental results on learning a combination of "search experts," each of which is a domain-specific query expansion strategy for a web search engine. 
Bounds on the Sample Complexity of Bayesian Learning Using Information Theory and the VC Dimension| Abstract In this paper we study a Bayesian or average-case model of concept learning with
Boosting Applied to Tagging and PP Attachment| Abstract Boosting is a machine learning algorithm that is not well known in computational linguistics.  We apply it to part-of-speech tagging and prepositional phrase attachment.  Performance is very encouraging.  We also show how to improve data quality by using boosting to identify annotation errors. 
Logistic Regression, AdaBoost and Bregman Distances| Abstract We give a unified account of boosting and logistic regression in which each learning problem is cast in terms of optimization of Bregman distances.  The striking similarity of the two problems in this framework allows us to design and analyze algorithms for both simultaneously, and to easily adapt algorithms designed for one problem to the other.  For both problems, we give new algorithms and explain their potential advantages over existing methods.  These algorithms are iterative and can be divided into two types based on whether the parameters are updated sequentially (one at a time) or in parallel (all at once).  We also describe a parameterized family of algorithms that includes both a sequential- and a parallel-update algorithm as special cases, thus showing how the sequential and parallel approaches can themselves be unified.  For all of the algorithms, we give convergence proofs using a general formalization of the auxiliary-function proof technique.  As one of our sequential-update algorithms is equivalent to AdaBoost, this provides the first general proof of convergence for AdaBoost.  We show that all of our algorithms generalize easily to the multiclass case, and we contrast the new algorithms with the iterative scaling algorithm.  We conclude with a few experimental results with synthetic data that highlight the behavior of the old and newly proposed algorithms in different settings. 
The Nonstochastic Multiarmed Bandit Problem| Abstract.  In the multiarmed
An extended abstract of this journal submission| Abstract We give a unified account of boosting and logistic regression in which each learning problem is cast in terms of optimization of Bregman distances.  The striking similarity of the two problems in this framework allows us to design and analyze algorithms for both simultaneously, and to easily adapt algorithms designed for one problem to the other.  For both problems, we give new algorithms and explain their potential advantages over existing methods.  These algorithms can be divided into two types based on whether the parameters are iteratively updated sequentially (one at a time) or in parallel (all at once).  We also describe a parameterized family of algorithms which interpolates smoothly between these two extremes.  For all of the algorithms, we give convergence proofs using a general formalization of the auxiliary-function proof technique.  As one of our sequential-update algorithms is equivalent to AdaBoost, this provides the first general proof of convergence for AdaBoost.  We show that all of our algorithms generalize easily to the multiclass case, and we contrast the new algorithms with iterative scaling.  We conclude with a few experimental results with synthetic data that highlight the behavior of the old and newly proposed algorithms in different settings. 
The Boosting Approach to Machine Learning An Overview| Abstract Boosting is a general method for improving the accuracy of any given learning algorithm.  Focusing primarily on the AdaBoost algorithm, this chapter overviews some of the recent work on boosting including analyses of AdaBoost's training error and generalization error; boosting's connection to game theory and linear programming; the relationship between boosting and logistic regression; extensions of AdaBoost for multiclass classification problems; methods of incorporating human knowledge into boosting; and experimental and applied work using boosting. 
Large Margin Classification Using the Perceptron Algorithm| Abstract.  We introduce and analyze a new algorithm for linear classification which
Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries| Abstract We study the problem of efficiently learning to play a game optimally against an unknown adversary chosen from a computationally bounded class.  We both contribute to the line of research on playing games against finite automata, and expand the scope of this research by considering new classes of adversaries.  We introduce the natural notions of games against recent history adversaries (whose current action is determined by some simple boolean formula on the recent history of play), and games against statistical adversaries (whose current action is determined by some simple function of the statistics of the entire history of play).  In both cases we give efficient algorithms for learning to play penny-matching and a more difficult game called contract .  We also give the most powerful positive result to date for learning to play against finite automata, an efficient algorithm for learning to play any game against any finite automata with probabilistic actions and low cover time. 
Learning Binary Relations and Total Orders| Abstract We study the problem of learning a binary relation between two sets of objects or between a set and itself.  We represent a binary relation between a set of size n and a set of size m as an n \Theta m matrix of bits, whose (i# j)entry is 1 if and only if the relation holds between the corresponding elements of the twosets.  We present polynomial prediction algorithms for learning binary relations in an extended on-line learning model, where the examples are drawn by the learner, by a helpful teacher, by an adversary, or according to a uniform probability distribution on the instance space.  In the first part of this paper, we present results for the case that the matrix of the relation has at most k rowtypes.  We present upper and lower bounds on the number of prediction mistakes any prediction algorithm makes when learning such a matrix under the extended on-line learning model.  Furthermore, we describe a technique that simplifies the proof of expected mistake bounds against a randomly chosen query sequence.  In the second part of this paper, we consider the problem of learning a binary relation that is a total order on a set.  We describe a general technique using a fully polynomial randomized approximation scheme (fpras) to implement a randomized version of the halving algorithm.  We apply this technique to the problem of learning a total order, using a fpras for counting the number of extensions of a partial order,
On the Convergence Rate of Good-Turing Estimators| Abstract Good-Turing adjustments of word frequencies are an important tool in natural language modeling.  In particular, for any sample of words, there is a set of words not occuring in that sample.  The total probability mass of the words not in the sample is the so-called missing mass.  Good showed that the fraction of the sample consisting of words that occur only once in the sample is a nearly unbiased estimate of the missing mass.  Here, we give a PACstyle high-probability confidence interval for the actual missing mass.  More generally, for k 0, we give a confidence interval for the true probability mass of the set of words occuring k times in the sample. 
SIGIR '98 Boosting and Rocchio Applied to Text Filtering| Abstract We discuss two learning algorithms for text filtering: modified Rocchio and a boosting algorithm called AdaBoost.  We show how both algorithms can be adapted to maximize any general utility matrix that associates cost (or gain) for each pair of machine prediction and correct label.  We first show that AdaBoost significantly outperforms another highly effective text filtering algorithm.  We then compare AdaBoost and Rocchio over three large text filtering tasks.  Overall both algorithms are comparable and are quite effective.  AdaBoost produces better classifiers than Rocchio when the training collection contains a very large number of relevant documents.  However, on these tasks, Rocchio runs much faster than AdaBoost. 
Training Algorithms for Linear Text Classifiers| Abstract Systems for text retrieval, routing, categorization and other IR tasks rely heavily on linear classifiers.  We propose that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers.  In contrast to most IR methods, theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms.  Experimental data is presented showing Widrow-Hoff and EG to be more effective than the widely used Rocchio algorithm on several categorization and routing tasks. 
Theoretical Views of Boosting and Applications| Abstract.  Boosting is a general method for improving the accuracy of any given learning algorithm.  Focusing primarily on the AdaBoost algorithm, we briefly survey theoretical work on boosting including analyses of AdaBoost's training error and generalization error, connections between boosting and game theory, methods of estimating probabilities using boosting, and extensions of AdaBoost for multiclass classification problems.  Some empirical work and applications are also described.  Background Boosting is a general method which attempts to "boost" the accuracy of any given learning algorithm.  Kearns and Valiant [29, 30] were the first to pose the question of whether a "weak" learning algorithm which performs just slightly better than random guessing in Valiant's PAC model [44] can be "boosted" into an arbitrarily accurate "strong" learning algorithm.  Schapire [36] came up with the first provable polynomial-time boosting algorithm in 1989.  A year later, Freund [16] developed a much more efficient boosting algorithm which, although optimal in a certain sense, nevertheless suffered from certain practical drawbacks.  The first experiments with these early boosting algorithms were carried out by Drucker, Schapire and Simard [15] on an OCR task.  AdaBoost The AdaBoost algorithm, introduced in 1995 by Freund and Schapire [22], solved many of the practical difficulties of the earlier boosting algorithms, and is the focus of this paper.  Pseudocode for AdaBoost is given in Fig.  1 in the slightly generalized form given by Schapire and Singer [40].  The algorithm takes as input a training set (x 1 ; y 1 ); : : : ; (x m ; ym ) where each x i belongs to some domain or instance space X , and each label y i is in some label set Y .  For most of this paper, we assume Y =f\Gamma 1; +1g; later, we discuss extensions to the multiclass case.  AdaBoost calls a given weak or base learning algorithm repeatedly in a series of rounds t = 1; : : : ; T .  One of the main ideas of the algorithm is to maintain a distribution or set of weights over the training set.  The weight of this distribution on training example i on round t is denoted D t (i).  Initially, all weights are set equally, but on each round, the weights of incorrectly classified Given: (x 1 ; y 1 ); : : : ; (x m ; ym ) where x i 2 X , y i 2 Y = f\Gamma 1; +1g Initialize D 1 (i) = 1=m.  For t = 1; : : : ; T : -- Train weak learner using distribution D t .  -- Get weak hypothesis h t : X ! R.  -- Choose ff t 2 R.  -- Update: D t+1 (i) = D t (i) exp(\Gamma ff t y i h t (x i )) Z t where Z t is a normalization factor (chosen so that D t+1 will be a distribution).  Output the final hypothesis: H(x) = sign / T X t=1 ff t h t (x) ! : Fig.  1.  The boosting algorithm AdaBoost.  examples are increased so that the weak learner is forced to focus on the hard examples in the training set.  The weak learner's job is to find a weak hypothesis h t : X ! R appropriate for the distribution D t .  In the simplest case, the range of each h t is binary, i. e. , restricted to f\Gamma 1; +1g; the weak learner's job then is to minimize the error ffl t = Pr iD t [h t (x i ) 6= y i ] : Once the weak hypothesis h t has been received, AdaBoost chooses a parameter ff t 2 R which intuitively measures the importance that it assigns to h t .  In the figure, we have deliberately left the choice of ff t unspecified.  For binary h t , we typically set ff t = 1 2 ln ` 1 \Gamma ffl t ffl t ' : (1) More on choosing ff t follows below.  The distribution D t is then updated using the rule shown in the figure.  The final hypothesis H is a weighted majority vote of the T weak hypotheses where ff t is the weight assigned to h t .  Analyzing the training error The most basic theoretical property of AdaBoost concerns its ability to reduce the training error.  Specifically, Schapire and Singer [40], in generalizing a theorem of Freund and Schapire [22], show that the training error of the final hypothesis
A Comparison of New and Old Algorithms for a Mixture Estimation Problem| Abstract.  We investigate the problem of estimating the proportion vector which maximizes the likelihood of a given sample for a mixture of given densities.  We adapt a framework developed for supervised learning and give simple derivations for many of the standard iterative algorithms like gradient projection and EM.  In this framework, the distance between the new and old proportion vectors is used as a penalty term.  The square distance leads to the gradient projection update, and the relative entropy to a new update which we call the exponentiated gradient update (EGj ).  Curiously, when a second order Taylor expansion of the relative entropy is used, we arrive at an update EMj which, for j = 1, gives the usual EM update.  Experimentally, both the EMj-update and the EGj-update for j ? 1 outperform the EM algorithm and its variants.  We also prove a polynomial bound on the rate of convergence of the EGj algorithm. 
Using and Combining Predictors That Specialize| Abstract.  We study online learning algorithms that predict by combining the predictions of several subordinate prediction algorithms, sometimes called "experts. 
Advances in Boosting| Abstract Boosting is a general method of generating many simple classification rules and combining them into a single, highly accurate rule.  This paper reviews the AdaBoost boosting algorithm and some of its underlying theory, and then looks at some of the challenges of applying AdaBoost to bidding in complicated auctions and to human-computer spoken-dialogues systems. 
Adding Dense, Weighted Connetions to WORDNET| Abstract WORDNET, a ubiquitous tool for natural language processing, suffers from sparsity of connections between its component concepts (synsets).  Through the use of human annotators, a subset of the connections between 1000 hand-chosen synsets was assigned a value of "evocation" representing how much the first concept brings to mind the second.  These data, along with existing similarity measures, constitute the basis of a method for predicting evocation between previously unrated pairs. 
Game Theory, On-Line Prediction and Boosting| Abstract We study the close connections between game theory, on-line prediction and boosting.  After a brief review of game theory, we describe an algorithm for learning to play repeated games based on the on-line prediction methods of Littlestone and Warmuth.  The analysis of this algorithm yields a simple proof of von Neumann's famous minmax theorem, as well as a provable method of approximately solving a game.  We then show that the on-line prediction model is obtained by applying this gameplaying algorithm to an appropriate choice of game and that boosting is obtained by applying the same algorithm to the "dual" of this game. 
On the Worst-case Analysis of Temporal-difference Learning Algorithms \Lambda| abstract We study the worst-case behavior of a family of learning algorithms based on Sutton's method of temporal differences.  In our on-line learning framework, learning takes place in a sequence of trials, and the goal of the learning algorithm is to estimate a discounted sum of all the reinforcements that will be received in the future.  In this setting, we are able to prove general upper bounds on the performance of a slightly modified version of Sutton's so-called TD( ) algorithm.  These bounds are stated in terms of the performance of the best linear predictor on the given training sequence, and are proved without making any statistical assumptions of any kind about the process producing the learner's observed training sequence.  We also prove lower bounds on the performance of any algorithm for this learning problem, and give a similar analysis of the closely related problem of learning to predict in a model in which the learner must produce predictions for a whole batch of observations before receiving reinforcement. 
Learning Sparse Multivariate Polynomials over a Field with Queries and Counterexamples| Abstract.  We consider the problem of learning a polynomial over an arbitrary field F defined on a set of boolean variables.  We present the first provably effective algorithm for exactly identifying such polynomials using membership and equivalence queries.  Our algorithm runs in time polynomial in n, the number of variables, and t, the number of nonzero terms appearing in the polynomial.  The algorithm makes at most nt + 2 equivalence queries, and at most (nt + 1)(t 2 + 3t)=2 membership queries.  Our algorithm is equally effective for learning a generalized type of polynomial defined on certain kinds of semilattices.  We also present an extension of our algorithm for learning multilinear polynomials when the domain of each variable is the entire field F . 
Machine Learning: Proceedings of the Fourteenth International Conference| Abstract.  This paper describes a new technique for solving multiclass learning problems by combining Freund and Schapire's boosting algorithm with the main ideas of Dietterich and Bakiri's method of error-correcting output codes (ECOC).  Boosting is a general method of improving the accuracy of a given base or "weak" learning algorithm.  ECOC is a robust method of solving multiclass learning problems by reducing to a sequence of two-class problems.  We show that our new hybrid method has advantages of both: Like ECOC, our method only requires that the base learning algorithm work on binary-labeled data.  Like boosting, we prove that the method comes with strong theoretical guarantees on the training and generalization error of the final combined hypothesis assuming only that the base learning algorithm perform slightly better than random guessing.  Althoughprevious methodswere known for boostingmulticlass problems, the new method may be significantly faster and require less programming effort in creating the base learning algorithm.  We also compare the new algorithm experimentally to other voting methods. 
Efficient Learning of Typical Finite Automata from Random Walks| Abstract This paper describes new and efficient algorithms for learning deterministic finite automata.  Our approach is primarily distinguished by two features: (1) the adoption of an average-case setting to model the "typical" labeling of a finite automaton, while retaining a worst-case model for the underlying graph of the automaton, along with (2) a learning model in which the learner is not provided with the means to experiment with the machine, but rather must learn solely by observing the automaton's output behavior on a random input sequence.  The main contribution of this paper is in presenting the first efficient algorithms for learning non-trivial classes of automata in an entirely passive learning model.  We adopt an on-line learning model in which the learner is asked to predict the output of the next state, given the next symbol of the random input sequence; the goal of the learner is to make as few prediction mistakes as possible.  Assuming the learner has a means of resetting the target machine to a fixed start state, we first present an efficient algorithm that makes an expected polynomial number of mistakes in this model.  Next, we show how this first algorithm can be used as a subroutine by a second algorithm that also makes a polynomial number of mistakes even in the absence of a reset.  Along the way, we prove a number of combinatorial results for randomly labeled automata.  We also show that the labeling of the states and the bits of the input sequence need not be truly random, but merely semi-random.  Finally, we discuss an extension of our results to a model in which automata are used to represent distributions over binary strings. 
Efficient Distribution-Free Learning of Probabilistic Concepts| Abstract In this paper we investigate a new formal model of machine learning in which the concept (boolean function) to be learned may exhibit uncertain or probabilistic behavior---thus, the same input may sometimes be classified as a positive example and sometimes as a negative example.  Such probabilistic concepts (or p-concepts) may arise in situations such as weather prediction, where the measured variables and their accuracy are insufficient to determine the outcome with certainty.  We adopt from the Valiant model of learning [27] the demands that learning algorithms be efficient and general in the sense that they perform well for a wide class of p-concepts and for any distribution over the domain.  In addition to giving many efficient algorithms for learning natural classes of p-concepts, we study and develop in detail an underlying theory of learning p-concepts. 
Decision-Theoretic Bidding Based on Learned Density Models in Simultaneous, Interacting Auctions| Abstract Auctions are becoming an increasingly popular method for transacting business, especially over the Internet.  This article presents a general approach to building autonomous bidding agents to bid in multiple simultaneous auctions for interacting goods.  A core component of our approach learns a model of the empirical price dynamics based on past data and uses the model to analytically calculate, to the greatest extent possible, optimal bids.  We introduce a new and general boosting-based algorithm for conditional density estimation problems of this kind, i. e. , supervised learning problems in which the goal is to estimate the entire conditional distribution of the real-valued label.  This approach is fully implemented as ATTac-2001, a top-scoring agent in the second Trading Agent Competition (TAC-01).  We present experiments demonstrating the effectiveness of our boosting-based price predictor relative to several reasonable alternatives. 
Exact Identification of Read-once Formulas Using Fixed Points of Amplification Functions \Lambda| Abstract In this paper we describe a new technique for exactly identifying certain classes of read-once Boolean formulas.  The method is based on sampling the input-output behavior of the target formula on a probability distribution which is determined by the fixed point of the formula's amplification function (defined as the probability that a 1 is output by the formula when each input bit is 1 independently with probability p).  By performing various statistical tests on easily sampled variants of the fixedpoint distribution, we are able to efficiently infer all structural information about any logarithmic-depth formula (with high probability).  We apply our results to prove the existence of short universal identification sequences for large classes of formulas.  We also describe extensions of our algorithms to handle high rates of noise, and to
Performance Guarantees for Regularized Maximum Entropy Density Estimation| Abstract.  We consider the problem of estimating an unknown probability distribution from samples using the principle of maximum entropy (maxent).  To alleviate overfitting with a very large number of features, we propose applying the maxent principle with relaxed constraints on the expectations of the features.  By convex duality, this turns out to be equivalent to finding the Gibbs distribution minimizing a regularized version of the empirical log loss.  We prove nonasymptotic bounds showing that, with respect to the true underlying distribution, this relaxed version of maxent produces density estimates that are almost as good as the best possible.  These bounds are in terms of the deviation of the feature empirical averages relative to their true expectations, a number that can be bounded using standard uniform-convergence techniques.  In particular, this leads to bounds that drop quickly with the number of samples, and that depend very moderately on the number or complexity of the features.  We also derive and prove convergence for both sequential-update and parallel-update algorithms.  Finally, we briefly describe experiments on data relevant to the modeling of species geographical distributions. 
Adaptive game playing using multiplicative weights| Abstract We present a simple algorithm for playing a repeated game.  We show that a player using this algorithm suffers average loss that is guaranteed to come close to the minimum loss achievable by any fixed strategy.  Our bounds are non-asymptotic and hold for any opponent.  The algorithm, which uses the multiplicative-weight methods of Littlestone and Warmuth, is analyzed using the Kullback-Liebler divergence.  This analysis yields a new, simple proof of the minmax theorem, as well as a provable method of approximately solving a game.  A variant of our game-playing algorithm is proved to be optimal in a very strong sense. 
On the Dynamics of Boosting| Abstract In order to understand AdaBoost's dynamics, especially its ability to maximize margins, we derive an associated simplified nonlinear iterated map and analyze its behavior in low-dimensional cases.  We find stable cycles for these cases, which can explicitly be used to solve for AdaBoost's output.  By considering AdaBoost as a dynamical system, we are able to prove Ratsch and Warmuth's conjecture that AdaBoost may fail to converge to a maximal-margin combined classifier when given a `nonoptimal' weak learning algorithm.  AdaBoost is known to be a coordinate descent method, but other known algorithms that explicitly aim to maximize the margin (such as AdaBoost and arc-gv) are not.  We consider a differentiable function for which coordinate ascent will yield a maximum margin solution.  We then make a simple approximation to derive a new boosting algorithm whose updates are slightly more aggressive than those of arc-gv. 
Appearing in the proceedings of the Second European Conference on Computational Learning Theory,| Abstract.  We consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework.  The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting.  We show that the multiplicative weight-update rule of Littlestone and Warmuth [10] can be adapted to this model yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems.  We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games and prediction of points in R n .  We also show how the weight-update rule can be used to derive a new boosting algorithm which does not require prior knowledge about the performance of the weak learning algorithm. 
Experiments with a New Boosting Algorithm| Abstract.  In an earlier paper, we introduced a new "boosting" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing.  We also introduced the related notion of a "pseudo-loss" which is a method for forcing a learning algorithm of multi-label conceptsto concentrate on the labels that are hardest to discriminate.  In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems.  We performed two sets of experiments.  The first set compared boosting to Breiman's "bagging" method when used to aggregate various classifiers (including decision trees and single attributevalue tests).  We compared the performance of the two methods on a collection of machine-learning benchmarks.  In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem. 
A Brief Introduction to Boosting| Abstract Boosting is a general method for improving the accuracy of any given learning algorithm.  This short paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting.  Some examples of recent applications of boosting are also described.  Background Boosting is a general method which attempts to "boost" the accuracy of any given learning algorithm.  Boosting has its roots in a theoretical framework for studying machine learning called the "PAC" learning model, due to Valiant [37]; see Kearns and Vazirani [24] for a good introduction to this model.  Kearns and Valiant [22, 23] were the first to pose the question of whether a "weak" learning algorithm which performs just slightly better than random guessing in the PAC model can be ``boosted" into an arbitrarily accurate "strong" learning algorithm.  Schapire [30] came up with the first provable polynomial-time boosting algorithm in 1989.  A year later, Freund [14] developed a much more efficient boosting algorithm which, although optimal in a certain sense, nevertheless suffered from certain practical drawbacks.  The first experiments with these early boosting algorithms were carried out by Drucker, Schapire and Simard [13] on an OCR task.  AdaBoost The AdaBoost algorithm, introduced in 1995 by Freund and Schapire [18], solved many of the practical difficulties of the earlier boosting algorithms, and is the focus of this paper.  Pseudocode for AdaBoost is given in Fig.  1.  The algorithm takes as input a training set (x 1 ; y 1 ); : : : ; (xm ; y m ) where each x i belongs to some domain or instance space X, and each label y i is in some label set Y .  For most of this paper, we assume Y =f\Gamma 1; +1g; later, we discuss extensions to the multiclass case.  AdaBoost calls a given weak or base learning algorithm repeatedly in a series of rounds t = 1; : : : ; T .  Given: (x 1 ; y 1 ); : : : ; (xm ; ym ) where x i 2 X, y i 2 Y =f\Gamma 1; +1g Initialize D 1 (i) = 1=m. 
Machine Learning: Proceedings of the Nineteenth International Conference, 2002| Incorporating Prior Knowledge into Boosting.  Abstract We describe a modification to the AdaBoost algorithm that permits the incorporation of prior human knowledge as a means of compensating for a shortage of training data.  We give a convergence result for the algorithm, and we describe experiments on four datasets showing that prior knowledge can substantially improve performance. 
Boosting for Document Routing| ABSTRACT RankBoost is a recently proposed algorithm for learning ranking functions.  It is simple to implement and has strong justifications from computational learning theory.  We describe the algorithm and present experimental results on applying it to the document routing problem.  The first set of results applies RankBoost to a text representation produced using modern term weighting methods.  Performance of RankBoost is somewhat inferior to that of a state-of-the-art routing algorithm which is, however, more complex and less theoretically justified than RankBoost.  RankBoost achieves comparable performance to the state-of-the-art algorithm when combined with feature or example selection heuristics.  Our second set of results examines the behavior of RankBoost when it has to learn not only a ranking function but also all aspects of term weighting from raw data.  Performance is usually, though not always, less good here, but the term weighting functions implicit in the resulting ranking functions are intriguing, and the approach could easily be adapted to mixtures of textual and nontextual data. 
Computational Learning Theory: Fourth European Conference,| Abstract.  Boosting is a general method for improving the accuracy of any given learning algorithm.  Focusing primarily on the AdaBoost algorithm, we briefly survey theoretical work on boosting including analyses of AdaBoost's training error and generalization error, connections between boosting and game theory, methods of estimating probabilities using boosting, and extensions of AdaBoost for multiclass classification problems.  We also briefly mention some empirical work.  Background Boosting is a general method which attempts to "boost" the accuracy of any given learning algorithm.  Kearns and Valiant [21, 22] were the first to pose the question of whether a "weak" learning algorithm which performs just slightly better than random guessing in Valiant's PAC model [34] can be "boosted" into an arbitrarily accurate "strong" learning algorithm.  Schapire [28] came up with the first provable polynomial-time boosting algorithm in 1989.  A year later, Freund [13] developed a much more efficient boosting algorithm which, although optimal in a certain sense, nevertheless suffered from certain practical drawbacks.  The first experiments with these early boosting algorithms were carried out by Drucker, Schapire and Simard [12] on an OCR task.  AdaBoost The AdaBoost algorithm, introduced in 1995 by Freund and Schapire [16], solved many of the practical difficulties of the earlier boosting algorithms, and is the focus of this paper.  Pseudocode for AdaBoost is given in Fig.  1 in the slightly generalized form given by Schapire and Singer [31].  The algorithm takes as input a training set (x 1 ; y 1 ); : : : ; (xm ; ym ) where each x i belongs to some domain or instance space X, and each label y i is in some label set Y .  For most of this paper, we assume Y =f\Gamma 1; +1g; later, we discuss extensions to the multiclass case.  AdaBoost calls a given weak or base learning algorithm repeatedly in a series of rounds t = 1; : : : ; T .  One of the main ideas of the algorithm is to maintain a distribution or set of weights over the training set.  The weight of this distribution on training example i on round t is denoted D t (i).  Initially, all weights are set equally, but on each round, the weights of incorrectly classified Given: (x 1 ; y 1 ); : : : ; (xm ; ym ) where x i 2 X, y i 2 Y = f\Gamma 1; +1g Initialize D 1 (i) = 1=m.  For t = 1; : : : ; T : -- Train weak learner using distribution D t .  -- Get weak hypothesis h t : X ! R.  -- Choose ff t 2 R.  -- Update: D t+1 (i) = D t (i) exp(\Gamma ff t y i h t (x i )) Z t where Z t is a normalization factor (chosen so that D t+1 will be a distribution).  Output the final hypothesis: H(x) = sign / T X t=1 ff t h t (x) ! : Fig.  1.  The boosting algorithm AdaBoost.  examples are increased so that the weak learner is forced to focus on the hard examples in the training set.  The weak learner's job is to find a weak hypothesis h t : X ! R appropriate for the distribution D t .  In the simplest case, the range of each h t is binary, i. e. , restricted to f\Gamma 1; +1g; the weak learner's job then is to minimize the error ffl t = Pr iD t [h t (x i ) 6= y i ] : Once the weak hypothesis h t has been received, AdaBoost chooses a parameter ff t 2 R which intuitively measures the importance that it assigns to h t .  In the figure, we have deliberately left the choice of ff t unspecified.  For binary h t , we typically set ff t = 1 2 ln ` 1 \Gamma ffl t ffl t ' : (1) More on choosing ff t follows below.  The distribution D t is then updated using the rule shown in the figure.  The final hypothesis H is a weighted majority vote of the T weak hypotheses where ff t is the weight assigned to h t .  Analyzing the training error The most basic theoretical property of AdaBoost concerns its ability to reduce the training error.  Specifically, Schapire and Singer [31], in generalizing a theorem of Freund and Schapire [16], show that the training error of the final hypothesis
On-Line Portfolio Selection Using Multiplicative Updates| Abstract We present an on-line investment algorithm which achieves almost the same wealth as the best constant-rebalanced portfolio determined in hindsight from the actual market outcomes.  The algorithm employs a multiplicative update rule derived using a framework introduced by Kivinen and Warmuth.  Our algorithm is very simple to implement and requires only constant storage and computing time per stock in each trading period.  We tested the performance of our algorithm on real stock data from the New York Stock Exchange accumulated during a 22-year period.  On this data, our algorithm clearly outperforms the best single stock as well as Cover's universal portfolio selection algorithm.  We also present results for the situation in which the investor has access to additional "side information. "
Why Averaging Classifiers Can Protect Against Overfitting| Abstract We study a simple learning algorithm for binary classification.  Instead of predicting with the best hypothesis in the hypothesis class, this algorithm predicts with a weighted average of all hypotheses, weighted exponentially with respect to their training error.  We show that the prediction of this algorithm is much more stable than the prediction of an algorithm that predicts with the best hypothesis.  By allowing the algorithm to abstain from predicting on some examples, we show that the predictions it makes when it does not abstain are very reliable.  Finally, we show that the probability that the algorithm abstains is at most about twice the generalization error of the best hypothesis in the class. 
Boosting the margin: A new explanation for the effectiveness of voting methods| Abstract.  One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero.  In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximumnumber of votes received by any incorrect label.  We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error.  We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples.  Finally, we compare our explanation to those based on the bias-variance decomposition. 
A maximum entropy approach to species distribution modeling| Abstract We study the problem of modeling species geographic distributions, a critical problem in conservation biology.  We propose the use of maximum-entropy techniques for this problem, specifically, sequential-update algorithms that can handle a very large number of features.  We describe experiments comparing maxent with a standard distribution-modeling tool, called GARP, on a dataset containing observation data for North American breeding birds.  We also study how well maxent performs as a function of the number of training examples and training time, analyze the use of regularization to avoid overfitting when the number of examples is small, and explore the interpretability of models constructed using maxent. 
Toward Efficient Agnostic Learning| Abstract.  In this paper we initiate an investigation of generalizations of the Probably Approximately Correct (PAC) learning model that attempt to significantly weaken the target function assumptions.  The ultimate goal in this direction is informally termed agnostic learning, in which we make virtually no assumptions on the target function.  The name derives from the fact that as designers of learning algorithms, we give up the belief that Nature (as represented by the target function) has a simple or succinct explanation.  We give a number of positive and negative results that provide an initial outline of the possibilities for agnostic learning.  Our results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an efficient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnostic learning, and an algorithm for a learning problem that involves hidden variables. 
Improved Boosting Algorithms Using Confidence-rated Predictions| Abstract.  We describe several improvements to Freund and Schapire'
Maximum Entropy Correlated Equilibria| Abstract We study maximum entropy correlated equilibria in (multi-player) games and provide two gradient-based algorithms that are guaranteed to converge to such equilibria.  Although we do not provide convergence rates for the algorithms, they do have strong connections to similar algorithms that have been found to be effective heuristics in practice for tasks such as statistical estimation. 
Drifting Games| Abstract.  We introduce and study a general, abstract game played between two players called the shepherd and the adversary. 
A Short Introduction to Boosting| Abstract Boosting is a general method for improving the accuracy of any given learning algorithm.  This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting's relationship to support-vector machines.  Some examples of recent applications of boosting are also described. 
to appear| Improved Boosting Algorithms Using Confidence-rated Predictions. 
Training algorithms for text classifiers,|
Using output codes to boost multiclass learning problems|
Boosting and Rocchio Applied to Text Filtering|
BoosTexter: A Boosting-based System for Text Categorization|
Boosting Performance in Neural Networks|
The Strength of Weak Learnability|
The Design and Analysis of Efficient Learning Algorithms|
Boosting Based on a Smooth Margin|
How to use expert advice|
On the learnability of discrete distributions|
A decision-theoretic generalization of on-line learning and an application boosting|
Exact Identification of Circuits Using Fixed Points of Amplification Functions (Abstract)|
Inference of finite automata using homing sequences|
94, "On the Learnability of Discrete Distributions",|
How to use expert advice|
Improved boosting algorithms using confidence-rated prediction|
Theoretical Views of Boosting|
Diversity-Based Inference of Finite Automata|
Inference of Finite Automata Using Homing Sequences|
Incorporating Prior Knowledge into Boosting|
On the Sample Complexity of Weak Learning|
Improving Performance in Neural Networks Using a Boosting Algorithm|
The minimal disagreement parity problem as a hard satisfiability problem|
A boosting-based system for text categorization|
A new approach to unsupervised learning in deterministic environments|
in press)| Improved boosting algorithms using confidence-rated predictions. 
A brief introduction to boosting|
The strength of weak learnability|
Discussion on Arcing classifiers, auth|
BoosTexter: A system for multiclass multi-label text categorization|
Estimating Average-Case Learning Curves Using Bayesian, Statistical Physics and VC Dimension Methods|
To appear| Boostexter: A boosting-based system for text categorization. 
Bounds on the sample complexity of Bayesian learning theory using information theory and the VC dimension|
Large Margin Classifi8016`- Using the Perceptron Algorithm,|
Discussion of the paper "Arcing classifiers" by Leo Breiman|
Learning Probabilistic Read-once Formulas on Product Distributions|
Pattern Languages are not Learnable|
The emerging theory of average-case complexity|
Experiments with a new boosting alogrithm|
Toward efficient agnostic leaning|
ATTac-2001: A Learning, Autonomous Bidding Agent|
On the Worst-Case Analysis of Temporal-Difference Learning Algorithms|
How to use expert advice (extended abstract)|
Training algorithms for liner text classifiers|
Strength of weak learners|
The strenght of weak learnability|
Experiments with a new boosting algorithms|
The dynamics of AdaBoost: Cyclic behavior and convergence of margins|
Analysis of boosting algorithms using the smooth margin function: A study of three algorithms|
Discussion of the paper \additive logistic regression: a statistical view of boosting"|
Efficient Distribution-free Learning of Probabilistic Concepts," pages 382--391|
Portfolio selection using multiplicative updates|
An introduction to boosting algorithm|
Inference of Finite Automata Using Homing Sequences (Extended Abstract)|
Diversity-based inference of finite automata|
Adaboost and logistic regression unified in the context of information geometry|
A learning, autonomous bidding agent|
Experiments with a new booting algorithm,|
Combining active and semisupervised learning for spoken language understanding,|
Some experiments with a new boosting algorithm|
Tr, "Active learning for spoken language understanding,|
Exact identification of circuits using fixed points of amplification functions, In Proceedings of the Thirty-First Annual Symposium on Foundations of Computer Science,|
Exact Identification of Read-Once Formulas Using Fixed Points of Amplification Functions|
Inference of Finite Automata Using Homing|
The strength of weaklearning,|
Experiments with a new b sting alg rithm|
Information Processing Systems 8,|
Using output codes to boost multiclass learning problems|
Boosting for document routing|
b] Game Theory, On-line Prediction and Boosting,|
Tr,|
Game theory, online prdiction and boosting|
in press), "A Decision-Theoretic Generalization of On-line Learning and an Application to Boosting,"|
Toward efficient agnostic learning (extended abstract)|
A decision theoretic generalization of online learing and and application to boosting|
