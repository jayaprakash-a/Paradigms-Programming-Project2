Solid or not solid: Vision for radar target validation| Abstract In the context of combining Radar and Vision sensors for a fusion application in dense city traffic situations, one of the major challenges is to be able to validate Radar targets.  We take a high-level fusion approach assuming that both sensor modalities have the capacity to independently locate and identify targets of interest.  In this context, Radar targets can either correspond to a Vision target --- in which case the target is validated without further processing --or not.  It is the latter case that drives the focus of this paper.  A non-matched Radar target can correspond to some solid object which is not part of the objects of interest of the Vision sensor (such as a guard-rail) or can be caused by reflections in which case it is a ghost target which does not match any physical object in the real world.  We describe a number of computational steps for the decision making of non-matched Radar targets.  The computations combine both direct motion parallax measurements and indirect motion analysis --- which are not sufficient for computing parallax but are nevertheless quite effective --- and pattern classification steps for covering situations which motion analysis are weak or ineffective.  One of the major advantages of our high-level fusion approach is that it allows the use of simpler (low cost) Radar technology to create a combined high performance system. 
On Photometric Issues in 3D Visual Recognition From A Single 2D Image| Abstract.  We describe the problem of recognition under changing illumination conditions and changing viewing positions from a computational and human vision perspective.  On the computational side we focus on the mathematical problems of creating an equivalence class for images of the same 3D object undergoing certain groups of transformations --- mostly those due to changing illumination, and briefly discuss those due to changing viewing positions.  The computational treatment culminates in proposing a simple scheme for recognizing, via alignment, an image of a familiar object taken from a novel viewing position and a novel illumination condition.  On the human vision aspect, the paper is motivated by empirical evidence inspired by Mooney images of faces that suggest a relatively high level of visual processing is involved in compensating for photometric sources of variability, and furthermore, that certain limitations on the admissible representations of image information may exist.  The psychophysical observations and the computational results that follow agree in several important respects, such as the same (apparent) limitations on image representations. 
Time-varying Shape Tensors for Scenes with Multiply Moving Points| Abstract We derive single view indexing functions for dynamic scenes where dynamic is defined as a scene consisting of multiply moving points each moving independently with constant velocity.  The indexing functions we derive are view independent and form a generalization of the ^shape tensors~ associated with rigid scenes by introducing a time-varying parameter.  We derive those indexing functions under full 3D projective, 3D af#ne, and various reduced configurations.  The indexing functions were implemented and tested for matching against objects for which their non-rigid motion is an intrinsic part of their character human gait recognition and hand gesture identification are the two chosen application examples. 
Kernel Feature Selection| Abstract We address the problem of using a kernel spectral criterion function for feature selection.  A feature selection paradigm using spectral properties of the affinity matrix of the input data was recently introduced in [11] and which leads to a bilinear interaction between entries of the data sample.  Our goal in this paper is to extend the idea of spectral criteria for feature selection to higher order interactions among the data by introducing a kernel operation through which high-order mappings of the original feature vectors can be made possible. 
Direct Estimation of Motion and Extended Scene Structure from a Moving Stereo Rig| Abstract We investigate the relationship between the kinematics (infinitesimal motion model) of a calibrated Stereo Rig and point and line image feature measurements seen at two time instances of the rig's motion (four images in all).  In particular, we are interested in the byproduct of this analysis providing a direct connection between the spatio-temporal derivatives of the images at two time instances and kinematics of the 3D motion of the Rig.  We establish a fundamental result showing that 3 quadruples of point-line-line-line matches (i. e. , point in the reference image and lines coincident with the corresponding points in the remaining three images) are sufficient for a unique linear solution for the kinematics of the rig.  In other words, the projected instantaneous motion of "one and a half" 3D lines is sufficient for recovering the kinematics of the moving rig.  In particular, spatio-temporal derivatives across 3 points are sufficient for a direct estimation of the rig's motion.  Consequently, we describe a new direct estimation method for motion estimation and 3D reconstruction from stereo image sequences obtained by a stereo rig moving through a rigid world.  Correspondences (optic flow) are not required as spatio-temporal derivative are used instead.  One can then use the images from both pairs combined, to compute a dense depth map.  Finally, since the basic equations are linear, we combine the contribution coming from all pixels in the image using a Least Squares approach. 
Q-Warping: Direct Computation of Quadratic Reference Surfaces| Abstract We consider the problem of wrapping around an object, of which two views are available, a reference surface and recovering the resulting parametric flow using direct computations (via spatio-temporal derivatives).  The well known examples are affine flow models and 8-parameter flow models --- both describing a flow field of a planar reference surface.  We extend those classic flow models to deal with a Quadric reference surface and work out the explicit parametric form of the flow field.  As a result we derive a simple warping algorithm that maps between two views and leaves a residual flow proportional to the 3D deviation of the surface from a virtual quadric surface.  The applications include image morphing, model building, image stabilization, and disparate view correspondence. 
Tensorial Transfer: Representation of N ? 3 Views of 3D scenes \Lambda| Abstract The recently discovered "trilinear tensor" has been shown to play a similar role to the "fundamental" matrix, but with three views instead of two views, in representing the relative motion parameters of an observer moving in the 3D projective world.  The issue of a general representation for any number of views remains an open problem.  The main result presented here is the closed-form concatenation of any number of views.  The concatenation operation shows that N tensors are sufficient for representing a set of N +2 views, i. e. , the tensor of any triplet of views from the set can be generated in closedform from an arbitrary collection of N tensors over this set.  These concatenation operators may be useful in the context of image synthesis, image mosaicing and video compression. 
Omni-Rig Sensors: What Can be Done With a Non-Rigid Vision Platform?| Abstract We describe the principles of building a moving vision platform (a Rig) that once calibrated can thereon selfadjust to changes in its internal configuration and maintain an Euclidean representation of the 3D world using only projective measurements.  Formally, we address the question of how to obtain an invariant 3D projective representation from a dynamic collection of cameras.  We show that the maximal generality is reached when the rig consists of 5 cameras whose center of projection remain fixed relative to each other during the motion.  In other words, the non-rigid component motion may consist of change of internal parameters and relative camera orientations.  The configuration reduces to 3 views when the Rig is built using a single physical camera with half-mirrors (beam-splitters) for creating 3 distinct views.  We also briefly discuss 2-view configurations using halfmirrors and the principle behind adapting the configuration to allow for zoom lenses in the system.  The new research paradigm on non-rigid rigs (we term "Omni-Rig") is applicable to the design of Vision-based sensors that after calibration can move in space while changing critical elements of their configuration --- such as changing focus on the fly, zoom, relative camera orientation and inclination of focal plane to object's surface orientation --- without the need for recalibration, i. e. , using only projective calculations throughout its motion. 
Crowd detection in video sequences| Abstract--- We present a real-time system that detects moving crowd in a video sequence.  Crowd detection differs from pedestrian detection in that we assume that no individual pedestrian can be properly segmented in the image.  We propose a scheme that looks at the motion patterns of crowd in the spatio-temporal domain and give an efficient implementation that can detect crowd in real-time.  In our experiments we detected crowd at distances of up to 70m. 
Sparse Spectral-based Feature Selection with Side Information \Lambda| Abstract We address the problem of selecting a subset of the most relevant features from a set of sample data in cases where there are multiple (equally reasonable) solutions.  In particular, this topic includes the suppression of one of the solutions given "side" data, i. e. , when one is given information about undesired aspects of the data.  Such situations often arise when there are several, even conflicting, dimensions to the data.  For example, documents can be clustered based on topic, authorship or writing style; images of human faces can be clustered based on illumination conditions, facial expressions or by person identity; gene expressions levels can be clustered by pathologies or by correlations that also exist in other conditions, and so forth.  We address this problem by extending the recently introduced Q ; ff algorithm for feature selection [10].  The Q ; ff algorithm uses spectral properties of the affinity (or Laplacian) matrix of the input data sample to guide the search for a relevant subset of features (coordinates).  The most relevant subset of coordinates is the one that induces the most coherent collection of k clusters in the subspace defined by the selected coordinates.  In this work we address the problem which arises when different coordinate selections induce equally good clusters in their respective subspaces.  We derive a principled manner to represent unwanted cluster arrangements, such as "side" data in various forms, as part of the optimization functional for feature selection and also derive a topographical structure of all selected feature subsets. 
On Calibration and Reconstruction from Planar Curves| Abstract We describe in this paper closed-form solutions to the following problems in multi-view geometry of n'th order curves: (i) recovery of the fundamental matrix from 4 or moreconic matches in two views, (ii) recovery of the homography matrix from a single n'th order (n # 3) matching curve and, in turn, recovery of the fundamental matrix from two matching n'th order planar curves, and (iii) 3D reconstruction of a planar algebraic curve from two views.  Although some of these problems, notably (i) and (iii), were introduced in the past [15, 3], our derivations are analytic with resulting closed form solutions.  We have also conducted synthetic experiments on (i) and real image experiments on (ii) and (iii) with subpixel performance levels, thus demonstrating the practical use of our results. 
Shape Tensors for Efficient and Learnable Indexing| Abstract Multi-point geometry: The geometry of 1 point in N images under perspective projection has been thoroughly investigated, identifying bilinear, trilinear, and quadrilinear relations between the projections of 1 point in 2, 3 and 4 frames respectively.  The dual problem - the geometry of N points in 1 image - has been studied mostly in the context of object recognition, often assuming weak perspective or affine projection.  We provide here a complete description of this problem.  We employ a formalism in which multiframe and multi-point geometries appear in symmetry: points and projections are interchangeable.  We then derive bilinear equations for 6 points (dual to 4frame geometry), trilinear equations for 7 points (dual to 3-frame geometry), and quadrilinear equations for 8 points (dual to the epipolar geometry).  We show that the quadrilinear equations are dependent on the the bilinear and trilinear equations, and we show that adding more points will not generate any new equation.  Applications to reconstruction and recognition: The new equations are used to design new algorithms for the reconstruction of shape from many frames, and for learning invariant relations for indexing into a data-base.  We describe algorithms which require matching 6 (or more) corresponding points from at least 4 images, 7 (or more) points from at least 3 images, or 8 (or more) points from at least 2 images.  Unlike previous approaches, the equations developed here lead to direct and linear solutions without going through the cameras' geometry.  Our final linear shape computation uses all the available data -- all points and all frames simultaneously: it uses a factorization of the matrix of invariant relations into 2 components of rank 4, a shape matrix and a coordinate-system matrix. 
Example Based Image Analysis and Synthesis| Abstract Image analysis and graphics synthesis can be achieved with learning techniques using directly image examples without physically-based, 3D models.  We describe here novel techniques for the analysis and the synthesis of new grey-level (and color) images.  With the first technique, ffl the mapping from novel images to a vector of "pose" and "expression" parameters can be learned from a small set of example images using a function approximation technique that we call an analysis network; ffl the inverse mapping from input "pose" and "expression" parameters to output grey-level images can be synthesized from a small set of example images and used to produce new images under real-time control using a similar learning network, called in this case a synthesis network.  This technique relies on (i) using a correspondence algorithm that matches corresponding pixels among pairs of grey-level images and effectively "vectorizes" them, and (ii) exploiting a class of multidimensional interpolation networks -- Regularization Networks -- that approximate the nonlinear mapping between the vector input and the vector output.  We also describe a second technique for analysis and synthesis of images, which can be formulated within the same theoretical framework and discuss the somewhat different implementation tradeoffs in terms of memory and computation.  As a third contribution, we introduce an approach for generating novel grey-level images from a single example image by learning the desired transformation from prototypical examples.  The three techniques described here have several applications in computer graphics, special effects, interactive multimedia and object recognition systems.  The analysis network can be regarded as a passive and trainable universal interface, that is a control device which may be used as a generalized computer mouse, instead of "gloves", "body suits" and joy sticks.  The synthesis network is an unconventional and novel approach to computer graphics.  The techniques described here can be used for very low bandwidth teleconferencing and interactive simulations. 
Degenerate N point Configurations of Three Views: Do Critical Surfaces Exist?| Abstract When the geometry of 3D space is reconstructed from a pair of views, using the "Fundamental matrix" as the object of analysis, then it is known (as early as the 1940s) that there exists a "critical surface" for which the solution of 3-space is ambiguous.  We show that when 3-space is reconstructed from a triplet of views, using the "Trilinear Tensor" as the object of analysis, there are no critical surfaces.  In addition to theoretical interest of solving an open problem, this result has profound practical significance.  The numerical instability associated with Structure from Motion is largely attributed to the existence of ``critical volumes" that arise from the existence of critical surfaces coupled with errors in the image measurements.  The lack of critical surfaces in the context of three views (provided that the trilinear tensor is used) suggests that better stability in the presence of errors can be gained. 
Learning over Sets using Kernel Principal Angles| Abstract We consider the problem of learning with instances defined over a space of sets of vectors.  We derive a new positive definite kernel f (A,B) defined over pairs of matrices A,B based on the concept of principal angles between two linear subspaces.  We show that the principal angles can be recovered using only inner-products between pairs of column vectors of the input matrices thereby allowing the original column vectors of A,B to be mapped onto arbitrarily high-dimensional feature spaces.  We demonstrate the usage of the matrix-based kernel function f (A,
Trilinear Tensor: The Fundamental Construct of Multiple-view Geometry and Its Applications| Abstract.  The topic of representation, recovery and manipulation of three-dimensional (3D) scenes from two-dimensional (2D) images thereof, provides a fertile ground for both intellectual theoretically inclined questions related to the algebra and geometry of the problem and to practical applications such as Visual Recognition, Animation and View Synthesis, recovery of scene structure and camera ego-motion, object detection and tracking, multi-sensor alignment, etc.  The basic materials have been known since the turn of the century, but the full scope of the problem has been under intensive study since 1992, first on the algebra of two views and then on the algebra of multiple views leading to a relatively mature understanding of what is known as ``multilinear matching constraints", and the "trilinear tensor" of three or more views.  The purpose of this paper is, first and foremost, to provide a coherent framework for expressing the ideas behind the analysis of multiple views.  Secondly, to integrate the various incremental results that have appeared on the subject into one coherent manuscript. 
Pedestrian Detection for Driving Assistance Systems: Single-frame Classification and System Level Performance| Abstract We describe the functional and architectural breakdown of a monocular pedestrian detection system.  We describe in detail our approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set.  Single-frame classification performance results and system level performance figures for daytime conditions are presented with a discussion about the remaining gap to meet a daytime normal weather condition production system. 
Feature Selection for Unsupervised and Supervised Inference: the Emergence of Sparsity in a Weighted-based Approach| Abstract The problem of selecting a subset of relevant features in a potentially overwhelming quantity of data is classic and found in many branches of science including --- examples in computer vision, text processing and more recently bioinformatics are abundant.  In this work we present a definition of "relevancy" based on spectral properties of the Affinity (or Laplacian) of the features' measurement matrix.  The feature selection process is then based on a continuous ranking of the features defined by a least-squares optimization process.  A remarkable property of the feature relevance function is that sparse solutions for the ranking values naturally emerge as a result of a "biased non-negativity" of a key matrix in the process.  As a result, a simple least-squares optimization process converges onto a sparse solution, i. e. , a selection of a subset of features which form a local maxima over the relevance function.  The feature selection algorithm can be embedded in both unsupervised and supervised inference problems and empirical evidence show that the feature selections typically achieve high accuracy even when only a small fraction of the features are relevant. 
On Projection Matrices| P k !P 2 , k = 3; ###; 6,
Linear Image Coding for Regression and Classification using the Tensor-rank Principle| Abstract Given a collection of images (matrices) representing a
Tensor Embedding of the Fundamental Matrix| Doing that weintroduce a 3 # 3 # 3 tensor F jk i ,we call the bifocal tensor, that represents the bilinear constraint.  The bifocal and trifocal tensors share the same form and share the same contraction properties.  By close inspection of the contractions of the bifocal tensor into matrices we show that one can represent the family of rank-2 homography matrices by[#]#F where # is a free vector.  We then discuss four applications of the new representation: (i) Quasi-metric viewing of projective data, (ii) triangulation, (iii) view synthesis, and (iv) recovery of camera ego-motion from a stream of views. 
and their Applications in Computer Vision| Abstract Projection matrices from projective spaces P 3 to P 2 have long been used in multiple-view geometry to model the perspective projection created by the pin-hole camera.  In this work we introduce higher-dimensional mappings P k ! P 2 ,
Q-Warping: Direct Computation of Quadratic Reference Surfaces| Abstract We consider the problem of wrapping around an object, of which two views are available, a reference surface and recovering the resulting parametric flow using direct computations (via spatio-temporal derivatives).  The well known examples are affine flow models and 8-parameter flow models --- both describing a flow field of a planar reference surface.  We extend those classic flow models to deal with a Quadric reference surface and work out the explicit parametric form of the flow field.  As a result we derive a simple warping algorithm that maps between two views and leaves a residual flow proportional to the 3D deviation of the surfacefrom a virtual quadric surface.  The applications include
Ranking with Large Margin Principle: Two Approaches| Abstract We discuss the problem of ranking k instances with the use of a "large margin" principle.  We introduce two main approaches: the first is the "fixed margin" policy in which the margin of the closest neighboring classes is being maximized --- which turns out to be a direct generalization of SVM to ranking learning.  The second approach allows for k 1 different margins where the sum of margins is maximized.  This approach is shown to reduce to #-SVM when the number of classes k = 2.  Both approaches are optimal in size of 2l where l is the total number of training examples.  Experiments performed on visual classification and "collaborative filtering" show that both approaches outperform existing ordinal regression algorithms applied for ranking and multi-class SVM applied to general multi-class classification. 
Principal Component Analysis over Continuous Subspaces and Intersection of Half-Spaces| Abstract.  Principal Component Analysis (PCA) is one of the most popular techniques for dimensionality reduction of multivariate data points with application areas covering many branches of science.  However, conventional PCA handles the multivariate data in a discrete manner only, i. e. , the covariance matrix represents only sample data points rather than higher-order data representations.  In this paper we extend conventional PCA by proposing techniques for constructing the covariance matrix of uniformly sampled continuous regions in parameter space.  These regions include polytops defined by convex combinations of sample data, and polyhedral regions defined by intersection of half spaces.  The applications of these ideas in practice are simple and shown to be very effective in providing much superior generalization properties than conventional PCA for appearance-based recognition applications. 
Image-based view synthesis by combining trilinear tensors and learning techniques| Abstract We present a new method for rendering novel images of flexible 3D objects from a small number of example images in correspondence.  The strength of the method is the ability to synthesize images whose viewing position is significantly far away from the viewing cone of the example images ("view extrapolation"), yet without ever modeling the 3D structure of the scene.  The method relies on synthesizing a chain of "trilinear tensors" that governs the warping function from the example images to the novel image, together with a multi-dimensional interpolation function that synthesizes the non-rigid motions of the viewed object from the virtual camera position.  We show that two closely spaced example images alone are sufficient in practice to synthesize a significant viewing cone, thus demonstrating the ability of representing an object by a relatively small number of model images --- for the purpose of cheap and fast viewers that can run on standard hardware. 
On Degeneracy of Linear Reconstruction from Three Views: Linear Line Complex and Applications \Lambda| Abstract This paper investigates the linear degeneracies of projective structure estimation from point and line features across three views.  We show that the rank of the linear system of equations for recovering the trilinear tensor of three views reduces to 23 (instead of 26) in the case when the scene is a Linear Line Complex (set of lines in space intersecting at a common line) and is 21 when the scene is planar.  The LLC situation is only linearly degenerate, and we show that one can obtain a unique solution when the admissibility constraints of the tensor are accounted for.  The line configuration described by an LLC, rather than being some obscure case, is in fact quite typical.  It includes, as a particular example, the case of a camera moving down a hallway in an office environment or down an urban street.  Furthermore, an LLC situation may occur as an artifact such as in direct estimation from spatiotemporal derivatives of image brightness.  Therefore, an investigation into degeneracies and their remedy is important also in practice. 
Algebraic Set Kernels with Application to Inference Over Local Image Representations| Abstract This paper presents a general family of algebraic positive definite similarity functions over spaces of matrices with varying column rank.  The columns can represent local regions in an image (whereby images have varying number of local parts), images of an image sequence, motion trajectories in a multibody motion, and so forth.  The family of set kernels we derive is based on a group invariant tensor product lifting with parameters that can be naturally tuned to provide a cook-book of sorts covering the possible "wish lists" from similarity measures over sets of varying cardinality.  We highlight the strengths of our approach by demonstrating the set kernels for visual recognition of pedestrians using local parts representations. 
Trilinearity of Three Perspective Views and its Associated Tensor| Abstract It has been established that certain trilinear froms of three perspective views give rise to a tensor of 27 intrinsic coefficients [11].  We show in this paper that a permutation of the the trilinear coefficients produces three homography matrices (projective transformations of planes) of three distinct intrinsic planes, respectively.  This, in turn, yields the result that 3D invariants are recovered directly --- simply by appropriate arrangement of the tensor's coefficients.  On a secondary level, we show new relations between fundamental matrix, epipoles, Euclidean structure and the trilinear tensor.  On the practical side, the new results extend the existing envelope of methods of 3D recovery from 2D views --- for example, new linear methods that cut through the epipolar geometry, and new methods for computing epipolar geometry using redundancy available across many views. 
Grouping Contours by Iterated Pairing Network| Abstract We describe in this paper a network that performs grouping of image contours.  The input to the net are fragments of image contours, and the output is the partitioning of the fragments into groups, together with a saliency measure for each group.  The grouping is based on a measure of overall length and curvature.  The network decomposes the overall optimization problem into independent optimal pairing problems performed at each node.  The resulting computation maps into a uniform locally connected network of simple computing elements.  1 The Problem: Contour Grouping A problem that often arises in visual information processing is the linking of contour fragments into optimal groups.  For example, certain subsets of contours spontaneously form perceptual groups, as illustrated in Fig.  1, and are often detected immediately without scanning the image in a systematic manner.  Grouping process of this type are likely to play an important role in object recognition by segmenting the image and selecting image structures that are likely to correspond to objects of interest in the scene.  We propose that some form of autonomous grouping is performed at an early stage based on geometrical characteristics, that are independent of the identity of objects to be selected.  The grouping process is governed by the notion of saliency in a way that priority is given to forming salient groups at the expense of potentially less salient ones.  This general notion can again be illustrated by Fig.  1; it appears that certain groups spontaneously emerge, while grouping decisions concerning the less salient parts of the image may remain unresolved.  As we shall see, the computation below exhibits a similar behavior.  We define a grouping of the image contours as the formation of a set of disjoint Figure 1: Contours that spontaneously form perceptual groups with various degrees of saliency.  On the left is an edge image of a plane surrounded by a car, a house, trees and texture.  The image on the right contains three circles, having decreasing degrees of saliency, in a background of randomly placed and oriented segments.  groups, each corresponding to a curve that may have any number of gaps, and whose union covers all the contour fragments in the image.  Given a function F (A) that measures some desired property of a group A, we would like to find a disjoint set of groups fA 1 ; :::; Amg that maximizes P i F (A i ) over all possible groupings.  Our definition of the problem is related to, but not identical with, problems studied in the past under headings of "perceptual organization", "segmentation", "cueing" and ``figure-ground separation".  In our definition of grouping, local grouping decisions based on collinearity of neighboring edge segments may be overridden in favor of more global decisions that are governed by the overall saliency of the groups.  The paper introduces a novel grouping method having the following properties: (i) the grouping optimizes an overall saliency measure, (ii) the optimization problem is mapped onto a uniform locally connected network of simple computing elements, and (iii) the network's architecture and its computation are different in several respects from traditional neural network models.  2 Optimal Grouping For the purpose of grouping it is convenient to consider the image as a graph of edge elements.  The vertices of the graph correspond to image pixels, and the arcs to elementary edge fragments.  The input to the grouping problem is a contour image, represented by a subset E r of the elements in the graph.  A path in the graph corresponds to a contour in the image having any number of gaps.  This implies that the grouping process implicitly bridges across gaps.  This filling-in process is critical to any grouping scheme as demonstrated by the circles in Fig.  1.  The emphasis in this paper is on 1-D chains of elements such as objects' bounding contours.  Grouping is therefore a collections of chains of A 1 ; :::; Am such that A i `` A j = ; i 6= j and [ i A i ' E r .  To define an optimal grouping we will define a function F (A) that measures the quality of a group A.  An optimal grouping is then a grouping that maximizes P m i=1 F (A i ) over all possible groupings of the elements. 
Algebraic Functions For Recognition| Abstract--- In the general case, a trilinear relationship between three perspective views is shown to exist.  The trilinearity result is shown to be of much practical use in visual recognition by alignment --- yielding a direct reprojection method that cuts through the computations of camera transformation, scene structure and epipolar geometry.  Moreover, the direct method is linear and sets a new lower theoretical bound on the minimal number of points that are required for a linear solution for the task of reprojection.  The proof of the central result may be of further interest as it demonstrates certain regularities across homographies of the plane and introduces new view invariants.  Experiments on simulated and real image data were conducted, including a comparative analysis with epipolar intersection and the linear combination methods, with results indicating a greater degree of robustness in practice and a higher level of performance in re-projection tasks. 
On the Reprojection of 3D and 2D Scenes Without Explicit Model Selection| Abstract It is known that recovering projection matrices from planar configurations is ambiguous, thus, posing the problem of model selection --- is the scene planar (2D) or non-planar (3D)? For a 2D scene one would recover a homography matrix, whereas for a 3D scene one would recover the fundamental matrix or trifocal tensor.  The task of model selection is especially problematic when the scene is neither 2D nor 3D --- for example a \thin" volume in space.  In this paper we show that for certain tasks, such as reprojection, thereisno need to select a model.  The ambiguity that arises froma2Dscene is orthogonal to the reprojection process, thus if one desires to use multilinear matching constraints for transferring points along a sequence of views it is possible to do so under any situation of 2D, 3D or \thin" volumes. 
On the Structure and Properties of the Quadrifocal Tensor| Abstract The quadrifocal tensor which connects image measurements along 4 views is not yet well understood as its counterparts the fundamental matrix and the trifocal tensor.  This paper establishes the structure of the tensor as an \epipolehomography" pairing Q ijkl = v 0j H ikl, v 00k H ijl + v 000l H ijk where v 0 ;v 00 ;v 000 are the epipoles in views 2,3,4, H is the \homography tensor" the 3-view analogue of the homography matrix, and the indices i; j; k; l are attached to views 1,2,3,4 respectively --- i. e. , H ikl is the homography tensor of views 1,3,4.  In the course of deriving the structure Q ijkl we show that Linear Line Complex (LLC) mappings are the basic building block in the process.  We also introduceacomplete break-down of the tensor slices: 3 # 3 # 3 slices are homography tensors, and 3 # 3 slices are LLC mappings.  Furthermore, we present a closed-form formula of the quadrifocal tensor described by the trifocal tensor and fundamental matrix, and also show how to recover projection matrices from the quadrifocal tensor.  We also describe the form of the 51 non-linear constraints a quadrifocal tensor must adhere to. 
Model-based brightness constraints: on direct estimation of structure and motion| Abstract We describe a new direct method for estimating structure and motion from image intensities of multiple views.  We extend the direct methods of [9] to three views.  Adding the third view enables us to solve for motion, and compute a dense depth map of the scene, directly from image spatiotemporal derivatives in a linear manner without first having to find point correspondences or compute optical flow.  We describe the advantages and limitations of this method which are then verified with experiments using real images. 
Affine 3-D Reconstruction from Two Projective Images of Independently Translating Planes| Abstract Consider two views of a multi-body scene consisting of k planar bodies moving in pure translation one relative to the other.  We show that the fundamental matrices, one per body, live in a 3-dimensional subspace, which when represented as a step-3 extensor is the common transversal on the collection of extensors defined by the homography matrices H 1 ; :::; H k of the moving planes.  We show that as much as five bodies are necessary for recovering the common transversal from the homography matrices, from which we show how to recover the fundamental matrices and the affine calibration between the two cameras. 
Illumination and View Position in 3D Visual Recognition| Abstract It is shown that both changes in viewing position and illumination conditions can be compensated for, prior to recognition, using combinations of images taken from different viewing positions and different illumination conditions.  It is also shown that, in agreement with psychophysical findings, the computation requires at least a sign--bit image as input --contours alone are not sufficient. 
Revisiting Single-View Shape Tensors: Theory and Applications| Abstract.  Given the projection of a sucient number of points it is possible to algebraically eliminate the camera parameters and obtain viewinvariant functions of image coordinates and space coordinates.  These single view invariants have been introduced in the past, however, they are not as well understood as their dual multi-view tensors.  In this paper we revisit the dual tensors (bilinear, trilinear and quadlinear), both the general and the reference-plane reduced version, and describe the complete set of synthetic constraints, properties of the tensor slices, reprojection equations, non-linear constraints and reconstruction formulas.  We then apply some of the new results, such as the dual reprojection equations, for multi-view point tracking under occlusions. 
On Representation Theory in Computer Vision Problems \Lambda| Abstract We introduce the following general question: Let V be a complex n-dimensional space and for m k consider the GL(V )-module V (n# m# k) ae V \Omegam defined by V (n# m# k)=f v 1 \Omega \Delta\Delta\Delta \Omega vm 2 V \Omegam : dim Spanfv 1 #:::#v mgk g : We would like to determine dim V (n# m# k) for any choice of n# m k.  This question appears in various disguises in computer vision problems where the constraints of a multi-linear problem occupy a lowdimensional subspace.  We discuss two such problems: analysis of constraints in single view indexing functions (the 8-point shape tensor), and the analysis of the constraints in dynamic P n ! P n alignments, i. e. , where the point sets are allowed to move within a k-dimensional subspace while the n-dimensional space is being multiply projected (multiple views) onto copies of the m-dimensional space.  We then derive the solution to the general problem using tools from representation theory. 
Omni-Rig: Linear Self-Recalibration of a Rig with Varying Internal and External Parameters| Abstract We describe the principles of building a moving vision platform (a Rig) that once calibrated can thereon self-adjust to changes in its internal configuration and maintain an Euclidean representation of the 3D world using only projective measurements.  We term this calibration paradigm "OmniRig".  We assume that after calibration the cameras may change critical elements of their configuration, including internal parameters and centers of projection.  Theoretically we show that knowing only the rotations between a set of cameras is sufficient for Euclidean calibration even with varying internal parameters and unknown translations.  No other information of the world is required. 
Duality of Multi-Point and Multi-Frame Geometry: Fundamental Shape Matrices and Tensors| Abstract.  We provide a complete analysis of the geometry of N points in 1 image, employing a formalism in which multi-frame and multi-point geometries appear in symmetry: points and projections are interchangeable.  We derive bilinear equations for 6 points, trilinear equations for 7 points, and quadrilinear equations for 8 points.  The new equations are used to design new algorithms for the reconstruction of projective shape from many frames.  Shape is represented by shape descriptors, which are sufficient for object recognition, and for the simulation of new images of the object.  We further propose a linear shape reconstruction scheme which uses all the available data - all points and all frames - simultaneously.  Unlike previous approaches, the equations developed here lead to direct and linear computation of shape, without going through the cameras' geometry. 
Manifold Pursuit: A New Approach to Appearance Based Recognition| Abstract Manifold Pursuit (MP) extends Principal Component Analysis to be invariant to a desired group of image-plane transformations of an ensemble of un-aligned images.  We derive a simple technique for projecting a misaligned target image onto the linear subspace defined by the superpositions of a collection of model images.  We show that it is possible to generate a fixed projection matrix which would separate the projected image into the aligned projected target and a residual image which accounts for the mis-alignment.  An iterative procedure is then introduced for eliminating the residual image and leaving the correct aligned projected target image.  Taken together, we demonstrate a simple and effective technique for obtaining invariance to image-plane transformations within a linear dimensionality reduction approach. 
Vision-based ACC with a Single Camera: Bounds on Range and Range Rate Accuracy| Abstract This paper describes a Vision-based Adaptive Cruise Control (ACC) system which uses a single camera as input.  In particular we discuss how to compute range and range-rate from a single camera and discuss how the imaging geometry affects the range and range rate accuracy.  We determine the bound on the accuracy given a particular configuration.  These bounds in turn determine what steps must be made to achieve good performance.  The system has been implemented on a test vehicle and driven on various highways over thousands of miles. 
Kernel Feature Selection with Side Data Using a Spectral Approach| to current methods we tested (PCA,OPCA,CPCA and SDR-SI). 
Ambiguity in Reconstruction from Images of Six Points| Abstract Let S be a set of six points in
A Robust Method for Computing Vehicle Ego-motion| Abstract We describe a robust method for computing the ego-motion of the vehicle relative to the road using input from a single camera mounted next to the rear view mirror.  Since feature points are unreliable in cluttered scenes we use direct methods where image values in the two images are combined in a global probability function.  Combined with the use of probability distribution matrices, this enables the formulation of a robust method that can ignore large number of outliers as one would encounter in real traffic situations.  The method has been tested in real world environments and has been shown to be robust to glare, rain and moving objects in the scene. 
3D Reconstruction from Tangent-of-Sight Measurements of a Moving Object Seen from a Moving Camera| Abstract Consider the situation of a monocular image sequence with known ego-motion observing a 3D point moving simultaneously but along a path of up to second order, i. e.  it can trace a line in 3D or a conic shapedpath.  We wish to reconstruct the 3D path from the projection of the tangent to the path at each time instance.  This problem is analogue to the \trajectory triangulation" of lines and conic sections recently introduced in [1, 3], but instead of observing a point projection we observe a tangent projection and thus obtain a far simpler solution to the problem.  We show that the 3D path can be solved in a natural manner, and linearly, using degenerate quadric envelopes - specifically the disk quadric.  Our approach works seamlessly with both linear and second order paths, thus thereisnoneed to know in advance the shape of the path as with the previous approaches for which lines and conics weretreated as distinct.  Our approach is linear in both straight line and conic paths, unlike the non-linear solution associated with point trajectory [3].  We provide experiments that show that our methodbehaves extremely well on a wide variety of scenarios, including those with multiple moving objects along lines and conic shapedpaths. 
Trajectory Triangulation over Conic Sections| Abstract We consider the problem of reconstructing the 3D coordinates of a moving point seen from a monocular moving camera, i. e. , to reconstruct moving objects from line-of-sight measurements only.  The task is feasible only when some constraints are placed on the shape of the trajectory of the moving point.  We coin the family of such tasks as \trajectory triangulation".  In this paper we focus on trajectories whose shapeisa conic-section and show that generally 9 views are suffficient for a unique reconstruction of the moving point and fewer views when the conic is a known type (like a circle in 3D Euclidean space for which 7 views are suffficient).  Experiments demonstrate that our solutions arepractical.  The paradigm of Trajectory Triangulation in general pushes the envelopeofprocessing dynamic scenes forward.  Thus static scenes becomeaparticular case of a more general task of reconstructing scenes rich with moving objects (where an object could be a single point). 
On the Synthesis of Dynamic Scenes from Reference Views| Abstract We consider a scene, containing many objects moving with constant velocity along straight line paths, seen from three reference viewpoints at three different times. The scene may even consist only of moving objects with no static features.  We wish to create a new image sequence showing the scene from arbitrary viewing position and arbitrary time.  We make use of a newly discovered tool, the "dual Htensor"[1], that connects together three views of a coplanar configuration of (unlabeled) static and moving points.  The newly synthesized images use constant velocity in the world to achive realistic and physically correct images. 
Homography Tensors: On Algebraic Entities that Represent Three Views of Static or Moving Planar Points| Abstract We introducea3 # 3 # 3 tensor H ijk and its dual H ijk which represent the 2D projective mapping of points across threeprojections (views).  The tensor H ijk is a generalization of the well known 2D collineation matrix (homography matrix) and it concatenates two homography matrices to represent the joint mapping across three views.  The dual tensor H ijk concatenates two dual homography matrices (mappings of line space) and is responsible for representing the mapping associated with moving points along straight-line paths, i. e. , H ijk can berecoveredfrom line-of-sight measurements only. 
On the Equivalence Between the Support Vector Machine for Classification and Sparsified Fisher's Linear Discriminant| Abstract.  We show that the orientation and location of the separating hyperplane for 2-class supervised pattern classification obtained by the Support Vector Machine (SVM) proposed byVapnik and his colleagues, is equivalent to the solution obtained by Fisher's Linear Discriminant on the set of Support Vectors.  In other words, SVM can be seen as a way to \sparsify" Fisher's Linear Discriminant in order to obtain the most generalizing classification from the training set. 
Multi-Frame Infinitesimal Motion Model for the Reconstruction of (Dynamic) Scenes with Multiple Linearly Moving Objects| Abstract We introduce new small-motion multi-frame equations applicable to the reconstruction of dynamic scenes in which points are allowed to move along straight-line paths with constant velocity.  The motion equations apply to both static and dynamic points, thus prior segmentation is not necessary.  We present a reconstruction algorithm of camera motion, scene structure, and point trajectories embedded into a multi-frame factorization principle which requires the minimum of 11 images and 7 points (out of which at least 3 are dynamic). 
Kernel Principal Angles for Classification Machines with Applications to Image Sequence Interpretation| Abstract We consider the problem of learning with instances defined over a space of sets of vectors.  We derive a new positive definite kernel f(A, B) defined over pairs of matrices A, B based on the concept of principal angles between two linear subspaces.  We show that the principal angles can be recovered using only inner-products between pairs of column vectors of the input matrices thereby allowing the original column vectors of A, B to be mapped onto arbitrarily high-dimensional feature spaces.  We apply this technique to inference over image sequences applications of face recognition and irregular motion trajectory detection. 
Structural saliency: The detection of globally salient structures using a locally connected network",Proc|
The Quotient Image: Class Based Recognition and Synthesis under Varying Illumination Conditions|
Geometry and Photometry in 3D Visual Recognition|
Correspondence and affine shape from two orthographic views: Motion and Recognition|
Projective depth: A geometric invariant for 3D reconstruction from two perspective/orthographic views and for visual recognition|
The Rank 4 Constraint in Multiple (>=3) View Geometry|
Trajectory Triangulation of Lines: Reconstruction of a 3D point Moving along a Line from a Monocular Image Sequence|
Novel View Synthesis by Cascading Trilinear Tensors|
Fundamental tensor: On the geometry of three perspective views|
Relative Affine Structure: Canonical Model for 3D From 2D Geometry and Applications|
Trilinearity in Visual Recognition by Alignment|
Relative Affine Structure: Theory and Application to 3D Reconstruction from Perspective|
Thereading fundamaental matrices|
Richly occluded scenes and the problem of reprojection versus reconstruction|
The generalized trilinear constraints and the uncertainty tensor|
Elimination: An Approach to the study of 3D-from-2|
On the Structure and Properties of the Quadrifocal Tensor| Computer Science and Engineering. 
The Quotient image: Class based recognition and synthesis under varying illumination|
Novel view synthesis in tensor space|
On geometric and algebraic aspects of 3D affine and projective structures from perspective 2D views|
Direct feature selection with implicit inference|
Learning over Sets using Kernel|
On projection matrices P k ! P 2 ; k = 3; : : : ; 6, and their applications in computer vision|
The rank4 constraint in multiple view geometry|
A geometric invariant for visual recognition and 3d reconstruction from two perspective/orthographic views,|
Join Tensors: On 3D-to-3D Alignment of Dynamic Sets|
Two-body Segmentation from Two Perspective Views|
Trilinear Constraints Revisited: Generalized Trilinear Constraints and the Tensor Brightness Constraint|
The Quadric Reference Surface: Applications in Registering Views of Complex 3D Objects|
Algebraic Description of Relative Affine Structure: Connections to Euclidean, Affine and Projective Structure|,. 
Multiple view geometry of algebraic curves|
N?4 camera geometry part I: rank consistency across trilinear tensors,|
D Reconstruction from Tangentof-Sight Measurements of a Moving Object Seen from a Moving Camera|
On the trilinear tensor of three perspective views and its associated tensor|
Image based view synthesis|
Threading Fundamental Matrices|
Direct methods for estimation of structure and motion from three views| Technical report,. 
Structural saliency|
View synthesis in tensor space|
Unifying two-view and three-view geometry|
The Study of 3D-from-2D Using Elimination|
Example Based Image Analysis and Synthesis", MIT AI-|
Pedestrian Detection for Driving Assistance Systems|
Poggio T, 1993 "Example-based image analysis and synthesis"|
\Trilinear tensor: The fundamental construct Fig| 9.  A few angles of a reconstructed face models. 
Grouping Contours by Iterated Pairing Networks|
Shapes Descriptors: Bilinear, Trilinear and Quadlinear Relations for Multi-Point Geometry, and Linear Projective Reconstruction Algorithms,|
Vision-based ACC with a Single Camera: Bounds on Range and Range Rate|
On projection matrices P^k #|
Algebraic derivations of relative affine structure and applications to 3d reconstruction from 2d views|
Correspondence and Ane Shape from two Orthographic Views:|
Structural saliency: The detection of globally salient structures using a locally connected network| Revised version,. 
On photometric issues to feature-based object recognition|
Novel view synthesis in sensor space,|
Unifying two-view and three-view geometry|InARPA,. 
Lecture notes on machine learning|
