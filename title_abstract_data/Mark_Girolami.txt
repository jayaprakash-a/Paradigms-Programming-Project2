On Kernel Principal Component Regression with Covariance Inflation Criterion for Model Selection| and other 'kernel' regression techniques is given and two benchmark problems demonstrate the comparable performance of CIC to cross-validation techniques.  In all reported experiments CIC provides the models with equal performance in comparison to Kernel RR.  Moreover, on a significant real world application, Kernel PCR with CIC resulted in smaller model compared to Kernel PCR with the cross-validation technique employed for the selection of principal components. 
Topic Identification in Dynamical Text by Complexity Pursuit| Abstract.  The problem of analysing dynamically evolving textual data has arisen within the last few years.  An example of such data is the discussion appearing in Internet chat lines.  In this Letter a recently introduced source separation method,termed as complexity pursuit, is applied to the problem of finding topics in dynamical text and is compared against several blind separation algorithms for the problem considered.  Complexity pursuit is a generalisation of projection pursuit to time series and it is able to use both higher-order statistical measures and temporal dependency information in separating the topics.  Experimental results on chat
Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles| Abstract To provide a compact generative representation of the sequential activity of a number of individuals within a group there is a tradeoff between the definition of individual specific and global models.  This paper proposes a linear-time distributed model for finite state symbolic sequences representing traces of individual user activity by making the assumption that heterogeneous user behavior may be `explained' by a relatively small number of common structurally simple behavioral patterns which may interleave randomly in a user-specific proportion.  The results of an empirical study on three different sources of user traces indicates that this modelling approach provides an efficient representation scheme, reflected by improved prediction performance as well as providing lowcomplexity and intuitively interpretable representations. 
Kernel PCA for Feature Extraction and De-Noising in Non-linear Regression| Abstract In this paper, we propose the application of the Kernel Principal Component Analysis (PCA) technique for feature selection in a high-dimensional feature space where input variables are mapped by a Gaussian kernel.  The extracted features are employed in the regression problems of chaotic Mackey-Glass time-series prediction in a noisy environment and estimating human signal detection performance from brain event-related potentials elicited by task relevant signals.  We compared results obtained using either Kernel PCA or linear PCA as data preprocessing steps.  On the human signal detection task we report the superiority of Kernel PCA feature extraction over linear PCA.  Similar to linear PCA we demonstrate de-noising of the original data by the appropriate selection of various non-linear principal components.  The theoretical relation and experimental comparison of Kernel Principal Components Regression, Kernel Ridge Regression and -insensitive Support Vector Regression is also provided. 
An Adaptive Support Vector Regression Filter: A Signal Detection Application| Abstract A new method for the construction of nonlinear adaptive filters called adaptive support vector regression is introduced for signal detection in noisy environments.  A modi#cation of support vector regression for online learning is motivated by the chunking approach and is based on repeated retraining of the filter parameters without the loss of former estimates.  Performance of the proposed method was found superior to the method using a Resource-Allocating RBF network with Givens QR decomposition and pruning [8]. 
Kernel PCA Feature Extraction of Event-Related Potentials for Human Signal Detection Performance| Abstract In this paper, we propose the application of the Kernel PCA technique for feature selection in high-dimensional feature space where input variables are mapped by a Gaussian kernel.  The extracted features are employed in the regression problem of estimating human signal detection performance from brain event-related potentials elicited by task relevant signals.  We report the superiority of Kernel PCA for feature extraction over linear PCA. 
An Expectation-Maximization Approach to Nonlinear Component Analysis| Abstract The proposal of considering nonlinear principal component
Biologically valid linear factor models of gene expression| ABSTRACT Motivation: The identification of physiological processes underlying and generating the expression pattern observed in microarray experiments is a major challenge.  Principal component analysis (PCA) is a linear multivariate statistical method that is regularly employed for that purpose as it provides a reduced-dimensional representation for subsequent study of possible biological processes responding to the particular experimental conditions.  Making explicit the data assumptions underlying PCA highlights their lack of biological validity thus making biological interpretation of the principal components problematic.  A microarray data representation which enables clear biological interpretation is a desirable analysis tool.  Results: We address this issue by employing the probabilistic interpretation of PCA and proposing alternative linear factor models which are based on refined biological assumptions.  A practical study on two well-understood microarray datasets highlights the weakness of PCA and the greater biological interpretability of the linear models we have developed.  Availability: The model estimation routines are currently implemented as Matlab routines and these, as well as data and results reported, are available from the following URL:
Negentropy and Kurtosis as Projection Pursuit Indices Provide Generalised ICA Algorithms| Abstract We develop a generalised form of the independent component analysis (ICA) algorithm introduced by Bell and Sejnowski [1], Amari et al [2] and lately by Pearlmutter and Parra [3] and also MacKay [4].  Motivated by information theoretic indices for exploratory projection pursuit (EPP) we show that maximisation by natural gradient ascent of the divergence of a multivariate distribution from normality, using the negentropy as a distance measure, yields a generalised ICA.  We introduce a form of nonlinearity which has an inherently simple form and exhibits the Bussgang property [30] within the algorithm.  We show that this is sufficient to perform ICA on data which has latent variables exhibiting either unimodal or bimodal probability density functions (PDF) or both.  Kurtosis has been used as a moment based projection pursuit index and as a contrast for ICA [5, 6, 7].  We introduce a simple adaptive nonlinearity which is formed by on-line estimation of the latent variable kurtosis and demonstrate the removal of the standard ICA constraint of latent variable pdf modality uniformity. 
Independent Component Analysis Using an Extended Infomax Algorithm for Mixed Sub-Gaussian and Super-Gaussian Sources| An extension of the infomax algorithm of Bell and Sejnowski (1995) is presented that is able blindly to separate mixed signals with sub- and supergaussian source distributions.  This was achieved by using a simple type of learning rule first derived by Girolami (1997) by choosing negentropy as a projection pursuit index.  Parameterized probability distributions that have sub- and supergaussian regimes were used to derive a general learning rule that preserves the simple architecture proposed by Bell and Sejnowski (1995), is optimized using the natural gradient by Amari (1998), and uses the stability analysis of Cardoso and Laheld (1996) to switch between sub- and supergaussian regimes.  We demonstrate that the extended infomax algorithm is able to separate 20 sources with a variety of source distributions easily.  Applied to high-dimensional data from electroencephalographic recordings, it is effective at separating artifacts such as eye blinks and line noise from weaker electrical signals that arise from sources in the brain. 
Extraction of Sleep-Spindles from the Electroencephalogram (EEG)| Abstract Independent component analysis (ICA) is a powerful tool for separating signals from their observed mixtures.  This area of research has produced many varied algorithms and approaches to the solution of this problem.  The majority of these methods adopt a truly blind approach and disregard available a priori information in order to extract the original sources or a specific desired signal.  In this contribution we propose a fixed point algorithm which utilizes a priori information in finding a specified signal of interest from the sensor measurements.  This technique is applied to the extraction and channel isolation of sleep spindles from a multi-channel electroencephalograph (EEG). 
A Combined Latent Class and Trait Model for the Analysis and Visualization of Discrete Data| Abstract We present a general framework for data analysis and visualisation by means of topographic organization and clustering.  Imposing distributional assumptions on the assumed underlying latent factors makes the proposed model suitable for both visualisation and clustering.  The system's noise will be modeled in parametric form, as a member of the exponential family of distributions and this allows us to deal with different (continuous or discrete) types of observables in a unified framework.  In this paper we focus on discrete case formulations which, contrary to self organizing methods for continuous data, imply variants of Bregman divergencies as measures of dissimilarity between data and reference points, and also define the matching nonlinear relation between latent and observable variables.  Therefore, the trait variant of the model can be seen as a data-driven noisy nonlinear Independent Component Analysis, which is capable of revealing meaningful structure in the multivariate observable data and visualise it in two dimensions.  The class variant (which performs the clustering) of our model performs data-driven parametric mixture modeling.  The combined (trait and class) model along with the associated estimation procedures allows us to interpret the visualisation result, in the sense of a topographic ordering.  One important application of this work is the discovery of underlying semantic structure in text based documents.  Experimental results on various subsets of the Twenty-Newsgroups text corpus and binary coded digits data are given by way of demonstration. 
Finding Topics in Dynamical Text: Application to Chat Line Discussions| ABSTRACT The problem of analysing dynamically evolving textual data has recently arisen.  An example of such data is the discussion appearing in Internet chat lines.  In this paper a recently introduced method, termed complexity pursuit, is used to extract the topics of a dynamical chat line discussion.  Experimental results demonstrate that meaningful topics can be found and also suggest the applicability of the method to query-based retrieval from a temporally changing text stream. 
On an equivalence between PLSI and LDA| ABSTRACT Latent Dirichlet Allocation (LDA) is a fully generative approach to language modelling which overcomes the inconsistent generative semantics of Probabilistic Latent Semantic Indexing (PLSI).  This paper shows that PLSI is a maximum a posteriori estimated LDA model under a uniform Dirichlet prior, therefore the perceived shortcomings of PLSI can be resolved and elucidated within the LDA framework. 
Sequential Activity Profiling : Latent Dirichlet Allocation of Markov Chains| Abstract To provide a parsimonious generative representation of the sequential activity of a number of individuals within a population there is a necessary tradeoff between the definition of individual specific and global representations.  A linear-time algorithm is proposed that defines a distributed predictive model for finite state symbolic sequences which represent the traces of the activity of a number of individuals within a group.  The algorithm is based on a straightforward generalization of latent Dirichlet allocation to time-invariant Markov chains of arbitrary order.  The modelling assumption made is that the possibly heterogeneous behavior of individuals may be represented by a relatively small number of simple and common behavioral traits which may interleave randomly according to an individual-specific distribution.  The results of an empirical study on three different application domains indicate that this modelling approach provides an efficient low-complexity and intuitively interpretable representation scheme which is reflected by improved prediction performance over comparable models. 
Orthogonal Series Density Estimation and the Kernel Eigenvalue Problem|
A common neural network model for unsupervised exploratory data analysis and independent component analysis|
Fast Extraction of Semantic Features from a Latent Semantic Indexed Text Corpus|
A Probabilistic Framework for the Hierarchic Organisation and Classification of Document Collections|
An Alternative Perspective on Adaptive Independent Component Analysis Algorithms|
A Variational Method for Learning Sparse and Overcomplete Representations|
A Temporal Model of Linear Anti-Hebbian Learning|
A Combined Latent Class and Trait Model for the Analysis and Visualization of Discrete Data|
Latent class and trait models for data classification and visualisation|
A Unifying InformationTheoretic Framework For Independent Component Analysis,|
An Assessment of Feature Relevance in Predicting Protein Function from Sequence|
A General Framework for a Principled Hierarchical Visualization of Multivariate Data|
Probability Density Estimation from Optimally Condensed Data Samples|
jnowski, "Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources,|
