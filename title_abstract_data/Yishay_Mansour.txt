Combining online algorithms for rejection and acceptance| ABSTRACT Resource allocation and admission control are critical tasks in a communication network, that often must be performed online.  Algorithms for these types of problems have been considered both under benefit models (e. g. , with a goal of approximately maximizing the number of calls accepted) and under cost models (e. g. , with a goal of approximately minimizing the number of calls rejected).  Unfortunately, algorithms designed for these two measures can often be quite different, even polar opposites (e. g. , [1, 8]).  In this work we consider the problem of combining algorithms designed for each of these objectives in a way that simultaneously is good under both measures.  More formally, we are given an algorithm A which is cA competitive w. r. t.  the number of accepted calls and an algorithm R which is cR competitive w. r. t.  the number of rejected calls.  We derive a combined algorithm whose competitive ratio is O(cRcA) for rejection and O(c 2 A ) for acceptance.  We also show building on known techniques that given a collection of k algorithms, we can construct one master algorithm which performs similar to the best algorithm among the k for the acceptance problem and another master algorithm which performs similar to the best algorithm among the k for the rejection problem.  Using our main result we can combine the two master algorithms to a single algorithm which guarantees both rejection and acceptance competitiveness. 
Experts in a Markov Decision Process| Abstract We consider an MDP setting in which the reward function is allowed to change during each time step of play (possibly in an adversarial manner), yet the dynamics remain fixed.  Similar to the experts setting, we address the question of how well can an agent do when compared to the reward achieved under the best stationary policy over time.  We provide efficient algorithms, which have regret bounds with no dependence on the size of state space.  Instead, these bounds depend only on a certain horizon time of the process and logarithmically on the number of actions.  We also show that in the case that the dynamics change over time, the problem becomes computationally hard. 
Simple Learning Algorithms for Decision Trees and Multivariate Polynomials| Abstract In this paper we develop a new approach for learning decision trees and multivariate polynomials via interpolation of multivariate polynomials.  This new approach yields simple learning algorithms for multivariate polynomials and decision trees over finite fields under any constant bounded product distribution.  The output hypothesis is a (single) multivariate polynomial that is an ffl-approximation of the target under any constant bounded product distribution.  The new approach demonstrates the learnability of many classes under any constant bounded product distribution and using membership queries, such as j-disjoint DNF's and multivariate polynomials with bounded degree over any field.  The technique shows how to interpolate multivariate polynomials with bounded term size from membership queries only.  This in particular gives a learning algorithm for O(log n)-depth decision tree from membership queries only and a new learning algorithm of any multivariate polynomial over sufficiently large fields from membership queries only.  We show that our results for learning from membership queries only are the best possible. 
An Omega( log ()) Lower Bound for Broadcast in Radio Networks| Abstract We show that for any randomized broadcast protocol for radio networks, there exists a network in which the expected time to broadcast a message is \Omega(D log(N=D)), where D is the diameter of the network and N is the number of nodes.  This implies a tight lower bound of \Omega(D log N) for any D N 1\Gamma '' , where '' ? 0 is any constant. 
Competitive Queue Policies for Differentiated Services| Abstract We consider the setting of a network providing differentiated services.  As is often the case in differentiated services, we assume that the packets are tagged as either being a high priority packet or a low priority packet.  Outgoing links in the network are serviced by a single FIFO queue.  Our model gives a benefit of ff 1 to each high priority packet and a benefit of 1 to each low priority packet.  A queue policy controls which of the arriving packets are dropped and which enter the queue.  Once a packet enters the queue it is eventually sent.  The aim of a queue policy is to maximize the sum of the benefits of all the packets it sends.  We analyze and compare different queue policies for this problem using the competitive analysis approach, where the benefit of the online policy is compared to the benefit of an optimal offline policy.  We derive both upper and lower bounds for the policies we consider.  We believe that competitive analysis gives important insight to the performance of these queuing policies. 
A Construction of a Cipher from a Single Pseudorandom Permutation| Abstract We suggest a scheme for a block cipher which uses only one randomly chosen permutation, F .  The key, consisting of two blocks, K 1 and K 2 is used in the following way: The message block is XORed with K 1 before applying F , and the outcome is XORed with K 2 , to produce the cryptogram block.  We show that the resulting cipher is secure (when the permutation is random or pseudorandom).  This removes the need to store, or generate a multitude of permutations. 
Improved combination of online algorithms for acceptance and rejection| ABSTRACT Given two admission control algorithms that are cA-acceptcompetitive and cR-reject-competitive respectively, we give two ways to make an algorithm that is simultaneously O(cA )accept-competitive and O(cAcR)-reject-competitive.  The combined algorithms make no reference to the offline optimal solution.  In addition, one of the algorithms does not require knowing the value of either cA or cR .  This improves on work of Azar, Blum, and Mansour, whose combined algorithm was O(c 2 A )-accept-competitive, involved computing offline optimal solutions, and required knowing the values of both cA and cR . 
Adaptive AIMD Congestion Control [Extended Abstract]| ABSTRACT The main objectives of a congestion control algorithm are high bandwidth utilization, fairness and responsiveness in changing environment.  However, these objectives are contradicting in particular situations since the algorithm has to constantly probe available bandwidth, which may affect its stability.  This paper proposes a novel congestion control algorithm that achieves high bandwidth utilization providing fairness among competing connections and, on the other hand, is sufficiently responsive to changes of available bandwidth.  The main idea of the algorithm is to use adaptive setting for the additive increase/multiplicative decrease (AIMD) congestion control scheme, where parameters may change dynamically, with respect to the current network conditions. 
Lower bounds for randomized mutual exclusion| We establish, for the first time, lower bounds for randomized mutual exclusion algorithms (with a read-modify-write operation).  Our main result is that a constant-size shared variable cannot guarantee strong fairness, even if randomization is allowed.  In fact, we prove a lower bound of \Omega(log log n) bits on the size of the shared variable, which is also tight.  We investigate weaker fairness conditions and derive tight (upper and lower) bounds for them as well.  Surprisingly, it turns out that slightly weakening the fairness condition results in an exponential reduction in the size of the required shared variable.  Our lower bounds rely on an analysis of Markov chains that may be of interest on its own and may have applications elsewhere. 
Adaptive AIMD congestion control| Abstract The main objectives of a congestion control algorithm are high bandwidth utilization, fairness and responsiveness in changing environment.  However, these objectives are contradicting in particular situations since the algorithm has to constantly probe available bandwidth, which may affect its stability.  This paper proposes a novel congestion control algorithm that achieves high bandwidth utilization providing fairness among competing connections and, on the other hand, is sufficiently responsive to changes of available bandwidth.  The main idea of the algorithm is to use adaptive setting for the Additive Increase/Multiplicative Decrease (AIMD) congestion control scheme, where parameters may change dynamically, with respect to the current network conditions. 
Approximate Equivalence of Markov Decision Processes| Abstract.  We consider the problem of finding the minimal -equivalent MDP for an MDP given in its tabular form.  We show that the problem is NP-Hard and then give a bicriteria approximation algorithm to the problem.  We suggest that the right measure for finding minimal -equivalent model is L1 rather than L1 by giving both an example, which demonstrates the drawback of using L1 , and performance guarantees for using L1 .  In addition, we give a polynomial algorithm that decides whether two MDPs are equivalent. 
On the Boosting Ability of Top-Down Decision Tree Learning Algorithms| Abstract We analyze the performance of top-down algorithms for decision tree learning, such as those employed by the widely used C4. 5 and CART software packages.  Our main result is a proof that such algorithms are boosting algorithms.  By this we mean that if the functions that label the internal nodes of the decision tree can weakly approximate the unknown target function, then the top-down algorithms we study will amplify this weak advantage to build a tree achieving any desired level of accuracy.  The bounds we obtain for this amplification show an interesting dependence on the splitting criterion used by the top-down algorithm.  More precisely, if the functions used to label the internal nodes have error 1=2\Gamma fl as approximations to the target function, then for the splitting criteria used by CART and C4. 5, trees of size (1=ffl) O(1=fl 2 ffl 2 ) and (1=ffl) O(log(1=ffl)=fl 2 ) (respectively) suffice to drive the error below ffl.  Thus (for example), a small constant advantage over random guessing is amplified to any larger constant advantage with trees of constant size.  For a new splitting criterion suggested by our analysis, the much stronger bound of (1=ffl) O(1=fl 2 ) (which is polynomial in 1=ffl) is obtained, which is provably optimal for decision tree algorithms.  The differing bounds have a natural explanation in terms of concavity properties of the splitting criterion.  The primary contribution of this work is in proving that some popular and empirically successful heuristics that are based on first principles meet the criteria of an independently motivated theoretical model. 
An O(n log log n ) Learning Algorithm for DNF under the Uniform Distribution| Abstract We show that a DNF with terms of size at most d can be approximated by a function with at most d O(d log 1=") non zero Fourier coefficients such that the expected error squared, with respect to the uniform distribution, is at most ''.  This property is used to derive a learning algorithm for DNF, under the uniform distribution.  The learning algorithm uses queries and learns, with respect to the uniform distribution, a DNF with terms of size at most d in time polynomial in n and d O(d log 1=") .  The interesting implications are for the case when '' is constant.  In this case our algorithm learns a DNF with a polynomial number of terms in time n O(log log n) , and a DNF with terms of size at most O(log n= log log n) in polynomial time. 
Policy Gradient Methods for Reinforcement Learning with Function Approximation| Abstract Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable.  In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters.  Williams's REINFORCE method and actor--critic methods are examples of this approach.  Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function.  Using this result, we prove for the first time that a version of policy iteration with arbitrary dierentiable function approximation is convergent to a locally optimal policy.  Large applications of reinforcement learning (RL) require the use of generalizing function approximators such neural networks, decision-trees, or instance-based methods.  The dominant approach for the last decade has been the value-function approach, in which all function approximation eort goes into estimating a value function, with the action-selection policy represented implicitly as the "greedy" policy with respect to the estimated values (e. g. , as the policy that selects in each state the action with highest estimated value).  The value-function approach has worked well in many applications, but has several limitations.  First, it is oriented toward finding deterministic policies, whereas the optimal policy is often stochastic, selecting dierent actions with specific probabilities (e. g. , see Singh, Jaakkola, and Jordan, 1994).  Second, an arbitrarily small change in the estimated value of an action can cause it to be, or not be, selected.  Such discontinuous changes have been identified as a key obstacle to establishing convergence assurances for algorithms following the value-function approach (Bertsekas and Tsitsiklis, 1996).  For example, Q-learning, Sarsa, and dynamic programming methods have all been shown unable to converge to any policy for simple MDPs and simple function approximators (
On the Convergence Complexity of Optimistic Rate Based Flow Control Algorithms (Brief Announcement)| Abstract This paper studies basic properties of rate based flow-control algorithms and of the maxmin fairness criteria.  For the algorithms we suggest a new approach for their modeling and analysis, which may be considered more "optimistic" and realistic than traditional approaches.  Three variations of the approach are presented and their rate of convergence to the optimal max-min fairness solution is analyzed.  In addition, we introduce and analyze approximate rate based flow control algorithms.  We show that under certain conditions the approximate algorithms may converge faster.  However, we show that the resulting flows may be substantially different than the flows dictated by the max-min fairness.  We further demonstrate that the max-min fairness solution can be very sensitive to small changes, i. e. , there are configurations in which an addition or deletion of a session with rate ffi may change the allocation of another session by \Omega(ffi \Delta 2 n 2 ), but by no more than O(ffi \Delta 2 n ).  This implies that the max-min fairness criteria may provide a bad estimate of how far a set of flow allocations is from the optimal allocation. 
Improved Competitive Guarantees for QoS Buffering| Abstract We consider a network providing Differentiated Services (Diffserv) which allow Internet service providers (ISP) to offer different levels of Quality of Service (QoS) to different traffic streams.  We study two types of buffering policies that are used in network switches supporting QoS.  In the FIFO type, packets must be transmitted in the order they arrive.  In the bounded-delay type, each packet has a maximum delay time by which it must be transmitted, or otherwise it is lost.  In both models, the buffer space is limited, and packets are lost if the buffer is full.  Each packet has an intrinsic value, and the goal is to maximize the total value of transmitted packets.  Our main contribution is an algorithm for the FIFO model for arbitrary packet values that for the first time achieves a competitive ratio better than 2, namely 2- # for a constant # } 0.  We also describe an algorithm for the bounded delay model that simulates our algorithm for the FIFO model, and show that it achieves the same competitive ratio. 
Nash Convergence of Gradient Dynamics in General-Sum Games| Abstract Multi-agent games are becoming an increasingly prevalent formalism for the study of electronic commerce and auctions.  The speed at which transactions can take place and the growing complexity of electronic marketplaces makes the study of computationally simple agents an appealing direction.  In this work, we analyze the behavior of agents that incrementally adapt their strategy through gradient ascent on expected payoff, in the simple setting of two-player, two-action, iterated general-sum games, and present a surprising result.  We show that either the agents will converge to a Nash equilibrium, or if the strategies themselves do not converge, then their average payoffs will nevertheless converge to the payoffs of a Nash equilibrium. 
A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization| Abstract In this work, we present a new bottom-up algorithm for decision tree pruning that is very efficient (requiring only a single pass through the given tree), and prove a strong performance guarantee for the generalization error of the resulting pruned tree.  Wework in the typical setting in which the given tree T mayhave been derived from the given training sample S, and thus may badly over#t S.  In this setting, we give bounds on the amount of additional generalization error that our pruning suffers compared to the optimal pruning of T .  More generally, our results show that if there is a pruning of T with small error, and whose size is small compared to jSj, then our algorithm will find a pruning whose error is not much larger.  This style of result has been called an index of resolvability result by Barron and Cover in the context of density estimation.  Anovel feature of our algorithm is its locality --- the decision to prune a subtree is based entirely on properties of that subtree and the sample reaching it.  To analyze our algorithm, we develop tools of local uniform convergence,a generalization of the standard notion that may prove useful in other settings. 
On Diffusing Updates in a Byzantine Environment| Abstract We study how to efficiently diffuse updates to a large distributed system of data replicas, some of which may exhibit arbitrary (Byzantine) failures.  We assume that strictly fewer than t replicas fail, and that each update is initially received by at least t correct replicas.  The goal is to diffuse each update to all correct replicas while ensuring that correct replicas accept no updates generated spuriously by faulty replicas.  To achieve reliable diffusion, each correct replica accepts an update only after receiving it from at least t others.  We provide the first analysis of epidemic-style protocols for such environments.  This analysis is fundamentally different from known analyses for the benign case due to our treatment of fully Byzantine failures---which, among other things, precludes the use of digital signatures for authenticating forwarded updates.  We propose two epidemic-style diffusion algorithms and two measures that characterize the efficiency of diffusion algorithms in general.  We characterize both of our algorithms according to these measures, and also prove lower bounds with regards to these measures that show that our algorithms are close to optimal. 
Online Learning versus Offline Learning| Abstract.  We present an off-line variant of the mistake-bound model of learning.  Just like in the well studied on-line model, a learner in the offline model has to learn an unknown concept from a sequence of elements of the instance space on which he makes "guess and test" trials.  In both models, the aim of the learner is to make as few mistakes as possible.  The difference between the models is that, while in the on-line model only the set of possible elements is known, in the off-line model the sequence of elements (i. e. , the identity of the elements as well as the order in which they are to be presented) is known to the learner in advance.  We give a combinatorial characterization of the number of mistakes in the off-line model.  We apply this characterization to solve several natural questions that arise for the new model.  First, we compare the mistake bounds of an off-line learner to those of a learner learning the same concept classes in the on-line scenario.  We show that the number of mistakes in the on-line learning is at most a log n factor more than the off-line learning, where n is the length of the sequence.  In addition, we show that if there is an off-line algorithm that does not make more than a constant number of mistakes for each sequence then there is an online algorithm that also does not make more than a constant number of mistakes.  The second issue we address is the effect of the ordering of the elements on the number of mistakes of an off-line learner.  It turns out that there are sequences on which an off-line learner can guarantee at most one mistake, yet a permutation of the same sequence forces him to err on many elements.  We prove, however, that the gap, between the off-line mistake bounds on permutations of the same sequence of n-many elements, cannot be larger than a multiplicative factor of log n,
Optimizing TCP Retransmission Timeout| Abstract--- Delay spikes on Internet paths can cause spurious TCP timeouts leading to significant throughput degradation.  However, if TCP is too slow to detect that a retransmission is necessary, it can stay idle for a long time instead of transmitting.  The goal is to find a Retransmission Timeout (RTO) value that balances the throughput degradation between both of these cases.  In the current TCP implementations, RTO is a function of the Round Trip Time (RTT) alone.  We show that the optimal RTO that maximizes the TCP throughput need to depend also on the TCP window size.  Intuitively, the larger the TCP window size, the longer the optimal RTO.  We derive the optimal RTO for several RTT distributions.  An important advantage of our algorithm is that it can be easily implemented based on the existing TCP timeout mechanism. 
Competitve buffer management for shared-memory switches| ABSTRACT We consider buffer management policies for shared memory packet switches supporting Quality of Service (QoS).  There are two interesting dimensions in which the setting may different.  The first is the packet size, whether all the packets of the same fixed size or do packets have variable length.  The second is the value of the packets, do all the packets have the same value or do different packets have different values.  The goal of the buffer management policy is to maximize the total value of packets transmitted.  Our main result is to show that the well-known Longest Queue Drop (LQD) policy is 2-competitive and at least p 2-competitive for the case of fixed size and value packets.  We also show a 4=3 general lower bound on the competitiveness in this case.  We extend the results to the case of variable size fixed value packets, and derive a slightly worse bound.  For the case of variable value we derive randomized policy whose competitive ratio is logarithmic on the ratio of the maximal to minimal value. 
Dynamic Bandwidth Allocation Policies \Lambda| Abstract When traffic of connectionless best effort protocols such as IP is carried over connection oriented protocols with guaranteed bandwidth, such as CBR connection in ATM, the interface layer between the protocols (i. e. , AAL - the ATM Adaption Layer) need to specify the bandwidth requirement and the duration of the bandwidth reservation.  The purpose of this paper is to develop policies for deciding and for adjusting the amount of bandwidth requested for a best effort connection over such networks.  Our aim is to develop such policies that achieve a good trade off between latency and utilization.  The performances of the different policies are compared by an empirical evaluation. 
From External to Internal Regret| Abstract.  External regret compares the performance of an online algorithm, selecting among N actions, to the performance of the best of those actions in hindsight.  Internal regret compares the loss of an online algorithm to the loss of a modified online algorithm, which consistently replaces one action by another.  In this paper, we give a simple generic reduction that, given an algorithm for the external regret problem, converts it to an efficient online algorithm for the internal regret problem.  We provide methods that work both in the full information model, in which the loss of every action is observed at each time step, and the partial information (bandit) model, where at each time step only the loss of the selected action is observed.  The importance of internal regret in game theory is due to the fact that in a general game, if each player has sublinear internal regret, then the empirical frequencies converge to a correlated equilibrium.  For external regret we also derive a quantitative regret bound for a very general setting of regret, which includes an arbitrary set of modification rules (that possibly modify the online algorithm) and an arbitrary set of time selection functions (each giving different weight to each time step).  The regret for a given time selection and modification rule is the difference between the cost of the online algorithm and the cost of the modified online algorithm, where the costs are weighted by the time selection function.  This can be viewed as a generalization of the previously-studied sleeping experts setting. 
Predicting and bypassing end-to-end internet service degradations| Abstract We study the patterns and predictability of Internet End-to-End service degradations, where a degradation is a significant deviation of the round trip time between a client and a server.  We use simultaneous RTT measurements collected from several locations to a large representative set of Web sites and study the duration and extent of degradations.  We combine these measurements with BGP cluster information to learn on the location of the cause.  We evaluate a number of predictors based upon Hidden Markov Models and Markov Models.  Predictors typically exhibit a tradeoff between two types of errors, false positives (incorrect degradation prediction) and false negatives (a degradation is not predicted).  The costs of these error-types is application dependent, but we capture the entire spectrum using a precision versus recall tradeoff.  Using this methodology, we learn what information is most valuable for prediction (recency versus quantity of past measurements).  Surprisingly, we also conclude that predictors that utilize history in a very simple way perform as well as more sophisticated ones.  One important application of prediction is gateway selection, which is applicable when a LAN is connected through multiple gateways to one or several ISP's.  Gateway selection can boost reliability and survivability by selecting for each connection the (hopefully) best gateway.  We show that gateway selection using our predictors can reduce the degradations to half of that obtained by routing all the connections through the best gateway. 
Fast Convergence of Selfish Rerouting| Abstract We consider n anonymous selfish users that route their communication through m parallel links.  The users are allowed to reroute, concurrently, from overloaded links to underloaded links.  The dierent rerouting decisions are concurrent, randomized and independent.  The rerouting process terminates when the system reaches a Nash equilibrium, in which no user can improve its state.  We study the convergence rate of several migration policies.  The first is a very natural policy, which balances the expected load on the links, for the case that all users are identical and apply it, we show that the rerouting terminates in expected O(log log n + log m) stages.  Later, we consider the Nash rerouting policies class, in which every rerouting stage is a Nash equilibrium and the users are greedy with respect to the next load they observe.  We show a similar termination bounds for this class.  We study the structural properties of the Nash rerouting policies, and derive both existence result and an ecient algorithm for the case that the number of links is small.  We also show that if the users have dierent weights then there exists a set of weights such that every Nash rerouting terminates in -( p n) stages with high probability . 
Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries| Abstract We study the problem of efficiently learning to play a game optimally against an unknown adversary chosen from a computationally bounded class.  We both contribute to the line of research on playing games against finite automata, and expand the scope of this research by considering new classes of adversaries.  We introduce the natural notions of games against recent history adversaries (whose current action is determined by some simple boolean formula on the recent history of play), and games against statistical adversaries (whose current action is determined by some simple function of the statistics of the entire history of play).  In both cases we give efficient algorithms for learning to play penny-matching and a more difficult game called contract .  We also give the most powerful positive result to date for learning to play against finite automata, an efficient algorithm for learning to play any game against any finite automata with probabilistic actions and low cover time. 
Implementation Issues in the Fourier Transform Algorithm| Abstract The Fourier transform of boolean functions has come to play an important role in proving many important learnability results.  We aim to demonstrate that the Fourier transform techniques are also a useful and practical algorithm in addition to being a powerful theoretical tool.  We describe the more prominent changes we have introduced to the algorithm, ones that were crucial and without which the performance of the algorithm would severely deteriorate.  One of the benefits we present is the confidence level for each prediction which measures the likelihood the prediction is correct. 
Centralized broadcast in multihop radio networks| Abstract We show that for any radio network there exists a schedule of a broadcast whose time is O(D+log 5
Greedy Packet Scheduling| Next, tight time bounds of d + k\Gamma 1 are proved for a specific greedy algorithm on the class of shortest paths in n-vertex networks.  Finally it is shown that when the routes are arbitrary, the time achieved by various "natural" greedy algorithms can be as bad as \Omega(d p k + k), for any k, and even for d = \Omega(n). 
Learning Under Persistent Drift| Abstract.  In this paper we study learning algorithms for environments which are changing over time.  Unlike most previous work, we are interested in the case where the changes might be rapid but their "direction" is relatively constant.  We model this type of change by assuming that the target distribution is changing continuously at a constant rate from one extreme distribution to another.  We show in this case how to use a simple weighting scheme to estimate the error of an hypothesis, and using this estimate, to minimize the error of the prediction. 
Centrum voor Wiskunde en Informatica Software ENgineering Improved Competitive Guarantees for QoS Buffering| CWI's research has a theme-oriented structure and is grouped into four clusters.  Listed below are the names of the clusters and in parentheses their acronyms. 
Jitter Control in QoS Networks \Lambda EXTENDED ABSTRACT| Abstract We study jitter control in networks guaranteeing quality of service (QoS).  Jitter measures variability of delivery times in packet streams.  We propose on-line algorithms that control jitter and compare their performance to the best possible (by an off-line algorithm) for any given arrival sequence.  For delay jitter, where the goal is to minimize the difference between delay times of different packets, we give an on-line algorithm using buffer size of 2B which guarantees the same delay-jitter as an off-line algorithm using buffer space B.  We show that 2B space is the minimum space required by any on-line algorithm to provide delayjitter related to the best possible delay-jitter using B buffer space.  We also show that the guarantees made by our online algorithm hold even for distributed implementations, where the total buffer space is distributed along the path of the connection, provided that the input stream satisfies a certain simple property.  For rate jitter, where the goal is to minimize the difference between inter-arrival times, we develop an on-line algorithm using a buffer of size 2B + h for any h 1, and compare its jitter to the jitter of an optimal off-line algorithm using buffer size B.  Our algorithm guarantees that the difference is bounded by a term proportional to B=h.  We also prove that 2B space is necessary for on-line algorithms with non-trivial guarantees for rate-jitter control. 
PAC Bounds for Multi-armed Bandit and Markov Decision Processes| Abstract.  The bandit problem is revisited and considered under the PAC model.  Our main contribution in this part is to show that given n arms, it suffices to pull the arms O( n # 2
Jitter Control in QoS Networks| Abstract| We study jitter control in networks with guaranteed quality of service (QoS) from the competitive analysis point of view: We propose on-line algorithms that control jitter and compare their performance to the best possible (by an off-line algorithm) for any given arrival sequence.  For delay jitter, where the goal is to minimize the difference between delay times of different packets, we show that a simple on-line algorithm using buffer of B slots guarantees the same delay-jitter as the best off-line algorithm using buffer space B=2.  We prove that the guarantees made by our on-line algorithm hold even for simple distributed implementations, where the total buffer space is distributed along the path of the connection, provided that the input stream satisfies a certain simple property.  For rate jitter, where the goal is to minimize the difference between inter-arrival times, we develop an on-line algorithm using a buffer of size 2B + h for any h # 1, and compare its jitter to the jitter of an optimal off-line algorithm using buffer size B.  We prove that our algorithm guarantees that the difference is bounded by a term proportional to B=h. 
An Information-Theoretic Analysis of Hard and Soft Assignment Methods for Clustering| Abstract Assignment methods are at the heart of many algorithms for unsupervised learning and clustering --- in particular, the well-known K-means and Expectation-Maximization (EM) algorithms.  In this work, we study several different methods of assignment, including the "hard" assignments used by K-means and the "soft" assignments used by EM.  While it is known that K-means minimizes the distortion on the data and EM maximizes the likelihood, little is known about the systematic differences of behavior between the two algorithms.  Here we shed light on these differences via an information-theoretic analysis.  The cornerstone of our results is a simple decomposition of the expected distortion, showing that K-means (and its extension for inferring general parametric densities from unlabeled sample data) must implicitly manage a trade-off between how similar the data assigned to each cluster are, and how the data are balanced among the clusters.  How well the data are balanced is measured by the entropy of the partition defined by the hard assignments.  In addition to letting us predict and verify systematic differences between K-means and EM on specific examples, the decomposition allows us to give a rather general argument showing that K-means will consistently find densities with less "overlap" than EM.  We also study a third natural assignment method that we call posterior assignment, that is close in spirit to the soft assignments of EM, but leads to a surprisingly different algorithm. 
Buffer Overflows of Merging Streams| Abstract.  We consider a network merging streams of packets with different quality of service (QoS) levels, where packets are transported from input links to output links via multiple merge stages.  Each merge node is equipped with a finite buffer, and since the bandwidth of a link outgoing from a merge node is in general smaller than the sum of incoming bandwidths, overflows may occur.  QoS is modeled by assigning a positive value to each packet, and the goal of the system is to maximize the total value of packets transmitted on the output links.  We assume that each buffer runs an independent local scheduling policy, and analyze FIFO policies that must deliver packets in the order they were received.  We show that a simple local on-line algorithm called Greedy does essentially as well as the combination of locally optimal (off-line) schedules.  We introduce a concept we call the weakness of a link, defined as the ratio between the longest time a packet spends in the system before transmitted over the link, and the longest time a packet spends in that link's buffer.  We prove that for any tree, the competitive factor of Greedy is at most the maximal link weakness. 
Approximate Planning in Large POMDPs via Reusable Trajectories| Abstract We consider the problem of reliably choosing a near-best strategy from a restricted class of strategies \Pi in a partially observable Markov decision process (POMDP).  We assume we are given the ability to simulate the POMDP, and study what might be called the sample complexity --- that is, the amount of data one must generate in the POMDP in order to choose a good strategy.  We prove upper bounds on the sample complexity showing that, even for infinitely large and arbitrarily complex POMDPs, the amount of data needed can be finite, and depends only linearly on the complexity of the restricted strategy class \Pi, and exponentially on the horizon time.  This latter dependence can be eased in a variety of ways, including the application of gradient and local search algorithms.  Our measure of complexity generalizes the classical supervised learning notion of VC dimension to the settings of reinforcement learning and planning. 
Buffer Overflow Management in QoS Switches| Abstract We consider two types of buffering policies that are used in network switches supporting QoS (Quality of Service).  In the FIFO type, packets must be released in the order they arrive; the difficulty in this case is the limited buffer space.  In the bounded-delay type, each packet has a maximum delay time by which it must be released, or otherwise it is lost.  We study the cases where the incoming streams overload the buffers, resulting in packet loss.  In our model, each packet has an intrinsic value; the goal is to maximize the total value of packets transmitted Our main contribution is a thorough investigation of the natural greedy algorithms in various models.  For the FIFO model we prove tight bounds on the competitive ratio of the greedy algorithm that discards the packets with the lowest value.  We also prove that the greedy algorithm that drops the earliest packets among all low-value packets is the best greedy algorithm.  This algorithm can be as much as 1:5 times better than the standard tail-drop policy, that drops the latest packets.  In the bounded delay model we show that the competitive ratio of any online algorithm for a uniform bounded delay buffer is bounded away from 1, independent of the delay size.  We analyze the greedy algorithm in the general case and in three special cases: delay bound 2; link bandwidth 1; and only two possible packet values.  Finally, we consider the off-line scenario.  We give efficient optimal algorithms and study the relation between the bounded-delay and FIFO models in this case. 
Almost k-wise independence versus k-wise independence| Abstract We say that a distribution over f0; 1g n is almost k-wise independent if its restriction to every k coordinates results in a distribution that is close to the uniform distribution.  A natural question regarding almost k-wise independent distributions is how close they are to some k-wise independent distribution.  We show that the latter distance is essentially n \Theta(k) times the former distance. 
Harmonic buffer management policy for shared memory switches| Abstract In this paper we consider shared-memory switches.  We introduce a novel general non-preemptive buffer management scheme, which considers the queues ordered by their size.  We propose a new scheduling policy, based on our general scheme, which we call the Harmonic policy.  We analyze the performance of the Harmonic policy by means of competitive analysis and demonstrate that its throughput competitive ratio is at most ln(N) + 2, where N is the number of output ports.  We also present a lower bound of #(log N= log log N) on the performance of any online deterministic policy.  Our simulations also show that the Harmonic policy achieves high throughput and easily adapts to changing load conditions. 
Learning with Maximum-Entropy Distributions \Lambda| Abstract We are interested in distributions which are derived as a maximumentropy distribution given a set of constraints.  More specifically, we are interested in the case where the constraints are the expectation of individual and pairs of attributes.  For such a given maximum entropy distribution we develop an efficient learning algorithm for read-once DNF.  We also show how to extend our results to monotone read-k DNF, following the techniques of [HM91]
Weakly learning DNF and characterizing statistical query learning using Fourier analysis| Abstract We present new results, both positive and negative, on the well-studied problem of learning disjunctive normal form (DNF) expressions.  We first prove that an algorithm due to Kushilevitz and Mansour [16] can be used to weakly learn DNF using membership queries in polynomial time, with respect to the uniform distribution on the inputs.  This is the first positive result for learning unrestricted DNF expressions in polynomial time in any nontrivial formal model of learning.  It provides a sharp contrast with the results of Kharitonov [15], who proved that AC 0 is not efficiently learnable in the same model (given certain plausible cryptographic assumptions).  We also present efficient learning algorithms in various models for the read-k and SAT-k subclasses of DNF.  For our negative results, we turn our attention to the recently introduced statistical query model of learning [11].  This model is a restricted version of the popular Probably Approximately Correct (PAC) model [23], and practically every class known to be efficiently learnable in the PAC model is in fact learnable in the statistical query model [11].  Here we give a general characterization of the complexityof statistical query learning in terms of the number of uncorrelated functions in the concept class.  This is a distributiondependent quantity yielding upper and lower bounds on the number of statistical queries required for learning on any input distribution.  As a corollary,
Agnostic Boosting| Abstract.  We extend the boosting paradigm to the realistic setting of agnostic learning, that is, to a setting where the training sample is generated by an arbitrary (unknown) probability distribution over examples and labels.  We define a fi-weak agnostic learner with respect to a hypothesis class F as follows: given a distribution P it outputs some hypothesis h 2 F whose error is at most erP (F ) + fi, where erP (F ) is the minimal error of an hypothesis from F under the distribution P (note that for some distributions the bound may exceed a half).  We show a boosting algorithm that using the weak agnostic learner computes a hypothesis whose error is at most maxfc1 (fi)er(F ) c 2 (fi) ; fflg, in time polynomial in 1=ffl.  While this generalization guarantee is significantly weaker than the one resulting from the known PAC boosting algorithms, one should note that the assumption required for fi-weak agnostic learner is much weaker.  In fact, an important virtue of the notion of weak agnostic learning is that in many cases such learning is achieved by efficient algorithms. 
Action Elimination and Stopping Conditions for Reinforcement Learning| Abstract We consider incorporating action elimination procedures in reinforcement learning algorithms.  We suggest a framework that is based on learning an upper and a lower estimates of the value function or the Q-function and eliminating actions that are not optimal.  We provide a model-based and a model-free variants of the elimination method.  We further derive stopping conditions that guarantee that the learned policy is approximately optimal with high probability.  Simulations demonstrate a considerable speedup and added robustness. 
Fast Planning in Stochastic Games| Abstract Stochastic games generalize Markov decision processes (MDPs) to a multiagent setting by allowing the state transitions to depend jointly on all player actions, and having rewards determined by multiplayer matrix games at each state.  We consider the problem of computing Nash equilibria in stochastic games, the analogue of planning in MDPs.  We begin by providing a generalization of finite-horizon value iteration that computes a Nash strategy for each player in generalsum stochastic games.  The algorithm takes an arbitrary Nash selection function as input, which allows the translation of local choices between multiple Nash equilibria into the selection of a single global Nash equilibrium.  Our main technical result is an algorithm for computing near-Nash equilibria in large or infinite state spaces.  This algorithm builds on our finite-horizon value iteration algorithm, and adapts the sparse sampling methods of Kearns, Mansour and Ng (1999) to stochastic games.  We conclude by describing a counterexample showing that infinite-horizon discounted value iteration, which was shown by Shapley to converge in the zero-sum case (a result we give extend slightly here), does not converge in the general-sum case. 
Competitive algorithms for VWAP and limit order trading| ABSTRACT We introduce new online models for two important
A Tight Bound for Approximating the Square Root| Abstract We prove an \Omega(log log(1="))
Diffusion without false rumors: on propagating updates in a Byzantine environment| Abstract We study how to efficiently diffuse updates to a large distributed system of data replicas, some of which may exhibit arbitrary (Byzantine) failures.  We assume that strictly fewer than t replicas fail, and that each update is initially received by at least t correct replicas.  The goal is to diffuse each update to all correct replicas while ensuring that correct replicas accept no updates generated spuriously by faulty replicas.  To achieve this, each correct replica further propagates an update only after receiving it from at least t others.  In this way, no correct replica will ever propagate or accept an update that only faulty replicas introduce, since it will receive that update from only the t 1 faulty replicas.  We provide the first analysis of diffusion protocols for such environments.  This analysis is fundamentally different from known analyses for the benign case due to our treatment of fully Byzantine failures---which, among other things, precludes the use of digital signatures for authenticating forwarded updates.  We propose two measures that characterize the efficiency of diffusion algorithms, delay and fan-in, and prove general lower bounds with regards to these measures.  We then provide a family of diffusion algorithms that have nearly optimal delay/fan-in product. 
Learning Boolean Functions via the Fourier Transform| Abstract We survey learning algorithms
Pessimistic decision tree pruning based on tree size| Abstract In this work we develop a new criteria to perform pessimistic decision tree pruning.  Our method is theoretically sound and is based on theoretical concepts such as uniform convergence and the Vapnik-Chervonenkis dimension.  We show that our criteria is very well motivated, from the theory side, and performs very well in practice.  The accuracy of the new criteria is comparable to that of the current method used in C4. 5. 
Boosting Using Branching Programs| Abstract It is known that decision tree learning can be viewed as a form of boosting.  Given a weak learning hypothesis one can show that the training error of a decision tree declines as jT j\Gamma fi where jT j is the size of the decision tree and fi is a constant determined by the weak learning hypothesis.  Here we consider the case of decision DAGs --- decision trees in which a given node can be shared by different branches of the tree, also called branching programs (BP).  Node sharing allows a branching programs to be exponentially more compact than the corresponding decision tree.  We show that under the same weak learning assumption used for decision tree learning there exists a greedy BP-growth algorithm whose training error is guaranteed to decline as 2 \Gamma fi p jT j , where jT j is the size of the branching program and fi is a constant determined by the weak learning hypothesis.  Therefore, from the perspective of boosting theory, branching programs are exponentially more efficient than decision trees. 
Computation in Noisy Radio Networks| Abstract In this paper we examine noisy radio (broadcast) networks in which every bit transmitted has a certain probability to be flipped.  Each processor has some initial input bit, and the goal is to compute a function of the initial inputs.  In this model we show a protocol to compute any threshold function using only a linear number of transmissions. 
''-discrepancy sets and their applications for interpolation of sparse polynomials| Abstract We present a simple explicit construction of a probability distribution supported on (p\Gamma 1) 2 vectors in Z n p , where p n=" is a prime, for which the absolute value of each nontrivial Fourier coefficients is bounded by ''.  This construction is used to derandomize the algorithm of [Man92] that interpolates a sparse polynomial in polynomial time in the bit complexity model. 
Auctions with Budget Constraints| Abstract.  In a combinatorial auction k dierent items are sold to n bidders, where the objective of the seller is to maximize the revenue.  The main diculty to find an optimal allocation is due to the fact that the valuation function of each bidder for bundles of items is not necessarily an additive function over the items.  An auction with budget constraints is a common special case where bidders generally have additive valuations, yet they have a limit on their maximal valuation.  Auctions with budget constraints were analyzed by Lehmann, Lehmann and Nisan [11], as part of a wider class of auctions, where they have shown that maximizing the revenue is NP-hard, and presented a greedy 2-approximation algorithm.  In this paper we present exact and approximate algorithms for auctions with budget constraints.  We present a randomized algorithm with an approximation ratio of e e-1 1. 582, which can be derandomized.  We analyze the special case where all bidders have the same budget constraint, and show an algorithm whose approximation ratio is between 1. 3837 and 1. 3951.  We also present an FPTAS for the case of a constant number of bidders. 
Competitive Access Time via Dynamic Storage Rearrangement| Abstract We model the problem of storing items in some warehouse (modeled as an undirected graph) where a server has to visit items over time, with the goal of minimizing the total distance traversed by the server.  Special cases of this problem include the management of a real industrial stacker crane warehouse [G], automatic robot run warehouses [Ho], disk track optimization to minimize access time [GS, P, W, YW], managing two dimensional memory (bubble memory and mass storage systems) [KMW, W, YW], doubly linked list management, and the process migration problem.  The static version of this problem assumes some known probability distribution on the access patterns.  The study of special cases of this static version was first considered by Hardy, Littlewood and P'olya in 1932 [HLP].  In this work we initiate the study of the dynamic version of the problem, where the robot may rearrange the warehouse to deal efficiently with future events.  We require no statistical assumptions on the access pattern, and give competitive algorithms that rearrange the warehouse over time to deal efficiently with the true access patterns.  We give non-trivial upper bounds for the general problem, along with some interesting lower bounds.  In addition, we model realistic data access patterns on disk storage by considering two practically significant scenarios: access to some database via
The Computational Complexity of Universal Hashing| Abstract Any implementation of Carter-Wegman universal hashing from nbit strings to m-bit strings requires a time-space tradeoff of TS = #(nm).  The bound holds in the general boolean branching program model, and thus in essentially any model of computation.  As a corollary, computing a+ b # c in any field F requires a quadratic time-space tradeoff, and the bound holds for any representation of the elements of the field.  Other lower bounds on the complexity of any implementation of universal hashing are given as well: Quadratic AT 2 bound for VLSI implementation; #(log n) parallel time bound on a CREW PRAM; and exponential size for constant depth circuits. 
Optimal smoothing schedules for real-time streams (extended abstract)| Abstract We consider the problem of smoothing real-time streams (such as video streams), where the goal is to reproduce a variablebandwidth stream remotely, while minimizing bandwidth cost, space overhead, and playback delay.  We focus on lossy schedules, where some bytes may be dropped due to limited bandwidth or space.  We present the following results.  First, we determine the optimal tradeoff between buffer space, queuing delay, and link bandwidth for lossy smoothing schedules .  Specifically, this means that if one of these parameters is under our control, we can precisely calculate the optimal value which minimizes data loss while avoiding resource wastage.  The tradeoff is accomplished by a simple generic algorithm, that allows one some freedom in choosing which data to discard.  This algorithm is very easy to implement both at the server and at the client, and it enjoys the nice property that only the server decides which data to discard, and the client needs only to reconstruct the stream.  In a second set of results we study the case where different parts of the data have different importance, modeled by assigning a real ^weight~ to each byte in the stream.  For this setting we use competitive analysis, i. e. , we compare the weight delivered by on-line algorithms to the weight of an optimal off-line schedule using the same resources.  We prove that a natural greedy algorithm is 4-competitive.  We also prove a lower bound of 1:25 on the competitive ratio of any deterministic on-line algorithm.  Finally, we give a few experimental results which show that smoothing is extremely effective in practice, and that the greedy algorithm performs very well in the weighted case. 
Reinforcement Learning in POMDPs| Abstract We consider the most realistic reinforcement learning setting in which an agent starts in an unknown environment (the POMDP) and must follow one unbroken chain of experience with no access to "resets" or "offline" simulation.  We provide algorithms for general POMDPs that obtain near optimal average reward.  One algorithm we present has a convergence rate which depends exponentially on a certain horizon time of an optimal policy, but has no dependence on the number of (unobservable) states.  The main building block of our algorithms is an implementation of an approximate reset strategy, which we show always exists in every POMDP.  An interesting aspect of our algorithms is how they use this strategy when balancing exploration and exploitation. 
Learning Rates for Q-learning| Abstract In this paper we derive convergence rates for Q-learning.  We show an interesting relationship between the convergence rate and the learning rate used in the Q-learning.  For a polynomial learning rate, one which is 1/t ! at time t where ! 2 (1/2, 1), we show that the convergence rate is polynomial in 1/(1 - ), where is the discount factor.  In contrast we show that for a linear learning rate, one which is 1/t at time t, the convergence rate has an exponential dependence on 1/(1 - ).  In addition we show a simple example that proves that this exponential behavior is inherent for a linear learning rate. 
Reinforcement Learning and Mistake Bounded Algorithms| Abstract Markov Decision Process (MDP) and Partially Observable MDP (POMDP) have become the model of choice in reinforcement learning.  This work explores an interesting connection between mistake bounded learning algorithms and computing a near-best strategy, from a restricted class of strategies, for a given POMDP.  We show that if a class of strategies has a mistake bound algorithm that makes at most d mistakes, then there is an algorithm to compute a near-best strategy from the class in time polynomial in 1=ffl, the accuracy parameter, log(1=ffi), the confidence parameter, H, the horizon parameter, and exponential in d, the mistake bound.  Our transformation assumes only the ability to execute actions in the POMDP and the ability to reset the POMDP to its initial state. 
Time Optimal Self-Stabilizing Synchronization Extended Abstract| Abstract In this paper we present a time optimal self-stabilizing scheme for network synchronization.  Our construction has two parts.  First, we give a simple rule by which each node can compute its pulse number as a function of its neighbors' pulse numbers.  The rule we give stabilizes in time bounded by the diameter of the network, does not invoke global operations, and does not require any additional memory space.  However, it assumes that pulse numbers may grow unboundedly.  The second part of the construction (which is of independent interest on its own right) takes care of this problem.  Specifically, we present the first self-stabilizing reset procedure that stabilizes in time proportional to the diameter of the network. 
Efficient Nash Computation in Large Population Games with Bounded Influence| Abstract We introduce a general representation of largepopulation games in which each player's influence on the others is centralized and limited, but may otherwise be arbitrary.  This representation significantly generalizes the class known as congestion games in a natural way.  Our main results are provably correct and efficient algorithms for computing and learning approximate Nash equilibria in this general framework. 
QoS-Competitive Video Buffering| Abstract.  Many multimedia applications require transmission of streaming video from a server to a client across an internetwork.  In many cases loss may be unavoidable due to congestion or heterogeneous nature of the network.  We explore how discard policies can be used in order to maximize the quality of service (QoS) perceived by the client.  In our model the QoS of a video stream is measured in terms of a cost function, which takes into account the discarded frames.  In this paper we consider online policies for selective frame discard and analyze their performance by means of competitive analysis.  In competitive analysis the performance of a given online policy is compared with that of an optimal offline policy.  In this work we present competitive policies for a wide range of cost functions, describing the QoS of a video stream. 
Why Averaging Classifiers Can Protect Against Overfitting| Abstract We study a simple learning algorithm for binary classification.  Instead of predicting with the best hypothesis in the hypothesis class, this algorithm predicts with a weighted average of all hypotheses, weighted exponentially with respect to their training error.  We show that the prediction of this algorithm is much more stable than the prediction of an algorithm that predicts with the best hypothesis.  By allowing the algorithm to abstain from predicting on some examples, we show that the predictions it makes when it does not abstain are very reliable.  Finally, we show that the probability that the algorithm abstains is at most about twice the generalization error of the best hypothesis in the class. 
Chapter 1 Broadcast in Radio Networks| Abstract We show that for any radio network there exists a schedule of a broadcast whose time is O(D + log 5 (n)), where D is the diameter and n is the number of nodes.  (This result implies an optimal broadcast to networks with D = \Omega(log 5 n). ) We present a (centralized) polynomial time algorithm that given a network and a source, outputs a schedule for broadcasting the message from the source to the rest of the network. 
Competitive Dynamic Bandwidth Allocation| Abstract We propose a realistic theoretical model for dynamic bandwidth allocation.  Our model takes into account the two classical quality of service parameters: latency and utilization, together with a newly introduced parameter: number of bandwidth allocation changes, which are costly operations in today's networks.  Our model assumes that sessions join the network with a certain delay requirement rather than a bandwidth requirement as assumed in previous models.  In addition, the network has a certain utilization requirement.  Given bounds on latency and utilization, we design online algorithms that minimize the number of bandwidth allocation changes. 
Trade-offs between communication throughput and parallel time| Abstract We study the effect of limited communication throughput on parallel computation in a setting where the number of processors is much smaller than the length of the input.  Our model has p processors that communicate through a shared memory of size m.  The input has size n, and can be read directly by all the processors.  We will be primarily interested in studying cases where n AE p AE m.  As a test case we study the list reversal problem.  For this problem we prove a time lower bound of \Omega( n p mp ).  (A similar lower bound holds also for the problems of sorting, finding all unique elements, convolution, and universal hashing. ) This result shows that limiting the communication (i. e. , small m) has significant effect on parallel computation.  We show an almost matching upper bound of O( n p mp log O(1) n).  The upper bound requires the development of a few interesting techniques which can alleviate the limited communication in some general settings.  Specifically,
On Completeness and Soundness in Interactive Proof Systems| ABSTRACT -- An interactive proof system with Perfect Completeness (resp.  Perfect Soundness) for a language L is an interactive proof (for L) in which for every x 2 L (resp.  x 62 L) the verifier always accepts (resp.  always rejects).  We show that any language having an interactive proof system has one (of the Arthur-Merlin type) with perfect completeness.  On the other hand, only languages in NP have interactive proofs with perfect soundness. 
Game Theory with Restricted Strategies (DRAFT: Please do not circulate|).  Abstract We present a theory of multiplayer games in which each player chooses their strategy from a limited class that may be significantly weaker than the class of all mixed strategies.  As in much of AI and machine learning, such restrictions may be desirable for reasons of computational tractability.  We define and study the notions of restricted Nash equilibria, local restricted Nash equilibria, and restricted security strategies.  We illustrate a number of these concepts with two well-studied games from the literature, the War of Attrition and Pricebots games, in which both players are restricted to play mixed strategies that are mixtures of Gaussians. 
Jitter Control in QoS Networks \Lambda| Abstract We study jitter control in networks with guaranteed quality of service (QoS) from the competitive analysis point of view: We propose on-line algorithms that control jitter and compare their performance to the best possible (by an off-line algorithm) for any given arrival sequence.  For delay jitter, where the goal is to minimize the difference between delay times of different packets, we show that a simple on-line algorithm using buffer of B slots guarantees the same delay-jitter as the best off-line algorithm using buffer space B=2.  We prove that the guarantees made by our on-line algorithm hold even for simple distributed implementations, where the total buffer space is distributed along the path of the connection, provided that the input stream satisfies a certain simple property.  For rate jitter, where the goal is to minimize the difference between inter-arrival times, we develop an on-line algorithm using a buffer of size 2B + h for any h 1, and compare its jitter to the jitter of an optimal off-line algorithm using buffer size B.  We prove that our algorithm guarantees that the difference is bounded by a term proportional to B=h. 
A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes| Abstract A critical issue for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP.  In stochastic environments with very large or infinite state spaces, traditional planning and reinforcement learning algorithms may be inapplicable, since their running time typically grows linearly with the state space size in the worst case.  In this paper we present a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states.  The running time is exponential in the horizon time (which depends only on the discount factor # and the desired degree of approximation to the optimal policy).  Our algorithm thus provides a different complexity trade-off than classical algorithms such as value iteration | rather than scaling linearly in both horizon time and state space size, our running time trades an exponential dependence on the former in exchange for no dependence on the latter.  Our algorithm is based on the idea of sparse sampling .  We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suces to compute nearoptimal actions from any state of an MDP.  Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs [KMN00]. 
Phantom: A Simple and Effective Flow Control Scheme| Abstract This paper presents Phantom, a simple constant space algorithm for rate based flow control.  As shown by our simulations, it converges fast to a fair rate allocation while generating a moderate queue length.  While our approach can be easily implemented in ATM switches for managing ABR traffic, it is also suitable for flow control in TCP router based networks.  Both the introduced overhead and the required modifications in TCP flow control systems are minimal.  The implementation of this approach in TCP guarantees fairness and provides a unifying interconnection between TCP routers and ATM networks.  The new algorithm easily inter-operates with current TCP flow control mechanisms and thus can be gradually introduced into installed based TCP networks. 
Accuracy vs| Simplicity: A Complex Trade-Off #.  Abstract Inductive learning aims at finding general rules that hold true in a database.  Targeted learning seeks rules for the prediction of the value of a variable based on the values of others, as in the case of linear or non-parametric regression analysis.  Non-targeted learning finds regularities without a specific prediction goal.  We model the product of non-targeted learning as rules that state that a certain phenomenon never happens, or that certain conditions necessitate another.  For all types of rules, there is a trade-off between the rule's accuracy and its simplicity.  Thus rule selection can be viewed as a choice problem, among pairs of degree of accuracy and degree of complexity.  However, one cannot in general tell what is the feasible set in the accuracycomplexity space.  Formally, we show that finding out whether a point belongs to this set is computationally hard.  In particular, in the context of linear regression, finding a small set of variables that obtain a certain value of R 2 is computationally hard.  Computational complexity may explain why a person is not always aware of rules that, if # Earlier versions of this
On the Complexity of Policy Iteration| Abstract Decision-making problems in uncertain or stochastic domains are often formulated as Markov decision processes (MDPs).  Policy iteration (PI) is a popular algorithm for searching over policy-space, the size of which is exponential in the number of states.  We are interested in bounds on the complexity of PI that do not depend on the value of the discount factor.  In this paper we prove the first such non-trivial, worst-case, upper bounds on the number of iterations required by PI to converge to the optimal policy. 
Bandwidth Allocation with Preemption \Lambda| Abstract Bandwidth allocation is a fundamental problem in the design of networks where bandwidth has to be reserved for connections in advance.  The problem is intensified when the requested bandwidth exceeds the capacity and not all requests can be served.  Furthermore, acceptance/rejection decisions regarding connections have to be made on-line, without knowledge of future requests.  We show that the ability to preempt (i. e. , abort) connections while in service in order to be able to schedule "more valuable" connections substantially improves the overall throughput of some networks.  We present bandwidth allocation strategies that use preemption and show that they achieve constant competitiveness with respect to the throughput, given that any single call occupies only a constant fraction of the bandwidth. 
On Learning Conjunctions with Malicious Noise \Lambda| Abstract We show how to learn monomials in the presence of malicious noise,
Efficient On-Line Call Control Algorithms \Lambda| Abstract We study the problem of on-line call control, i. e. , the problem of accepting or rejecting an incoming call without knowledge of future calls.  The problem is a part of the more general problem of bandwidth allocation and management.  Intuition suggests that knowledge of future call arrivals can be crucial to the performance of the system.  In this paper, however, we present preemptive deterministic on-line call control algorithms.  We use competitive analysis to measure their performance--i. e. , we compare our algorithms to their off-line, clairvoyant counterparts---and prove optimality for some of them.  The model we consider in this paper is that of a line of nodes, and investigate a variety of cases concerning the value of the calls.  The value is accrued only if the call terminates successfully; otherwise---if the call is rejected, or prematurely terminated---no value is gained.  The performance of the algorithm is then measured by the cumulative value achieved, when given a sequence of calls.  The variety of call value criteria that we study---constant; proportional to the length of the call's route; proportional to its holding time---captures many of the natural cost assignments to network services. 
Shamir| Commpetitive packet routing on grids. 
Broadcast in Radio Networks|
Learning Decision Trees Using the Fourier Spectrum|
Constant depth circuits, Fourier transforms, and learnability|
Improved selection in totally monotone arrays|
Many-to-one packet routing on grids|
Randomized Interpolation and Approximation of Sparse Polynomials|
Time optimal self-stabilizing synchronization|
Slide-The Key to Polynomial End-to-End Communication|
Reliable Communication Over Unreliable Channels|
On the learnability of discrete distributions|
Optimal Smoothing Schedules for Real-Time Streams|
Greedy Packet Scheduling on Shortest Paths|
An \Omega(D log n) Lower Bound for Broadcast in Radio Networks,|
On the Bit Complexity of Distributed Computations in a Ring with a Leader|
Constant Depth Circuits, Fourier Transform, and Learnability|
Learning Monotone DNF Formulas on Product Distributions|
Efficient On-Line Call Control Algorithms|
94, "On the Learnability of Discrete Distributions",|
Application of Eigenanalysis to the Western North American Power System",|
Voltage Stability Analysis Using Generic Dynamic Load Models",|
Randomized approxmation and interpolation of sparse polynomials|
Competitive queueing policies for QoS switches|
Interactive Proof Systems: Provers that never Fail and Random Selection (Extended Abstract)|
Convergence time to nash equilibria|
editor, Suggested techniques for voltage stability analysis,|
Time Optimal SelfStabilizing Synchronization|
An Efficient Topology Update Protocol for Dynamic Networks|
Polynomial End-To-End Communication (Extended Abstract)|
An approximation algorithm for minimum-cost network design|
Convergence Time to Nash Equilibria|
Shamir, "Jitter control in QoS networks" IEEE Symposium on|
An O(n log log n ) learning algorihm for DNF under the uniform distribution|
A Sparse Sampling Alogorithm for Near-Optimal Planning in Large Markov Decision Processes|
Randomness in Private Computations|
On construction of k--wise independent random variables|
The Intractability of Bounded Protocols for Non-FIFO Channels|
Data Link Layer: Two Impossibility Results|
Dynamic Bandwidth Allocation Policies|
The Impossibility of Implementing Reliable Communication in the Face of Crashes, to appear|
Randomized on-line algorithms for graph closures|
Online learning of reliable network paths|
Applying the weak learning framework to understand and improve C4|5. 
Improved second-order bounds for prediction with expert advice|
Learning decision rees using fourier spectrum|
Language Complexity on the Synchronous Anonymous Ring|
The Impossibility of Implementing Reliable Communication in the Face of Crashes|
Sharkawi, "Large Scale Dynamic Security Screening and Ranking Using Neuron Networks,|
The Intractability of Bounded Protocols for On-Line Sequence Transmission over Non-FIFO Channels|
Results on Learnability and the Vapnik-Chervonenkis Dimension|
Learning Decision Trees Using the Fourier Sprectrum (Extended Abstract)|
en, \Competitive Queue Policies for Differentiated Services,|
Proofs that Never Fail and Random Selection,|
Predicting and bypassing internet end-to-end service degradations|
Some results on learnability and the VapnikChervonenkis dimension|
The Shrinking Generator|
\An approximation algorithm for minimum-cost network design", The Weizman Institute of Science Tech|
Optimal universal learning and prediction of probabilistic concepts|
Learning with Maximum-Entropy Distributions|
in press)| Policy gradient methods for reinforcement learning with function approximation. 
Constant Depth Circuits, AC 0|
Generalization Bounds for Decision Trees|
\Policy gradient mehtods for reinforcement lenaring with function approximation,|
Sparse Sampling Methods for Planning and Learning in Large and Partially Observable Markov Decision Processes|
The Complexity of Approximating the Square Root (Extended Summary)|
Lower Bounds for Computations with the Floor Operation|
Fast Exponentiation Using the Truncation Operation|
An #(D lg(N=D)) lower bound for broadcast in radio networks,|
"AdaVegas: Adaptive Control for TCP Vegas,|
A Parametrization Scheme for Classifying Models of Learnability|
Exact Inference of Hidden Structure from Sample Data in noisy-OR Networks|
Learning via Fourier transform|
Adaptive TCP Flow Control|
An O(n) Learning Algorithm for DNF Under the Uniform Distribution|
Lecture notes on learning theory|
editor), "Voltage Stability of Power Systems: Concepts, Analytical Tools and Industry Experience",|
Space ecient fair queuing by stochastic memory multiplexing|
Lower bounds for randomized mutual exclusion (extended abstract)|
Randomized approximation and interpolation of sparse polynomials|
Sorting on a Ring of Processors|
Theoretical Advances in Neural Computation and Learning|
Prason Tiwari, "A Lower Bound for Integer Greatest Common Divisor Computations,"|
"On diffusing Updates in Byzantine Environment",|
