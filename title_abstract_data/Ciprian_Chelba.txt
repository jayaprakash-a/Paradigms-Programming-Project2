Distributed Speech Processing in MiPad's Multimodal User Interface| Abstract---This paper describes the main components of MiPad (Multimodal Interactive PAD) and especially its distributed speech processing aspects.  MiPad is a wireless mobile PDA prototype that enables users to accomplish many common tasks using a multimodal spoken language interface and wireless-data technologies.  It fully integrates continuous speech recognition and spoken language understanding, and provides a novel solution for data entry in PDAs or smart phones, often done by pecking with tiny styluses or typing on minuscule keyboards.  Our user study indicates that the throughput of MiPad is significantly superior to that of the existing pen-based PDA interface.  Acoustic modeling and noise robustness in distributed speech recognition are key components in MiPad's design and implementation.  In a typical scenario, the user speaks to the device at a distance so that he or she can see the screen.  The built-in microphone thus picks up a lot of background noise, which requires MiPad be noise robust.  For complex tasks, such as dictating e-mails, resource limitations demand the use of a client--server (peer-to-peer) architecture, where the PDA performs primitive feature extraction, feature quantization, and error protection, while the transmitted features to the server are subject to further speech feature enhancement, speech decoding and understanding before a dialog is carried out and actions rendered.  Noise robustness can be achieved at the client, at the server or both.  Various speech processing aspects of this type of distributed computation as related to MiPad's potential deployment are presented in this paper.  Recent user interface study results are also described.  Finally, we point out future research directions as related to several key MiPad functionalities. 
Parsing Conversational Speech Using Enhanced Segmentation| Abstract The lack of sentence boundaries and presence of
PUTTING LANGUAGE INTO LANGUAGE MODELING y| ABSTRACT In this paper we describe the statistical Structured Language Model (SLM) that uses grammatical analysis of the hypothesized sentence segment (prefix) to predict the next word.  We first describe the operation of a basic, completely lexicalized SLM that builds up partial parses as it proceeds left to right.  We then develop a chart parsing algorithm and with its help a method to compute the prediction probabilities P (w i+1 jW i ): We suggest useful computational shortcuts followed by a method of training SLM parameters from text data.  Finally, we introduce more detailed parametrization that involves non-terminal labeling and considerably improves smoothing of SLM statistical parameters.  We conclude by presenting certain recognition and perplexity results achieved on standard corpora. 
Structured Language Modeling for Speech Recognition| Abstract A new language model for speech recognition is presented.  The model develops hidden hierarchical syntactic-like structure incrementally and uses it to extract meaningful information from the word history, thus complementing the locality of currently used trigram models.  The structured language model (SLM) and its performance in a two-pass speech recognizer --- lattice decoding --- are presented.  Experiments on the WSJ corpus show an improvement in both perplexity (PPL) and word error rate (WER) over conventional trigram models.  1 Structured Language Model An extensive presentation of the SLM can be found in [1].  The model assigns a probability P (W; T ) to every sentence W and its every possible binary parse T .  The terminals of T are the words of W with POStags, and the nodes of T are annotated with phrase headwords and non-terminal labels.  Let W be a sentence of length n words to which we have prepended !s? and appended !/s? so that w 0 =!s? and w n+1 =!/s?.  Let W k be the word k-prefix w 0 : : : w k of the sentence and W k T k the word-parse k-prefix.  Figure 1 shows a word-parse k-prefix; h0 . .  h---m are the exposed heads, each head being a pair(headword, non-terminal label), or (word, POStag) in the case of a root-only tree.  h_0 = (h_0. word, h_0. tag) h_{-1} h_{-m} = (<s}, SB)
Expoiting Syntactic Structure for Language Modeling| Abstract The paper presents a language model that develops syntactic structure and uses it to extract meaningful information from the word history, thus enabling the use of long distance dependencies.  The model assigns probability to every joint sequence of words--binary-parse-structure with headword annotation and operates in a left-to-right manner --therefore usable for automatic speech recognition.  The model, its probabilistic parameterization, and a set of experiments meant to evaluate its predictive power are presented; an improvement over standard trigram modeling is achieved. 
Position Specific Posterior Lattices for Indexing Speech| Abstract The paper presents the Position Specific Posterior Lattice, a novel representation of automatic speech recognition lattices that naturally lends itself to efficient indexing of position information and subsequent relevance ranking of spoken documents using proximity.  In experiments performed on a collection of lecture recordings --- MIT iCampus data --- the spoken document ranking accuracy was improved by 20% relative over the commonly used baseline of indexing the 1-best output from an automatic speech recognizer.  The Mean Average Precision (MAP) increased from 0. 53 when using 1-best output to 0. 62 when using the new lattice representation.  The reference used for evaluation is the output of a standard retrieval engine working on the manual transcription of the speech collection.  Albeit lossy, the PSPL lattice is also much more compact than the ASR 3-gram lattice from which it is computed --- which translates in reduced inverted index size as well --- at virtually no degradation in word-error-rate performance.  Since new paths are introduced in the lattice, the ORACLE accuracy increases over the original ASR lattice. 
SPEECH OGLE: Indexing Uncertainty for Spoken Document Search| Abstract The paper presents the Position Specific Posterior Lattice (PSPL), a novel lossy representation of automatic speech recognition lattices that naturally lends itself to efficient indexing and subsequent relevance ranking of spoken documents.  In experiments performed on a collection of lecture recordings --- MIT iCampus data --- the spoken document ranking accuracy was improved by 20% relative over the commonly used baseline of indexing the 1-best output from an automatic speech recognizer.  The inverted index built from PSPL lattices is compact --- about 20% of the size of 3-gram ASR lattices and 3% of the size of the uncompressed speech --- and it allows for extremely fast retrieval.  Furthermore, little degradation in performance is observed when pruning PSPL lattices, resulting in even smaller indexes --- 5% of the size of 3-gram ASR lattices. 
Information Extraction Using the Structured Language Model| Abstract The paper presents a data-driven approach to information extraction (viewed as template filling) using the structured language model (SLM) as a statistical parser.  The task of template filling is cast as constrained parsing using the SLM.  The model is automatically trained from a set of sentences annotated with frame/slot labels and spans.  Training proceeds in stages: first a constrained syntactic parser is trained such that the parses on training data meet the specified semantic spans, then the non-terminal labels are enriched to contain semantic information and finally a constrained syntactic+semantic parser is trained on the parse trees resulting from the previous stage.  Despite the small amount of training data used, the model is shown to outperform the slot level accuracy of a simple semantic grammar authored manually for the MiPad | personal information management | task. 
A Structured Language Model| Abstract A new language model inspired by linguistic analysis is presented.  The model develops hidden hierarchical structure incrementally and uses it to extract meaningful information from the word history --- thus enabling the use of extended distance dependencies --- in an attempt to complement the locality of currently used n-gram Markov models.  The model, its probabilistic parametrization, a reestimation algorithm for the model parameters and a set of experiments meant to evaluate its potential for speech recognition are presented. 
REFINEMENT OF A STRUCTURED LANGUAGE MODEL y| ABSTRACT A new language model for speech recognition inspired by linguistic analysis is presented.  The model develops hidden hierarchical structure incrementally and uses it to extract meaningful information from the word history --- thus enabling the use of extended distance dependencies --- in an attempt to complement the locality of currently used n-gram Markov models.  The model, its probabilistic parametrization, a reestimation algorithm for the model parameters and a set of experiments meant to evaluate its potential for speech recognition are presented. 
WS96 Project Report DEPENDENCY LANGUAGE MODELING| Abstract This report summarizes the work of the Dependency Language Modeling group at the 1996 Summer Speech Workshop at the Center for Language and Speech Processing at Johns Hopkins University (WS96).  We motivate and describe a novel statistical language model based on the syntactic dependencies between words.  The model is formulated in the maximum entropy framework, which expresses statistical constraints on the frequencies of various type of dependencies, as well the standard N-gram statistics.  We describe how this model was applied to the recognition of spontaneous English speech from the Switchboard corpus.  Because of implementation constraints, only a reduced version of our model could be tested.  The model gave a modest improvement over an N-gram baseline model.  A byproduct of the project is the Maximum Entropy Modeling Toolkit (MEMT), a freely available software package for domain-independent maximum entropy modeling. 
Recognition Performance of a Structured Language Model| ABSTRACT A new language model for speech recognition inspired by linguistic analysis is presented.  The model develops hidden hierarchical structure incrementally and uses it to extract meaningful information from the word history --- thus enabling the use of extended distance dependencies --- in an attempt to complement the locality of currently used trigram models.  The structured language model, its probabilistic parameterization and performance in a two-pass speech recognizer are presented.  Experiments on the SWITCHBOARD corpus show an improvement in both perplexity and word error rate over conventional trigram models. 
Richer Syntactic Dependencies for Structured Language Modeling| ABSTRACT The paper investigates the use of richer syntactic dependencies in the structured language model (SLM).  We present two simple methods of enriching the dependencies in the syntactic parse trees used for intializing the SLM.  We evaluate the impact of both methods on the perplexity (PPL) and word-error-rate (WER, N-best rescoring) performance of the SLM.  We show that the new model achieves an improvement in PPL and WER over the baseline results reported using the SLM on the UPenn Treebank and Wall Street Journal (WSJ) corpora, respectively. 
A Study on Richer Syntactic Dependencies for Structured Language Modeling| Abstract We study the impact of richer syntactic dependencies on the performance of the structured language model (SLM) along three dimensions: parsing accuracy (LP/LR), perplexity (PPL) and worderror-rate (WER, N-best re-scoring).  We show that our models achieve an improvement in LP/LR, PPL and/or WER over the reported baseline results using the SLM on the UPenn Treebank and Wall Street Journal (WSJ) corpora, respectively.  Analysis of parsing performance shows correlation between the quality of the parser (as measured by precision/recall) and the language model performance (PPL and WER).  A remarkable fact is that the enriched SLM outperforms the baseline 3-gram model in terms of WER by 10% when used in isolation as a second pass (N-best re-scoring) language model. 
STRUCTURE AND PERFORMANCE OF A DEPENDENCY LANGUAGE MODEL| ABSTRACT We present a maximum entropy language model that incorporates both syntax and semantics via a dependency grammar.  Such a grammar expresses the relations between words by a directed graph.  Because the edges of this graph may connect words that are arbitrarily far apart in a sentence, this technique can incorporate the predictive power of words that lie outside of bigram or trigram range.  We have built several simple dependency models, as we call them, and tested them in a speech recognition experiment.  We report experimental results for these models here, including one that has a small but statistically significant advantage (p ! :02) over a bigram language model. 
Adaptation of Maximum Entropy Capitalizer: Little Data Can Help a Lot| Abstract A novel technique for maximum "a posteriori" (MAP) adaptation of maximum entropy (MaxEnt) and maximum entropy Markov models (MEMM) is presented.  The technique is applied to the problem of recovering the correct capitalization of uniformly cased text: a "background" capitalizer trained on 20Mwds of Wall Street Journal (WSJ) text from 1987 is adapted to two Broadcast News (BN) test sets --one containing ABC Primetime Live text and the other NPR Morning News/CNN Morning Edition text --- from 1996.  The "in-domain" performance of the WSJ capitalizer is 45% better than that of the 1-gram baseline, when evaluated on a test set drawn from WSJ 1994.  When evaluating on the mismatched "out-ofdomain" test data, the 1-gram baseline is outperformed by 60%; the improvement brought by the adaptation technique using a very small amount of matched BN data --- 25-70kwds --- is about 20-25% relative.  Overall, automatic capitalization error rate of 1. 4% is achieved on BN data. 
Exploiting Syntactic Structure for Natural Language Modeling|
Refinement of a Structured Language Model|
Exploiting Syntactic Structures for Language Modeling|
Structured language modeling|
A study on richer syntactic dependencies for structured language modeling|
Dependency language modeling|
Portability of Syntactic Structure for Language Modeling|
Combination of statistical and rule-based approaches for spoken language understanding|
Structured language models|
Structured language modelin|
(to be published in csl oct 00)|
