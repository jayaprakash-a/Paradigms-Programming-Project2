Learning to Parse Pictures of People| body plans, however they have been used to detect both whole pedestrians and combinations of rigidly positioned subimages (typically, upper body, arms, and legs) in street scenes, under a wide range of illumination, pose and clothing variations.  RVMs are SVM-like classifiers that offer a well-founded probabilistic interpretation and improved sparsity for reduced computation.  We demonstrate their benefits experimentally in a series of results showing great promise for learning detectors in more general situations. 
'Where was this taken?' Semi-supervised kernel based learning for location recognition| Abstract In this report we compare the performance of various supervised and semi-supervised learning techniques on the problem of classifying incoming images according to their indoor or outdoor location, given a small set of training images taken at each location.  Recently nonlinear kernel based methods such as Support Vector Machines[6][7][8] have become very popular in visual pattern recognition.  There also has been recent work on transductive inference[1][7] which uses test data alongwith the training data to improve upon the performance.  The performance of various methods is evaluated against dierent sizes of the training data, keeping a fixed test data.  We compare inductive and transductive SVM's with dierent kernels, some simple parametric techniques and a few non-parametric kernel methods.  In particular we evaluate the extent to which semi-supervised learning methods can reduce the burden of labelling the training images by taking the test images into account.  The results show that SVMs outperform all other inductive techniques.  The semi-supervised transductive SVMs perform better than inductive SVMs for large enough data, but the performance falls when the training data is reduced to very low values(ref.  fig(6)). 
Kinematic Jump Processes For Monocular 3D Human Tracking| Abstract A major difficulty for 3D human body tracking from monocular image sequences is the near non-observability of kinematic degrees of freedom that generate motion in depth.  For known link (body segment) lengths, the strict non-observabilities reduce to twofold `
Estimating Articulated Human Motion With Covariance Scaled Sampling| Abstract We present a method for recovering 3D human body motion from monocular video sequences based on a robust image matching metric, incorporation of joint limits and non-self-intersection constraints, and a new sample-and-refine search strategy guided by rescaled cost-function covariances.  Monocular 3D body tracking is challenging: besides the difficulty of matching an imperfect, highly flexible, self-occluding model to cluttered image features, realistic body models have at least 30 joint parameters subject to highly nonlinear physical constraints, and at least a third of these degrees of freedom are nearly unobservable in any given monocular image.  For image matching we use a carefully designed robust cost metric combining robust optical flow, edge energy, and motion boundaries.  The nonlinearities and matching ambiguities make the parameter-space cost surface multi-modal, ill-conditioned and highly nonlinear, so searching it is difficult.  We discuss the limitations of CONDENSATION-like samplers, and describe a novel hybrid search algorithm that combines inflated-covariance-scaled sampling and robust continuous optimization subject to physical constraints and model priors.  Our experiments on challenging monocular sequences show that robust cost modeling, joint and selfintersection constraints, and informed sampling are all essential for reliable monocular 3D motion estimation. 
Variational Space-Time Motion Segmentation| Abstract We propose a variational method for segmenting image sequences into spatio-temporal domains of homogeneous motion.  To this end, we formulate the problem of motion estimation in the framework of Bayesian inference, using a prior which favors domain boundaries of minimal surface area.  We derive a cost functional which depends on a surface in space-time separating a set of motion regions, as well as a set of vectors modeling the motion in each region.  We propose a multiphase level set formulation of this functional, in which the surface and the motion regions are represented implicitly by a vector-valued level set function.  Joint minimization of the proposed functional results in an eigenvalue problem for the motion model of each region and in a gradient descent evolution for the separating interface.  Numerical results on real-world sequences demonstrate that minimization of a single cost functional generates a segmentation of space-time into multiple motion regions. 
A Factorization Based Algorithm for Multi-Image Projective Structure and Motion| Abstract We propose a method for the recovery of projective shape and motion from multiple images of a scene by the factorization of a matrix containing the images of all points in all views.  This factorization is only possible when the image points are correctly scaled.  The major technical contribution of this paper is a practical method for the recovery of these scalings, using only fundamental matrices and epipoles estimated from the image data.  The resulting projective reconstruction algorithm runs quickly and provides accurate reconstructions.  Results are presented for simulated and real images. 
Linear Projective Reconstruction from Matching Tensors| Abstract This paper describes initial work on a family of projective reconstruction techniques that extract projection matrices directly and linearly from matching tensors estimated from image data.  The simplest methods use fundamental matrices and epipoles, alternative ones use trilinear tensors.  All of the data is treated uniformly, and there is no reliance on `privileged' images or tokens.  The approach is based on `joint image closure relations' --- bilinear constraints between matching tensors and projection matrices, that express the fact that the former derive from the latter.  The performance of the new techniques is quantified and compared with that of several existing methods. 
A Unification of Autocalibration Methods| Abstract This paper describes a unified theory for autocalibration of a moving camera.  The camera models can be 2D projective, 2D affine camera and 1D projective projections.  The scenes can be either non-planar scenes or planar scenes and the camera may also undergoes a pure rotation.  All these cases are unified into the same framework based on the direction bases.  Each formulation on the direction bases is also paralleled with that on projective geometry concepts, essentially encoded by the various forms of the absolute conic.  This unification provides not only a common theoretical framework, but also suggests unified parameterisation schema for estimation procedures. 
Learning to track 3D human motion from silhouettes| Abstract We describe a sparse Bayesian regression method for recovering 3D human body motion directly from silhouettes extracted from monocular video sequences.  No detailed body shape model is needed, and realism is ensured by training on real human motion capture data.  The tracker estimates 3D body pose by using Relevance Vector Machine regression to combine a learned autoregressive dynamical model with robust shape descriptors extracted automatically from image silhouettes.  We studied several different combination methods, the most effective being to learn a nonlinear observation-update correction based on joint regression with respect to the predicted state and the observations.  We demonstrate the method on a 54-parameter full body pose model, both quantitatively using motion capture based test sequences, and qualitatively on a test video sequence. 
Building Roadmaps of Minima and Transitions in Visual Models| Abstract Becoming trapped in suboptimal local minima is a perennial problem when optimizing visual models, particularly in applications like monocular human body tracking where complicated parametric models are repeatedly fitted to ambiguous image measurements.  We show that trapping can be significantly reduced by building `roadmaps' of nearby minima linked by transition pathways --- paths leading over low `mountain passes' in the cost surface --- found by locating the transition state (codimension-1 saddle point) at the top of the pass and then sliding downhill to the next minimum.  We present two families of transition-state-finding algorithms based on local optimization.  In eigenvector tracking, unconstrained Newton minimization is modified to climb uphill towards a transition state, while in hypersurface sweeping, a moving hypersurface is swept through the space and moving local minima within it are tracked using a constrained Newton method.  These widely applicable numerical methods, which appear not to be known in vision and optimization, generalize methods from computational chemistry where finding transition states is critical for predicting reaction parameters.  Experiments on the challenging problem of estimating 3D human pose from monocular images show that our algorithms find nearby transition states and minima very efficiently, but also underline the disturbingly large numbers of minima that can exist in this and similar model based vision problems. 
Factorization Methods for Projective Structure and Motion|
Bundle Adjustment - A Modern Synthesis|
Projective geometry for image analysis|
A new approach to geometric fitting|
Autocalibration and the absolute quadric|
Autocalibration from Planar Scenes|
The geometry of projective reconstruction I: Matching constraints and the joint image| Submitted to Int. 
Matching Constraints and the Joint Image|
Covariance Scaled Sampling for Monocular 3D Body Tracking|
The geometry of projective reconstruction I: Matching constraints and the joint image|
Joint Feature Distributions for Image Correspondence|
Plane+Parallax, Tensors and Factorization|
Hyperdynamics Importance Sampling|
eds|: Vision algorithms, theory and practice:. 
The Absolute Quadric,|
Model-based sonar localisation for mobile robots|
Automatic Camera Placement for Robot Vision Tasks|
Bundle ajustment - a modern synthesis|
Critical Motions in Euclidean Structure from Motion|
Autocalibration from planar surfaces|
Covariance scaled sampling for monocular 3D body tracking|
Hyperdynamic importance sampling|
Mapping Minima and Transitions in Visual Models|
Bundle Adjustment - Modern Synthesis,|
Tracking Articulated Motion Using a Mixture of Autoregressive Models|
3D Human Pose from Silhouettes by Relevance Vector Regression|
Autocalibation from Planar Scenes|
A Robust Multiple Hypothesis Approach to Monocular Human Motion Tracking,|
Tracking Articulated Motion with Piecewise Learned Dynamical Models|
Learning to parse picture of people|
The tradeoff between generative and discriminative classifiers|
A comprehensive survey of bundle adjustment in computer vision|
Camera Pose and Calibration from 4 or 5 Known 3D Points|
iAutocalibration and the absolute quadric,j|
Vision Algorithms: Theory and Practice|
The geometry and matching of curves in multiple views|
Hierarchical part-based visual object categorization|
Optima Estimatio o Mat hin Constrai ts In: SMILE'98: Eu o a Worksho o 3 Structu f o Multipl Image o a ge-S al Envi onments|
