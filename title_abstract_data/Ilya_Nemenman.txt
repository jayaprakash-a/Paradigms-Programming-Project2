Entropy and Inference, Revisited| Abstract We study properties of popular near--uniform (Dirichlet) priors for learning undersampled probability distributions on discrete nonmetric spaces and show that they lead to disastrous results.  However, an Occam--style phase space argument expands the priors into their infinite mixture and resolves most of the observed problems.  This leads to a surprisingly good estimator of entropies of discrete distributions.  Learning a probability distribution from examples is one of the basic problems in data analysis.  Common practical approaches introduce a family of parametric models, leading to questions about model selection.  In Bayesian inference, computing the total probability of the data arising from a model involves an integration over parameter space, and the resulting "phase space volume" automatically discriminates against models with larger numbers of parameters---hence the description of these volume terms as Occam factors [1, 2].  As we move from finite parameterizations to models that are described by smooth functions, the integrals over parameter space become functional integrals and methods from quantum field theory allow us to do these integrals asymptotically; again the volume in model space consistent with the data is larger for models that are smoother and hence less complex [3].  Further, at least under some conditions the relevant degree of smoothness can be determined self--consistently from the data, so that we approach something like a model independent method for learning a distribution [4].  The results emphasizing the importance of phase space factors in learning prompt us to look back at a seemingly much simpler problem, namely learning a distribution on a discrete, nonmetric space.  Here the probability distribution is just a list of numbers {q i },
Predictability, complexity and learning| We de ne predictive information I pred (T) as the mutual information between the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times T: I pred (T) can remain nite, grow logarithmically, or grow as a fractional power law.  If the time series allows us to learn a model with a nite number of parameters, then I pred (T) grows logarithmically with a coef cient that counts the dimensionality of the model space.  In contrast, power-law growth is associated, for example, with the learning of in nite parameter (or nonparametric) models such as continuous functions with smoothness constraints.  There are connections between the predictive information and measures of complexity that have been de ned both in learning theory and the analysis of physical systems through statistical mechanics and dynamical systems theory.  Furthermore, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of I pred (T) provides the unique measure for the complexity of dynamics underlying a time series.  Finally, we discuss how these ideas may be useful in problems in physics, statistics, and biology. 
Learning Continuous Distributions: Simulations With Field Theoretic Priors| Abstract Learning of a smooth but nonparametric probability density can be regularized using methods of Quantum Field Theory.  We implement a field theoretic prior numerically, test its efficacy, and show that the free parameter of the theory (`smoothness scale') can be determined self consistently by the data; this forms an infinite dimensional generalization of the MDL principle.  Finally, we study the implications of one's choice of the prior and the parameterization and conclude that the smoothness scale determination makes density estimation very weakly sensitive to the choice of the prior, and that even wrong choices can be advantageous for small data sets.  One of the central problems in learning is to balance `goodness of fit' criteria against the complexity of models.  An important development in the Bayesian approach was thus the realization that there does not need to be any extra penalty for model complexity: if we compute the total probability that data are generated by a model, there is a factor from the volume in parameter space---the `Occam factor'---that discriminates against models with more parameters [1, 2].  This works remarkably well for systems with a finite number of parameters and creates a complexity `razor' (after `Occam's razor') that is almost equivalent to the celebrated Minimal Description Length (MDL) principle [3].  In addition, if the a priori distributions involved are strictly Gaussian, the ideas have also been proven to apply to some infinite--dimensional (nonparametric) problems [4].  It is not clear, however, what happens if we leave the finite dimensional setting to consider nonparametric problems which are not Gaussian, such as the estimation of a smooth probability density.  A possible route to progress on the nonparametric problem was opened by noticing [5] that a Bayesian prior for density estimation is equivalent to a quantum field theory (QFT).  In particular, there are field theoretic methods for computing the infinite dimensional analog of the Occam factor, at least asymptotically for large numbers of examples.  These observations have led to a number of papers [6, 7, 8, 9] exploring alternative formulations and their implications for the speed of learning.  Here we return to the original formulation of Ref.  [5] and use numerical methods to address some of the questions left open by the analytic work [10]: What is the result of balancing the infinite dimensional Occam factor against the goodness of fit? Is the QFT inference optimal in using all of the information relevant for learning [11]? What happens if our learning problem is strongly atypical of the prior distribution? Following Ref.  [5], if N i.  i.  d.  samples fx i g; i = 1 : : : N; are observed, then the probability that a particular density Q(x)
Complexity through nonextensivity| Abstract The problem of de,ningand studyingcomplexity of a time series has interested people for years.  In the context of dynamical systems, Grassberger has suggested that a slow approach of the entropy to its extensive asymptotic limit is a sign of complexity.  We investigate this idea further by information theoretic and statistical mechanics techniques and show that these arguments can be made precise, and that they generalize many previous approaches to complexity, in particular, unifyingideas from the physics literature with ideas from learningand codingtheory; there are even connections of this statistical approach to algorithmic or Kolmogorov complexity.  Moreover, a set of simple axioms similar to those used by Shannon in his development of information theory allows us to prove that the divergent part of the subextensive component of the entropy is a unique complexity measure.  We classify time series by their complexities and demonstrate that beyond the "logarithmic" complexity classes widely anticipated in the literature there are qualitatively more complex, "power-law" classes which deserve more attention. 
Occam factors and model-independent Bayesian learning of continuous distributions|
Information theory and learning: a physical approach|
