Expressivity versus Eciency of Graph Kernels| Abstract.  Recently, kernel methods have become a popular tool for machine learning and data mining.  As most `real-world' data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data.  One of the most widely used tools for modeling structured data are graphs.  In this paper we study the trade-off between expressivity and eciency of graph kernels.  First, we motivate the need for this discussion by showing that fully general graph kernels can not even be approximated eciently.  We also discuss generalizations of graph kernels defined in literature and show that they are either not positive definite or not very useful.  Finally, we propose a new graph kernel based on subtree patterns.  We argue that while a little more computationally expensive, this kernel is more expressive than kernels based on walks. 
Large-Scale Multiclass Transduction| Abstract We present a method for performing transductive inference on very large datasets.  Our algorithm is based on multiclass Gaussian processes and is effective whenever the multiplication of the kernel matrix or its inverse with a vector can be performed sufficiently fast.  This holds, for instance, for certain graph and string kernels.  Transduction is achieved by variational inference over the unlabeled data subject to a balancing constraint. 
Roc analysis on sisyphus data,|
A survey of kernels for structured data|
Zeno for rapid collaboration in data mining projects|
Graph kernels and Gaussian processes for relational reinforcement learning|
Exponential and geometric kernels for graphs|
First blood vessels in the avian neural tube are formed by a combination of dorsal angioblast immigration and ventral sprouting of endothelial cells|
