Hierarchical Visualization of Time-Series Data Using Switching Linear Dynamical Systems| Abstract We propose a novel visualization algorithm for high-dimensional time-series data.  In contrast to most visualization techniques we do not assume consecutive data points to be independent.  The basic model is a linear dynamical system which can be seen as a dynamic extension of a probabilistic principal component model.  A further extension to a particular switching linear dynamical system allows a representation of complex data onto multiple and even a hierarchy of plots.  Using sensible approximations based on expectation propagation the projections can be performed in essentially the same order complexity as its static counterpart.  We apply our method on a real-world data set with sensor readings from a paper machine. 
Visualization of process data with dynamic Bayesian networks| Abstract We describe a novel visualization algorithm for high-dimensional timeseries data.  The underlying model is a switching linear dynamical system, a particular variant of a dynamic Bayesian network.  An important difference with most existing visualization techniques is the possibility to incorporate time dependencies between data points.  Exact inference in switching linear dynamical systems is intractable, but new techniques for approximate inference enable fast computation of accurate posteriors.  The model can be learned with a standard EM-algorithm.  We illustrate our method on a real-world data set with sensor readings from a paper machine. 
Multi-scale Switching Linear Dynamical Systems| Abstract--- Switching linear dynamic systems can monitor dynamic systems that operate in different regimes.  In this article we introduce a class of multi-scale switching linear dynamical systems that are particularly suited if such regimes form a hierarchy. 
Gaussian Quadrature Based Expectation Propagation| Abstract We present a general approximation method for Bayesian inference problems.  The method is based on Expectation Propagation (EP).  Projection steps in the EP iteration that cannot be done analytically are done using Gaussian quadrature.  By identifying a general form in the projections, the only quadrature rules that are required are for exponential family weight functions.  The corresponding cumulant and moment generating functions can then be used to automatically derive the necessary quadrature rules.  In this article the approach is restricted to approximating families that factorize to a product of onedimensional families.  The final algorithm has interesting similarities with particle filtering algorithms.  We discuss these, and also discuss the relationship with variational Bayes and Laplace propagation.  Experimental results are given for an interesting model from mathematical finance. 
To appear in proceedings of ICANN 2003 Multi-Scale Switching Linear Dynamical Systems| Abstract.  Switching linear dynamic systems can monitor systems that operate in different regimes.  In this article we introduce a class of multiscale switching linear dynamical systems that are particularly suited if such regimes form a hierarchy.  The setup consists of a specific switching linear dynamical system for every level of coarseness.  Jeffrey's rule of conditioning is used to coordinate the models at the different levels.  When the models are appropriately constrained, inference at finer levels can be performed independently for every subtree.  This makes it possible to determine the required degree of detail on-line.  The refinements of very improbable regimes need not be explored.  The computational complexity of exact inference in both the standard and the multi-class switching linear dynamical system is exponential in the number of observations.  We describe an appropriate approximate inference algorithm based on expectation propagation and relate it to a variant of the Bethe free energy. 
IMPROVED UNSCENTED KALMAN SMOOTHING FOR STOCK VOLATILITY ESTIMATION| Abstract.  We introduce a novel approximate inference algorithm for non-linear dynamical systems.  The algorithm is based upon expectation propagation and Gaussian quadrature.  The first forward pass is strongly related to the unscented Kalman filter.  It improves upon unscented Kalman filtering by only making Gaussian approximations in the latent and not in the observation space.  Smoothed estimates can be found without inverting latent space dynamics and can be improved by iteration.  Multiple forward and backward passes make it possible to improve local approximations and make them as consistent as possible.  We demonstrate the validity of the approach with an interesting inference problem in stochastic stock volatility models.  The traditional unscented Kalman filter is ill suited for this problem: it can be proven that the traditional filter effectively never updates prior beliefs.  The novel algorithm gives good results and improves with iteration.  INFERENCE IN STOCHASTIC VOLATILITY MODELS In 1973, Black, Scholes and Merton [1, 7] reasoned that under certain idealized market assumptions the prices of stocks and derivatives on those stocks are coupled.  A derivative is a financial product whose pay-o# is determined by the price of another asset.  A European call option for instance entitles the holder the right to buy a certain stock for a specific price, the strike price, at a specific moment in the future, the maturity time.  The effective pay-o# at maturity time is the difference between the stock price and the strike price if the former exceeds the latter, and zero otherwise.  If all the market assumptions from [1, 7] hold, the price of such an option is a deterministic function of the current price of the underlying stock, the stock's volatility, the risk-free interest rate, the strike price and the maturity time of the option.  Any other price allows traders to sell over priced and buy under priced assets and make a risk-free profit.  One of the crucial assumptions is that the underlying stock S follows a geometric Brownian motion dS S = dt + p V dz.  (1) In (1) dz is a Brownian motion, is a drift and p V is the volatility.  The latter two are constant or a deterministic function of time.  It is mainly the assumption of constant volatility that does not seem to hold in practice.  Equation (1) implies that daily log returns are normally distributed with constant mean and standard deviation.  What is observed for most stocks is that this standard deviation (the volatility) is not constant, but is auto-correlated and mean reverting.  Also the returns do not appear to come from a normal distribution but from a distribution with heavier tails.  These observations have led many researchers to formulate stochastic volatility models; models where the volatility itself follows an (unobserved) stochastic process.  In our experiments we will use a discrete time model that is inspired by the model from [3].  We denote the log returns with y t = log S t S t- 1 , where t ranges over exchange closing times.  As mentioned previously, if the volatility would be constant, the y t 's would be identically, independently and normally distributed.  We keep the mean of this distribution fixed at , but treat the volatility as a random variable itself.  We define x t to be the log of the volatility at time t.  It follows an AR process with a base level l to which it reverts with rate a.  The complete model reads x t = a(x t- 1 - l) + l + # t , # t # N (0, q), (2) y t = e x t # t + , # t # N (0, 1) .  (3) In the above N (m, v) denotes the Gaussian probability distribution with mean m and variance v.  All disturbances # t and # t are assumed to be independently drawn.  At t = 1, x 1 # N (m 1 , v 1 ).  Figure 1 shows an artificial dataset generated from this model.  The latent state dynamics are linear and Gaussian, but the observation model is non-linear.  As a result exact inference of filtered and smoothed posteriors, p(x t |y 1:t ) and p(x t |y 1:T ), with T } t, is infeasible.  In this article we will introduce an approximate inference technique that is closely related to the unscented Kalman filter [4] but significantly improves upon it.  We will consider the following general class of non-linear models x t = f(x t- 1 , # t ), # t # N (0, q) (4) y t = g(x t , # t ), # t # N (0, r) .  (5) The only requirement on g is that p(y t |x t ) = R g(x t , # t )p(# t ) with p(# t ) Gaussian, can be computed analytically.  For this to hold it is sufficient (but not necessary) that g is linear in # t . 
Generalized belief propagation for approximate inference in hybrid Bayesian networks| Abstract We apply generalized belief propagation to approximate inference in hybrid Bayesian networks.  In essence, in the algorithms developed for discrete networks we only have to change \strong marginalization" (exact) into \weak marginalization" (same moments) or, equivalently, the \sum" operation in the (generalized) sum-product algorithm into a \collapse" operation.  We describe both a message-free single-loop algorithm based on fixed-point iteration and a more tedious double-loop algorithm guaranteed to converge to a minimum of the Kikuchi free energy.  With the cluster variation method we can interpolate between the minimal Kikuchi approximation and the (strong) junction tree algorithm.  Simulations on the emission network of [7], extended in [13], indicate that the Kikuchi approximation in practice often works really well, even in the dicult case of discrete children of continuous parents. 
Expectation propagation for approximate inference in dynamic Bayesian networks| Abstract We describe expectation propagation for approximate inference in dynamic Bayesian networks as a natural extension of Pearl's exact belief propagation.  Expectation propagation is a greedy algorithm, converges in many practical cases, but not always.  We derive a double-loop algorithm, guaranteed to converge to a local minimum of a Bethe free energy.  Furthermore, we show that stable fixed points of (damped) expectation propagation correspond to local minima of this free energy, but that the converse need not be the case.  We illustrate the algorithms by applying them to switching linear dynamical systems and discuss implications for approximate inference in general Bayesian networks. 
Approximate Expectation Maximization| Abstract We discuss the integration of the expectation-maximization (EM) algorithm for maximum likelihood learning of Bayesian networks with belief propagation algorithms for approximate inference.  Specifically we propose to combine the outer-loop step of convergent belief propagation algorithms with the M-step of the EM algorithm.  This then yields an approximate EM algorithm that is essentially still double loop, with the important advantage of an inner loop that is guaranteed to converge.  Simulations illustrate the merits of such an approach. 
