Computation of Smooth Optical Flow in a Feedback Connected Analog Network| Abstract In 1986, Tanner and Mead [1] implemented an interesting constraint satisfaction circuit for global motion sensing in aVLSI.  We report here a new and improved aVLSI implementation that provides smooth optical flow as well as global motion in a two dimensional visual field.  The computation of optical flow is an ill-posed problem, which expresses itself as the aperture problem.  However, the optical flow can be estimated by the use of regularization methods, in which additional constraints are introduced in terms of a global energy functional that must be minimized.  We show how the algorithmic constraints of Horn and Schunck [2] on computing smooth optical flow can be mapped onto the physical constraints of an equivalent electronic network.  1 Motivation The perception of apparent motion is crucial for navigation.  Knowledge of local motion of the environment relative to the observer simplifies the calculation of important tasks such as time-to-contact or focus-of-expansion.  There are several methods to compute optical flow.  They have the common problem that their computational load is large.  This is a severe disadvantage for autonomous agents, whose computational power is restricted by energy, size and weight.  Here we show how the global regularization approach which is necessary to solve for the ill-posed nature of computing optical flow, can be formulated as a local feedback constraint, and implemented as a physical analog device that is computationally efficient. 
Silicon retina sensing guided by omni-directional vision| Abstract: A way of combining a relatively new sensor-technology, that is optical analog VLSI devices, with a standard digital omni-directional vision system is investigated.  The sensor used is a neuromorphic analog VLSI sensor that estimates the global visual image motion.  The sensor provides two analog output voltages that represent the components of the global optical flow vector.  The readout is guided by an omni-directional mirror that maps the location of the ball and directs the robot to align its position so that a sensor-actuator module that includes the analog VLSI optical flow sensor can be activated.  The purpose of the sensoractuator module is to operate with a higher update rate than the standard vision system and thus increase the reactivity of the robot for very specific situations.  This paper will demonstrate an application example where the robot is a goalkeeper with the task of defending the goal during a penalty kick. 
COMPACT INTEGRATED TRANSCONDUCTANCE AMPLIFIER CIRCUIT FOR TEMPORAL DIFFERENTIATION| ABSTRACT A compact integrated CMOS circuit for temporal differentiation is presented.  It consists of a high-gain inverting amplifier, an active non-linear transconductance and a capacitor and requires only 4 transistors in its minimal configuration.  The circuit provides two rectified current outputs that are proportional to the temporal derivative of the input voltage signal.  Besides the compactness of its design, the presented circuit is not dependent on the DC-value of the input signal, as compared with known integrated differentiator circuits [1].  Measured chip results show that the circuit operates on a large input frequency range for which it provides nearideal temporal differentiation.  The circuit is particularly suited for focal-plane implementations of gradient-based visual motion systems.  1.  MOTIVATION A critical constraint in focal-plane design is the compactness of the pixel.  Implementations of gradient-based motion estimation algorithms critically rely on the robust and exact estimation of spatio-temporal intensity gradients [2, 3, 4].  In elaborate 2D motion processing systems, the extraction of the temporal intensity gradient is only a fraction of the total signal processing performed in each pixel [5].  Compact circuits are favorable in order to reduce pixel sizes.  A linear capacitor # is an ideal differentiator because the capacitive current # # induced by a change in the voltage # # across the capacitor # is given by # # # # fiff # fiff # High-gain amplifier feedback circuits have been proposed where the linear resistance # allows an indirect measure of # # (see e. g.  [6, 7, 8]).  The "grounded-capacitor" differentiator (Figure 1a) forces the potential # # on the capacitive node to follow the input This work was supported by ETH Forschungskredit 0-23819-01.  a C V in I c R A+ + V c V out b C V in I c+ + R A V c V ref V out Figure 1: Two complementary versions of the transconductance amplifier differentiator.  (a) The "grounded-capacitor" differentiator.  The voltage # # is forced to follow # fiff .  (b) The "clamped-capacitor" differentiator.  Instead of following the input, # # is clamped to the reference # ### .  signal # fiff .  The voltage # ### therefore represents a superposition of the input signal and its temporal derivative which is evident from the circuit's transfer function # # #### #### ### fiff fiff # ### # #### (1) where # is the gain of the amplifier and the approximation is valid for # # #.  The "clamped-capacitor" differentiator (Figure 1b) however, clamps # # to the reference # ### .  The voltage # ### is now (negatively) proportional to the temporal derivative of the input signal as expressed by the transfer-function # # ##### fiff ### fiff fiff # ### #### # (2) In both circuits, # # represents the ideal temporal derivative of the input signal # fiff for ideal amplification and linear # and #.  Implementations of the two circuits in standard CMOS technology suffer from the limited possibilities to create high linear resistances.  Using active resistive elements, implementations of the "grounded-capacitor" differentiator have been proposed such as the "hysteretic differentiator" and the "diff2" circuit [1].  Due to the non-linear characteristics of
Classifying Patterns of Visual Motion - a Neuromorphic Approach| Abstract We report a system that classifies and can learn to classify patterns of visual motion on-line.  The complete system is described by the dynamics of its physical network architectures.  The combination of the following properties makes the system novel: Firstly, the front-end of the system consists of an aVLSI optical flow chip that collectively computes 2-D global visual motion in real-time [1].  Secondly, the complexity of the classification task is significantly reduced by mapping the continuous motion trajectories to sequences of 'motion events'.  And thirdly, all the network structures are simple and with the exception of the optical flow chip based on a Winner-Take-All (WTA) architecture.  We demonstrate the application of the proposed generic system for a contactless man-machine interface that allows to write letters by visual motion.  Regarding the low complexity of the system, its robustness and the already existing front-end, a complete aVLSI system-on-chip implementation is realistic, allowing various applications in mobile electronic devices. 
ANALOG INTEGRATED 2-D OPTICAL FLOW SENSOR WITH PROGRAMMABLE PIXELS| ABSTRACT We present a framework for real-time visual motion perception consisting of a novel analog VLSI optical flow sensor with reconfigurable pixels, connected in feedback with a controlling processor.  The 2-D sensor array is composed of motion processing pixels that can be individually recruited to form dynamic ensembles that collectively compute visual motion.  This flexible framework lends itself to the emulation of multi-layer recurrent network architectures for highlevel processing of visual motion.  In particular, attentional modulation can easily be incorporated in the visual motion processing.  We show a simple example of visual tracking that demonstrates the potential of the framework.  1.  MOTIVATION Estimation of visual motion is an important aspect of visual processing in freely behaving and cognitive autonomous systems.  However, it is difficult to obtain a reliable estimate because visual motion is inherently ambiguous.  The ambiguity can be resolved by estimating the visual motion in terms of a model that relates the observed spatio-temporal brightness changes in a visual scene with the underlying physical world producing it.  The better the model, the better is the understanding of the visual scene, and so the better is the estimate of visual motion.  The selection of the model is a trade-off between computational cost and functional reliability.  Simple models, such as Normal Flow, offer computationally trackablity and real-time performance at the cost of poor estimates under some conditions.  Elaborate models, on the other hand, provide more generally acceptable results but are computationally expensive.  For example, the estimation of visual motion of an object usually requires the integration of visual information across its outline, an operation that requires dynamical recombination of the individual units of a retinotopic array of local motion processors. 
Analog VLSI Focal-Plane Array With Dynamic Connections for the Estimation of Piecewise-Smooth Optical Flow| Abstract---An analog very large-scale integrated (aVLSI) sensor is presented that is capable of estimating optical flow while detecting and preserving motion discontinuities.  The sensor's architecture is composed of two recurrently connected networks.  The units in the first network (the optical-flow network) collectively estimate two-dimensional optical flow, where the strength of their nearest-neighbor coupling determines the degree of motion integration.  While the coupling strengths in our previous implementations were globally set and adjusted by the operator, they are now dynamically and locally controlled by a second on-chip network (the motion-discontinuity network).  The coupling strengths are set such that visual motion integration is inhibited across image locations that are likely to represent motion boundaries.  Results of a prototype sensor illustrate the potential of the approach and its functionality under real-world conditions. 
Constraint optimization networks for visual motion perception - analysis and synthesis|
