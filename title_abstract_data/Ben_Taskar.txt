Rich probabilistic models for gene expression| ABSTRACT Clustering is commonly used for analyzing gene expression data.  Despite their successes, clustering methods suffer from a number of limitations.  First, these methods reveal similarities that exist over all of the measurements, while obscuring relationships that exist over only a subset of the data.  Second, clustering methods cannot readily incorporate additional types of information, such as clinical data or known attributes of genes.  To circumvent these shortcomings, we propose the use of a single coherent probabilistic model, that encompasses much of the rich structure in the genomic expression data, while incorporating additional information such as experiment type, putative binding sites, or functional information.  We show how this model can be learned from the data, allowing us to discover patterns in the data and dependencies between the gene expression patterns and additional attributes.  The learned model reveals context-specific relationships, that exist only over a subset of the experiments in the dataset.  We demonstrate the power of our approach on synthetic data and on two real-world gene expression data sets for yeast.  For example, we demonstrate a novel functionality that falls naturally out of our framework: predicting the "cluster" of the array resulting from a gene mutation based only on the gene's expression pattern in the context of other mutations. 
Probabilistic Classification and Clustering in Relational Data| Abstract Supervised and unsupervised learning methods have traditionally focused on data consisting of independent instances of a single type.  However, many real-world domains are best described by relational models in which instances of multiple types are related to each other in complex ways.  For example, in a scientific paper domain, papers are related to each other via citation, and are also related to their authors.  In this case, the label of one entity (e. g. , the topic of the paper) is often correlated with the labels of related entities.  We propose a general class of models for classification and clustering in relational domains that capture probabilistic dependencies between related instances.  We show how to learn such models efficiently from data.  We present empirical results on two real world data sets.  Our experiments in a
Structured Prediction via the Extragradient Method| Abstract We present a simple and scalable algorithm for large-margin estimation of structured models, including an important class of Markov networks and combinatorial models.  We formulate the estimation problem as a convex-concave saddle-point problem and apply the extragradient method, yielding an algorithm with linear convergence using simple gradient and projection calculations.  The projection step can be solved using combinatorial algorithms for min-cost quadratic flow.  This makes the approach an efficient alternative to formulations based on reductions to a quadratic program (QP).  We present experiments on two very different structured prediction tasks: 3D image segmentation and word alignment, illustrating the favorable scaling properties of our algorithm. 
Exponentiated Gradient Algorithms for Large-margin Structured Classification| Abstract We consider the problem of structured classification, where the task is to predict a label y from an input x, and y has meaningful internal structure.  Our framework includes supervised training of Markov random fields and weighted context-free grammars as special cases.  We describe an algorithm that solves the large-margin optimization problem defined in [12], using an exponential-family (Gibbs distribution) representation of structured objects.  The algorithm is efficient---even in cases where the number of labels y is exponential in size---provided that certain expectations under Gibbs distributions can be calculated efficiently.  The method for structured labels relies on a more general result, specifically the application of exponentiated gradient updates [7, 8] to quadratic programs. 
Learning Probabilistic Relational Models with Structural Uncertainty| Abstract Most real-world data is stored in relational form.  In
Learning on the Test Data: Leveraging Unseen Features| Abstract This paper addresses the problem of classification in
Probabilistic Models of Text and Link Structure for Hypertext Classification| Abstract Most text classification methods treat each document as an independent instance.  However, in many text domains, documents are linked and the topics of linked documents are correlated.  For example, web pages of related topics are often connected by hyperlinks and scientific papers from related fields are commonly linked by citations.  We propose a unified probabilistic model for both the textual content and the link structure of a document collection.  Our model is based on the recently introduced framework of Probabilistic Relational Models (PRMs), which allows us to capture correlations between linked documents.  We show how to learn these models from data and use them efficiently for
Large margin methods for structured classification: Exponentiated gradient algorithms and PAC-Bayesian generalization bounds| Abstract.  We consider the problem of structured classification, where the task is to predict a label y from an input x, and y has meaningful internal structure.  Our framework includes supervised training of both Markov random fields and weighted context-free grammars as special cases.  We describe an algorithm that solves the large-margin optimization problem defined in [12], using an exponentialfamily (Gibbs distribution) representation of structured objects.  The algorithm is efficient -- even in cases where the number of labels y is exponential in size -provided that certain expectations under Gibbs distributions can be calculated efficiently.  The optimization method we use for structured labels relies on a more general result, specifically the application of exponentiated gradient (EG) updates [4, 5] to quadratic programs (QPs).  We describe a new method for solving QPs based on these techniques, and give bounds on its rate of convergence.  In addition to their application to the structured-labels task, the EG updates lead to simple algorithms for optimizing "conventional" binary or multiclass SVM problems.  Finally, we give a new generalization bound for structured classification, using PAC-Bayesian methods for the analysis of large margin classifiers. 
Max-Margin Parsing| Abstract We present a novel discriminative approach to parsing inspired by the large-margin criterion underlying
Statistical Models for Relational Data| Abstract.  We introduce a new type of probabilistic model for relational domains, a statistical relational model (SRM).  An SRM is a statistical model of a particular database instantiation.  The SRM captures the tuple frequencies in the database, and in particular the SRM captures the frequencies with which tuples join.  The SRM provides a compact model of a data base and can be used to quickly give (approximate) answers to queries on this database.  Because it models a joint distribution over tuples from multiple tables, it is ideally to mining multi-relational databases.  We describe the semantics of SRMs and a learning algorithm for SRMs.  We provide experimental results showing that using only a small fraction of the space of the original database, we can still accurately answer a wide range of queries. 
Learning Probabilistic Models of Relational Structure| We describe the appropriate conditions for using each model and present learning algorithms for each.  We present experimental results showing that the learned models can be used to predict relational structure and, moreover, the observed relational structure can be used to provide better predictions for the attributes in the model. 
Selectivity Estimation using Probabilistic Models| ABSTRACT Estimating the result size of complex queries that involve selection on multiple attributes and the join of several relations is a difficult but fundamental task in database query processing.  It arises in cost-based query optimization, query profiling, and approximate query answering.  In this paper, we show how probabilistic graphical models can be effectively used for this task as an accurate and compact approximation of the joint frequency distribution of multiple attributes across multiple relations.  Probabilistic Relational Models (PRMs) are a recent development that extends graphical statistical models such as Bayesian Networks to relational domains.  They represent the statistical dependencies between attributes within a table, and between attributes across foreign-key joins.  We provide an efficient algorithm for constructing a PRM from a database, and show how a PRM can be used to compute selectivity estimates for a broad class of queries.  One of the major contributions of this work is a unified framework for the estimation of queries involving both select and foreign-key join operations.  Furthermore, our approach is not limited to answering a small set of predetermined queries; a single model can be used to effectively estimate the sizes of a wide collection of potential queries across multiple tables.  We present results for our approach on several real-world databases.  For both single-table multi-attribute queries and a general class of select-join queries, our approach produces more accurate estimates than standard approaches to selectivity estimation, using comparable space and time. 
Max-Margin Markov Networks| Abstract In typical classification tasks, we seek a function which assigns a label to a single object. 
Link Prediction in Relational Data| Abstract Many real-world domains are
Probabilistic clustering in relational data|
Using probabilistic models for selectivity estimation|
Label and Link Prediction in Relational Data|
Learning associative Markov networks|
Probabilistic models of relational structure|
Structured prediction, dual extragradient and Bregman projections|
A discriminative matching approach to word alignment|
Learning Structured Prediction Models: A Large Margin Approach|
Probabilistic clusterin in relational data|
