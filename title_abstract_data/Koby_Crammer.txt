A new family of online algorithms for category ranking| ABSTRACT We describe a new family of topic-ranking algorithms for multi-labeled documents.  The motivation for the algorithms stems from recent advances in online learning algorithms.  The algorithms we present are simple to implement and are time and memory ecient.  We evaluate the algorithms on the Reuters-21578 corpus and the new corpus released by Reuters in 2000.  On both corpora the algorithms we present outperform adaptations to topic-ranking of Rocchio's algorithm and the Perceptron algorithm.  We also outline the formal analysis of the algorithm in the mistake bound model.  To our knowledge, this work is the first to report performance results with the entire new Reuters corpus. 
Online Large-Margin Training of Dependency Parsers| Abstract We present an effective training algorithm for linearly-scored dependency parsers that implements online largemargin multi-class training (Crammer and Singer, 2003; Crammer et al. , 2003) on top of efficient parsing techniques for dependency trees (Eisner, 1996).  The trained parsers achieve a competitive dependency accuracy for both English and Czech with no language specific enhancements. 
Learning from Data of Variable Quality| Abstract We initiate the study of learning from multiple sources of limited data, each of which may be corrupted at a different rate.  We develop a complete theory of which data sources should be used for two fundamental problems: estimating the bias of a coin, and learning a classifier in the presence of label noise.  In both cases, efficient algorithms are provided for computing the optimal subset of data. 
Improved Output Coding for Classification Using Continuous Relaxation| Abstract Output coding is a general method for solving multiclass problems by reducing them to multiple binary classification problems.  Previous research on output coding has employed, almost solely, predefined discrete codes.  We describe an algorithm that improves the performance of output codes by relaxing them to continuous codes.  The relaxation procedure is cast as an optimization problem and is reminiscent of the quadratic program for support vector machines.  We describe experiments with the proposed algorithm, comparing it to standard discrete output codes.  The experimental results indicate that continuous relaxations of output codes often improve the generalization performance, especially for short codes. 
Thermal characterization of defects in aircraft structures via spatially controlled heat application| ABSTRACT Recent advances in thermal imaging technology have spawned a number of new thermal NDE techniques that provide quantitative information about flaws in aircraft structures.  Thermography has a number of advantages as an inspection technique.  It is a totally noncontacting, nondestructive, imaging technology capable of inspecting a large area in a matter of a few seconds.  The development of fast, inexpensive image processors have aided in the attractiveness of thermography as an NDE technique.  These image processors have increased the signal to noise ratio of thermography and facilitated significant advances in post-processing.  The resulting digital images enable archival records for comparison with later inspections thus providing a means of monitoring the evolution of damage in a particular structure.  The National Aeronautics and Space Administration's Langley Research Center has developed a thermal NDE technique designed to image a number of potential flaws in aircraft structures.  The technique involves injecting a small, spatially controlled heat flux into the outer surface of an aircraft.  Images of fatigue cracking, bond integrity and material loss due to corrosion are generated from measurements of the induced surface temperature variations.  This paper will present a discussion of the development of the thermal imaging system as well as the techniques used to analyze the resulting thermal images.  Spatial tailoring of the heat coupled with the analysis techniques represent a significant improvement in the delectability of flaws over conventional thermal imaging. 
A needle in a haystack: local one-class optimization| Abstract This paper addresses the problem of finding a small and coherent subset of points in a given data.  This problem, sometimes referred to as one-class or set covering, requires to find a small-radius ball that covers as many data points as possible.  It rises naturally in a wide range of applications, from finding gene-modules to extracting documents' topics, where many data points are irrelevant to the task at hand, or in applications where only positive examples are available.  Most previous approaches to this problem focus on identifying and discarding a possible set of outliers.  In this paper we adopt an opposite approach which directly aims to find a small set of coherently structured regions, by using a loss function that focuses on local properties of the data.  We formalize the learning task as an optimization problem using the InformationBottleneck principle.  An algorithm to solve this optimization problem is then derived and analyzed.  Experiments on gene expression data and a text document corpus demonstrate the merits of our approach. 
Kernel Design Using Boosting| Abstract The focus of the paper is the problem of learning kernel operators from empirical data.  We cast the kernel design problem as the construction of an accurate kernel from simple (and less accurate) base kernels.  We use the boosting paradigm to perform the kernel construction process.  To do so, we modify the booster so as to accommodate kernel operators.  We also devise an efficient weak-learner for simple kernels that is based on generalized eigen vector decomposition.  We demonstrate the effectiveness of our approach on synthetic data and on the USPS dataset.  On the USPS dataset, the performance of the Perceptron algorithm with learned kernels is systematically better than a fixed RBF kernel. 
On the Learnability and Design of Output Codes for Multiclass Problems| Abstract Output coding is a general framework for solving multiclass categorization problems.  Previous research on output codes has focused on building multiclass machines given predefined output codes.  In this paper we discuss for the first time the problem of designing output codes for multiclass problems.  For the design problem of discrete codes, which have been used extensively in previous works, we present mostly negative results.  We then introduce the notion of continuous codes and cast the design problem of continuous codes as a constrained optimization problem.  We describe three optimization problems corresponding to three different norms of the code matrix.  Interestingly, for the l 2 norm our formalism results in a quadratic program whose dual does not depend on the length of the code.  A special case of our formalism provides a multiclass scheme for building support vector machines which can be solved efficiently.  We give a time and space efficient algorithm for solving the quadratic program.  Preliminary experiments we have performed with synthetic data show that our algorithm is often two orders of magnitude faster than standard quadratic programming packages. 
Learning Algorithm for Enclosing Points in Bregmanian Spheres| Abstract.  We discuss the problem of finding a generalized sphere that encloses points originating from a single source.  The points contained in such a sphere are within a maximal divergence from a center point.  The divergences we study are known as the Bregman divergences which include as a special case both the Euclidean distance and the relative entropy.  We cast the learning task as an optimization problem and show that it results in a simple dual form which bears interesting algebraic properties.  We then discuss a general algorithmic framework to solve the optimization problem.  Our training algorithm employs an auxiliary function that bounds the dual's objective function and can be used with a broad class of Bregman functions.  As a specific application of the algorithm we give a detailed derivation for the relative entropy.  We analyze the generalization ability of the algorithm by adopting margin-style proof techniques.  We also describe and analyze two schemes of online algorithms for the case when the radius of the sphere is set in advance. 
Pranking with Ranking| Abstract We discuss the problem of ranking instances.  In our framework each instance is associated with a rank or a rating, which is an integer from 1 to k.  Our goal is to find a rank-prediction rule that assigns each instance a rank which is as close as possible to the instance's true rank.  We describe a simple and ecient online algorithm, analyze its performance in the mistake bound model, and prove its correctness.  We describe two sets of experiments, with synthetic data and with the EachMovie dataset for collaborative filtering.  In the experiments we performed, our algorithm outperforms online algorithms for regression and classification applied to ranking. 
Ultraconservative Online Algorithms for Multiclass Problems| Abstract.  In this paper we study online classification algorithms for multiclass problems in the mistake bound model.  The hypotheses we use maintain one prototype vector per class.  Given an input instance, a multiclass hypothesis computes a similarity-score between each prototype and the input instance and then sets the predicted label to be the index of the prototype achieving the highest similarity.  To design and analyze the learning algorithms in this paper we introduce the notion of ultraconservativeness.  Ultraconservative algorithms are algorithms that update only the prototypes attaining similarity-scores which are higher than the score of the correct label's prototype.  We start by describing a family of additive ultraconservative algorithms where each algorithm in the family updates its prototypes by finding a feasible solution for a set of linear constraints that depend on the instantaneous similarity-scores.  We then discuss a specific online algorithm that seeks a set of prototypes which have a small norm.  The resulting algorithm, which we term MIRA (for Margin Infused Relaxed Algorithm) is ultraconservative as well.  We derive mistake bounds for all the algorithms and provide further analysis of MIRA using a generalized notion of the margin for multiclass problems. 
Margin Analysis of the LVQ Algorithm| Abstract Prototypes based algorithms are commonly used to reduce the computational complexity of Nearest-Neighbour (NN) classifiers.  In this paper we discuss theoretical and algorithmical aspects of such algorithms.  On the theory side, we present margin based generalization bounds that suggest that these kinds of classifiers can be more accurate then the 1-NN rule.  Furthermore, we derived a training algorithm that selects a good set of prototypes using large margin principles.  We also show that the 20 years old Learning Vector Quantization (LVQ) algorithm emerges naturally from our framework. 
Online Classification on a Budget| Abstract Online algorithms for classification often require vast amounts of memory and computation time when employed in conjunction with kernel functions.  In this paper we describe and analyze a simple approach for an on-the-fly reduction of the number of past examples used for prediction.  Experiments performed with real datasets show that using the proposed algorithmic approach with a single epoch is competitive with the support vector machine (SVM) although the latter, being a batch algorithm, accesses each training example multiple times. 
A Temporal Kernel-Based Model for Tracking Hand-Movements from Neural Activities| Abstract We devise and experiment with a dynamical kernel-based system for tracking hand movements from neural activity.  The state of the system corresponds to the hand location, velocity, and acceleration, while the system's input are the instantaneous spike rates.  The system's state dynamics is defined as a combination of a linear mapping from the previous estimated state and a kernel-based mapping tailored for modeling neural activities.  In contrast to generative models, the activity-to-state mapping is learned using discriminative methods by minimizing a noise-robust version of the ` 1 norm.  We use this approach to predict hand trajectories on the basis of neuronal activity in motor cortex of behaving monkeys and find that the proposed approach is more accurate than both a static approach based on support vector regression and the Kalman filter. 
On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines|
Complex zeros of the error function and of the complementary error function,|
e-stat|
Thermographic Imaging of Cracks in Thin Metal Sheets,|
Quantitative Thermal Imaging of Aircraft Structures,|
Towards Autonomic Networking Using Overlay Routing Techniques|
Psychometric properties and confirmatory factor analysis of the self-concealment scale|
