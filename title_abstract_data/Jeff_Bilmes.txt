A Novel Representation for Rhythmic Structure| Abstract We have developed a representation for musical rhythm and rhythmic structure based on concepts derived from African and African-American musics.  Included in the representation are a model for expressive timing against an isochronous pulse, and a cellular approach to musical organization.  In our implementation, the representation and its data structures are controlled and modified in real time using MAX.  The richness of control over many meaningful musical quantities distinguishes our representation from those in more common usage, such as music notation programs, sequencers, and drum machines. 
DBN BASED MULTI-STREAM MODELS FOR SPEECH| ABSTRACT We propose dynamic Bayesian network (DBN) based synchronous and asynchronous multi-stream models for noise-robust automatic speech recognition.  In these models, multiple noise-robust features are combined into a single DBN obtain better performance than any single feature system alone.  Results on the Aurora 2. 0 noisy speech task show significant improvements our synchronous model over both single stream models and over a ROVER based fusion method. 
High-Speed, Low-Resource Automatic Speech Recognition System| Date: In presenting this thesis in partial fulfillment of the requirements for a Master's degree at the University of Washington, I agree that the Library shall make its copies freely available for inspection.  I further agree that extensive copying of this thesis is allowable only for scholarly purposes, consistent with "fair use" as prescribed in the U. 
SPEECH FEATURE SMOOTHING FOR ROBUST ASR| ABSTRACT In this paper, we evaluate smoothing within the context of the MVA (mean subtraction, variance normalization, and ARMA filtering) post-processing scheme for noise-robust automatic speech recognition.  MVA has shown great success in the past on the Aurora 2. 0 and 3. 0 corpora even though it is computationally inexpensive.  Herein, MVA is applied to many acoustic feature extraction methods, and is evaluated using Aurora 2. 0.  We evaluate MVA post-processing on MFCCs, LPCs, PLPs, RASTA, Tandem, Modulation-filtered Spectrogram, and Modulation CrossCorreloGram features.  We conclude that while effectiveness does depend on the extraction method, the majority of features benefit significantly from MVA, and the smoothing ARMA filter is an important component.  It appears that the effectiveness of normalization and smoothing depends on the domain in which it is applied, being most fruitfully applied just before being scored by a probabilistic model.  Moreover, since it is both effective and simple, our ARMA filter should be considered a candidate method in most noise-robust speech recognition tasks. 
References for: Graphical Model Research in Audio, Speech, and Language Processing| Abstract This document provides a list of references to accompany the tutorial entitled as above and presented during the 2003 Uncertainty in Artificial Intelligence (UAI'03) conference, and mentioned at various times during the talk.  The list is far from complete, and is intended only to provide a useful starting point and to give a bit of historical perspective. 
The pSather Fat Parallel Virtual Machine (PFPVM) Interface| Abstract A critical part of the plan for portable pSather is the definition of a run-time interface that can be efficiently implemented on the wide range of platforms targeted by the project.  This document describes in detail the runtime interface assumed to exist by the pSather compiler.  Implementation details are not described herein. 
LOW-RESOURCE NOISE-ROBUST FEATURE POST-PROCESSING ON AURORA 2|0.  ABSTRACT We present a highly effective and extremely simple noiserobust front end based on novel post-processing of standard MFCC features.  It performs remarkably well on the Aurora 2. 0 noisydigits database without requiring any increase in model complexity.  Compared to the Aurora 2. 0 baseline system, our technique improves the average word error rate by 45% in the multicondition training case, (matched training/testing conditions) and 60% in the clean training case (mismatched training/testing conditions) --- this is an improvement that rivals some of the best known results on this database.  Our method, moreover, improves the performances in all cases, regardless of clean or noisy speech, matched or mis-matched environments.  Our technique is entirely general because it makes no assumptions about the existence, type, or level of noise in the speech signal.  Moreover, its simplicity means that it should be easy to integrate with other techniques in order to yield further improvements. 
STOCHASTIC PERCEPTUAL SPEECH MODELS WITH DURATIONAL DEPENDENCE| ABSTRACT In [6], we develop statistical model of speech recognition where emphasis is placed on the perceptually-relevant and information-rich portion of the speech signal.  In that model, speech is viewed as a sequence of elementary decisions or Auditory Events (avents) that are made in response to loci of significant spectral change.  These decision points are interleaved with periods during which insufficient information has been accumulated to make the next decision.  Wehave called this a Stochastic Perceptual Avent Model, or SPAM.  In the work reported here, wehave extended our initial experimental implementation [7] to include other probabilistic dependencies specified in the original theory, particularly the dependence on the time from the current frame backtothe previous hypothesized avent. 
Focused Word Segmentation for ASR| Abstract We propose a new set of features based on the temporal statistics of the spectral entropy of speech.  We show why these features make good inputs for a speech detector.  Moreover, we propose a back-end that uses the evidence from the above features in a `focused' manner.  Subsequently, by means of recognition experiments we show that using the above back-end leads to significant performance improvements, but merely appending the features to the standard feature vector does not improve performance.  We also report a 10% average improvement in word error rate over our baseline for the highly mis-matched case in the Aurora3. 0 corpus. 
University of Washington Graduate School This is to certify that I have examined this copy of a doctoral dissertation by| Date: In presenting this dissertation in partial fulfillment of the requirements for the Doctoral degree at the University of Washington, I agree that the Library shall make its copies freely available for inspection.  I further agree that extensive copying of this dissertation is allowable only for scholarly purposes, consistent with "fair use" as prescribed in the U. S.  Copyright Law.  Requests for copying or reproduction of this dissertation may be referred to Bell and Howell Information and Learning, 300 North Zeeb Road, Ann Arbor, MI 48106-1346, to whom the author has granted "the right to reproduce and sell (a) copies of the manuscript in microform and/or (b) printed copies of the manuscript made from microform. 
DATA-DRIVEN VECTOR CLUSTERING FOR LOW-MEMORY FOOTPRINT ASR| ABSTRACT It is important to produce automatic speech recognition (ASR) systems that use as few computational and memory resources as possible, especially in low-memory/low-power environments such as for personal digital assistants.  One way to achieve this is through parameter quantization.  In this work, we compare a variety of novel subvector clustering procedures for ASR system parameter quantization.  Specifically, we look at systematic data-driven subvector selection techniques based on entropy minimization, and compare performance on a 150-word isolated word speech recognition task.  While the optimal entropy-minimizing quantization methods are intractable, we show that although several of our heuristic techniques are elaborate in their attempt to approximate the optimal clustering, a simple scalar quantization scheme using separate codebooks performs remarkably well. 
The Vocal Joystick: A Voice-Based Human-Computer Interface for Individuals with Motor Impairments| Abstract We present a novel voice-based humancomputer interface designed to enable individuals with motor impairments to use vocal parameters for continuous control tasks.  Since discrete spoken commands are ill-suited to such tasks, our interface exploits a large set of continuous acousticphonetic parameters like pitch, loudness, vowel quality, etc.  Their selection is optimized with respect to automatic recognizability, communication bandwidth, learnability, suitability, and ease of use.  Parameters are extracted in real time, transformed via adaptation and acceleration, and converted into continuous control signals.  This paper describes the basic engine, prototype applications (in particular, voice-based web browsing and a controlled trajectory-following task), and initial user studies confirming the feasibility of this technology. 
USING MUTUAL INFORMATION TO DESIGN FEATURE COMBINATIONS| ABSTRACT Combination of different feature streams is a well-established method for improving speech recognition performance.  This empirical success, however, poses theoretical problems when trying to design combination systems: is it possible to predict which feature streams will combine most advantageously, and which of the many possible combination strategies will be most successful for the particular feature streams in question? We approach these questions with the tool of conditional mutual information (CMI), estimating the amount of information that one feature stream contains about the other, given knowledge of the correct subword unit label.  We argue that CMI of the raw feature streams should be useful in deciding whether to use independent or conjoint acoustic models for the streams; this is only weakly supported by our results.  We also argue that CMI between the outputs of independent classifiers based on each stream should help predict which streams can be combined most beneficially.  Our results confirm the usefulness of this measure. 
Q-Clustering| Abstract We show that Queyranne's algorithm for minimizing symmetric submodular functions can be used for clustering with a variety of different objective functions.  Two criteria that we consider in this paper are the maximum separation criterion, and the minimum description length criterion.  The first criterion tries to maximize the minimum distance between elements of different clusters, and is inherently "discriminative".  We will show that we can compute optimal clusterings into k clusters for any given k in polynomial time for this criterion.  The second criterion seeks to minimize the description length of the clusters given a probabilistic generative model.  We show that we can compute the optimal partitioning into 2 clusters, and approximate partitioning into more clusters.  Our approach differs from previous approaches to this problem which are either ad-hoc (with no well-defined objective criterion), or are approximate (which cannot guarantee optimal clusterings with respect to the objective function).  We show that the algorithm can be extended to other criteria by presenting a modified objective function which can still be exactly optimized, while being less sensitive to outliers.  We present results on three data sets. 
CUSTOM ARITHMETIC FOR HIGH-SPEED, LOW-RESOURCE ASR SYSTEMS| ABSTRACT With the skyrocketing popularity of mobile devices, new processing methods tailored for low-resource systems have become necessary.  We propose the use of custom arithmetic, arithmetic logic tailored to a specific application.  In a system with all parameters quantized to low precision, such arithmetic can be implemented through a set of small, fast table lookups.  We present here a framework for the design of such a system architecture, and several heuristic algorithms to optimize system performance.  In addition, we apply our techniques to an automatic speech recognition (ASR) application.  Our simulations on various architectures show that on most modern processor designs, we can expect a cycle-count speedup of at least 3 times while requiring a total of only 59kB of ROMs to hold the lookup tables. 
Statistical Models for Automatic Performance Tuning| Abstract Achieving peak performance from library subroutines usually requires
HIDDEN-ARTICULATOR MARKOV MODELS: PERFORMANCE IMPROVEMENTS AND ROBUSTNESS TO NOISE| ABSTRACT A Hidden-Articulator Markov Model (HAMM) is a Hidden Markov Model (HMM) in which each state represents an articulatory configuration.  Articulatory knowledge, known to be useful for speech recognition [4], is represented by specifying a mapping of phonemes to articulatory configurations; vocal tract dynamics are represented via transitions between articulatory configurations.  In previous work [13], we extended the articulatory-feature model introduced by Erler [7] by using diphone units and a new technique for model initialization.  By comparing it with a purely random model, we showed that the HAMM can take advantage of articulatory knowledge.  In this paper, we extend that work in three ways.  First, we decrease the number of parameters, making it comparable in size to standard HMMs.  Second, we evaluate our model in noisy contexts, verifying that articulatory knowledge can provide benefits in adverse acoustic conditions.  Third, we use a corpus of sideby-side speech and articulator trajectories to show that the HAMM can reasonably predict the movement of the articulators. 
CODEBOOK DESIGN FOR ASR SYSTEMS USING CUSTOM ARITHMETIC UNITS| ABSTRACT Custom arithmetic is a novel and successful technique to reduce the computation and resource utilization of ASR systems running on mobile devices.  It represents all floating-point numbers by integer indices and substitutes a sequence of table lookups for all arithmetic operations.  The first and crucial step in custom arithmetic design is to quantize system variables, preferably to low precision.  This paper explores several techniques to quantize variables with high entropy, including a reordering of Gaussian computation and a normalization of Viterbi search.  Furthermore, a discriminatively inspired distortion measure is investigated for scalar quantization to better maintain recognition accuracy.  Experiments on an isolated word recognition show that each system variable can be scalar quantized to less than 8 bits using a standard quantization method, except for the alpha probability in Viterbi search which requires 10 bits.  However, using our normalization and discriminative distortion measure, the forward probability can be quantized to 9 bits, thereby halving the corresponding lookup table size.  This greatly reduces the memory bandwidth and enables the implementation of custom arithmetic on ASR systems. 
In International Congress of Phonetic Sciences| ABSTRACT Coarticulation in speech is one of the most difficult problems for automatic speech recognition (ASR) systems.  The degree of coarticulation is assumed to vary with contextual conditions, such as differences in speaking rate, stress, etc.  In the past, coarticulation has been studied using only limited data sets and using acousticphonetic methods such as formant analysis.  We propose a method that statistically analyzes the degree of coarticulatory influence on features typically used for automatic speech recognition systems (LPCs, MFCCs, RASTA, and compressed subband spectral envelopes).  This method computes the Conditional Mutual Information (CMI) between time/feature-position pairs under a variety of coarticulatory conditions.  We applied this method on a twohour subset of the Switchboard database and analyzed CMI for various speaking rate, stress, and vowel category conditions.  Results show that CMI is indeed larger for those phonetic conditions believed to possess more coarticulation. 
FACTORED SPARSE INVERSE COVARIANCE MATRICES| ABSTRACT Most HMM-based speech recognition systems use Gaussian mixtures as observation probability density functions.  An important goal in all such systems is to improve parsimony.  One method is to adjust the type of covariance matrices used.  In this work, factored sparse inverse covariance matrices are introduced.  Based on U 0 DU factorization, the inverse covariance matrix can be represented using linear regressive coefficients which 1) correspond to sparse patterns in the inverse covariance matrix (and therefore represent conditional independence properties of the Gaussian), and 2), result in a method of partial tying of the covariance matrices without requiring non-linear EM update equations.  Results show that the performance of full-covariance Gaussians can be matched by factored sparse inverse covariance Gaussians having significantly fewer parameters. 
Mixtures of Gaussians with Sparse Regression Matrices| Abstract When fitting a mixture of Gaussians to training data there are usually two choices for the type of Gaussians used.  Either diagonal or full covariance.  Imposing a structure, though may be restrictive and lead to degraded performance and/or increased computations.  In this work we use several criteria to estimate the structure of regression matrices of a mixture of Gaussians.  Unlike many previous approaches, the criteria tested in this work attempt to estimate a discriminative structure, which is suited for classification tasks.  We report results on the 1996 NIST speaker recognition task and compare the performance of our criteria to non-discriminative strtucture-finding algorithm, like structural EM. 
THE 2001 GMTK-BASED SPINE ASR SYSTEM| ABSTRACT This paper provides a detailed description of the University of Washington automatic speech recognition (ASR) system for the 2001 DARPA SPeech In Noisy Environments (SPINE) task.  Our system makes heavy use of the graphical modeling toolkit (GMTK), a general purpose graphical modeling-based ASR system that allows arbitrary parameter tying, flexible deterministic and stochastic dependencies between variables, and a generalized maximum likelihood parameter estimation algorithm.  In our SPINE system, GMTK was used for acoustic model training whereas feature extraction, speaker adaptation, and first-pass decoding were performed by HTK.  Our integrated GMTK/HTK system demonstrates the relative merits provided by each tool.  Novel aspects of our SPINE system include the capturing of correlations among feature vectors via a globally-shared factored sparse inverse covariance matrix and generalized EM training. 
ENERGY AND LOUDNESS FOR SPEED CONTROL IN THE VOCAL JOYSTICK| ABSTRACT We propose and describe several methods for using speech power as an estimate of intentional loudness, and a mapping from this loudness estimate to a continuous control.  This is performed in the context of a novel voice-based human-computer interface designed to enable individuals with motor impairments to use vocal tract parameters for both discrete and continuous control tasks.  The interface uses vocal gestures to control continuous movement and discrete sounds for other events.  We conduct a user preference survey to gauge user reaction to the various methods in a mouse cursor control context.  We find that loudness is an effective mechanism to control mouse cursor movement speed when mapping vocalic gestures to spatial position. 
Object Class Recognition using Images of Abstract Regions| Abstract With the advent of many large image databases, both commercial and personal, content-based image retrieval has become an important research area.  While most early efforts retrieved images based on appearance, it is now recognized that most users want to retrieve images based on the objects present in them.  This paper addresses the challenging task of recognizing common objects in color photographic images.  We represent images as sets of feature vectors of multiple types of abstract regions, which come from various segmentation processes.  We model each abstract region as a mixture of Gaussian distributions over its feature space.  We have developed a new semi-supervised version of the EM algorithm for learning the distributions of the object classes.  We use supervisory information to tell the procedure the set of objects that exist in each training image, but we do not use any such supervisory information about where (ie.  in which regions) the objects are located in the images.  Instead, we rely on our EM-like algorithm to break the symmetry in an initial solution that is estimated with error.  Experiments are conducted on a set of 860 images to show the efficacy of our approach. 
Multi-Speaker Language Modeling| Abstract In conventional language modeling, the words from only one speaker at a time are represented, even for conversational tasks such as meetings and telephone calls.  In a conversational or meeting setting, however, speakers can have significant influence on each other.  To recover such un-modeled inter-speaker information, we introduce an approach for conversational language modeling that considers words from other speakers when predicting words from the current one.  By augmenting a normal trigram context, our new multi-speaker language model (MSLM) improves on both Switchboard and ICSI Meeting Recorder corpora.  Using an MSLM and a conditional mutual information based word clustering algorithm, we achieve a 8. 9% perplexity reduction on Switchboard and a 12. 2% reduction on the ICSI Meeting Recorder data. 
Algorithms for Data-Driven ASR Parameter Quantization| Abstract There is fast growing research on designing energy-efficient computational devices and applications running on them.  As one of the most compelling applications for mobile devices, automatic speech recognition (ASR) requires new methods to allow it to use fewer computational and memory resources while still achieving a high level of accuracy.  One way to achieve this is through parameter quantization.  In this work, we compare a variety of novel sub-vector clustering procedures for ASR system parameter quantization.  Specifically, we look at systematic data-driven sub-vector selection techniques, most of which are based on entropy minimization, and others on recognition accuracy maximization on a development set.  We compare performance on two speech databases, phonebook, an isolated word speech recognition task, and timit, a phonetically diverse connected-word speech corpus.  While the optimal entropy-minimizing or accuracy-driven quantization methods are intractable, several simple schemes including scalar quantization with separate codebooks per parameter and joint scalar quantization with normalization perform well in their attempt to approximate the optimal clustering. 
DYNAMIC CLASSIFIER COMBINATION IN HYBRID SPEECH RECOGNITION SYSTEMS USING UTTERANCE-LEVEL CONFIDENCE VALUES| ABSTRACT A recent development in the hybrid HMM/ANN speech recognition paradigm is the use of several subword classifiers, each of which provides different information about the speech signal.  Although the combining methods have obtained promising results, the strategies so far proposed have been relatively simple.  In most cases frame-level subword unit probabilities are combined using an unweighted product or sum rule.  In this paper, we argue and empirically demonstrate that the classifier combination approach can benefit from a dynamically weighted combination rule, where the weights are derived from higher-than-frame-level confidence values. 
Necessary Intransitive Likelihood-Ratio Classifiers| Abstract In this work, we introduce an information-theoretic based correction term to the likelihood ratio classification method for multiple classes.  Under certain conditions, the term is sufficient for optimally correcting the difference between the true and estimated likelihood ratio, and we analyze this in the Gaussian case.  We find that the new correction term significantly improves the classification results when tested on medium vocabulary speech recognition tasks.  Moreover, the addition of this term makes the class comparisons analogous to an intransitive game and we therefore use several tournament-like strategies to deal with this issue.  We find that further small improvements are obtained by using an appropriate tournament.  Lastly, we find that intransitivity appears to be a good measure of classification confidence. 
DBN BASED MULTI-STREAM MODELS FOR AUDIO-VISUAL SPEECH RECOGNITION| ABSTRACT In this paper, we propose a model based on Dynamic Bayesian Networks (DBNs) to integrate information from multiple audio and visual streams.  We also compare the DBN based system (implemented using the Graphical Model Toolkit (GMTK)) with a classical HMM (implemented in the Hidden Markov Model Toolkit (HTK)) for both the single and two stream integration problems.  We also propose a new model (mixed integration) to integrate information from three or more streams derived from different modalities and compare the new model's performance with that of a synchronous integration scheme.  A new technique to estimate stream confidence measures for the integration of three or more streams is also developed and implemented.  Results from our implementation using the Clemson University Audio Visual Experiments (CUAVE) database indicate an absolute improvement of about ### in word accuracy in the -4 to 10db average case when making use of two audio and one video streams for the mixed integration models over the sychronous models. 
A Dynamic Bayesian Framework to Model Context and Memory in Edit Distance Learning: An Application to Pronunciation Classification| Abstract Sitting at the intersection between
STRUCTURALLY DISCRIMINATIVE GRAPHICAL MODELS FOR AUTOMATIC SPEECH RECOGNITION -- RESULTS FROM THE 2001 JOHNS HOPKINS SUMMER WORKSHOP| ABSTRACT In recent years there has been growing interest in discriminative parameter training techniques, resulting from notable improvements in speech recognition performance on tasks ranging in size from digit recognition to Switchboard.  Typified by Maximum Mutual Information training, these methods assume a fixed statistical modeling structure, and then optimize only the associated numerical parameters (such as means, variances, and transition matrices).  In this paper, we explore the significantly different methodology of discriminative structure learning.  Here, the fundamental dependency relationships between random variables in a probabilistic model are learned in a discriminative fashion, and are learned separately from the numerical parameters.  In order to apply the principles of structural discriminability, we adopt the framework of graphical models, which allows an arbitrary set of variables with arbitrary conditional independence relationships to be modeled at each time frame.  We present results using a new graphical modeling toolkit (described in a companion paper) from the recent 2001 Johns Hopkins Summer Workshop.  These results indicate that significant gains result from discriminative structural analysis of both conventional MFCC and novel AM-FM features on the Aurora continuous digits task. 
Discriminatively Structured Graphical Models for Speech Recognition The Graphical Models Team JHU 2001 Summer Workshop| Abstract In recent years there has been growing interest in discriminative parameter training techniques, resulting from notable improvements in speech recognition performance on tasks ranging in size from digit recognition to
On Statistical Models in Automatic Tuning| Abstract.  Achieving peak performance from library subroutines usually requires extensive, machine-dependent tuning by hand.  Automatic tuning systems have emerged in response, and they typically operate, at compile-time, by (1) generating a large number of possible implementations of a subroutine, and (2) selecting a fast implementation by an exhaustive, empirical search.  This paper applies statistical techniques to exploit the large amount of performance data collected during the search.  First, we develop a heuristic for stopping an exhaustive compiletime search early if a near-optimal implementation is found.  Second, we show how to construct run-time decision rules, based on run-time inputs, for selecting from among a subset of the best implementations.  We apply our methods to actual performance data collected by the PHiPAC tuning system for matrix multiply on a variety of hardware platforms. 
DATA-DRIVEN EXTENSIONS TO HMM STATISTICAL DEPENDENCIES| ABSTRACT In this paper, a new technique is introduced that relaxes the HMM conditional independence assumption in a principled way.  Without increasing the number of states, the modeling power of an HMM is increased by including only those additional probabilistic dependencies (to the surrounding observation context) that are believed to be both relevant and discriminative.  Conditional mutual information is used to determine both relevance and discriminability.  Extended Gaussian-mixture HMMs and newEM update equations are introduced.  In an isolated word speech database, results show an average 34% word error improvement over an HMM with the same number of states, and a 15% improvement over an HMM with a comparable number of parameters. 
Graphical Model Approach to Pitch Tracking| Abstract Many pitch trackers based on dynamic programming require meticulous design of local cost and transition cost functions.  The forms of these functions are often empirically determined and their parameters are tuned accordingly.  Parameter tuning usually requires great effort without a guarantee of optimal performance.  This work presents a graphical model framework to automatically optimize pitch tracking parameters in the maximum likelihood sense.  Therein, probabilistic dependencies between pitch, pitch transition and acoustical observations are expressed using the language of graphical models, and probabilistic inference is accomplished using the Graphical Model Toolkit (GMTK).  Experiments show that this framework not only expedites the design of a pitch tracker, but also yields remarkably good performance for both pitch estimation and voicing decision. 
COMBINATION AND JOINT TRAINING OF ACOUSTIC CLASSIFIERS FOR SPEECH RECOGNITION| product rule when jointly training and combining multiple systems using a generalization of the product rule. 
Optimizing Matrix Multiply Using PHiPAC: A Portable, High-Performance, ANSI C Coding Methodology| Abstract Modern microprocessors can achieve high performance on linear algebra kernels but this currently requires extensive machine-specific hand tuning.  Wehave developed a methodology whereby near-peak performance on a wide range of systems can be achieved automatically for such routines.  First, by analyzing current machines and C compilers, we've developed guidelines for writing Portable, High-Performance, ANSI C (PHiPAC, pronounced \fee-pack").  Second, rather than code by hand, we produce parameterized code generators.  Third, we write search scripts that find the best parameters for a given system.  We report on a BLAS GEMM compatible multi-level cache-blocked matrix multiply generator which produces code that achieves around 90% of peak on the Sparcstation-20/61, IBM RS/6000-590, HP 712/80i, SGI Power Challenge R8k, and SGI Octane R10k, and over 80% of peak on the SGI Indigo R4k.  The resulting routines are competitive with vendoroptimized BLAS GEMMs. 
Genetic Triangulation of Graphical Models for Speech and Language Processing| Abstract Graphical models are an increasingly popular approach for speech and language processing.  As researchers design ever more complex models it becomes crucial to find triangulations that make inference problems tractable.  This paper presents a genetic algorithm for triangulation search that is well-suited for speech and language graphical models.  It is unique in two ways: First, it can find triangulations appropriate for graphs with a mix of stochastic and deterministic dependencies.  Second, the search is guided by optimizing the inference speed (CPU runtime) on real data.  We show results on 10 real-world speech and language graphs and demonstrate inference speed-ups over standard triangulation methods. 
Multi-rate Modeling, Model Inference, and Estimation for Statistical Classifiers| Date: In presenting this dissertation in partial fulfillment of the requirements for the doctoral degree at the University of Washington, I agree that the Library shall make its copies freely available for inspection.  I further agree that extensive copying of this dissertation is allowable only for scholarly purposes, consistent with "fair use" as prescribed in the
MIXED-MEMORY MARKOV MODELS FOR AUTOMATIC LANGUAGE IDENTIFICATION| ABSTRACT Automatic language identification (LID) continues to play an integral part in many multilingual speech applications.  The most widespread approach to LID is the phonotactic approach, which performs language classification based on the probabilities of phone sequences extracted from the test signal.  These probabilities are typically computed using statistical phone n-gram models.  In this paper we investigate the approximation of these standard n-gram models by mixed-memory Markov models with application to both a phone-based and an articulatory feature-based LID system.  We demonstrate significant improvements in accuracy with a substantially reduced set of parameters on a 10-way language identification task. 
Maximum Margin Learning and Adaptation of MLP Classifers| Abstract Conventional MLP classifiers used in phonetic recognition and speech recognition may encounter local minima during training, and they often lack an intuitive and flexible adaptation approach.  This paper presents a hybrid MLP-SVM classifier and its associated adaptation strategy, where the last layer of a conventional MLP is learned and adapted in the maximum separation margin sense.  This structure also provides a support vector based adaptation mechanism which better interpolates between a speaker-independent model and speakerdependent adaptation data.  Preliminary experiments on vowel classification have shown promising results for both MLP learning and adaptation problems. 
Hidden Feature Models for Speech Recognition Using Dynamic Bayesian Networks| Abstract In this paper, we investigate the use of dynamic Bayesian networks (DBNs) to explicitly represent models of hidden features, such as articulatory or other phonological features, for automatic speech recognition.  In previous work using the idea of hidden features, the representation has typically been implicit, relying on a single hidden state to represent a combination of features.  We present a class of DBN-based hidden feature models, and show that such a representation can be not only more expressive but also more parsimonious.  We also describe a way of representing the acoustic observation model with fewer distributions using a product of models, each corresponding to a subset of the features.  Finally, we describe our recent experiments using hidden feature models on the Aurora 2. 0 corpus. 
DIRECTED GRAPHICAL MODELS OF CLASSIFIER COMBINATION: APPLICATION TO PHONE RECOGNITION| ABSTRACT Classifier combination is a technique that often provides appreciable accuracy gains.  In this paper, we argue that the underlying statistical model of classifier combination should be made explicit.  Using directed graphical models (DGMs), we provide representations of two common combination schemes, the mean and product rules.  We also introduce new DGMs that yield novel combination rules.  We find that these new DGM-inspired rules can achieve significant accuracy gains on the TIMIT phone-classification task relative to existing combination schemes. 
The PHiPAC v1|0 Matrix-Multiply Distribution.  Abstract Modern microprocessors can achieve high performance on linear algebra kernels but this currently requires extensive machine-specific hand tuning.  We have developed a methodology whereby near-peak performance on a wide range of systems can be achieved automatically for such routines.  First, by analyzing current machines and C compilers, we've developed guidelines for writing Portable, High-Performance, ANSI C (PHiPAC, pronounced "feepack").  Second, rather than code by hand, we produce parameterized code generators.  Third, we write search scripts that find the best parameters for a given system.  We report on a BLAS GEMM compatible multi-level cache-blocked matrix multiply generator which produces code that achieves around 90% of peak on the Sparcstation-20/61, IBM RS/6000-590, HP 712/80i, SGI Power Challenge R8k, and SGI Octane R10k, and over 80% of peak on the SGI Indigo R4k.  In this paper, we provide a detailed description of the PHiPAC V1. 0 matrix multiply distribution.  We describe the code generator in detail including the various register and higher level blocking strategies.  We also document the organization and parameters of the search scripts.  This technical report is an expanded version of [BACD97]. 
BURIED MARKOVMODELS FOR SPEECH RECOGNITION| ABSTRACT Good HMM-based speech recognition performance requires at most minimal inaccuracies to be introduced by HMM conditional independence assumptions.  In this work, HMM conditional independence assumptions are relaxed in a principled way.  For each hidden state value, additional dependencies are added between observation elements to increase both accuracy and discriminability.  These additional dependenciesare chosen according to natural statistical dependencies extant in training data that are not well modeledbyanHMM. Theresultiscalledaburied Markov model (BMM) because the underlying Markov chain in an HMM is further hidden (buried) by specific cross-observation dependencies.  Gaussian mixture HMMs are extended to represent BMM dependencies and new EM update equations are derived.  On preliminary experiments with a large-vocabulary isolated-word speech database, BMMs are able to achieve an 11% improvement in WERwith only a 9. 5% increase in the number of parameters using a single state per mono-phone speech recognition system. 
ROBUST SPLICING COSTS AND EFFICIENT SEARCH WITH BMM MODELS FOR CONCATENATIVE SPEECH SYNTHESIS| ABSTRACT With the growing popularity of corpus-based methods for concatenative speech synthesis, a large amount of interest has been placed on borrowing techniques from the ASR community.  This paper explores the applications of Buried Markov Models (BMM) to speech synthesis.  We show that BMMs are more efficient than HMMs as a synthesis model, and focus on using BMM dependencies for computing splicing costs.  We also show how the computational complexity of the dynamic search can be significantly reduced by constraining the splicing points with a negligible loss in synthesis quality. 
USING PHIPAC TO SPEED ERROR BACK-PROPAGATION LEARNING| ABSTRACT We introduce PHiPAC, a coding methodology for developing portable high-performance numerical libraries in ANSI C.  Using this methodology, we have developed code for optimized matrix multiply routines.  These routines can achieve over 90% of peak performance on a variety of current workstations, and are often faster than vendor-supplied optimized libraries.  We then describe the bunch-mode back-propagation algorithm and how it can use the PHiPAC derived matrix multiply routines.  Using a set of plots, we investigate the tradeoffs between bunch size, convergence rate, and training speed using a standard speech recognition data set and show how use of the PHiPAC routines can lead to a significantly faster back-propagation learning algorithm. 
STATISTICAL ACOUSTIC INDICATIONS OF COARTICULATION| ABSTRACT Coarticulation in speech is one of the most difficult problems for automatic speech recognition (ASR) systems.  The degree of coarticulation is assumed to vary with contextual conditions, such as differences in speaking rate, stress, etc.  In the past, coarticulation has been studied using only limited data sets and using acousticphonetic methods such as formant analysis.  We propose a method that statistically analyzes the degree of coarticulatory influence on features typically used for automatic speech recognition systems (LPCs, MFCCs, RASTA, and compressed subband spectral envelopes).  This method computes the Conditional Mutual Information (CMI) between time/feature-position pairs under a variety of coarticulatory conditions.  We applied this method on a twohour subset of the Switchboard database and analyzed CMI for various speaking rate, stress, and vowel category conditions.  Results show that CMI is indeed larger for those phonetic conditions believed to possess more coarticulation. 
Statistical Modeling of Feedback Data in an Automatic Tuning System| Abstract Achieving peak performance from library subroutines usually requires extensive, machine-dependent tuning by hand.  Automatic tuning systems have been developed in response which typically operate, at compiletime, by (1) generating a large number of possible implementations of a subroutine, and (2) selecting a fast implementation by an exhaustive, empirical search.  In this paper, we show how statistical modeling of the performance feedback data collected during the search phase can be used in two novel and important ways.  First, we develop a heuristic for stopping an exhaustive compile-time search early if a near-optimal implementation is found.  Second, we show how to construct run-time decision rules, based on run-time inputs, for selecting from among a subset of the best implementations.  We apply our methods to actual performance data collected by the PHiPAC tuning system for matrix multiply on a variety of hardware and compiler platforms. 
NOVEL APPROACHES TO ARABIC SPEECH RECOGNITION: REPORT FROM THE 2002 JOHNS-HOPKINS SUMMER WORKSHOP| ABSTRACT Although Arabic is currently one of the most widely spoken languages in the world, there has been relatively little speech recognition research on Arabic compared to other languages.  Moreover, most previous work has concentrated on the recognition of formal rather than dialectal Arabic.  This paper reports on our project at the 2002 Johns Hopkins Summer Workshop, which focused on the recognition of dialectal Arabic.  Three problems were addressed: (a) the lack of short vowels and other pronunciation information in Arabic texts; (b) the morphological complexity of Arabic; and (c) the discrepancies between dialectal and formal Arabic.  We present novel approaches to automatic vowel restoration, morphology-based language modeling and the integration of outof-corpus language model data, and report significant word error rate improvements on the LDC Arabic CallHome task. 
SVitchboard 1: Small Vocabulary Tasks from Switchboard 1| Abstract We present a conversational telephone speech data set designed to support research on novel acoustic models.  Small vocabulary tasks from 10 words up to 500 words are defined using subsets of the Switchboard-1 corpus; each task has a completely closed vocabulary (an OOV rate of 0%).  We justify the need for these tasks, describe the algorithm for selecting them from a large corpus, give a statistical analysis of the data and present baseline whole-word hidden Markov model recognition results.  The goal of the paper is to define a common data set and to encourage other researchers to use it. 
INTERNATIONAL COMPUTER SCIENCE INSTITUTE| Abstract We empirically investigate a number of strategies for solving the clustering problem under the minimum variance error criterion.  First, we compare the behavior of four algorithms, 1) randomized minimum spanning tree, 2) hierarchical grouping, 3) randomized maximum cut, and 4) standard k-means.  We test these algorithms with a large corpus of both contrived and real-world data sets and find that standard k-means performs best.  We found, however, that standard k-means can, with non-negligible probability, do a poor job optimizing the minimum variance criterion.  We therefore investigate various randomized k-means modifications.  We empirically find that by running randomized k-means only a modest number of times, the probability of a poor solution becomes negligible.  Using a large number of CPU hours to experimentally derive the apparently optimal solutions, we also find that randomized k-means has the best rate of convergence to this apparent optimum. 
The Ring Array Processor: A Multiprocessing Peripheral for Connection Applications|
PHiPAC: A portable, high-performance, ANSI C coding methodology and its application to matrix multiply|
Maximum mutual information based reduction strategies for cross-correlation based joint distributional modeling,|
Graphical models and automatic speech recognition|
A gentle tutorial of the EM algorithm and its application to parameter estimation for gaussian mixture and Hidden Markov Models| Technical report,. 
A Model for Musical Rhythm|
"Timing is of Essence",|
"DBN multistream models for Mandarin toneme recognition,|
On Triangulating Dynamic Graphical Models|
Elimination is not enough: Non-minimal triangulations for graphical models|
"The vocal joystick,|
The PHiPAC WWW home page|
Feature pruning in likelihood evaluation of HMM-based ASR systems,|
Tree-Based Access Methods for Spatial Databases: Implementation and Performance Evaluation|
Novel approaches to arabic speech recognition: Report from the 2002 Johns-Hopkins workshop|
Factored Language Models and Generalized Parallel Backoff|
Using PHiPAC to speed Error Back-Propogation learning|
Optimizing matrix multiply using PHiPAC: a portable, high-performance, ANSI C coding methodology| Computer Science Dept. 
The Sather language compiler/debugger implementation|
Natural Statistic Models for Automatic Speech Recognition|
Timing is of the Essence: Perceptual and Computational Techniques for Representing, Learning, and Reproducing Expressive Timing in Percussive Rhythm|
Buried Markov models: A graphical-modeling approach to automatic speech recognition|
What HMMs can do|
Burried Markov models for speech recognition|
Dialog act tagging using graphical models,|
A graphical model approach to pitch tracking|
Software for ANN Training on a Ring Array Processor|
A gentle tutorial on the EM algorithm and application to gaussian mixtures and Baum-Welch|
Gaussian parameter sharing and training using a GEM algorithm|
Dynamic bayesian multi-networks|
The gmtk documentation,|
Towards simple methods of noise-robustness|
"The Concept of Preference in Conversation Analysis"|
On soft evidence in Bayesian networks,"|
Factored language models and general parallelized backoff|
Novel Speech Recognition Models for Arabic: JHU Summer Workshop 2002 Final Report|
Codebook design for ASR systems based on custom arithmetic,|
Discriminatively structured dynamic graphical models for speech recognition",|
Dynamic Bayesian Networks",|
Structurally discriminative graphical models for speech recognition," JHU CLSP Summer Workshop Final Report,|
Directed graphical models of classifier combinations: application to phone recognition|
Generalized acoustic classifier combination for speech recognition|
Introduction to the special issue on new computational paradigms for acoustic modeling in speech recognition,|
GMTK: The Graphical Models Toolkit,|
Neurocomputing on the RAP|
Joint Distributional Modeling with CrossCorrelation based Features",|
MVA processing of speech features|
Morgan N and Beck J 1992 Software for ANN training on a ring array processor|
The PHiPAC matrix-multiply distribution|
PAC-learning bounded tree-width graphical models|
Discriminatively structured graphical models for speech recognition| Technical Report Summer Workshop on Speech Recognition,. 
