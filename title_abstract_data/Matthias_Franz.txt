The View-Graph Approach to Visual Navigation and Spatial Memory| Abstract.  This paper describes a purely visual navigation scheme based on two elementary mechanisms (piloting and guidance) and a graph structure combining individual navigation steps controlled by these mechanisms.  In robot experiments in real environments, both mechanisms have been tested, piloting in an open environment and guidance in a maze with restricted movement opportunities.  The results indicate that navigation and path planning can be brought about with these simple mechanisms.  We argue that the graph of local views (snapshots) is a general and biologically plausible means of representing space and integrating the various mechanisms of map behaviour. 
On Robots and Flies: Modeling the visual orientation behavior of flies| Abstract Although artificial and biological systems face similar sensorimotor control problems, until today only a few attempts have been made to implement specific biological control structures on robots.  Nevertheless, the process of designing the sensorimotor control of a robot can contribute to our understanding of these mechanisms and can provide the basis of a critical evaluation of existing biological models.  Flies have developed a specialized visuomotor control for tasks such as course stabilization, fixation and approach towards stationary objects, tracking of moving objects, and landing, which are based on the analysis of visual motion information.  Theoretical and experimental results suggest that in flies the visuomotor control for course stabilization as well as fixation and approach towards stationary objects may be implemented at least partially by one common sensory circuit.  We present agents with a visuomotor controller that regulates the two behaviors of course stabilization and object fixation.  To test this controller under real world conditions, we implemented it on a miniature robot.  We have been able to show that, in addition to course stabilization and object fixation, the robot also approaches stationary objects. 
Implicit Wiener Series for Higher-Order Image Analysis| Abstract The computation of classical higher-order statistics such as higher-order moments or spectra is difficult for images due to the huge number of terms to be estimated and interpreted.  We propose an alternative approach in which multiplicative pixel interactions are described by a series of Wiener functionals.  Since the functionals are estimated implicitly via polynomial kernels, the combinatorial explosion associated with the classical higher-order statistics is avoided.  First results show that image structures such as lines or corners can be predicted correctly, and that pixel interactions up to the order of five play an important role in natural images.  Most of the interesting structure in a natural image is characterized by its higher-order statistics.  Arbitrarily oriented lines and edges, for instance, cannot be described by the usual pairwise statistics such as the power spectrum or the autocorrelation function: From knowing the intensity of one point on a line alone, we cannot predict its neighbouring intensities.  This would require knowledge of a second point on the line, i. e. , we have to consider some third-order statistics which describe the interactions between triplets of points.  Analogously, the prediction of a corner neighbourhood needs at least fourth-order statistics, and so on.  In terms of Fourier analysis, higher-order image structures such as edges or corners are described by phase alignments, i. e.  phase correlations between several Fourier components of the image.  Classically, harmonic phase interactions are measured by higher-order spectra [4].  Unfortunately, the estimation of these spectra for high-dimensional signals such as images involves the estimation and interpretation of a huge number of terms.  For instance, a sixth-order spectrum of a 16#16 sized image contains roughly 10 12 coefficients, about 10 10 of which would have to be estimated independently if all symmetries in the spectrum are considered.  First attempts at estimating the higher-order structure of natural images were therefore restricted to global measures such as skewness or kurtosis [8], or to submanifolds of fourth-order spectra [9].  Here, we propose an alternative approach that models the interactions of image points in a series of Wiener functionals.  A Wiener functional of order n captures those image components that can be predicted from the multiplicative interaction of n image points.  In contrast to higher-order spectra or moments, the estimation of a Wiener model does not require the estimation of an excessive number of terms since it can be computed implicitly via polynomial kernels.  This allows us to decompose an image into components that are characterized by interactions of a given order.  In the next section, we introduce the Wiener expansion and discuss its capability of modeling higher-order pixel interactions.  The implicit estimation method is described in Sect.  2, followed by some examples of use in Sect.  3.  We conclude in Sect.  4 by briefly discussing the results and possible improvements. 
Adaptive mixed norm optical flow estimation| ABSTRACT The pel-recursive computation of 2-D optical flow has been extensively studied in computer vision to estimate motion from image sequences, but it still raises a wealth of issues, such as the treatment of outliers, motion discontinuities and occlusion.  It relies on spatio-temporal brightness variations due to motion.  Our proposed adaptive regularized approach deals with these issues within a common framework.  It relies on the use of a data-driven technique called Mixed Norm (MN) to estimate the best motion vector for a given pixel.  In our model, various types of noise can be handled, representing different sources of error.  The motion vector estimation takes into consideration local image properties and it results from the minimization of a mixed norm functional with a regularization parameter depending on the kurtosis.  This parameter determines the relative importance of the fourth norm and makes the functional convex.  The main advantage of the developed procedure is that no knowledge of the noise distribution is necessary.  Experiments indicate that this approach provides robust estimates of the optical flow. 
Learning View Graphs for Robot Navigation| Abstract.  We present a purely vision-based scheme for learning a topological representation of an open environment.  The system represents selected places by local views of the surrounding scene, and finds traversable paths between them.  The set of recorded views and their connections are combined into a graph model of the environment.  To navigate between views connected in the graph, we employ a homing strategy inspired by findings of insect ethology.  In robot experiments, we demonstrate that complex visual exploration and navigation tasks can thus be performed without using metric information. 
Face Detection --- Efficient and Rank Deficient| Abstract This paper proposes a method for computing fast approximations to support vector decision functions in the field of object detection.  In the present approach we are building on an existing algorithm where the set of support vectors is replaced by a smaller, so-called reduced set of synthesized input space points.  In contrast to the existing method that finds the reduced set via unconstrained optimization, we impose a structural constraint on the synthetic points such that the resulting approximations can be evaluated via separable filters.  For applications that require scanning large images, this decreases the computational complexity by a significant amount.  Experimental results show that in face detection, rank deficient approximations are 4 to 6 times faster than unconstrained reduced set systems. 
Linear Combinations of Optic Flow Vectors for Estimating Self-Motion - a Real-World Test of a Neural Model| Abstract The tangential neurons in the fly brain are sensitive to the typical optic flow patterns generated during self-motion.  In this study, we examine whether a simplified linear model of these neurons can be used to estimate self-motion from the optic flow.  We present a theory for the construction of an estimator consisting of a linear combination of optic flow vectors that incorporates prior knowledge both about the distance distribution of the environment, and about the noise and self-motion statistics of the sensor.  The estimator is tested on a gantry carrying an omnidirectional vision sensor.  The experiments show that the proposed approach leads to accurate and robust estimates of rotation rates, whereas translation estimates turn out to be less reliable. 
Biomimetic robot navigation,|
Homing by parameterized scene matching|
On robots and flies: Modeling the visual orientation behavior of flies, " Robotics and Autonomous Systems 29,|
Where did I take that snapshot? Scene-based homing by image matching|
editors,|
Implicit Wiener series|
Learning Depth from Stereo|
Wide-field, motion-sensitive neurons and matched filters for optic flow fields|
Biomimetic robot navigation", Robotics and autonomous systems,|
On the integral cohomology of smooth toric varieties|
"Learning View Graphs for Robot Navigation", Technical Report no 33, Max-Planck Institute fur Biologische Kybernetik, 72076 Tubingen, Germany| Can be downloaded from the website:. 
