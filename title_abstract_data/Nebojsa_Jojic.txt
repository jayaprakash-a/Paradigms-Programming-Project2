Transformed Component Analysis: Joint Estimation of Spatial Transformations and Image Components| A simple, effective way to model images is to represent each input pattern by a linear combination of \component" vectors, where the amplitudes of the vectors are modulated to match the input.  This approach includes principal component analysis, independent component analysis and factor analysis.  In practice, images are subjected to randomly selected transformations of a known nature, such as translation, rotation and scale.  Direct application of the above methods will lead to severely blurred components and even to components that only account for the transformations and ignore the more interesting and useful structure.  We propose a method called transformed component analysis, which incorporates a discrete, hidden variable that accounts for transformations and uses a linear-time expectation maximization algorithm to jointly extract components and normalize for transformations.  We illustrate the algorithm using a shading problem, facial expression modeling and handwritten digit recognition. 
MULTIBAND AUDIO MODELING FOR SINGLE-CHANNEL ACOUSTIC SOURCE SEPARATION| ABSTRACT Detailed hidden Markov models (HMMs) that capture the constraints implicit in a particular sound can be used to estimate obscured or corrupted portions from partial observations, the situation encountered when trying to identify multiple, overlapping sounds.  However when the complexity and variability of the sounds are high, as in a particular speaker's voice, a detailed model might require several thousand states to cover the full range of different short-term spectra with adequate resolution.  To address the tractability problems of such large models, we break the source signals into multiple frequency bands, and build separate but coupled HMMs for each band, requiring many fewer states per model.  Modeling each frequency band independently, as in multiband speech models proposed by the ASR community, will result in many non-natural full spectral states.  To prevent this and to enforce consistency within and between bands, at any given frame the state in a particular band is determined by the previous state in that band and the states in the adjacent bands.  Coupling the bands in this manner results in a grid like model for the full spectrum.  Since exact inference of such a model is intractable, we derive an efficient approximation based on variational methods.  Results in source separation of combined signals modeled with this approach outperform the separation obtained by full-band models. 
Product Analysis: Learning to Model Observations as Products of Hidden Variables| Abstract Factor analysis and principal components analysis can be used to model linear relationships between observed variables and linearly map high-dimensional data to a lower-dimensional hidden space.  In factor analysis, the observations are modeled as a linear combination of normally distributed hidden variables.  We describe a nonlinear generalization of factor analysis, called \product analysis", that models the observed variables as a linear combination of products of normally distributed hidden variables.  Just as factor analysis can be viewed as unsupervised linear regression on unobserved, normally distributed hidden variables, product analysis can be viewed as unsupervised linear regression on products of unobserved, normally distributed hidden variables.  The mapping between the data and the hidden space is nonlinear, so we use an approximate variational technique for inference and learning.  Since product analysis is a generalization of factor analysis, product analysis always finds a higher data likelihood than factor analysis.  We give results on pattern recognition and illuminationinvariant image clustering. 
Learning Flexible Sprites in Video Layers| We propose a technique for automatically learning layers of \flexible sprites" { probabilistic 2-dimensional appearance maps and masks of moving, occluding objects.  The model explains each input image as a layered composition of flexible sprites.  A variational expectation maximization algorithm is used to learn a mixture of sprites from a video sequence.  For each input image, probabilistic inference is used to infer the sprite class, translation, mask values and pixel intensities (including obstructed pixels) in each layer.  Exact inference is intractable, but we show how a variational inference technique can be used to process 320 # 240 images at 1 frame/second.  The only inputs to the learning algorithm are the video sequence, the number of layers and the number of flexible sprites.  We give results on several tasks, including summarizing a video sequence with sprites, point-and-click video stabilization, and point-and-click object removal. 
Q-Clustering| Abstract We show that Queyranne's algorithm for minimizing symmetric submodular functions can be used for clustering with a variety of different objective functions.  Two criteria that we consider in this paper are the maximum separation criterion, and the minimum description length criterion.  The first criterion tries to maximize the minimum distance between elements of different clusters, and is inherently "discriminative".  We will show that we can compute optimal clusterings into k clusters for any given k in polynomial time for this criterion.  The second criterion seeks to minimize the description length of the clusters given a probabilistic generative model.  We show that we can compute the optimal partitioning into 2 clusters, and approximate partitioning into more clusters.  Our approach differs from previous approaches to this problem which are either ad-hoc (with no well-defined objective criterion), or are approximate (which cannot guarantee optimal clusterings with respect to the objective function).  We show that the algorithm can be extended to other criteria by presenting a modified objective function which can still be exactly optimized, while being less sensitive to outliers.  We present results on three data sets. 
Audio-Video Sensor Fusion with Probabilistic Graphical Models| Abstract.  We present a new approach to modeling and processing multimedia data.  This approach is based on graphical models that combine audio and video variables.  We demonstrate it by developing a new algorithm for tracking a moving object in a cluttered, noisy scene using two microphones and a camera.  Our model uses unobserved variables to describe the data in terms of the process that generates them.  It is therefore able to capture and exploit the statistical structure of the audio and video data separately, as well as their mutual dependencies.  Model parameters are learned from data via an EM algorithm, and automatic calibration is performed as part of this procedure.  Tracking is done by Bayesian inference of the object location from data.  We demonstrate successful performance on multimedia clips captured in real world scenarios using off-the-shelf equipment. 
3-D Reconstruction of Multipart Self-Occluding Objects| Abstract.  In this paper we present a method for reconstruction of multipart objects from several arbitrary views using deformable superquadrics as the models of the object's parts.  Two visual cues are used: occluding contours and stereo (possibly aided by projected patterns).  The object can be relatively complex and can exhibit numerous self occlusions from some or all views.  Our preliminary experiments on a human body and a tailor's mannequin show that the reconstruction is more complete than in purely stereo or structured light based methods and more precise than the reconstruction from occluding contours only. 
Capturing Image Structure with Probabilistic Index Maps| Abstract One of the major problems in modeling images for vision tasks is that images with very similar structure may locally have completely different appearance, e. g. , images taken under different illumination conditions, or the images of pedestrians with different clothing.  While there have been many successful attempts to address these problems in application-specific settings, we believe that underlying a large set of problems in vision is a representational deficiency of intensity-derived local measurements that are the basis of most efficient models.  We argue that interesting structure in images is better captured when the image is defined as a matrix whose entries are discrete indices to a separate palette of possible intensities, colors or other features, much like the image representation often used to save on storage.  In order to model the variability in images, we define an image class not by a single index map, but by a probability distribution over the index maps, which can be automatically estimated from the data, and which we call probabilistic index maps.  The existing algorithms can be adapted to work with this representation, as we illustrate in this paper on the example of transformation-invariant clustering and background subtraction.  Furthermore, the probabilistic index map representation leads to algorithms with computational costs proportional to either the size of the palette or the log of the size of the palette, making the cost of significantly increased invariance to non-structural changes quite bearable. 
Towards single-channel unsupervised source separation of speech mixtures: The layered harmonics/formants separation-tracking model| Abstract Speaker models for blind source separation are typically based on HMMs consisting of vast numbers of states to capture source spectral variation, and trained on large amounts of isolated speech.  Since observations can be similar between sources, inference relies on sequential constraints from the state transition matrix which are, however, quite weak.  To avoid these problems, we propose a strategy of capturing local deformations of the time-frequency energy distribution.  Since consecutive spectral frames are highly correlated, each frame can be accurately described as a nonuniform deformation of its predecessor.  A smooth pattern of deformations is indicative of a single speaker, and the cliffs in the deformation fields may indicate a speaker switch.  Further, the log-spectrum of speech can be decomposed into two additive layers, separately describing the harmonics and formant structure.  We model smooth deformations as hidden transformation variables in both layers, using MRFs with overlapping subwindows as observations, assumed to be a noisy sum of the two layers.  Loopy belief propagation provides for efficient inference.  Without any pre-trained speech or speaker models, this approach can be used to fill in missing time-frequency observations, and the local entropy of the deformation fields indicate source boundaries for separation. 
Epitomic analysis of appearance and shape| We present novel simple appearance and shape models that we call epitomes.  The epitome of an image is its miniature, condensed version containing the essence of the textural and shape properties of the image.  As opposed to previously used simple image models, such as templates or basis functions, the size of the epitome is considerably smaller than the size of the image or object it represents, but the epitome still contains most constitutive elements needed to reconstruct the image (Fig.  1).  A collection of images often shares an epitome, e. g. , when images are a few consecutive frames from a video sequence, or when they are photographs of similar objects.  A particular image in a collection is defined by its epitome and a smooth mapping from the epitome to the image pixels.  When the epitomic representation is used within a hierarchical generative model, appropriate inference algorithms can be derived to extract the epitome from a single image or a collection of images and at the same time perform various inference tasks, such as image segmentation, motion estimation, object removal and super-resolution. 
Topographic Transformation as a Discrete Latent Variable| Abstract Invariance to topographic transformations such as translation and shearing in an image has been successfully incorporated into feedforward mechanisms, e. g. , \convolutional neural networks", \tangent propagation".  We describe a way to add transformation invariance to a generative density model by approximating the nonlinear transformation manifold by a discrete set of transformations.  An EM algorithm for the original model can be extended to the new model by computing expectations over the set of transformations.  We show how to add a discrete transformation variable to Gaussian mixture modeling, factor analysis and mixtures of factor analysis.  We give results on filtering microscopy images, face and facial pose clustering, and handwritten digit modeling and recognition. 
Fast Transformation-Invariant Factor Analysis| Abstract Dimensionality reduction techniques such as principal component analysis and factor analysis are used to discover a linear mapping between high dimensional data samples and points in a lower dimensional subspace.  In [6], Jojic and Frey introduced mixture of transformation-invariant component analyzers (MTCA) that can account for global transformations such as translations and rotations, perform clustering and learn local appearance deformations by dimensionality reduction.  However, due to enormous computational requirements of the EM algorithm for learning the model, O(N 2 ) where N is the dimensionality of a data sample, MTCA was not practical for most applications.  In this paper, we demonstrate how fast Fourier transforms can reduce the computation to the order of NlogN .  With this speedup, we show the effectiveness of MTCA in various applications - tracking, video textures, clustering video sequences, object recognition, and object detection in images. 
Real-time on-line learning of transformed hidden Markov models from video| Abstract The transformed hidden Markov model is a temporal model that captures three typical causes of variability in video - scene/object class, appearance variability within the class, and image motion.  In our previous work, we showed that an exact EM algorithm can jointly learn the appearances of multiple objects and/or poses of an object, and track the objects or camera motion in video, starting simply from random initialization.  As such, this model can serve as a basis for both video clustering and object tracking applications.  However, the original algorithm requires a significant amount of computation that renders it impractical for video clustering and its off-line nature makes it unsuitable for real-time tracking applications.  In this paper, we propose a new, significantly faster, on-line learning algorithm that enables real-time clustering and tracking.  We demonstrate that the algorithm can extract objects using the constraints on their motion and also perform tracking while the appearance models are learned.  We also demonstrate the clustering results on an example of typical unrestricted personal media - the vacation video. 
Estimating Mixture Models of Images and Inferring Spatial Transformations Using the EM Algorithm| Abstract Mixture modeling and clustering algorithms are effective, simple ways to represent images using a set of data centers.  However, in situations where the images include background clutter and transformations such as translation, rotation, shearing and warping, these methods extract data centers that include clutter and represent different transformations of essentially the same data.  Taking face images as an example, it would be more useful for the different clusters to represent different poses and expressions, instead of cluttered versions of different translations, scales and rotations.  By including clutter and transformation as unobserved, latent variables in a mixture model, we obtain a new \transformed mixture of Gaussians", which is invariant to a specified set of transformations.  We show how a linear-time EM algorithm can be used to fit this model by jointly estimating a mixture model for the data and inferring the transformation for each image.  We show that this algorithm can jointly align images of a human head and learn different poses.  We also find that the algorithm performs better than knearest neighbors and mixtures of Gaussians on handwritten digit recognition. 
Deformable Spectrograms| Abstract Speech and other natural sounds show high temporal correlation and smooth spectral evolution punctuated by a few, irregular and abrupt changes.  In a conventional Hidden Markov Model (HMM), such structure is represented weakly and indirectly through transitions between explicit states representing `steps' along such smooth changes.  It would be more efficient and informative to model successive spectra as transformations of their immediate predecessors, and we present a model which focuses on local deformations of adjacent bins in a timefrequency surface to explain an observed sound, using explicit representation only for those bins that cannot be predicted from their context.  We further decompose the log-spectrum into two additive layers, which are able to separately explain and model the evolution of the harmonic excitation, and formant filtering of speech and similar sounds.  Smooth deformations are modeled with hidden transformation variables in both layers, using Markov Random fields (MRFs) with overlapping subwindows as observations; inference is efficiently performed via loopy belief propagation.  The model can fill-in deleted timefrequency cells without any signal model, and an entire signal can be compactly represented with a few specific states along with the deformation maps for both layers.  We discuss several possible applications for this new model, including source separation. 
Computer Modeling, Analysis and Synthesis of Dressed Humans| Abstract 1 In this paper we present a method for 3-D reconstruction of human bodies with application in CAD systems for garment design.  The reconstruction scheme uses image information from several arbitrary views and deformable superquadrics as the models of the body parts.  Two visual cues are used: occluding contours and stereo (possibly aided by projected patterns).  Our preliminary experiments show that the reconstruction is more complete than in purely stereo or structured light based methods and more precise than the reconstruction from occluding contours only.  From the reconstructed human body, the body measurements can be taken automatically, and used in garment design.  We give an example of draping of virtual garment over the photo-realistic 3D model of the imaged human.  One can easily envision the use of the described algorithms in the development of custom-fit garment retail software over the Internet, which would include the possibility of trying the garment on in virtual reality. 
On Analysis of Cloth Drape Range Data| Abstract.  In this paper we present an algorithm for analysis of the range data of cloth drapes.  The goal of the analysis is estimation of parameters for modeling and the geometry of the underlying object.  In an analysis-by-synthesis manner, the algorithm compares the drape of the model with the range data and searches for the best fit.  It can be applied to any physics-based cloth model.  The motivating application is fashion design using CAD systems, but the ability of the algorithm to estimate the shape of the object supporting the scanned cloth indicates the possibility of utilizing cloth models to overcome problems in human tracking algorithms, caused by clothing. 
Transformed Hidden Markov Models: Estimating Mixture Models of Images and Inferring Spatial Transformations in Video Sequences| Abstract In this paper we describe a novel generative model for video analysis called the transformed hidden Markov model (THMM). 
Estimating Cloth Draping Parameters from Range Data| ABSTRACT In this paper we present a computer vision algorithm for estimating cloth parameters for modeling.  In an analysis-by-synthesis manner, the algorithm compares the drape of the model with the range data and searches for the best fit.  It can be applied to any physics-based cloth model.  The motivating application is fashion design using CAD systems, but the ability of the algorithm to estimate the shape of the object supporting the scanned cloth, indicates the possibility of utilizing cloth models to overcome problems in human tracking algorithms, caused by clothing. 
Estimating smooth deformation models of substance and noise| Abstract By representing image prototypes, or "substance", by linear subspaces spanned by deformation fields derived from low-frequecy wavelets, impressive invariance to distortion can be built into generative probability models.  The prototypes representing substance and the distribution over wavelet coefficients can be estimated using EM, since exact inference is tractable in this model.  While this approach works for noise-free data, it is prone to errors for noisy data, where the noise is deformed and then confused with the prototypes representing substance.  We describe a generative model for smooth, nonuniform deformations, in which noise fields are deformed along with the prototypes representing substance.  This prevents deformed substance from being confused with deformed noise.  We show that a variational technique can be used for inference and parameter estimation in this model.  We give results on a very difficult, contrived problem and on facial expression modeling. 
Tracking Articulated Structures in Stereo Image Sequences| Abstract --- In this paper, we present an algorithm for real time 3-D tracking of articulated structures in stereo image sequences.  These sequences can be captured by an inexpensive commercially available system that also computes the dense disparity map in real time.  In our algorithm, the tracked object is modeled as a set of articulated 3D blobs, each adhering to a Gaussian distribution.  Classification of the disparity map pixels into the segments of the articulated object is based on the maximum likelihood principle with an additional mechanism for filling the missing data created by self-occlusions.  The articulation constraints are enforced through an Extended Kalman Filter, which can also be used to model the dynamics of the tracked object. 
A Comparison of Algorithms for Inference and Learning in Probabilistic Graphical Models|
Transformation-Invariant Clustering Using the EM Algorithm|
Probability Models for High Dynamic Range Imaging|
Transformation-invariant clustering and dimensionality reduction|
Learning Graphical Models of Images, Videos and Their Spatial Transformations|
Separating Appearance from Deformation|
Detection and Estimation of Pointing Gestures in Dense Disparity Maps|
Subband audio modeling for single-channel acoustic source separation,"|
Learning Appearance and Transparency Manifolds of Occluded Objects in Layers|
Transformation invariant clustering and linear component analysis|
Tracking Self-Occluding Articulated Objects in Dense Disparity Maps|
Learning mixture models of images and inferring spatial transforms using the EM algorithm|
Advances in algorithms for inference and learning in complex probability models for vision,|
Estimating Mixture Models of Images and Inferring Spatial|
Tracking articulated objects in dense disparity maps|
Tamper-Resistant Biometric IDs,|
Estimation of Pointing Parameters in Dense Disparity Maps,|
Detecting and estimating pointing gestures in dense disparity maps|
A generative model of dense optical flow in layers|
Topographic trans ormation as a discrete latent variable|
Trans ormed hidden Markov models: estimating mixture models o images and in erring spatial trans ormations in video sequences|
Fast, Large-Scale Transformation-Invariant Clustering|
Learning subspace models of occluded objects in layers,|
A generalized feature extractor using expansion matching and the Karhunen-Loeve transform|
Flexible models: A powerful alternative to exemplars and explicit models|
A Graphical Model for Audiovisual Object Tracking|
Transformed Hidden Markov Models: Estimating Mixture Models of Images and Inferring Spatial Transformations in Video Sequence|
\Dynamic transformed mixtures of Gaussians,"|
\Tracking articulated structures in dense disparity maps,|
