Sousveillance: Inventing and Using Wearable Computing Devices for Data Collection in Surveillance Environments| Being Surveilled These days, if you feel like somebody' s watching you, you might be right.  One year after the Sept 11 attacks, security experts and privacy advocates say there has been a surge in the number of video cameras installed around the country [U. S. ].  The electronic eyes keep an unwavering gaze on eve rything from the Golden Gate Bridge to the Washington Monument. . . .  [For example,] a group of anti-surveillance activists [say]. . .  they have seen a 40% increase in new cameras in New York's financial district since last September [2001] (Evangelista 2002).  VIDEO\_SURVEILLANCE and its regime of control. . .  the banalization or popularization of global surveillance, or to put it another way, the DEMOCRATIZATION OF VOYEURISM on a planetary scale, has overexposed even our most private activities.  So doing, it has exposed us
Learning vehicular dynamics, with application to modeling| Abstract We consider the problem of modeling a helicopter's dynamics based on stateaction trajectories collected from it.  The contributions of this paper are twofold.  First, we consider the linear models learned by CIFER(the industry standard in helicopter identification), and show that their parameterization makes certain properties of dynamical systems, such as inertia, fundamentally difficult to capture.  We propose an alternative (acceleration based) parameterization that does not suffer from this deficiency, and that can be learned as efficiently from data.  Second, even though a Markov decision process model of helicopter's dynamics would explicitly model only the one-step transitions, we are often interested in a model's predictive performance over longer timescales.  In this paper, we present an efficient algorithm for (approximately) minimizing the prediction error over long time scales.  We present empirical results on two different helicopters.  Although this work was motivated by the problem of modeling helicopters, the ideas presented here are general, and can be applied to modeling large classes of vehicular dynamics. 
On Spectral Clustering: Analysis and an algorithm| Abstract Despite many empirical successes of spectral clustering methods| algorithms that cluster points using eigenvectors of matrices derived from the data|there are several unresolved issues.  First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways.  Second, many of these algorithms have no proof that they will actually compute a reasonable clustering.  In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab.  Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well.  We also show surprisingly good experimental results on a number of challenging clustering problems. 
Robust Textual Inference using Diverse Knowledge Sources| Abstract We present a machine learning approach to robust textual inference, in which parses of the text and the hypothesis sentences are used to measure their asymmetric "similarity", and thereby to decide if the hypothesis can be inferred.  This idea is realized in two different ways.  In the first, each sentence is represented as a graph (extracted from a dependency parser) in which the nodes are words/phrases, and the links represent dependencies.  A learned, asymmetric, graph-matching cost is then computed to measure the similarity between the text and the hypothesis.  In the second approach, the text and the hypothesis are parsed into the logical formula-like representation used by (Harabagiu et al. , 2000).  An abductive theorem prover (using learned costs for making different types of assumptions in the proof) is then applied to try to infer the hypothesis from the text, and the total "cost" of proving the hypothesis is used to decide if the hypothesis is entailed. 
Approximate Inference A lgorithms for Two-Layer Bayesian Networks| Abstract We present a class of approximate inference algorithms for graphical models of the QMR-DT type.  We give convergence rates for these algorithms and for the Jaakkola and Jordan (1999) algorithm, and verify these theoretical predictions empirically.  We also present empirical results on the difficult QMR-DT network problem, obtaining performance of the new algorithms roughly comparable to the Jaakkola and Jordan algorithm. 
Improving Text Classification by Shrinkage in a Hierarchy of Classes| Abstract When documents are organized in a large number of topic categories,
Web question answering: is more always better?| ABSTRACT This paper describes a question answering system that is designed to capitalize on the tremendous amount of data that is now available online.  Most question answering systems use a wide variety of linguistic resources.  We focus instead on the redundancy available in large corpora as an important resource.  We use this redundancy to simplify the query rewrites that we need to use, and to support answer mining from returned snippets.  Our system performs quite well given the simplicity of the techniques being utilized.  Experimental results show that question answering accuracy can be greatly improved by analyzing more and more matching passages.  Simple passage ranking and n-gram extraction techniques work well in our system making it efficient to use with many backend retrieval engines. 
Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping| Abstract This paper investigates conditions under which modifications to the reward function of a Markov decision process preserve the optimal policy.  It is shown that, besides the positive linear transformation familiar from utility theory, one can add a reward for transitions between states that is expressible as the difference in value of an arbitrary potential function applied to those states.  Furthermore, this is shown to be a necessary condition for invariance, in the sense that any other transformation may yield suboptimal policies unless further assumptions are made about the underlying MDP.  These results shed light on the practice of reward shaping, a method used in reinforcement learning whereby additional training rewards are used to guide the learning agent.  In particular, some well-known "bugs" in reward shaping procedures are shown to arise from non-potential-based rewards, and methods are given for constructing shaping potentials corresponding to distance-based and subgoalbased heuristics.  We show that such potentials can lead to substantial reductions in learning time. 
On Discriminative vs| Generative Classifiers: A comparison of logistic regression and naive Bayes.  Abstract We compare discriminative and generative learning as typified by logistic regression and naive Bayes.  We show, contrary to a widelyheld belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better.  This stems from the observation|which is borne out in repeated experiments|that while discriminative learning has lower asymptotic error, a generative classifier may also approach its (higher) asymptotic error much faster. 
Stable Algorithms for Link Analysis| ABSTRACT The Kleinberg HITS and the Google PageRank algorithms are eigenvector methods for identifying "authoritative" or "influential" articles, given hyperlink or citation information.  That such algorithms should give reliable or consistent answers is surely a desideratum, and in [10], we analyzed when they can be expected to give stable rankings under small perturbations to the linkage patterns.  In this paper, we extend the analysis and show how it gives insight into ways of designing stable link analysis methods.  This in turn motivates two new algorithms, whose performance we study empirically using citation data and web hyperlink data. 
A Data Clustering and Streamline Reduction Method for 3D MR Flow Vector Field Simplification| Abstract.  With the increasing capability of MR imaging and Computational Fluid Dynamics (CFD) techniques, a significant amount of data related to the haemodynamics of the cardiovascular systems are being generated.  Direct visualization of the data introduces unnecessary visual clutter and hides away the underlying trend associated with the progression of the disease.  To elucidate the main topological structure of the flow fields, we present in this paper a 3D visualisation method based on the abstraction of complex flow fields.  It uses hierarchical clustering and local linear expansion to extract salient topological flow features.  This is then combined with 3D streamline tracking, allowing most important flow details to be visualized.  Example results of the technique applied to both CFD and in vivo MR data sets are provided. 
PEGASUS: A policy search method for large MDPs and POMDPs| Abstract We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model.  Our approach is based on the following observation: Any (PO)MDP can be transformed into an "equivalent" POMDP in which all state transitions (given the current state and action) are deterministic.  This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions.  We give a natural way of estimating the value of all policies in these transformed POMDPs.  Policy search is then simply performed by searching for a policy with high estimated value.  We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with "sample complexity" bounds that have only a polynomial rather than exponential dependence on the horizon time.  Our method applies to arbitrary POMDPs, including ones with infinite state and action spaces.  We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle. 
Convergence rates of the Voting Gibbs classifier, with application to Bayesian feature selection| Abstract The Gibbs classifier is a simple approximation to the Bayesian optimal classifier in which one samples from the posterior for the parameter `, and then classifies using the single classifier indexed by that parameter vector.  In this paper, we study the Voting Gibbs classifier, which is the extension of this scheme to the full Monte Carlo setting, in which N samples are drawn from the posterior and new inputs are classified by voting the N resulting classifiers.  We show that the error of Voting Gibbs converges rapidly to the Bayes optimal rate; in particular the relative error decays at a rapid O(1=N) rate.  We also discuss the feature selection problem in the Voting Gibbs context.  We show that there is a choice of prior for Voting Gibbs such that the algorithm has high tolerance to the presence of irrelevant features.  In particular, the algorithm has sample complexity that is logarithmic in the number of irrelevant features. 
Stable adaptive control with online learning| Abstract Learning algorithms have enjoyed numerous successes in robotic control tasks.  In problems with time-varying dynamics, online learning methods have also proved to be a powerful tool for automatically tracking and/or adapting to the changing circumstances.  However, for safety-critical applications such as airplane flight, the adoption of these algorithms has been significantly hampered by their lack of safety, such as "stability," guarantees.  Rather than trying to show difficult, a priori, stability guarantees for specific learning methods, in this paper we propose a method for "monitoring" the controllers suggested by the learning algorithm online, and rejecting controllers leading to instability.  We prove that even if an arbitrary online learning method is used with our algorithm to control a linear dynamical system, the resulting system is stable. 
Policy Search via Density Estimation| Abstract We propose a new approach to the problem of searching a space of stochastic controllers for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP).  Following several other authors, our approach is based on searching in parameterized families of policies (for example, via gradient descent) to optimize solution quality.  However, rather than trying to estimate the values and derivatives of a policy directly, we do so indirectly using estimates for the probability densities that the policy induces on states at the different points in time.  This enables our algorithms to exploit the many techniques for efficient and robust approximate density propagation in stochastic systems.  We show how our techniques can be applied both to deterministic propagation schemes (where the MDP's dynamics are given explicitly in compact form,) and to stochastic propagation schemes (where we have access only to a generative model, or simulator, of the MDP).  We present empirical results for both of these variants on complex problems. 
Autonomous Helicopter Flight via Reinforcement Learning| Abstract Autonomous helicopter flight represents a challenging control problem, with complex, noisy, dynamics.  In this paper, we describe a successful application of reinforcement learning to autonomous helicopter flight.  We first fit a stochastic, nonlinear model of the helicopter dynamics.  We then use the model to learn to hover in place, and to fly a number of maneuvers taken from an RC helicopter competition. 
Preventing "Overfitting" of Cross-Validation Data| Abstract Suppose that, for a learning task, we have to select one hypothesis out of a set of hypotheses (that may, for example, have been generated by multiple applications of a randomized learning algorithm).  A common approach is to evaluate each hypothesis in the set on some previously unseen cross-validation data, and then to select the hypothesis that had the lowest cross-validation error.  But when the cross-validation data is partially corrupted such as by noise, and if the set of hypotheses we are selecting from is large, then "folklore" also warns about "overfitting" the crossvalidation data [Klockars and Sax, 1986, Tukey, 1949, Tukey, 1953].  In this paper, we explain how this "overfitting" really occurs, and show the surprising result that it can be overcome by selecting a hypothesis with a higher cross-validation error, over others with lower cross-validation errors.  We give reasons for not selecting the hypothesis with the lowest cross-validation error, and propose a new algorithm, LOOCVCV, that uses a computationally efficient form of leave--one--out crossvalidation to select such a hypothesis.  Finally, we present experimental results for one domain, that show LOOCVCV consistently beating picking the hypothesis with the lowest cross-validation error, even when using reasonably large cross-validation sets. 
An Information-Theoretic Analysis of Hard and Soft Assignment Methods for Clustering| Abstract Assignment methods are at the heart of many algorithms for unsupervised learning and clustering --- in particular, the well-known K-means and Expectation-Maximization (EM) algorithms.  In this work, we study several different methods of assignment, including the "hard" assignments used by K-means and the "soft" assignments used by EM.  While it is known that K-means minimizes the distortion on the data and EM maximizes the likelihood, little is known about the systematic differences of behavior between the two algorithms.  Here we shed light on these differences via an information-theoretic analysis.  The cornerstone of our results is a simple decomposition of the expected distortion, showing that K-means (and its extension for inferring general parametric densities from unlabeled sample data) must implicitly manage a trade-off between how similar the data assigned to each cluster are, and how the data are balanced among the clusters.  How well the data are balanced is measured by the entropy of the partition defined by the hard assignments.  In addition to letting us predict and verify systematic differences between K-means and EM on specific examples, the decomposition allows us to give a rather general argument showing that K-means will consistently find densities with less "overlap" than EM.  We also study a third natural assignment method that we call posterior assignment, that is close in spirit to the soft assignments of EM, but leads to a surprisingly different algorithm. 
Approximate Planning in Large POMDPs via Reusable Trajectories| Abstract We consider the problem of reliably choosing a near-best strategy from a restricted class of strategies \Pi in a partially observable Markov decision process (POMDP).  We assume we are given the ability to simulate the POMDP, and study what might be called the sample complexity --- that is, the amount of data one must generate in the POMDP in order to choose a good strategy.  We prove upper bounds on the sample complexity showing that, even for infinitely large and arbitrarily complex POMDPs, the amount of data needed can be finite, and depends only linearly on the complexity of the restricted strategy class \Pi, and exponentially on the horizon time.  This latter dependence can be eased in a variety of ways, including the application of gradient and local search algorithms.  Our measure of complexity generalizes the classical supervised learning notion of VC dimension to the settings of reinforcement learning and planning. 
Classification with Hybrid Generative/Discriminative Models| Abstract Although discriminatively trained classifiers are usually more accurate when labeled training data is abundant, previous work has shown that when training data is limited, generative classifiers can out-perform them.  This paper describes a hybrid model in which a high-dimensional subset of the parameters are trained to maximize generative likelihood, and another, small, subset of parameters are discriminatively trained to maximize conditional likelihood.  We give a sample complexity bound showing that in order to fit the discriminative parameters well, the number of training examples required depends only on the logarithm of the number of feature occurrences and feature set size.  Experimental results show that hybrid models can provide lower test error and can produce better accuracy/coverage curves than either their purely generative or purely discriminative counterparts.  We also discuss several advantages of hybrid models, and advocate further work in this area. 
Online and batch learning of pseudo-metrics| Abstract We describe and analyze an online algorithm for supervised learning of pseudo-metrics.  The algorithm receives pairs of instances and predicts their similarity according to a pseudo-metric.  The pseudo-metrics we use are quadratic forms parameterized by positive semi-definite matrices.  The core of the algorithm is an update rule that is based on successive projections onto the positive semi-definite cone and onto half-space constraints imposed by the examples.  We describe an efficient procedure for performing these projections, derive a worst case mistake bound on the similarity predictions, and discuss a dual version of the algorithm in which it is simple to incorporate kernel operators.  The online algorithm also serves as a building block for deriving a large-margin batch algorithm.  We demonstrate the merits of the proposed approach by conducting experiments on MNIST dataset and on document filtering. 
Meta-learning for text classification| Abstract Many text classification algorithms, including multinomial and multivariate Bernoulli naive Bayes and most TFIDF variants (such as "probabilistic TFIDF"), make classification predictions by computing an inner product between a test document vector and a parameter vector.  Here, the parameter vector is computed as some simple, closed-form, function g of the training set statistics.  Much research work in text classification consists of manually trying to find better functions g, and indeed, the last few decades have seen numerous heuristic proposals for new g.  In this paper, we propose an algorithm for automatically learning this function from data.  The g found by our algorithm then defines a new learning algorithm for text classification, which we can apply to novel classification tasks.  We show that our learned learning algorithm outperforms naive Bayes and TFIDF on a variety of multiclass text classification tasks. 
Online Bounds for Bayesian Algorithms| Abstract We present a competitive analysis of Bayesian learning algorithms in the online learning setting and show that many simple Bayesian algorithms (such as Gaussian linear regression and Bayesian logistic regression) perform favorably when compared, in retrospect, to the single best model in the model class.  The analysis does not assume that the Bayesian algorithms' modeling assumptions are "correct," and our bounds hold even if the data is adversarially chosen.  For Gaussian linear regression (using logloss), our error bounds are comparable to the best bounds in the online learning literature, and we also provide a lower bound showing that Gaussian linear regression is optimal in a certain worst case sense.  We also give bounds for some widely used maximum a posteriori (MAP) estimation algorithms, including regularized logistic regression. 
Learning syntactic patterns for automatic hypernym discovery DRAFT VERSION - DO NOT CIRCULATE| Abstract We present a new algorithm for learning hypernym (is-a) relations from text, a key problem in machine learning for natural language understanding.  This method generalizes earlier work that relied on hand-built lexico-syntactic patterns by introducing a general-purpose formalization of the pattern space based on syntactic dependency paths.  We learn these paths automatically by taking hypernym/hyponym word pairs from WordNet, finding sentences containing these words in a large parsed corpus, and automatically extracting these paths.  These paths are then used as features in a high-dimensional representation of noun relationships.  We use a logistic regression classifier based on these features for the task of corpus-based hypernym pair identification.  Our classifier is shown to outperform previous pattern-based methods for identifying hypernym pairs (using WordNet as a gold standard), and is shown to outperform those methods as well as WordNet on an independent test set. 
Apprenticeship learning via inverse reinforcement learning| Abstract We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform.  This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off.  We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert.  Our algorithm is based on using "inverse reinforcement learning" to try to recover the unknown reward function.  We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function. 
Learning first-order Markov models for control| Abstract First-order Markov models have been successfully applied to many problems, for example in modeling sequential data using Markov chains, and modeling control problems using the Markov decision processes (MDP) formalism.  If a first-order Markov model's parameters are estimated from data, the standard maximum likelihood estimator considers only the first-order (single-step) transitions.  But for many problems, the firstorder conditional independence assumptions are not satisfied, and as a result the higher order transition probabilities may be poorly approximated.  Motivated by the problem of learning an MDP's parameters for control, we propose an algorithm for learning a first-order Markov model that explicitly takes into account higher order interactions during training.  Our algorithm uses an optimization criterion different from maximum likelihood, and allows us to learn models that capture longer range effects, but without giving up the benefits of using first-order Markov models.  Our experimental results also show the new algorithm outperforming conventional maximum likelihood estimation in a number of control problems where the MDP's parameters are estimated from data. 
Link Analysis, Eigenvectors and Stability| Abstract The HITS and the PageRank algorithms are eigenvector methods for identifying "authoritative" or "influential" articles, given hyperlink or citation information.  That such algorithms should give consistent answers is surely a desideratum, and in this paper, we address the question of when they can be expected to give stable rankings under small perturbations to the hyperlink patterns.  Using tools from matrix perturbation theory and Markov chain theory, we provide conditions under which these methods are stable, and give specific examples of instability when these conditions are violated.  We also briefly describe a modification to HITS that improves its stability. 
Update of the search for the neutrinoless decay| Abstract We present an update of the search for the lepton family number violating decay ! fl using 12:6 million + \Gamma pairs collected with the CLEO detector.  No evidence of a signal has been found and the corresponding upper limit is B(! fl) ! 1:1 \Theta 10 \Gamma 6 at 90% CL, significantly smaller than previous experimental limits.  S.  Ahmed, 1 M.  S.  Alam, 1 S.  B.  Athar, 1 L.  Jian, 1 L.  Ling, 1 A.  H.  Mahmood, 1; \Lambda M.  Saleem, 1 S.  Timm, 1 F.  Wappler, 1 A.  Anastassov, 2 J.  E.  Duboscq, 2 K.  K.  Gan, 2 C.  Gwon, 2 T.  Hart, 2 K.  Honscheid, 2 H.  Kagan, 2 R.  Kass, 2 J.  Lorenc, 2 T.  K.  Pedlar, 2 H.  Schwarthoff, 2 E.  von Toerne, 2 M.  M.  Zoeller, 2 S.  J.  Richichi, 3 H.  Severini, 3 P.  Skubic, 3 A.  Undrus, 3 S.  Chen, 4 J.  Fast, 4 J.  W.  Hinson, 4 J.  Lee, 4 N.  Menon, 4 D.  H.  Miller, 4 E.  I.  Shibata, 4 I.  P.  J.  Shipsey, 4 V.  Pavlunin, 4 D.  Cronin-Hennessy, 5 Y.  Kwon, 5;y A. L.  Lyon, 5 E.  H.  Thorndike, 5 C.  P.  Jessop, 6 H.  Marsiske, 6 M.  L.  Perl, 6 V.  Savinov, 6 D.  Ugolini, 6 X.  Zhou, 6 T.  E.  Coan, 7 V.  Fadeyev, 7 I.  Korolkov, 7 Y.  Maravin, 7 I.  Narsky, 7 R.  Stroynowski, 7 J.  Ye, 7 T.  Wlodek, 7 M.  Artuso, 8 R.  Ayad, 8 E.  Dambasuren, 8 S.  Kopp, 8 G.  Majumder, 8 G.  C.  Moneti, 8 R.  Mountain, 8 S.  Schuh, 8 T.  Skwarnicki, 8 S.  Stone, 8 G.  Viehhauser, 8 J. C.  Wang, 8 A.  Wolf, 8 J.  Wu, 8 S.  E.  Csorna, 9 K.  W.  McLean, 9 Sz.  M'arka,
First Search for CP violation in Tau Lepton Decay| Abstract We have performed the first search for CP violation in tau lepton decay.  CP violation in lepton decay does not occur in the minimal standard model but can occur in extensions such as the multi-Higgs doublet model.  It appears as a characteristic difference between the #- and # + decay angular distributions for the semi-leptonic decay modes such as # - ! K 0 # - #.  We define an observable asymmetry to exploit this and find no evidence for any CP violation.  S.  Anderson, 1 Y.  Kubota, 1 S.  J.  Lee, 1 J.  J.  O'Neill,
regularization, and rotational invariance| Abstract We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting.  Focusing on logistic regression, we show that using L 1 regularization of the parameters, the sample complexity (i. e. , the number of training examples required to learn "well,") grows only logarithmically in the number of irrelevant features.  This logarithmic rate matches the best known bounds for feature selection, and indicates that L 1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples.  We also give a lowerbound showing that any rotationally invariant algorithm---including logistic regression with L 2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features. 
Learning random walk models for inducing word dependency distributions| Abstract Many NLP tasks rely on accurately estimating word dependency probabilities P(w 1 |w 2 ), where the words w 1 and w 2 have a particular relationship (such as verb-object).  Because of the sparseness of counts of such dependencies, smoothing and the ability to use multiple sources of knowledge are important challenges.  For example, if the probability P(N |V ) of noun N being the subject of verb V is high, and V takes similar objects to V 0 , and V 0 is synonymous to V 00 , then we want to conclude that P(N |V 00 ) should also be reasonably high---even when those words did not cooccur in the training data.  To capture these higher order relationships, we propose a Markov chain model, whose stationary distribution is used to give word probability estimates.  Unlike the manually defined random walks used in some link analysis algorithms, we show how to automatically learn a rich set of parameters for the Markov chain's transition probabilities.  We apply this model to the task of prepositional phrase attachment, obtaining an accuracy of 87. 56%. 
Simultaneous Mapping and Localization With Sparse Extended Information Filters: Theory and Initial Results| Abstract This paper describes a scalable algorithm for the simultaneous mapping and localization (SLAM) problem.  SLAM is the problem of determining the location of environmental features with a roving robot.  Many of today's popular techniques are based on extended Kalman filters (EKFs), which require update time quadratic in the number of features in the map.  This paper develops the notion of sparse extended information filters (SEIFs), as a new method for solving the SLAM problem.  SEIFs exploit structure inherent in the SLAM problem, representing maps through local, Web-like networks of features.  By doing so, updates can be performed in constant time, irrespective of the number of features in the map.  This paper presents several original constant-time results of SEIFs, and provides simulation results that show the high accuracy of the resulting maps in comparison to the computationally more cumbersome EKF solution. 
Autonomous inverted helicopter flight via reinforcement learning| Abstract.  Helicopters have highly stochastic, nonlinear, dynamics, and autonomous helicopter flight is widely regarded to be a challenging control problem.  As helicopters are highly unstable at low speeds, it is particularly difficult to design controllers for low speed aerobatic maneuvers.  In this paper, we describe a successful application of reinforcement learning to designing a controller for sustained inverted flight on an autonomous helicopter.  Using data collected from the helicopter in flight, we began by learning a stochastic, nonlinear model of the helicopter's dynamics.  Then, a reinforcement learning algorithm was applied to automatically learn a controller for autonomous inverted hovering.  Finally, the resulting controller was successfully tested on our autonomous helicopter platform. 
Distance Metric Learning with Application to Clustering with Side-Information| Abstract Many algorithms rely critically on being given a good metric over their inputs.  For instance, data can often be clustered in many "plausible" ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the input space's metric until sufficiently good clusters are found.  For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider "similar. " For instance, we may ask them to provide examples.  In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in R n , learns a distance metric over R n that respects these relationships.  Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms.  We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance. 
Game Theory with Restricted Strategies (DRAFT: Please do not circulate|).  Abstract We present a theory of multiplayer games in which each player chooses their strategy from a limited class that may be significantly weaker than the class of all mixed strategies.  As in much of AI and machine learning, such restrictions may be desirable for reasons of computational tractability.  We define and study the notions of restricted Nash equilibria, local restricted Nash equilibria, and restricted security strategies.  We illustrate a number of these concepts with two well-studied games from the literature, the War of Attrition and Pricebots games, in which both players are restricted to play mixed strategies that are mixtures of Gaussians. 
Robust textual inference via learning and abductive reasoning| Abstract We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text.  More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al. , 2000).  An abductive theorem prover then tries to find the minimum "cost" set of assumptions necessary to show that one statement follows from the other.  These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet.  If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred.  Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving.  We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score. 
Latent Dirichlet Allocation| Abstract We propose a generative model for text and other collections of discrete data, that generalizes or improves on several previous models, including naive Bayes/unigram, mixtures of naive Bayes [6], and Hofmann's pLSI/aspect model [3].  In the context of text modeling, our model posits that each document is generated as a mixture of topics, where the continuous-valued mixture proportions are distributed as a latent Dirichlet random variable.  Inference and learning are carried out eciently via variational algorithms.  We present empirical results on applications of this model to problems in text modeling, collaborative filtering, and text classification. 
A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes| Abstract A critical issue for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP.  In stochastic environments with very large or infinite state spaces, traditional planning and reinforcement learning algorithms may be inapplicable, since their running time typically grows linearly with the state space size in the worst case.  In this paper we present a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states.  The running time is exponential in the horizon time (which depends only on the discount factor # and the desired degree of approximation to the optimal policy).  Our algorithm thus provides a different complexity trade-off than classical algorithms such as value iteration | rather than scaling linearly in both horizon time and state space size, our running time trades an exponential dependence on the former in exchange for no dependence on the latter.  Our algorithm is based on the idea of sparse sampling .  We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suces to compute nearoptimal actions from any state of an MDP.  Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs [KMN00]. 
Fast Gaussian Process Regression using KD-Trees| Abstract The computation required for Gaussian process regression with n training examples is about O(n 3 ) during training and O(n) for each prediction.  This makes Gaussian process regression too slow for large data sets.  In this paper, we present a fast approximation method, based on kd-trees, that significantly reduces both the prediction and the training times of Gaussian process regression. 
Algorithms for Inverse Reinforcement Learning| Abstract This paper addresses the problem of inverse reinforcement learning (IRL) in Markov decision processes, that is, the problem of extracting a reward function given observed, optimal behavior.  IRL may be useful for apprenticeship learning to acquire skilled behavior, and for ascertaining the reward function being optimized by a natural system.  We first characterize the set of all reward functions for which a given policy is optimal.  We then derive three algorithms for IRL.  The first two deal with the case where the entire policy is known; we handle tabulated reward functions on a finite state space and linear functional approximation of the reward function over a potentially infinite state space.  The third algorithm deals with the more realistic case in which the policy is known only through a finite set of observed trajectories.  In all cases, a key issue is degeneracy|the existence of a large set of reward functions for which the observed policy is optimal.  To remove degeneracy, we suggest some natural heuristics that attempt to pick a reward function that maximally differentiates the observed policy from other, sub-optimal policies.  This results in an eciently solvable linear programming formulation of the IRL problem.  We demonstrate our algorithms on simple discrete/#nite and continuous/in#nite state problems. 
Data-Intensive Question Answering|
Latent Dirichlet models for application in information retrieval|
Web Question Answering:|
Simultaneous localization and mapping with sparse extended information filters|
Feature selection, L1 vs| L2 regularization, and rotational invariance. 
Distance metric learnign with application to clustering with side-information|
On Feature Selection: Learning with Exponentially Many Irrelevant Features as Training Examples|
Stable algorithms for link analysis, in:|
Simultaneous mapping and localization with sparse extended information filters|
Distance learning metric|
Inverted autonomous helicopter flight via reinforcement learning|
scaling in random networks|
1| 72 Improving text classification byshrinkage in a hierarchy of classes. 
Weiss On Spectral Clustering: analysis and an algorithm NIPS,|
Systems (NIPS*9),|
Shaping and policy search in reinforcement learning|
