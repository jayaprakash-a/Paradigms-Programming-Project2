Multiclass Discriminative Fields for Parts-Based Object Detection| Abstract In this paper, we present a discriminative framework for parts-based object detection based on the multiclass extensions of binary discriminative fields described in [1].  These fields allow simultaneous discriminative modeling of the appearance of individual parts and the geometric relationship between them.  The conventional Markov Random Field (MRF) formulations cannot be used for this purpose because they do not allow the use of data while modeling interaction between labels which is crucial for enforcing geometric consistencies between parts.  The proposed technique can handle object deformations, occlusions and multiple-instance detection in a single trained model with no added computational efforts.  The parameters of the field are learned using efficient maximum marginal approximations and inference is carried out using loopy belief propagation.  We demonstrate the efficacy of this approach through controlled preliminary experiments on rigid and deformable synthetic toy objects. 
Discriminative Fields for Modeling Spatial Dependencies in Natural Images| Abstract In this paper we present Discriminative Random Fields (DRF), a discriminative framework for the classification of natural image regions by incorporating neighborhood spatial dependencies in the labels as well as the observed data.  The proposed model exploits local discriminative models and allows to relax the assumption of conditional independence of the observed data given the labels, commonly used in the Markov Random Field (MRF) framework.  The parameters of the DRF model are learned using penalized maximum pseudo-likelihood method.  Furthermore, the form of the DRF model allows the MAP inference for binary classification problems using the graph min-cut algorithms.  The performance of the model was verified on the synthetic as well as the real-world images.  The DRF model outperforms the MRF model in the experiments. 
Shape-Based Recognition of Wiry Objects| Abstract We present an approach to the recognition of complexshaped objects in cluttered environments based on edge cues.  We first use example images of the desired object in typical backgrounds to train a classifier cascade which determines whether edge pixels in an image belong to an instance of the object or the clutter.  Presented with a novel image, we use the cascade to discard clutter edge pixels.  The features used for this classification are localized, sparse edge density operations.  Experiments validate the effectiveness of the technique for recognition of complex objects in cluttered indoor scenes under arbitrary out-of-image-plane rotation.  1
Provably-Convergent Iterative Methods for Projective Structure from Motion| Astract: The estimation of the projective structure of a scene from image correspondences can be formulated as the minimization of the mean-squared distance between predicted and observed image points with respect to the projection matrices, the scene point positions, and their depths.  Since these unknowns are not independent, constraints must be chosen to ensure that the optimization process is well posed.  This paper examines three plausible choices, and shows that the first one leads to the Sturm-Triggs projective factorization algorithm, while the other two lead to new provably-convergent approaches.  Experiments with synthetic and real data are used to compare the proposed techniques to the Sturm-Triggs algorithm and bundle adjustment. 
Man-Made Structure Detection in Natural Images using a Causal Multiscale Random Field| Abstract This paper presents a generative model based approach to man-made structure detection in 2D natural images.  The proposed approach uses a causal multiscale random field suggested in [3] as a prior model on the class labels on the image sites.  However, instead of assuming the conditional independence of the observed data, we propose to capture the local dependencies in the data using a multiscale feature vector.  The distribution of the multiscale feature vectors is modeled as mixture of Gaussians.  A set of robust multiscale features is presented that captures the general statistical properties of man-made structures at multiple scales without relying on explicit edge detection.  The proposed approach was validated on real-world images from the Corel data set, and a performance comparison with other techniques is presented. 
3-D Object Modeling and Recognition for Telerobotic Manipulation| Abstract This paper describes a system that semi-automatically builds a virtual world for remote operations by constructing 3-D models of a robot's work environment.  With a minimum of human interaction, planar and quadric surface representations of objects typically found in manmade facilities are generated from laser rangefinder data.  The surface representations are used to recognize complex models of objects in the scene.  These object models are incorporated into a larger world model that can be viewed and analyzed by the operator, accessed by motion planning and robot safeguarding algorithms, and ultimately used by the operator to command the robot through graphical programming and other high level constructs.  Limited operator interaction, combined with assumptions about the robots task environment, make the problem of modeling and recognizing objects tractable and yields a solution that can be readily incorporated into many telerobotic control schemes. 
Quadric-Based Polygonal Surface Simplification| The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of these organizations. 
Surface matching for object recognition in complex three-dimensional scenes| Abstract We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation.  Our object representation comprises descriptive images associated with oriented points on the surface of an object.  Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters.  The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point.  These images, localized descriptions of the global shape of the object, are invariant to rigid transformations.  Through correlation of images, point correspondences between a model and scene data are established.  Geometric consistency is used to group the correspondences from which plausible rigid transformations that align the model with the scene are calculated.  The transformations are then refined and verified using a modified iterative closest point algorithm.  The effectiveness of our representation comes from its ability to combine the descriptive nature of global object properties with the robustness to partial views and clutter of local shape descriptions. The wide applicability of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion. 
Experience with Rover Navigation for Lunar-Like Terrains| Abstract Reliable navigation is critical for a lunar rover, both for autonomous traverses and safeguarded, remote teleoperation.  This paper describes an implemented system that has autonomously driven a prototype wheeled lunar rover over a kilometer in natural, outdoor terrain.  The navigation system uses stereo terrain maps to perform local obstacle avoidance, and arbitrates steering recommendations from both the user and the rover.  The paper describes the system architecture, each of the major components, and the experimental results to date. 
Approximate Parameter Learning in Discriminative Fields| Abstract In this paper, we present an approach for approximate maximum likelihood parameter learning in discriminative field models, which is based on approximating true expectations with simple piecewise constant functions constructed using inference techniques.  Gradient ascent with these updates shows interesting weak-convergence behavior which is tied closely to the number of errors made during inference.  The performance of various approximations was evaluated with different inference techniques showing that the learned parameters lead to good classification performance so long as the method used for approximating the gradient is consistent with the inference mechanism.  The proposed approach is general enough to be used for conditional training of conventional MRFs. 
Discriminative Random Fields: A Discriminative Framework for Contextual Interaction in Classification| Abstract In this work we present Discriminative Random Fields (DRFs), a discriminative framework for the classification of image regions by incorporating neighborhood interactions in the labels as well as the observed data.  The discriminative random fields offer several advantages over the conventional Markov Random Field (MRF) framework.  First, the DRFs allow to relax the strong assumption of conditional independence of the observed data generally used in the MRF framework for tractability.  This assumption is too restrictive for a large number of applications in vision.  Second, the DRFs derive their classification power by exploiting the probabilistic discriminative models instead of the generative models used in the MRF framework.  Finally, all the parameters in the DRF model are estimated simultaneously from the training data unlike the MRF framework where likelihood parameters are usually learned separately from the field parameters.  We illustrate the advantages of the DRFs over the MRF framework in an application of man-made structure detection in natural images taken from the Corel database. 
Control of Polygonal Mesh Resolution for 3-D Computer Vision| Abstract A common representation in 3-D computer vision is the polygonal surface mesh because meshes can model objects of arbitrary shape and are easily constructed from sensed 3-D data.  The resolution of a surface mesh is the overall spacing between vertices that comprise the mesh.  Because sensed 3-D points are often unevenly distributed, the resolution of a surface mesh is often poorly defined.  We present an algorithm that transforms a mesh with an uneven spacing between vertices into a mesh with a more even spacing between vertices, thus improving its definition of resolution.  In addition, we show how the algorithm can be used to control the resolution of surface meshes, making them amenable to multiresolution approaches in computer vision.  The structure of our algorithm is modeled on iterative mesh simplification algorithms common in computer graphics; however, the individual steps in our algorithm are designed specifically to control mesh resolution.  An even spacing between vertices is generated by applying a sequence of local edge operations that promote uniform edge lengths while preserving mesh shape.  To account for polyhedral objects, we introduce an accurate shape change measure that permits edge operations along sharp creases.  By locally bounding the total change in mesh shape, drastic changes in global shape are prevented.  We show results from many 3-D sensing domains including computed tomography, range imaging, and digital elevation map construction. 
Stereo Perception and Dead Reckoning for a Prototype Lunar Rover| Abstract This paper describes practical, effective approaches to stereo perception and dead reckoning, and presents results from systems implemented for a prototype lunar rover operating in natural, outdoor environments.  The stereo perception hardware includes a binocular head mounted on a motion-averaging mast.  This head provides images to a normalized correlation matcher, that intelligently selects what part of the image to process (saving time), and subsamples the images (again saving time) without subsampling disparities (which would reduce accuracy).  The implementation has operated successfully during long-duration field exercises, processing streams of thousands of images.  The dead reckoning approach employs encoders, inclinometers, a compass, and a turn-rate sensor to maintain the position and orientation of the rover as it traverses.  The approach integrates classical odometry with inertial guidance.  The implementation succeeds in the face of significant sensor noise by virtue of sensor modelling, plus extensive filtering.  The stereo and dead reckoning components are used by an obstacle avoidance planner that projects a finite number of arcs through the terrain map, and evaluates the traversability of each arc to choose a travel direction that is safe and effective.  With these components integrated into a complete navigation system, a prototype rover has traversed over 1 km in lunar-like environments. 
On Pencils of Tangent Planes and the Recognition of Smooth 3D Shapes from Silhouettes| Abstract.  This paper presents a geometric approach to recognizing smooth objects from their outlines.  We define a signature function that associates feature vectors with objects and baselines connecting pairs of possible viewpoints.  Feature vectors, which can be projective, a6ne, or Euclidean, are computed using the planes that pass through a fixed baseline and are also tangent to the object's surface.  In the proposed framework, matching a test outline to a set of training outlines is equivalent to finding intersections in feature space between the images of the training and the test signature functions.  The paper presents experimental results for the case of internally calibrated perspective cameras, where the feature vectors are angles between epipolar tangent planes. 
Training Object Detection Models with Weakly Labeled Data| Abstract Appearance based object detection systems utilizing statistical models to capture real world variations in appearance have been shown to exhibit good detection performance.  The parameters of these statistical models are typically learned automatically from labeled training images.  This process can be difficult in that a large number of labeled training examples may be needed to accurately model appearance variation.  In this work we describe a method whereby a training set consisting of a small number of fully labeled training examples augmented with a set of weakly labeled examples can be used to train a detector which exhibits performance better than that which can be obtained with a reduced set of fully labeled training examples alone. 
Linear Model Hashing and Batch RANSAC for Rapid and Accurate Object Recognition| Abstract This paper proposes a joint feature-based model indexing and geometric constraint based alignment pipeline for efficient and accurate recognition of 3D objects from a large model database.  Traditional approaches either first prune the model database using indexing without geometric alignment or directly perform recognition based alignment.  The indexing based pruning methods without geometric constraints can miss the correct models under imperfections such as noise, clutter and obscurations.  Alignment based verification methods have to linearly verify each model in the database and hence do not scale up.  The proposed techniques use spin images as semi-local shape descriptors and Locality-Sensitive Hashing (LSH) to index into a joint spin image database for all the models.  The indexed models represented in the pruned set are further pruned using progressively complex geometric constraints.  A simple geometric configuration of multiple spin images, for instance a doublet, is first used to check for geometric consistency.  Subsequently, full Euclidean geometric constraints are applied using RANSAC-based techniques on the pruned spin images and the models to verify specific object identity.  As a result, the combined indexing and geometric alignment based pipeline is able to focus on matching the most promising models, and generate far less pose hypotheses while maintaining the same level of performance as the sequential alignment based recognition.  Furthermore, compared to geometric indexing techniques like Geometric Hashing, the construction time and storage complexity for the proposed technique remains linear in the number of features rather than higher order polynomial.  Experiments on a0 3D model database show promising results. 
Discriminant Filters For Object Recognition| Abstract This paper presents a technique for using training data to design image filters for appearance-based object recognition.  Rather than scanning the image with a single set of filters and using the results to test for the existence of objects, we use many sets of filters and take linear combinations of their outputs.  The combining coefficients are optimized in a training phase to encourage discriminability between the filter responses for distinct parts of the object and clutter.  Our experiments on three popular filter types show that by using this approach to combine sets of filters whose design parameters vary over a wide range, we can achieve detection performance competitive with that of any individual filter set.  This in turn can ease the task of fine-tuning the settings for both the filters and the mechanisms that analyze their outputs.  1
A Hybrid Object-Level/Pixel-Level Framework For Shape-based Recognition| Abstract This paper presents a technique for shape-based recognition that fuses pixellevel and object-level approaches into a unified framework.  A pixel-level algorithm classifies individual pixels as belonging to a target object or clutter based on automatically-selected shape features computed in a spatial arrangement around them; an object-level algorithm classifies object-sized rectangular image regions as objects or clutter by aggregating pixel classifier scores in the regions.  We train a cascade of interleaved pixel-level and objectlevel modules to quickly localize complex-shaped objects in highly cluttered scenes under arbitrary out-of-image-plane rotation.  Experimental results on a large set of real, highly-cluttered images of a common object under arbitrary out of image plane rotation demonstrate improvements over cascades of strictly pixel-level modules. 
Applications of non-metric vision to some visually guided robotics tasks| Abstract: We usually think of the physical space as being embedded in a three-dimensional Euclidean space where measurements of lengths and angles do make sense.  It turns out that for artificial systems, such as robots, this is not a mandatory viewpoint and that it is sometimes sufficient to think of the physical space as being embedded in an affine or even projective space.  The question then arises of how to relate these geometric models to image measurements and to geometric properties of sets of cameras.  We first consider that the world is modelled as a projective space and determine how projective invariant information can be recovered from the images and used in applications.  Next we consider that the world is an affine space and determine how affine invariant information can be recovered from the images and used in applications.  Finally, we do not move to the Euclidean layer because this is the layer where everybody else has been working with from the early days on, but rather to an intermediate level between the affine and Euclidean ones.  For each of the three layers we explain various calibration procedures, from fully automatic ones to ones that use some a priori information.  The calibration increases in difficulty from the projective to the Euclidean layer at the same time as the information that can be recovered from the images becomes more and more specific and detailed.  The two main applications that we consider are the detection of obstacles and the navigation of a robot vehicle. 
Surface Registration by Matching Oriented Points| Abstract For registration of 3-D free-form surfaces we have developed a representation which requires no knowledge of the transformation between views.  The representation comprises descriptive images associated with oriented points on the surface of an object.  Constructed using single point bases, these images are data level shape descriptions that are used for efficient matching of oriented points.  Correlation of images is used to establish point correspondences between two views; from these correspondences a rigid transformation that aligns the views is calculated.  The transformation is then refined and verified using a modified iterative closest point algorithm.  To demonstrate the generality of our approach, we present results from multiple sensing domains. 
Using Spin Images for Efficient Object Recognition in Cluttered 3D Scenes| Abstract We present a 3-D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion.  Recognition is based on matching surfaces by matching points using the spin-image representation.  The spin-image is a data level shape descriptor that is used to match surfaces represented as surface meshes.  We present a compression scheme for spin-images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models.  Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes. 
Incorporating Background Invariance into Feature-Based Object Recognition| Abstract Current feature-based object recognition methods use information derived from local image patches.  For robustness, features are engineered for invariance to various transformations, such as rotation, scaling, or affine warping.  When patches overlap object boundaries, however, errors in both detection and matching will almost certainly occur due to inclusion of unwanted background pixels.  This is common in real images, which often contain significant background clutter, objects which are not heavily textured, or objects which occupy a relatively small portion of the image. 
A Complete Navigation System for Goal Acquisition in Unknown Environments| Abstract Most autonomous outdoor navigation systems tested on actual robots have centered on local navigation tasks such as avoiding obstacles or following roads.  Global navigation has been limited to simple wandering, path tracking, straight-line goal seeking behaviors, or executing a sequence of scripted local behaviors.  These capabilities are insufficient for unstructured and unknown environments, where replanning may be needed to account for new information discovered in every sensor image.  To address these problems, we have developed a complete system that integrates local and global navigation.  The local system uses a scanning laser rangefinder to detect obstacles and recommend steering commands to ensure robot safety.  These obstacles are passed to the global system which stores them in a map of the environment.  With each addition to the map, the global system uses an incremental path planning algorithm to optimally replan the global path and recommend steering commands to reach the goal.  An arbiter combines the steering recommendations to achieve the proper balance between safety and goal acquisition.  This system was tested on a real robot and successfully drove it 1. 4 kilometers to find a goal given no a priori map of the environment. 
Path Planning with Hallucinated Worlds| Abstract--- We describe an approach that integrate midrange sensing into a dynamic path planning algorithm 1 .  The algorithm is based on measuring the reduction in path cost that would be caused by taking a sensor reading from candidate locations.  The planner uses this measure in order to decide where to take the next sensor reading.  Ideally, one would like to evaluate a path based on a map that is as close as possible to the true underlying world.  In practice, however, the map is only sparsely populated by data derived from sensor readings.  A key component of the approach described in this paper is a mechanism to infer (or "hallucinate") more complete maps from sparse sensor readings.  We show how this hallucination mechanism is integrated with the planner to produce better estimates of the gain in path cost occurred when taking sensor readings.  We show results on a real robot as well as a statistical analysis on a large set of randomly generated path planning problems on elevation maps from real terrain. 
Object Recognition by a Cascade of Edge Probes| Abstract We frame the problem of object recognition from edge cues in terms of determining whether individual edge pixels belong to the target object or to clutter, based on the configuration of edges in their vicinity.  A classifier solves this problem by computing sparse, localized edge features at image locations determined at training time.  In order to save computation and solve the aperture problem, we apply a cascade of these classifiers to the image, each of which computes edge features over larger image regions than its predecessors.  Experiments apply this approach to the recognition of real objects with holes and wiry components in cluttered scenes under arbitrary out-of-image-plane rotation.  1
An observation-constrained generative approach for probabilistic classification of image regions| Abstract In this paper, we propose a probabilistic region classification scheme for natural scene images.  In conventional generative methods, a generative model is learnt for each class using all the available training data belonging to that class.  However, if an input image has been generated from only a subset of the model support, use of the full model to assign generative probabilities can produce serious artifacts in the probability assignments.  This problem arises mainly when the different classes have multimodal distributions with considerable overlap in the feature space.  We propose an approach to constrain the class generative probability of a set of newly observed data by exploiting the distribution of the new data itself and using linear weighted mixing.  A Kullback -- Leibler Divergence-based fast model selection procedure is also proposed for learning mixture models in a low dimensional feature space.  The preliminary results on the natural scene images support the effectiveness of the proposed approach. 
Probabilistic Classification of Image Regions using an Observation-Constrained Generative Approach| Abstract--- In generic image understanding applications, one of the goals is to interpret the semantic context of the scene (e. g. , beach, office etc. ).  In this paper, we propose a probabilistic region classification scheme for natural scene images as a priming step for the problem of context interpretation.  In conventional generative methods, a generative model is learnt for each class using all the available training data belonging to that class.  However, if a set of newly observed data has been generated because of the subset of the model support, using the full model to assign generative probabilities can produce serious artifacts in the probability assignments.  This problem arises mainly when the different classes have multimodal distributions with considerable overlap in the feature space.  We propose an approach to constrain the class generative probability of a set of newly observed data by exploiting the distribution of the new data itself and using linear weighted mixing.  A KL-Divergence-based fast model selection procedure is also proposed for learning mixture models in a sparse feature space.  The preliminary results on the natural scene images support the effectiveness of the proposed approach. 
Minimum Risk Distance Measure for Object Recognition| Abstract The optimal distance measure for a given discrimination task under the nearest neighbor framework has been shown to be the likelihood that a pair of measurements have different class labels [5].  For implementation and efficiency considerations, the optimal distance measure was approximated by combining more elementary distance measures defined on simple feature spaces.  In this paper, we address two important issues that arise in practice for such an approach: (a) What form should the elementary distance measure in each feature space take? We motivate the need to use the optimal distance measure in simple feature spaces as the elementary distance measures; such distance measures have the desirable property that they are invariant to distance-respecting transformations.  (b) How do we combine the elementary distance measures? We present the precise statistical assumptions under which a linear logistic model holds exactly.  We benchmark our model with three other methods on a challenging face discrimination task and show that our approach is competitive with the state of the art. 
Object Recognition using Boosted Discriminants| Abstract We approach the task of object discrimination as that of learning efficient "codes" for each object class in terms of responses to a set of chosen discriminants.  We formulate this approach in an energy minimization framework.  The "code" is built incrementally by successively constructing discriminants that focus on pairs of training images of objects that are currently hard to classify.  The particular discriminants that we use partition the set of objects of interest into two well-separated groups.  We find the optimal discriminant as well as partition by formulating an objective criteria that measures the well-separateness of the partition.  We derive an iterative solution that alternates between the solutions for two generalized eigenproblems, one for the discriminant parameters and the other for the indicator variables denoting the partition.  We show how the optimization can easily be biased to focus on hard to classify pairs, which enables us to choose new discriminants one by one in a sequential manner.  We validate our approach on a challenging face discrimination task using parts as features and show that it compares favorably with the performance of an eigenspace method. 
3D Photography from Photographs and Video Clips| Abstract This paper addresses the problem of acquiring realistic visual models of the shape and appearance of complex three-dimensional (3D) scenes from collections of images, a process dubbed 3D photography.  We focus on three instances of this problem: (1) the image-based construction of projective visual hulls of complex surfaces from weakly-calibrated photographs; (2) the automated matching and registration of photographs of textured surfaces using aneinvariant patches and their geometric relationships; and (3) an approach to projective motion analysis and self-calibration explicitly accounting for natural camera constraints such as zero skew and capable of handling large numbers of images in an ecient and uniform manner.  We also briefly discuss some related applications of oriented dierential projective geometry to computer vision problems, including the determination of the ordering of rim segments in projective visual hull computation, and a purely projective proof of Koenderink's famous characterization of the local shape of visual contours. 
Weakly-Calibrated Stereo Perception for Rover Navigation|
3D measurements from imaging laser radars: how good are they?|
An Integral Approach to Free-Formed Object Modeling|
Iterative Projective Reconstruction from Multiple Views|
Pixel-Based Range Processing for Autonomous Driving|
Color Constancy Using KL-Divergence|
A Spherical Representation for Recognition of Free-Form Surfaces|
Active and Passive Range Sensing for Robotics|
Real-Thme 3-D Pose Estimation Using a High-Speed Range Sensor|
Shape representation and image segmentation using deformable surfaces|
Toward autonomous driving: the CMU Navlab| Part I - Perception. 
Harmonic Maps and Their Applications in Surface Matching|
Vision and navigation for the Carnegie Mellon NAVLAB|
Building 3-D Models from Unregistered Range Images|
The Optimal Distance Measure for Object Detection|
Combining Simple Discriminators for Object Discrimination|
Fully automatic registration of multiple 3D data sets|
Age related changes in human articular chondrocyte yield, proliferation and postexpansion chondrogenic capacity| Osteoarthritis Cartilage. 
Plasticity of clonal populations of dedi#erentiated adult human articular chondrocytes|
A Behavior-Based System For Off-Road Navigation|
3-D Vision Techniques for Autonomous Vehicles|
On 3D Shape Similarity|
Experimental Comparison of Techniques for Localization and Mapping Using a Bearing-Only Sensor|
Recognizing Objects by Matching Oriented Points|
Report on the 1995 Workshop on 3-D Object Representations in Computer Vision|
Performance of Space Subdivision Techniques in Ray Tracing|
Harmonic Shape Images: A Representation for 3D Free-Form Surfaces Based on Energy Minimization|
Deriving Orientation Cues from Stereo Images|
Invariant Filtering for Simultaneous Localization and Mapping|
A 3-D Recognition and Positioning Algorithm Using Geometrical Matching Between Primitive Surfaces|
Efficient Multiple Model Recognition in Cluttered 3-D Scenes|
Ambler: An Autonomous Rover for Planetary Exploration|
An Integrated System for Autonomous Off-Road Navigation|
"SMARTY: Point-Based Range Processing for Autonomous Driving,|
Experimental results in using aerial ladar data for mobile robot navigation|
Toward Practical Cooperative Stereo for Robotic Colonies|
Large Data Sets and Confusing Scenes in 3-D Surface Matching and Recognition|
Outdoor Scene Analysis Using Range Data,|
Parts-Based 3D Object Classification|
Experimental Analysis of Harmonic Shape Images|
3-D Map Reconstruction from Range Data|
Experime tal compariso of techiques for localizatio a d mappi g usi g a beari gs o ly se sor|
Multi-Scale Classification of 3-D Objects|
