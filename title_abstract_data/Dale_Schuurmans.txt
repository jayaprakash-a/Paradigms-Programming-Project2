Augmenting Naive Bayes Classifiers with Statistical Language Models| Abstract We augment naive Bayes models with statistical n-gram language models to address shortcomings of the standard naive Bayes text classifier.  The result is a generalized naive Bayes
Efficient Estimation exploiting Independence Constraints| Abstract There is an obvious way to obtain an unbiased estimate of the response to a query P ( C = c j E= e ) from a sufficiently large data sample: just use the empirical frequency.  Unfortunately, this can have high variance (or even be undefined) when the conditioning event E = e is rare.  In some situations, we are able to reduce this variance by exploiting our knowledge about the underlying distribution --- in particular, by using a known set of probabilistic indepedencies amongst the variables, encoded in the structure of a Bayesian belief network.  The report investigates ways to exploit those independencies when estimating the response to a probabilistic query.  In particular, we show a general approach that produces an unbiased estimate with small variance.  Of independent interest, we also present a closed form expression for the (asymptotic) variance of a response wrt a given structure and sample. 
Sequential PAC Learning| Abstract We consider the use of "on-line" stopping rules to reduce the number of training examples needed to pac-learn.  Rather than collect a large training sample that can be proved sufficient to eliminate all bad hypotheses a priori, the idea is instead to observe training examples one-at-a-time and decide "on-line" whether to stop and return a hypothesis, or continue training.  The primary benefit of this approach is that we can detect when a hypothesizer has actually "converged," and halt training before the standard fixed-sample-size bounds.  This paper presents a series of such sequential learning procedures for: distribution-free pac-learning, "mistake-bounded to pac" conversion, and distribution-specific pac-learning, respectively.  We analyze the worst case expected training sample size of these procedures, and show that this is often smaller than existing fixed sample size bounds --- while still providing the exact same worst case pac-guarantees.  We also provide lower bounds that show these reductions can at best involve constant (and possibly log) factors.  However, empirical studies show these sequential learning procedures actually use many times fewer training examples in practice. 
Knowing What Doesn't Matter: Exploiting Omitted Superfluous Data \Lambda| Abstract Most inductive inference algorithms (i. e. , "learners") work most effectively when their training data contain completely specified labeled samples.  In many diagnostic tasks, however, the data will include the values of only some of the attributes; we model this as a blocking process that hides the values of those attributes from the learner.  While blockers that remove the values of critical attributes can handicap a learner, this paper instead focuses on blockers that remove only superfluous attribute values, i. e. , values that are not needed to classify an instance, given the values of the other unblocked attributes.  We first motivate and formalize this model of "superfluous-value blocking," and then demonstrate that these omissions can be useful, by showing that certain classes that seem hard to learn in the general PAC model --viz. , decision trees --- are trivial to learn in this setting, and can even be learned in a manner that is very robust to classification noise.  We also discuss how this model can be extended to deal with (1) theory revision (i. e. , modifying an existing decision tree); (2) "complex" attributes (which correspond to combinations of other atomic attributes); (3) blockers that occasionally include superfluous values or exclude required values; and (4) other hypothesis classes (e. g. , DNF formulae). 
Combining Statistical Language Models via the Latent Maximum Entropy Principle| Abstract.  In this
A Hierarchical EM Approach to Word Segmentation| Abstract We propose a simple two-level hierarchical probability model for unsupervised word segmentation.  By treating words as strings composed of morphemes/phonemes which are themselves composed of character/phone strings, we use EM to first identify the important morphemes/phonemes in a corpus, and then use a second level of EM to identify words given a lower level morpheme/phoneme segmentation.  To further improve performance of the basic method we employ a mutual information criterion to eliminate long word agglomerations and reduce the size of the inferred lexicon while moving EM out of poor local maxima.  Experiments on the Brown corpus show that our method accurately recovers hidden word boundaries using less training data than current MDL based approaches, even though our method is only trained on raw unsupervised data. 
Fast (Distribution Specific) Learning| Abstract pac-learning results are often criticized for demanding impractically large training samples.  The common wisdom is that these large samples follow from the worst case nature of the analysis, and therefore pac-learning, though desirable, must not be a practical goal.  We however consider an alternative view: perhaps these large sample sizes are due to the presumed learning strategies which make inefficient use of the available training data.  To demonstrate this, we consider sequential learning strategies that autonomously decide when to stop training based on observing training examples as they arrive.  We show that for distribution specific learning these algorithms require far fewer training examples (on average) than existing fixed sample size approaches, and are able to learn with certainty not just high probability.  In fact, a simple sequential strategy is optimally efficient in many cases. 
Learning Continuous Latent Variable Models with Bregman Divergences| Abstract.  We present a class of unsupervised statistical learning algorithms that are formulated in terms of minimizing Bregman divergences| a family of generalized entropy measures with convex functions.  We obtain novel training algorithms that extract hidden latent structure by minimizing a Bregman divergence on training data, subject to a set of non-linear constraints which consider hidden variables.  An alternating minimization procedure with nested iterative scaling is proposed to find feasible solutions for the resulting constrained optimization problem.  The convergence of this algorithm along with its information geometric properties are characterized. 
General Convergence Results for Linear Discriminant Updates| Abstract The problem of learning linear discriminant concepts can be solved by various mistake-driven update procedures, including the Winnow family of algorithms and the well-known Perceptron algorithm.  In this paper we define the general class of quasi-additive algorithms, which includes Perceptron and Winnow as special cases.  We give a single proof of convergence that covers much of this class, including both Perceptron and Winnow but also many novel algorithms.  Our proof introduces a generic measure of progress that seems to capture much of when and how these algorithms converge.  Using this measure, we develop a simple general technique for proving mistake bounds, which we apply to the new algorithms as well as existing algorithms.  When applied to known algorithms, our technique "automatically" produces close variants of existing proofs (and we generally obtain the known bounds, to within constants)--thus showing, in a certain sense, that these seemingly diverse results are fundamentally isomorphic. 
Regret-based Utility Elicitation in Constraint-based Decision Problems| Abstract We propose new methods of preference elicitation for constraint-based optimization problems based on the use of minimax regret.  Specifically, we assume a constraintbased optimization problem (e. g. , product configuration) in which the objective function (e. g. , consumer preferences) are unknown or imprecisely specified.  Assuming a graphical utility model, we describe several elicitation strategies that require the user to answer only binary (bound) queries on the utility model parameters.  While a theoretically motivated algorithm can provably reduce regret quickly (in terms of number of queries), we demonstrate that, in practice, heuristic strategies perform much better, and are able to find optimal (or near-optimal) configurations with far fewer queries. 
Regularized Greedy Importance Sampling| Abstract Greedy importance sampling is an unbiased estimation technique that reduces the variance of standard importance sampling by explicitly searching for modes in the estimation objective.  Previous work has demonstrated the feasibility of implementing this method and proved that the technique is unbiased in both discrete and continuous domains.  In this paper we present a reformulation of greedy importance sampling that eliminates the free parameters from the original estimator, and introduces a new regularization strategy that further reduces variance without compromising unbiasedness.  The resulting estimator is shown to be effective for difficult estimation problems arising in Markov random field inference.  In particular, improvements are achieved over standard MCMC estimators when the distribution has multiple peaked modes. 
SEMANTIC N-GRAM LANGUAGE MODELING WITH THE LATENT MAXIMUM ENTROPY PRINCIPLE| ABSTRACT In this paper, we describe a unified probabilistic framework for statistical language modeling---the latent maximum entropy principle---which can eectively incorporate various aspects of natural language, such as local word interaction, syntactic structure and semantic document information.  Unlike previous work on maximum entropy methods for language modeling, which only allow explicit features to be modeled, our framework also allows relationships over hidden features to be captured, resulting in a more expressive language model.  We describe ecient algorithms for marginalization, inference and normalization in our extended models.  We then present experimental results for our approach on the Wall Street Journal corpus. 
Constraint-Based Optimization with the Minimax Decision Criterion| Abstract In many situations, a set of hard constraints encodes the feasible configurations of some system or product over which multiple users have distinct preferences.  However, making suitable decisions requires that the preferences of a specific user for different configurations be articulated or elicited, something generally acknowledged to be onerous.  We address two problems associated with preference elicitation in this paper: computing a best feasible solution when the user's utilities are imprecisely specified; and developing useful elicitation procedures that reduce utility uncertainty, with minimal user interaction, to a point where approximately optimal decisions can be made.  Our main contributions are threefold.  First, we propose the use of minimax regret as a suitable decision criterion for decision making in the presence of such utility function uncertainty.  Second, we devise several different procedures, all relying on mixed integer linear programs, that can be used to compute minimax regret and regret-optimizing solutions effectively.  In particular, our methods exploit generalized additive structure in a user's utility function to ensure tractable computation.  Third, we propose various elicitation methods that can be used to refine utility uncertainty in such a way as to quickly (i. e. , with as few questions as possible) reduce minimax regret.  Empirical study suggests that several of these methods are quite successful in minimizing the number of user queries, while remaining computationally practical so as to admit real-time user interaction. 
The Exponentiated Subgradient Algorithm for Heuristic Boolean Programming| Abstract Boolean linear programs (BLPs) are ubiquitous in AI.  Satisfiability testing, planning with resource constraints, and winner determination in combinatorial auctions are all examples of this type of problem.  Although increasingly well-informed by work in OR, current AI research has tended to focus on specialized algorithms for each type of BLP task and has only loosely patterned new algorithms on effective methods from other tasks.  In this paper we introduce a single general-purpose local search procedure that can be simultaneously applied to the entire range of BLP problems, without modification.  Although one might suspect that a general-purpose algorithm might not perform as well as specialized algorithms, we find that this is not the case here.  Our experiments show that our generic algorithm simultaneously achieves performance comparable with the state of the art in satisfiability search and winner determination in combinatorial auctions--two very different BLP problems.  Our algorithm is simple, and combines an old idea from OR with recent ideas from AI. 
An Adaptive Regularization Criterion for Supervised Learning| Abstract We introduce a new regularization criterion that exploits unlabeled data to adaptively control hypothesis-complexity in general supervised learning tasks.  The technique is based on an abstract metric-space view of supervised learning that has been successfully applied to model selection in previous research.  The new regularization criterion we introduce involves no free parameters and yet performs well on a variety of regression and conditional density estimation tasks.  The only proviso is that sucient unlabeled training data be available.  We demonstrate the e#ectiveness of our approach on learning radial basis functions and polynomials for regression, and learning logistic regression models for conditional density estimation. 
Monte Carlo inference via greedy importance sampling| Abstract We present a new method for conducting Monte Carlo inference in graphical models which combines explicit search with generalized importance sampling.  The idea is to reduce the variance of importance sampling by searching for significant points in the target distribution.  We prove that it is possible to introduce search and still maintain unbiasedness.  We then demonstrate our procedure on a few simple inference tasks and show that it can improve the inference quality of standard MCMC methods, including Gibbs sampling, Metropolis sampling, and Hybrid Monte Carlo.  This paper extends previous work which showed how greedy importance sampling could be correctly realized in the one-dimensional case. 
Efficient exploration for optimizing immediate reward| Abstract We consider the problem of learning an effective behavior strategy from reward.  Although much studied, the issue of how to use prior knowledge to scale optimal behavior learning up to real-world problems remains an important open issue.  We investigate the inherent data-complexity of behavior-learning when the goal is simply to optimize immediate reward.  Although easier than reinforcement learning, where one must also cope with state dynamics, immediate reward learning is still a common problem and is fundamentally harder than supervised learning.  For optimizing immediate reward, prior knowledge can be expressed either as a bias on the space of possible reward models, or a bias on the space of possible controllers.  We investigate the two paradigmatic learning approaches of indirect (reward-model) learning and direct-control learning, and show that neither uniformly dominates the other in general.  Model-based learning has the advantage of generalizing reward experiences across states and actions, but direct-control learning has the advantage of focusing only on potentially optimal actions and avoiding learning irrelevant world details.  Both strategies can be strongly advantageous in different circumstances.  We introduce hybrid learning strategies that combine the benefits of both approaches, and uniformly improve their learning efficiency. 
Dynamic Web log session identification with statistical language models| Abstract We present a novel session identification method based on statistical language modeling.  Unlike standard timeout methods, which use fixed time thresholds for session identification, we use an information theoretic approach which yields more robust results for identifying session boundaries.  We evaluate our new approach by learning interesting association rules from the segmented session files.  We then compare the performance of our approach to three standard session identification methods---the standard timeout method, the reference length method and the maximal forward reference method---and find that our statistical language modeling approach generally yields superior results.  However, as with every method, the performance of our technique varies with changing parameter settings.  Therefore, we also analyze the influence of the two key factors in our language modeling based approach: the choice of smoothing technique and the language model order.  We find that all standard smoothing techniques, save one, perform well, and that performance is robust to language model order. 
Latent Maximum Entropy Approach for Semantic N-gram Language Modeling| Abstract In this paper, we describe a unified probabilistic framework for statistical language modeling|the latent maximum entropy principle|which can effectively incorporate various aspects of natural language, such as local word interaction, syntactic structure and semantic document information.  Unlike previous work on maximum entropy methods for language modeling, which only allow explicit features to be modeled, our framework also allows relationships over hidden features to be captured, resulting in a more expressive language model.  We describe ecient algorithms for marginalization, inference and normalization in our extended models.  We then present promising experimental results for our approach on the Wall Street Journal corpus. 
Learning an Optimally Accurate Representation System| Abstract.  A default theory can sanction different, mutually incompatible, answers to certain queries.  We can identify each such theory with a set of related credulous theories, each of which produces but a single response to each query, by imposing a total ordering on the defaults.  Our goal is to identify the credulous theory with optimal "expected accuracy" averaged over the natural distribution of queries in the domain.  There are two obvious complications: First, the expected accuracy of a theory depends on the query distribution, which is usually not known.  Second, the task of identifying the optimal theory, even given that distribution information, is intractable.  This paper presents a method, OptAcc, that side-steps these problems by using a set of samples to estimate the unknown distribution, and by hill-climbing to a local optimum.  In particular, given any error and confidence parameters ffl; ffi ? 0, OptAcc produces a theory whose expected accuracy is, with probability at least 1\Gamma ffi, within ffl of a local optimum. 
Self-Supervised Chinese Word Segmentation| Abstract.  We propose a new unsupervised training method for acquiring probability models that accurately segment Chinese character sequences into words.  By constructing a core lexicon to guide unsupervised word learning, self-supervised segmentation overcomes the local maxima problems that hamper standard EM training.  Our procedure uses successive EM phases to learn a good probability model over character strings, and then prunes this model with a mutual information selection criterion to obtain a more accurate word lexicon.  The segmentations produced by these models are more accurate than those produced by training with EM alone. 
Monte Carlo Matrix Inversion Policy Evaluation| Abstract In 1950, Forsythe and Leibler (1950) introduced a statistical technique for finding the inverse of a matrix by characterizing the elements of the matrix inverse as expected values of a sequence of random walks.  Barto and Duff (1994) subsequently showed relations between this technique and standard dynamic programming and temporal differencing methods.  The advantage of the Monte Carlo matrix inversion (MCMI) approach is that it scales better with respect to statespace size than alternative techniques.  In this paper, we introduce an algorithm for performing reinforcement learning policy evaluation using MCMI.  We demonstrate that MCMI possesses accuracy similar to a maximum likelihood model-based policy evaluation approach but avoids ML's slow execution time.  In fact, we show that MCMI executes at a similar runtime to temporal differencing (TD).  We then illustrate a least-squares generalization technique for scaling up MCMI to large state spaces.  We compare this leastsquares Monte Carlo matrix inversion (LSMCMI) technique to the least-squares temporal differencing (LSTD) approach introduced by Boyan (1999) demonstrating that both LS-MCMI and LSTD have similar runtime. 
Maximum Margin Bayesian Networks| Abstract We consider the problem of learning Bayesian network classifiers that maximize the margin over a set of classification variables.  We find that this problem is harder for Bayesian networks than for undirected graphical models like maximum margin Markov networks (M 3 N), since the parameters in a Bayesian network must satisfy additional normalization constraints that an undirected graphical model need not respect.  Unfortunately, these normalization constraints eliminate the convexity properties of the training problem, and significantly complicate the optimization task.  Nevertheless, we derive an effective training algorithm that solves the maximum margin training problem for a range of network topologies, and otherwise converges to a locally optimal set of parameters for arbitrary network topologies.  Experimental results show that the method can demonstrate improved generalization performance when the directed graphical structure encodes relevant knowledge.  Our intent is to pose and investigate what we believe is a natural machine learning approach, while also pointing out its difficulties. 
Direct value-approximation for factored MDPs| Abstract We present a simple approach for computing reasonable policies for factored Markov decision processes (MDPs), when the optimal value function can be approximated by a compact linear form.  Our method is based on solving a single linear program that approximates the best linear fit to the optimal value function.  By applying an ecient constraint generation procedure we obtain an iterative solution method that tackles concise linear programs.  This direct linear programming approach experimentally yields a significant reduction in computation time over approximate value- and policy-iteration methods (sometimes reducing several hours to a few seconds).  However, the quality of the solutions produced by linear programming is weaker|usually about twice the approximation error for the same approximating class.  Nevertheless, the speed advantage allows one to use larger approximation classes to achieve similar error in reasonable time. 
Boltzmann Machine Learning with the Latent Maximum Entropy Principle| Abstract We present a new statistical learning paradigm for Boltzmann machines based on a new inference principle we have proposed: the latent maximum entropy principle (LME).  LME is different both from Jaynes' maximum entropy principle and from standard maximum likelihood estimation.  We demonstrate the LME principle by deriving new algorithms for Boltzmann machine parameter estimation, and show how a robust and rapidly convergent new variant of the EM algorithm can be developed.  Our experiments show that estimation based on LME generally yields better results than maximum likelihood estimation when inferring models from small amounts of data. 
Automatic Complexity Control for System Identification| Abstract As a prerequisite for system identi#cation based on c-mean clustering (FCM), it is necessary to assign the number of underlying partitions to be used for a given data set.  However, for the FCM clustering algorithm it is not known how to assign the number of clusters optimally a priori, and the problem of selecting an appropriate number of clusters is usually treated heuristically.  In this paper we derive a theoretical criterion for assigning the appropriate number of clusters.  We use a generalization of Stein's unbiased risk estimator (SURE) to derive a generic criterion that defines the optimum number of clusters to use for a given problem.  The ecacy of this criterion is illustrated in different experiments, including a benchmark problem involving the prediction of a chaotic time series. 
Automatic basis selection techniques for RBF networks| Abstract--- This paper proposes a generic criterion that defines the optimum number of basis functions for radial basis function neural networks.  The generalization performance of an RBF network relates to its prediction capability on independent test data.  This performance gives a measure of the quality of the chosen model.  An RBF network with an overly restricted basis gives poor predictions on new data, since the model has too little flexibility (yielding high bias and low variance).  By contrast, an RBF network with too many basis functions also gives poor generalization performance since it is too flexible and fits too much of the noise on the training data (yielding low bias but high variance).  Bias and variance are complementary quantities, and it is necessary to assign the number of basis function optimally in order to achieve the best compromise between them.  In this paper we use Stein's unbiased risk estimator (SURE) to derive an analytical criterion for assigning the appropriate number of basis functions.  Two cases of known and unknown noise have been considered and the efficacy of this criterion in both situations is illustrated experimentally.  The paper also shows an empirical comparison between this method and two well known classical methods, cross validation and the Bayesian information criterion, BIC. 
Language Independent Authorship Attribution with Character Level N-Grams| Abstract We present a method for computerassisted authorship attribution based on character-level n-gram language models.  Our approach is based on simple information theoretic principles, and achieves improved performance across a variety of languages without requiring extensive pre-processing or feature selection.  To demonstrate the effectiveness and language independence of our approach, we present experimental results on Greek, English, and Chinese data.  We show that our approach achieves state of the art performance in each of these cases.  In particular, we obtain a 18% accuracy improvement over the best published results for a Greek data set, while using a far simpler technique than previous investigations. 
Data Perturbation for Escaping Local Maxima in Learning| Abstract Almost all machine learning algorithms---be they for regression, classification or density estimation---seek hypotheses that optimize a score on training data.  In most interesting cases, however, full global optimization is not feasible and local search techniques are used to discover reasonable
Applying Machine Learning to Text Segmentation for Information Retrieval| Abstract We propose a self-supervised word segmentation technique for text segmentation in Chinese information retrieval.  This method combines the advantages of traditional dictionary based, character based and mutual information based approaches, while overcoming many of their shortcomings.  Experiments on TREC data show this method is promising.  Our method is completely language independent and unsupervised, which provides a promising avenue for constructing accurate multi-lingual or cross-lingual information retrieval systems that are flexible and adaptive.  We find that although the segmentation accuracy of self-supervised segmentation is not as high as some other segmentation methods, it is enough to give comparable (in some cases even better) retrieval performance.  It is commonly believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval.  However, for Chinese, we find that the relationship between segmentation and retrieval performance is in fact nonmonotonic; that is, at around 70% word segmentation accuracy an over-segmentation phenomenon begins to occur which leads to a reduction in information retrieval performance.  We demonstrate this effect by presenting an empirical investigation of information retrieval on Chinese TREC data, using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44% to 95%, including 70% word segmentation accuracy from our self-supervised word-segmentation approach.  It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters, while they are broken up by less accurate (but reasonable) segmenters, to a surprising advantage.  This suggests that words themselves might be too broad a notion to conveniently capture the general semantic meaning of Chinese text.  Our research suggests machine learning techniques can play an important role in building adaptable information retrieval systems and different evaluation standards for word segmentation should be given to different applications. 
Characterizing Rational Versus Exponential learning Curves| Abstract.  We consider the standard problem of learning a concept from random examples.  Here a learning curve can be defined to be the expected error of a learner's hypotheses as a function of training sample size.  Haussler, Littlestone and Warmuth have shown that, in the distribution free setting, the smallest expected error a learner can achieve in the worst case over a concept class C converges rationally to zero error (i. e. , \Theta(1=t) for training sample size t).  However, recently Cohn and Tesauro have demonstrated how exponential convergence can often be observed in experimental settings (i. e. , average error decreasing as e \Theta(\Gamma t) ).  By addressing a simple non-uniformity in the original analysis, this paper shows how the dichotomy between rational and exponential worst case learning curves can be recovered in the distribution free theory.  These results support the experimental findings of Cohn and Tesauro: for finite concept classes, any consistent learner achieves exponential convergence, even in the worst case; but for continuous concept classes, no learner can exhibit sub-rational convergence for every target concept and domain distribution.  A precise boundary between rational and exponential convergence is drawn for simple concept chains.  Here we show that somewhere dense chains always force rational convergence in the worst case, but exponential convergence can always be achieved for nowhere dense chains. 
Algorithm-Directed Exploration for Model-Based Reinforcement Learning in Factored MDPs| Abstract One of the central challenges in reinforcement learning is to balance the exploration/exploitation tradeoff while scaling up to large problems.  Although model-based reinforcement learning has been less prominent than value-based methods in addressing these challenges, recent progress has generated renewed interest in pursuing modelbased approaches: Theoretical work on the exploration/exploitation tradeoff has yielded provably sound model-based algorithms such as E 3 and Rmax , while work on factored MDP representations has yielded model-based algorithms that can scale up to large problems.  Recently the benefits of both achievements have been combined in the Factored E 3 algorithm of Kearns and Koller.  In this paper, we address a significant shortcoming of Factored E 3 : namely that it requires an oracle planner that cannot be feasibly implemented.  We propose an alternative approach that uses a practical approximate planner, approximate linear programming, that maintains desirable properties.  Further, we develop an exploration strategy that is targeted toward improving the performance of the linear programming algorithm, rather than an oracle planner.  This leads to a simple exploration strategy that visits states relevant to tightening the LP solution, and achieves sample efficiency logarithmic in the size of the problem description.  Our experimental results show that the targeted approach performs better than using approximate planning for implementing either Factored E 3 or Factored Rmax . 
Text Classification in Asian Languages without Word Segmentation| Abstract We present a simple approach for Asian language text classification without word segmentation, based on statistical # -gram language modeling.  In particular, we examine Chinese and Japanese text classification.  With character # -gram models, our approach avoids word segmentation.  However, unlike traditional ad hoc # -gram models, the statistical language modeling based approach has strong information theoretic basis and avoids explicit feature selection procedure which potentially loses significantly amount of useful information.  We systematically study the key factors in language modeling and their influence on classification.  Experiments on Chinese TREC and Japanese NTCIR topic detection show that the simple approach can achieve better performance compared to traditional approaches while avoiding word segmentation, which demonstrates its superiority in Asian language text classification. 
Waterloo at NTCIR-3: Using Self-supervised Word Segmentation| Abstract In this paper, we describe the system we use in the NTCIR-3 CLIR (cross language IR) task.  We participate the SLIR (single language IR) track.  In our system, we use a self-supervised word-segmentation technique for Chinese information retrieval, which combines the advantages of traditional dictionary based approaches with character based approaches, while overcoming many of their shortcomings.  This method is completely language independent and unsupervised, which provides a promising avenue for constructing accurate multi-lingual or cross-lingual information retrieval systems that are flexible and adaptive. 
Maximum Margin Clustering| Abstract We propose a new method for clustering based on finding maximum margin hyperplanes through data.  By reformulating the problem in terms of the implied equivalence relation matrix, we can pose the problem as a convex integer program.  Although this still yields a difficult computational problem, the hard-clustering constraints can be relaxed to a soft-clustering formulation which can be feasibly solved with a semidefinite program.  Since our clustering technique only depends on the data through the kernel matrix, we can easily achieve nonlinear clusterings in the same manner as spectral clustering.  Experimental results show that our maximum margin clustering technique often obtains more accurate results than conventional clustering methods.  The real benefit of our approach, however, is that it leads naturally to a semi-supervised training method for support vector machines.  By maximizing the margin simultaneously on labeled and unlabeled training data, we achieve state of the art performance by using a single, integrated learning principle. 
Greedy Linear Value-Approximation for Factored Markov Decision Processes| Abstract Significant recent work has focused on using linear representations to approximate value functions for factored Markov decision processes (MDPs). 
Unsupervised and Semi-supervised Multi-class Support Vector Machines| Abstract We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming.  Although support vector
Learning Default Concepts| Abstract Classical concepts, based on necessary and sufficient defining conditions, cannot classify logically insufficient object descriptions.  Many reasoning systems avoid this limitation by using ``default concepts" to classify incompletely described objects.  This paper addresses the task of learning such default concepts from observational data.  We first model the underlying performance task --- classifying incomplete examples --- as a probabilistic process that passes random test examples through a "blocker" that can hide object attributes from the classifier.  We then address the task of learning accurate default concepts from random training examples.  After surveying the learning techniques that have been proposed for this task in the machine learning and knowledge representation literatures, and investigating their relative merits, we present a more data-efficient learning technique, developed from well-known statistical principles.  Finally, we extend Valiant's paclearning framework to this context and obtain a number of useful learnability results. 
Boosting in the Limit: Maximizing the Margin of Learned Ensembles| Abstract The "minimum margin" of an ensemble classifier on a given training set is, roughly speaking, the smallest vote it gives to any correct training label.  Recent work has shown that the Adaboost algorithm is particularly effective at producing ensembles with large minimum margins, and theory suggests that this may account for its success at reducing generalization error.  We note, however, that the problem of finding good margins is closely related to linear programming, and we use this connection to derive and test new "LPboosting" algorithms that achieve better minimum margins than Adaboost. 
A Simple Closed-Class/Open-Class Factorization for Improved Language Modeling| Abstract We describe a simple improvement to ngram language models where we estimate the distribution over closed-class (function) words separately from the conditional distribution of open-class words given function words.  In English, function words account for about 30% of written language, and also form a natural skeleton for most sentences.  By factoring a language model into a function word model and a conditional model over open-class words given function words, we largely avoid the problem of sparse training data in the first phase, and localize the need for sophisticated smoothing techniques primarily to the second conditional model.  We test our factored approach on the Brown and Wall Street Journal corpora and observe a 3. 5% to 25. 2% improvement in perplexity over standard methods, depending on the particular smoothing method and test set used.  Compared to other proposals for improving n-gram language models, our factorization has the advantage of inherent simplicity and eciency, and improves generalization between data sets. 
Learning Mixture Models with the Latent Maximum Entropy Principle| Abstract We present a new approach to estimating mixture models based on a new inference principle we have proposed: the latent maximum entropy principle (LME).  LME is different both from Jaynes' maximum entropy principle and from standard maximum likelihood estimation.  We demonstrate the LME principle by deriving new algorithms for mixture model estimation, and show how robust new variants of the EM algorithm can be developed.  Our experiments show that estimation based on LME generally yields better results than maximum likelihood estimation, particularly when inferring latent variable models from small amounts of data. 
A New Metric-Based Approach to Model Selection| Abstract We introduce a new approach to model selection that performs better than the standard complexitypenalization and hold-out error estimation techniques in many cases.  The basic idea is to exploit the intrinsic metric structure of a hypothesis space, as determined by the natural distribution of unlabeled training patterns, and use this metric as a reference to detect whether the empirical error estimates derived from a small (labeled) training sample can be trusted in the region around an empirically optimal hypothesis.  Using simple metric intuitions we develop new geometric strategies for detecting overfitting and performing robust yet responsive model selection in spaces of candidate functions.  These new metric-based strategies dramatically outperform previous approaches in experimental studies of classical polynomial curve fitting.  Moreover, the technique is simple, efficient, and can be applied to most function learning tasks.  The only requirement is access to an auxiliary collection of unlabeled training data. 
Language and Task Independent Text Categorization with Simple Language Models| Abstract We present a simple method for language independent and task independent text categorization learning, based on character-level n-gram language models.  Our approach uses simple information theoretic principles and achieves effective performance across a variety of languages and tasks without requiring feature selection or extensive pre-processing.  To demonstrate the language and task independence of the proposed technique, we present experimental results on several languages---Greek, English, Chinese and Japanese---in several text categorization problems---language identification, authorship attribution, text genre classification, and topic detection.  Our experimental results show that the simple approach achieves state of the art performance in each case. 
Representational Difficulties with Classifier Systems| ABSTRACT Classifier systems are currently in vogue as a way of using genetic algorithms to demonstrate machine learning.  However, there are a number of difficulties with the formalization that can influence how knowledge is represented and the rate at which the system can learn.  Some of the problems are inherent in classifier systems, and one must learn to cope with them, while others are pitfalls waiting to catch the unsuspecting implementor.  This paper identifies some of these difficulties, suggesting directions for the further evolution of classifier systems. 
Session Boundary Detection for Association Rule Learning Using n-Gram Language Models| Abstract.  We present a statistical method using n-gram language models to identify session boundaries in a large collection of Livelink log data.  The identified sessions are then used for association rule learning.  Unlike the traditional ad hoc timeout method, which uses fixed time thresholds for session identification, our method uses an information theoretic approach that provides a natural technique for performing dynamic session identification.  The effectiveness of our approach is evaluated with respect to 4 different interestingness measures.  We find that we obtain a significant improvement in each interestingness measure, ranging from a 26. 6% to 39% improvement on average over the best results obtained with standard timeout methods. 
Practical PAC Learning| Abstract We present new strategies for "probably approximately correct" (pac) learning that use fewer training examples than previous approaches.  The idea is to observe training examples one-at-a-time and decide "on-line" when to return a hypothesis, rather than collect a large fixed-size training sample.  This yields sequential learning procedures that pac-learn by observing a small random number of examples.  We provide theoretical bounds on the expected training sample size of our procedure --- but establish its efficiency primarily by a series of experiments which show sequential learning actually uses many times fewer training examples in practice.  These results demonstrate that paclearning can be far more efficiently achieved in practice than previously thought. 
Using self-supervised word segmentation in Chinese information retrieval| ABSTRACT We propose a self-supervised word-segmentation technique for Chinese information retrieval.  This method combines the advantages of traditional dictionary based approaches with character based approaches, while overcoming many of their shortcomings.  Experiments on TREC data show comparable performance to both the dictionary based and the character based approaches.  However, our method is completely language independent and unsupervised, which provides a promising avenue for constructing accurate multilingual or cross-lingual information retrieval systems that are flexible and adaptive. 
Learning Useful Horn Approximations| Abstract While the task of answering queries from an arbitrary propositional theory is intractable in general, it can typically be performed efficiently if the theory is Horn.  This suggests that it may be more efficient to answer queries using a "Horn approximation"; i. e. , a horn theory that is semantically similar to the original theory.  The utility of any such approximation depends on how often it produces answers to the queries that the system actually encounters; we therefore seek an approximation whose expected "coverage" is maximal.  Unfortunately, there are several obstacles to achieving this goal in practice: (i) The optimal approximation depends on the query distribution, which is typically not known a priori ; (ii) identifying the optimal approximation is intractable, even given the query distribution; and (iii) the optimal approximation might be too large to guarantee tractable inference.  This paper presents an approach that overcomes (or side-steps) each of these obstacles.  We define a learning process, AdComp, that uses observed queries to estimate the query distribution "online", and then uses these estimates to hill-climb, efficiently, in the space of size-bounded Horn approximations, until reaching one that is, with provably high probability, effectively at a local optimum. 
Learning Bayesian Nets that Perform Well| Abstract A Bayesian net (BN) is more than a succinct way to encode a probabilistic distribution; it also corresponds to a function used to answer queries.  A BN can therefore be evaluated by the accuracy of the answers it returns.  Many algorithms for learning BNs, however, attempt to optimize another criterion (usually likelihood, possibly augmented with a regularizing term), which is independent of the distribution of queries that are posed.  This paper takes the "performance criteria" seriously, and considers the challenge of computing the BN whose performance --- read ``accuracy over the distribution of queries" --- is optimal.  We show that many aspects of this learning task are more difficult than the corresponding subtasks in the standard model. 
Learning Coordination Classifiers| Abstract We present a new approach to ensemble classification that requires learning only a single base classifier.  The idea is to learn a classifier that simultaneously predicts pairs of test labels---as opposed to learning multiple predictors for single test labels--then coordinating the assignment of individual labels by propagating beliefs on a graph over the data.  We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data.  In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers.  Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination. 
Piecewise Linear Value Function Approximation for Factored MDPs| Abstract A number of proposals have been put forth in recent years for the solution of Markov decision processes (MDPs) whose state (and sometimes action) spaces are factored.  One recent class of methods involves linear value function approximation, where the optimal value function is assumed to be a linear combination of some set of basis functions, with the aim of finding suitable weights.  While sophisticated techniques have been developed for finding the best approximation within this constrained space, few methods have been proposed for choosing a suitable basis set, or modifying it if solution quality is found wanting.  We propose a general framework, and specific proposals, that address both of these questions.  In particular, we examine weakly coupled MDPs where a number of subtasks can be viewed independently modulo resource constraints.  We then describe methods for constructing a piecewise linear combination of the subtask value functions, using greedy decision tree techniques.  We argue that this architecture is suitable for many types of MDPs whose combinatorics are determined largely by the existence of multiple conflicting objectives. 
Combining Naive Bayes and n-Gram Language Models for Text Classification| Abstract.  We augment the naive Bayes model with an n-gram language model to address two shortcomings of naive Bayes text classifiers.  The chain augmented naive Bayes classifiers we propose have two advantages over standard naive Bayes classifiers.  First, a chain augmented naive Bayes model relaxes some of the independence assumptions of naive Bayes|allowing a local Markov chain dependence in the observed variables|while still permitting ecient inference and learning.  Second, smoothing techniques from statistical language modeling can be used to recover better estimates than the Laplace smoothing techniques usually used in naive Bayes classification.  Our experimental results on three real world data sets show that we achieve substantial improvements over standard naive Bayes classification, while also achieving state of the art performance that competes with the best known methods in these cases. 
Local Search Characteristics of Incomplete SAT Procedures| Abstract Effective local search methods for finding satisfying assignments of CNF formulae exhibit several systematic characteristics in their search.  We identify a series of measurable characteristics of local search behavior that are predictive of problem solving efficiency.  These measures are shown to be useful for diagnosing inefficiencies in given search
Automatic basis selection for RBF networks using Stein's unbiased risk estimator| Abstract--- The problem of selecting the appropriate number of basis functions is a critical issue for radial basis function neural networks.  An RBF network with an overly restricted basis gives poor predictions on new data, since the model has too little flexibility (yielding high bias and low variance).  By contrast, an RBF network with too many basis functions also gives poor generalization performance since it is too flexible and fits too much of the noise on the training data (yielding low bias but high variance).  Bias and variance are complementary quantities, and it is necessary to assign the number of basis function optimally in order to achieve the best compromise between them.  In this paper we derive a theoretical criterion for assigning the appropriate number of basis functions.  We use Stein's unbiased risk estimator (SURE) to derive a generic criterion that defines the optimum number of basis functions to use for a given problem.  The efficacy of this criterion is illustrated experimentally. 
The Latent Maximum Entropy Principle| Abstract We present an extension to Jaynes' maximum entropy principle that handles latent variables.  The principle of
Characterizing the generalization performance of model selection strategies| Abstract We investigate the structure of model selection problems via the bias/variance decomposition.  In particular, we characterize the essential aspects of a model selection task by the bias and variance profiles it generates over the sequence of hypothesis classes.  With this view, we develop a new understanding of complexity-penalization methods: First, the penalty terms can be interpreted as postulating a particular profile for the variances as a function of model complexity---if the postulated and true profiles do not match, then systematic under-fitting or over-fitting results, depending on whether the penalty terms are too large or too small.  Second, we observe that it is generally best to penalize according to the true variances of the task, and therefore no fixed penalization strategy is optimal across all problems.  We then use this characterization to introduce the notion of easy versus hard model selection problems.  Here we show that if the variance profile grows too rapidly in relation to the biases, then standard model selection techniques become prone to significant errors.  This can happen, for example, in regression problems where the independent variables are drawn from wide-tailed distributions.  To counter this, we discuss a new model selection strategy that dramatically outperforms standard complexity-penalization and hold-out methods on these hard tasks. 
On learning hierarchical classifications| Abstract Many significant real-world classification tasks involve a large number of categories which are arranged in a hierarchical
Investigating the Relationship between Word Segmentation Performance and Retrieval Performance in Chinese IR| Abstract It is commonly believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval.  In this paper we show that, for Chinese, the relationship between segmentation and retrieval performance is in fact nonmonotonic; that is, at around 70% word segmentation accuracy an over-segmentation phenomenon begins to occur which leads to a reduction in information retrieval performance.  We demonstrate this eect by presenting an empirical investigation of information retrieval on Chinese TREC data, using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44% to 95%.  It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters, while they are broken up by less accurate (but reasonable) segmenters, to a surprising advantage.  This suggests that words themselves might be too broad a notion to conveniently capture the general semantic meaning of Chinese text. 
Learning an Optimally Accurate Representational System| Abstract The multiple extension problem arises because a default theory can use different subsets of its defaults to propose different, mutually incompatible, answers to some queries.  This paper presents an algorithm that uses a set of observations to learn a credulous version of this default theory that is (essentially) "optimally accurate".  In more detail, we can associate a given default theory with a set of related credulous theories R = fR i g, where each R i uses its own total ordering of the defaults to determine which single answer to return for each query.  Our goal is to select the credulous theory that has the highest ``expected accuracy", where each R i 's expected accuracy is the probability that the answer it produces to a query will correspond correctly to the world.  Unfortunately, a theory's expected accuracy depends on the distribution of queries, which is usually not known.  Moreover, the task of identifying the optimal R opt 2 R, even given that distribution information, is intractable.  This paper presents a method, OptAcc, that sidesteps these problems by using a set of samples to estimate the unknown distribution, and by hill-climbing to a local optimum.  In particular, given any parameters ffl; ffi ? 0, OptAcc produces an R oa 2 R whose expected accuracy is, with probability at least 1 \Gamma ffi , within ffl of a local optimum. 
Learning to Classify Incomplete Examples| Abstract Most research on supervised learning assumes the attributes of training and test examples are completely specified.  Real-world data, however, is often incomplete.  This paper studies the task of learning to classify incomplete test examples, given incomplete (resp. , complete) training data.  We first show that the performance task of classifying incomplete examples requires the use of default classification functions which demonstrate nonmonotonic classification behavior.  We then extend the standard pac-learning model to allow attribute values to be hidden from the classifier, investigate the robustness of various learning strategies, and study the sample complexity of learning classes of default classification functions from examples. 
Augumenting Naive Bayes Text Classifier with Statistical Language Models|
Learning latent variable models with Bregman divergences|
Face Alignment Using Statistical Models and Wavelet Features|
Greedy Importance Sampling|
Effective Classification Learning|
Language Independent Author Attribution with N-Gram Language Models|
Applying Machine Learning for Text Segmentation in Information Retrieval|
Efficient, Accurate, and Reliable Machine Learning|
Special Issue on New methods for model selection and model combination,"|
Learning Bayesian nets that perform well|
Dynamic Web Log Session Identification with Statistical Language Model, to appear in Journal of the American Society for Information Science and Technology,|
Investigating the maximum likelihood alternative to td(#)|
Representation and Selection Techniques for Genetic Learning Systems,|
Automated authorship attribution with character level language models|
Learning using classifier systems: A survey|
Schaeffer|Schaeffler}| Representational difficulties with classifier systems. 
Learning accurate belief nets|
