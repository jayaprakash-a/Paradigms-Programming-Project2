On Exploiting Occlusions in Multiple-view Geometry| Abstract Occlusions are commonplace in man-made and natural environments; they often result in photometric features where a line terminates at an occluding boundary, resembling a "T".  We show that the 2-D motion of such Tjunctions in multiple views carries non-trivial information on the 3-D structure of the scene and its motion relative to the camera.  We show how the constraint among multiple views of T-junctions can be used to reliably detect them and differentiate them from ordinary point features.  Finally, we propose an integrated algorithm to recursively and causally estimate structure and motion in the presence of T-junctions along with other point-features. 
Euclidean Reconstruction and Reprojection up to Subgroups| Abstract The necessary and sufficient conditionsfor being able to estimate scene structure, motionand camera calibration from a sequence of images are very rarely satisfied in practice.  What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question.  For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration.  Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point.  To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction.  We also characterize vantage points that generate views that are altogether invariant to the ambiguity.  All the results are presented using simple notation that involves no tensors nor complex projective geometry, and should be accessible with basic background in linear algebra. 
Multi-view Stereo Beyond Lambert| Abstract We consider the problem of estimating the shape and radiance of an object from a calibrated set of views under the assumption that the reflectance of the object is nonLambertian.  Unlike traditional stereo, we do not solve the correspondence problem by comparing image-to-image.  Instead, we exploit a rank constraint on the radiance tensor field of the surface in space, and use it to define a discrepancy measure between each image and the underlying model.  Our approach automatically returns an estimate of the radiance of the scene, along with its shape, represented by a dense surface.  The former can be used to generate novel views that capture the non-Lambertian appearance of the scene.  Figure 1: (COLOR) Scenes with strong specularities or made of translucent materials with no distinct point features are a challenge to most stereo algorithms. 
Tales of Shape and Radiance in Multi-view Stereo| Abstract To what extent can three-dimensional shape and radiance be inferred from a collection of images? Can the two be estimated separately while retaining optimality? How should the optimality criterion be computed? When is it necessary to employ an explicit model of the reflectance properties of a scene? In this paper we introduce a separation principle for shape and radiance estimation that applies to Lambertian scenes and holds for any choice of norm.  When the scene is not Lambertian, however, shape cannot be decoupled from radiance, and therefore matching image-to-image is not possible directly.  We employ a rank constraint on the radiance tensor, which is commonly used in computer graphics, and construct a novel cost functional whose minimization leads to an estimate of both shape and radiance for non-Lambertian objects, which we validate experimentally. 
Dynamic Texture Segmentation| Abstract We address the problem of segmenting a sequence of images of natural scenes into disjoint regions that are characterized by constant spatio-temporal statistics.  We model the spatio-temporal dynamics in each region by Gauss-Markov models, and infer the model parameters as well as the boundary of the regions in a variational optimization framework.  Numerical results demonstrate that -- in contrast to purely texture-based segmentation schemes -- our method is effective in segmenting regions that differ in their dynamics even when spatial statistics are identical. 
MODELING HUMAN GAITS WITH SUBTLETIES| Abstract: We present a novel approach to modeling subtleties in human motion.  We represent the trajectories of a certain number of salient features on the human body as the output of a dynamical system driven by an unknown stochastic input.  We present several techniques for inferring model parameters and input signal distributions corresponding to different optimality criteria, and evaluate the corresponding models for accuracy and predictive power.  In particular we exploit the higher order statistical information content in motion data to arrive at input signals with independent components and show that the human motion synthesized from non-Gaussian inputs capture best the subtle complexities of the motion data. 
Dynamical Models for Human Gait Synthesis| Abstract We present a novel approach to modeling human gaits such as walking and running.  We represent the trajectories of a certain number of salient features on the human body as the output of a dynamical system that is made up of two subsystems, an autonomous subsystem and a subsystem driven by an unknown stochastic input.  We present techniques for inferring model parameters and input signal distributions from data.  In particular, we exploit the higher-order statistical information content in motion capture data to arrive at input signals with independent components.  We show that we can synthesize arbitrarily long sequences of human gaits that capture the dynamic complexities and the distinct character of the original gait sequences. 
Scene and Motion Reconstruction from Defocused and Motion-Blurred Images via Anisotropic Diffusion| Abstract.  We propose a solution to the problem of inferring the depth map, radiance and motion field of a scene from a collection of motion-blurred and defocused images.  We model motion-blurred and defocused images as the solution of an anisotropic diffusion equation, whose initial conditions depend on the radiance and whose diffusion tensor encodes the shape of the scene, the motion field and the optics parameters.  We show that this model is well-posed and propose an efficient algorithm to infer the unknowns of the model.  Inference is performed by minimizing the discrepancy between the measured defocused images and the ones synthesized via diffusion.  Since the problem is ill-posed, we also introduce additional Tikhonov regularization terms.  The resulting method is fast and robust to noise as shown by experiments with both synthetic and real data. 
Multi-view Stereo Reconstruction of Dense Shape and Complex Appearance| Abstract We address the problem of estimating the three-dimensional shape and complex appearance of a scene from a calibrated set of views under fixed illumination.  Our approach relies on an affine subspace constraint that must be satisfied when the scene exhibits "diffuse + specular" reflectance characteristics.  This constraint is used to define a cost functional for the discrepancy between the measured images and those generated by the estimate of the scene, rather than attempting to match image-to-image directly.  Minimizing such a functional yields the optimal estimate of the shape of the scene, represented by a dense surface, as well as its radiance, represented by three functions defined on such a surface.  These can be used to generate novel views that capture the non-Lambertian appearance of the scene. 
A Semi-direct Approach to Structure From Motion| Abstract Reconstructing three-dimensional structure and motion is often decomposed into two steps: point feature correspondence and three-dimensional reconstruction.  This separation often causes gross errors since correspondence relies on the brightness constancy constraint that is local in space and time.  Therefore, we advocate the necessity to integrate visual information not only in time (i. e.  across different views), but also in space, by matching regions rather than points - using explicit photometric deformation models.  We present an algorithm that integrates 2D region tracking and 3D motion estimation into a closed loop based on an explicit geometric and photometric model, while detecting and rejecting outlier regions that do not fit the model.  Our algorithm is recursive and suitable for realtime implementation.  Our experiments show that it far exceeds the accuracy and robustness of point feature-based SFM algorithms. 
Optimal Structure from Motion: Local Ambiguities and Global Estimates| Abstract We present an analysis of SFM from the point of view of noise.  This analysis results in an algorithm that is provably convergent and provably optimal with respect to a chosen norm.  In particular, we cast SFM as a nonlinear optimization problem and define a bilinear projection iteration that converges to fixed points of a certain cost-function.  We then show that such fixed points are \fundamental", i. e.  intrinsic to the problem of SFM and not an artifact introduced by our algorithm.  We classify and characterize geometrically local extrema, and we argue that they correspond to phenomena observed in visual psychophysics.  Finally, we show under what conditions it is possible - given convergencetoalocal extremum - to \jump" to the valley containing the optimum; this leads us to suggest a representation of the scene which is invariant with respect to such local extrema. 
Real-Time 3-D Motion and Structure of Point-Features: A Front-End for Vision-Based Control and Interaction| Abstract We present a system that consists of one camera connected to a Personal Computer that can (
Dynamic Textures| Abstract.  Dynamic textures are sequences of images of moving scenes that exhibit certain stationarity properties in time; these include sea-waves, smoke, foliage, whirlwind etc.  We present a characterization of dynamic textures that poses the problems of modeling, learning, recognizing and synthesizing dynamic textures on a firm analytical footing.  We borrow tools from system identification to capture the "essence" of dynamic textures; we do so by learning (i. e.  identifying) models that are optimal in the sense of maximum likelihood or minimum prediction error variance.  For the special case of second-order stationary processes, we identify the model sub-optimally in closed-form.  Once learned, a model has predictive power and can be used for extrapolating synthetic sequences to infinite length with negligible computational cost.  We present experimental evidence that, within our framework, even low-dimensional models can capture very complex visual phenomena. 
Deformotion: Deforming Motion, Shape Average and the Joint Registration and Approximation of Structures in Images| Abstract What does it mean for a deforming object to be "moving"? How can we separate the overall motion (a finite-
Recognition of Human Gaits| Abstract We pose the problem of recognizing different types of human gait in the space of dynamical systems where each gait is represented.  Established techniques are employed to track a kinematic model of a human body in motion, and the trajectories of the parameters are used to learn a representation of a dynamical system, which defines a gait.  Various types of distance between models are then computed.  These computations are non trivial due to the fact that, even for the case of linear systems, the space of canonical realizations is not linear. 
A Factorization Method for 3D Multi-body Motion Estimation and Segmentation| Abstract We study the problem of estimating the motion of independently moving objects observed by a moving perspective camera.  Given a
Shape Representation via Harmonic Embedding| Abstract We present a novel representation of shape for closed planar contours explicitly designed to possess a linear structure.  This greatly simplifies linear operations such as averaging, principal component analysis or di#erentiation in the space of shapes.  The representation relies upon embedding the contour on a subset of the space of harmonic functions of which the original contour is the zero level set. 
Gait Recognition using Dynamic Affine Invariants| Abstract We present a method for recognizing classes of human gaits from video sequences.  We propose a novel imagebased representation of human gaits.  At any instant of time a gait is represented by a vector of affine invariant moments.  These invariants are computed on the binary silhouettes corresponding to the moving body.  We represent the time trajectories of the affine invariant moment vector as the output of a linear dynamical system driven by white noise.  The problem of gait classification then boils down to formulating distances and performing recognition in the space of linear dynamical systems.  Experimental results demonstrate the discriminative power of the proposed approach. 
3-D Motion and Structure from 2-D Motion Causally Integrated over Time: Implementation| Abstract.  The causal estimation of three-dimensional motion from a sequence of two-dimensional images can be posed as a nonlinear filtering problem.  We describe the implementation of an algorithm whose uniform observability, minimal realization and stability have been proven analytically in [5].  We discuss a scheme for handling occlusions, drift in the scale factor and tuning of the filter.  We also present an extension to partially calibrated camera models and prove its observability.  We report the performance of our implementation on a few long sequences of real images.  More importantly, however, we have made our real-time implementation -- which runs on a personal computer -- available to the public for first-hand testing. 
A Lagrangian Formulation of Nonholonomic Path Following| Abstract We address the problem of following an unknown planar contour with a nonholonomic vehicle based on visual feedback. 
Variational Space-Time Motion Segmentation| Abstract We propose a variational method for segmenting image sequences into spatio-temporal domains of homogeneous motion.  To this end, we formulate the problem of motion estimation in the framework of Bayesian inference, using a prior which favors domain boundaries of minimal surface area.  We derive a cost functional which depends on a surface in space-time separating a set of motion regions, as well as a set of vectors modeling the motion in each region.  We propose a multiphase level set formulation of this functional, in which the surface and the motion regions are represented implicitly by a vector-valued level set function.  Joint minimization of the proposed functional results in an eigenvalue problem for the motion model of each region and in a gradient descent evolution for the separating interface.  Numerical results on real-world sequences demonstrate that minimization of a single cost functional generates a segmentation of space-time into multiple motion regions. 
Estimation of 3D Surface Shape and Smooth Radiance from 2D Images: A Level Set Approach| We cast the problem of shape reconstruction of a scene as the global region segmentation of a collection of calibrated images.  We assume that the scene is composed of a number of smooth surfaces and a background, both of which support smooth Lambertian radiance functions.  We formulate the problem in a variational framework, where the solution (both the shape and radiance of the scene) is a minimizer of a global cost functional which combines a geometric prior on shape, a smoothness prior on radiance and a data fitness score.  We estimate the shape and radiance via an alternating minimization: The radiance is computed as the solutions of partial differential equations defined on the surface and the background.  The shape is estimated using a gradient descent flow, which is implemented using the level set method.  Our algorithm works for scenes with smooth radiances as well as fine homogeneous textures, which are known challenges to traditional stereo algorithms based on local correspondence. 
Stereoscopic Segmentation| Abstract We cast the problem of multiframe stereo reconstruction of a smooth shape as the global region segmentation of a collection of images of the scene.  Dually, the problem of segmenting multiple calibrated images of an object becomes that of estimating the solid shape that gives rise to such images.  We assume that the radiance has smooth statistics.  This assumption covers Lambertian scenes with smooth or constant albedo as well as fine homogeneous textures, which are known challenges to stereo algorithms based on local correspondence.  We pose the segmentation problem within a variational framework, and use fast level set methods to approximate the optimal solution numerically.  Our algorithm does not work in the presence of strong textures, where traditional reconstruction algorithms do.  It enjoys significant robustness to noise under the assumptions it is designed for. 
Towards Plenoptic Dynamic Textures| Abstract--- We present a technique to infer a model of the spatio-temporal statistics of a collection of images of dynamic scenes seen from a moving camera.  We use a time-variant linear dynamical system to jointly model the statistics of the video signal and the moving vantage point.  We propose three approaches to inference, the first based on the plenoptic function, the second based on interpolating linear dynamical models, the third based on approximating the scene as piecewise planar.  For the last two approaches, we also illustrate the potential of the proposed techniques with a number of experiments.  The resulting algorithms could be useful for video editing where the motion of the vantage point can be controlled interactively, as well as to perform stabilized synthetic generation of video sequences. 
Inpainting from Multiple Views| Abstract Inpainting refers to the task of filling in missing or damaged regions of an image.  In this paper, we are interested in the inpainting problem where the missing regions are so large that local inpainting methods fail.  As an alternative to the local principle, we make use of other images with related global information to enable a reasonable inpainting.  Our method has roughly three phases: landmark matching, interpolation, and copying.  The experimental results are promising. 
UCLA-CSD-TR030014 Dynamic Texture Segmentation| Abstract We address the problem of segmenting a sequence of images of natural scenes into disjoint regions that are characterized by constant spatio-temporal signatures.  We use simple linear-Gaussian models, and infer the signatures as well as the boundary of the regions in a variational optimization framework.  Our technique is effective in segmenting regions that differ in their dynamics even when spatial statistics are identical. 
Simultaneous Localization and Mapping using Multiple View Feature Descriptors| Abstract--- We propose a vision-based SLAM algorithm incorporating feature descriptors derived from multiple views of a scene, incorporating illumination and viewpoint variations.  These descriptors are extracted from video and then applied to the challenging task of wide baseline matching across significant viewpoint changes.  The system incorporates a single camera on a mobile robot in an extended Kalman filter framework to develop a 3D map of the environment and determine egomotion.  At the same time, the feature descriptors are generated from the video sequence, which can be used to localize the robot when it returns to a mapped location.  The kidnapped robot problem is addressed by matching descriptors without any estimate of position, then determining the epipolar geometry with respect to a known position in the map. 
Seeing Beyond Occlusions (and other marvels of a finite lens aperture)| Abstract We present a novel algorithm to reconstruct the geometry and photometry of a scene with occlusions from a collection of defocused images.  The presence of a finite lens aperture allows us to recover portions of the scene that would be occluded in a pin-hole projection, thus "uncovering" the occlusion.  We estimate the shape of each object (a surface, including the occluding boundaries), and its radiance (a positive function defined on the surface, including portions that are occluded by other objects). 
Variational Space-Time Motion Segmentation| Abstract We propose a variational method for segmenting image sequences into spatio-temporal domains of homogeneous motion.  To this end, we formulate the problem of motion estimation in the framework of Bayesian inference, using a prior which favors domain boundaries of minimal surface area.  We derive a cost functional which depends on a surface in space-time separating a set of motion regions, as well as a set of vectors modeling the motion in each region.  We propose a multiphase level set formulation of this functional, in which the surface and the motion regions are represented implicitly by a vector-valued level set function.  Joint minimization of the proposed functional results in an eigenvalue problem for the motion model of each region and in a gradient descent evolution for the separating interface.  Numerical results on real-world sequences demonstrate that minimization of a single cost functional generates a segmentation of space-time into multiple motion regions. 
Three dimensional transparent structure segmentation and multiple 3D motion estimation from monocular perspective image sequences \Lambda| Abstract A three dimensional scene can be segmented using different cues, such as boundaries, texture, motion, discontinuities of the optical flow, stereo, models for structure etc.  .  We investigate segmentation based upon one of these cues, namely three dimensional motion.  If the scene contains transparent objects, the two dimensional (local) cues are inconsistent, since neighboring points with similar optical flow can correspond to different objects.  We present a method for performing three dimensional motion-based segmentation of (possibly) transparent scenes together with recursive estimation of the motion of each independent rigid object from monocular perspective images.  Our algorithm is based on a recently proposed method for rigid motion reconstruction and a validation test which allows us to initialize the scheme and detect outliers during the motion estimation procedure.  The scheme is tested on challenging real and synthetic image sequences.  Segmentation is performed for the Ullmann's experiment of two transparent cylinders rotating about the same axis in opposite directions. 
Reducing "Structure From Motion": A General Framework for Dynamic Vision Part 1: Modeling| Abstract A number of methods have been proposed in the literature for estimating scenestructure and ego-motion from a sequence of images using dynamical models.  Despite the fact that all methods may be derived from a "natural" dynamical model within a unified framework, from an engineering perspective there are a number of trade-offs that lead to different strategies depending upon the applications and the goals one is targeting.  We want to characterize and compare the properties of each model such that the engineer may choose the one best suited to the specific application.  We analyze the properties of filters derived from each dynamical model under a variety of experimental conditions, assess the accuracy of the estimates, their robustness to measurement noise, sensitivity to initial conditions and visual angle, effects of the bas-relief ambiguity and occlusions, dependence upon the number of image measurements and their sampling rate. 
Real-Time Feature Tracking and Outlier Rejection with Changes in Illumination| Abstract We develop an efficient algorithm to track point features supported by image patches undergoing affine deformations and changes in illumination.  The algorithm is based on a combined model of geometry and photometry that is used to track features as well as to detect outliers in a hypothesis testing framework.  The algorithm runs in real time on a personal computer, and is available to the public. 
Recursive 3-D Visual Motion Estimation Using Subspace Constraints| Abstract The 3-D motion of a camera within a static environment produces a sequence of time-varying images that can be used for reconstructing the relative motion between the scene and the viewer.  The problem of reconstructing rigid motion from a sequence of perspective images may be characterized as the estimation of the state of a nonlinear dynamical system, which is defined by the rigidity constraint and the perspective measurement map.  The time-derivative of the measured output of such a system, which is called the ``2-D motion field" and is approximated by the "optical flow", is bilinear in the motion parameters, and may be used to specify a subspace constraint on the direction of heading independent of rotation and depth, and a pseudo-measurement for the rotational velocity as a function of the estimated heading.  The subspace constraint may be viewed as an implicit dynamical model with parameters on a differentiable manifold, and the visual motion estimation problem may be cast in a system-theoretic framework as the the identification of such an implicit model.  We use techniques which pertain to nonlinear estimation and identification theory to recursively estimate 3-D rigid motion from a sequence of images independent of the structure of the scene.  Such independence from scene-structure allows us to deal with a variable number of visible feature-points and occlusions in a principled way.  The further decoupling of the direction of heading from the rotational velocity generates a filter with a state that belongs to a two-dimensional and highly constrained state-space.  As a result, the filter exhibits robustness properties which are highlighted in a series of experiments on real and noisy synthetic image sequences.  While the position of feature-points is not part of the state of the model, the innovation process of the filter describes how each feature is compatible with a rigid motion interpretation, which allows us to test for outliers and makes the filter robust with respect to errors in the feature tracking/optical flow, reflections, T-junctions.  Once motion has been estimated, the 3-D structure of the scene follows easily.  By releasing the constraint that the visible points lie in front of the viewer, one may explain some psychophysical effects on the nonrigid percept of rigidly moving objects. 
A Model (In)Validation Approach to Gait Recognition| Abstract This paper addresses the problem of human gait recognition by applying model (in)validation techniques.  The main idea is to associate to each class of gaits a nominal model and a class of bounded energy inputs.  In this context, the problem of recognizing a sequence can be formulated as the problem of determining whether or not it could have been generated by a given model and its associated class of inputs.  By exploiting interpolation theory results this problem can be recast into as a Linear Matrix Inequality (LMI) optimization form and efficiently solved. 
An Algebraic Geometric Approach to the Identification of a Class of Linear Hybrid Systems| Abstract We propose an algebraic geometric solution to the identification of a class of linear hybrid systems.  We show that the identification of the model parameters can be decoupled from the inference of the hybrid state and the switching mechanism generating the transitions, hence we do not constraint the switches to be separated by a minimum dwell time.  The decoupling is obtained from the so-called hybrid decoupling constraint, which establishes a connection between linear hybrid system identification, polynomial factorization and hyperplane clustering.  In essence, we represent the number of discrete states n as the degree of a homogeneous polynomial p and the model parameters as factors of p.  We then show that one can estimate n from a rank constraint on the data, the coefficients of p from a linear system, and the model parameters from the derivatives of p.  The solution is closed form if and only if n # 4.  Once the model parameters have been identified, the estimation of the hybrid state becomes a simpler problem.  Although our algorithm is designed for noiseless data, we also present simulation results with noisy data. 
Dynamic Textures|
Editable Dynamic Textures|
Variational Multiframe Stereo in the Presence of Specular Reflections|
Structure from Motion Causally Integrated Over Time|
Region-Based Segmentation on Evolving Surfaces with Application to 3D Reconstruction of Shape and Piecewise Constant Radiance|
Dynamic Rigid Motion Estimation from Weak Perspective|
Motion Estimation on the Essential Manifold|
Structure From Motion for Scenes Without Features|
Observability of Linear Hybrid Systems|
Dynamic Visual Motion Estimation from Subspace Constraints|
Recursive Estimation of Camera Motion from Uncalibrated Image Sequences|
Stereoscopic Shading: Integrating Mult1Frame Shape Cues in a Variational Framework|
Observing Shape from Defocused Images|
Motion from fixation|
Region Matching with Missing Parts|
3D Shape from Anisotropic Diffusion|
Multiple View Feature Descriptors from Image Sequences via Kernel Principal Component Analysis|
