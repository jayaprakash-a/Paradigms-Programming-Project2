Adaptation and Unsupervised Learning| Abstract Adaptation is a ubiquitous neural and psychological phenomenon, with a wealth of instantiations and implications.  Although a basic form of plasticity, it has, bar some notable exceptions, attracted computational theory of only one main variety.  In this paper, we study adaptation from the perspective of factor analysis, a paradigmatic technique of unsupervised learning.  We use factor analysis to re-interpret a standard view of adaptation, and apply our new model to some recent data on adaptation in the domain of face discrimination. 
How Linear are Auditory Cortical Responses?| Abstract By comparison to some other sensory cortices, the functional properties of cells in the primary auditory cortex are not yet well understood.  Recent attempts to obtain a generalized description of auditory cortical responses have often relied upon characterization of the spectrotemporal receptive field (STRF), which amounts to a model of the stimulusresponse function (SRF) that is linear in the spectrogram of the stimulus.  How well can such a model account for neural responses at the very first stages of auditory cortical processing? To answer this question, we develop a novel methodology for evaluating the fraction of stimulus-related response power in a population that can be captured by a given type of SRF model.  We use this technique to show that, in the thalamo-recipient layers of primary auditory cortex, STRF models account for no more than 40% of the stimulus-related power in neural responses. 
A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning| Abstract Significant plasticity in sensory cortical representations can be driven in mature animals either by behavioural tasks that pair sensory stimuli with reinforcement, or by electrophysiological experiments that pair sensory input with direct stimulation of neuromodulatory nuclei, but usually not by sensory stimuli presented alone.  Biologically motivated theories of representational learning, however, have tended to focus on unsupervised mechanisms, which may play a significant role on evolutionary or developmental timescales, but which neglect this essential role of reinforcement in adult plasticity.  By contrast, theoretical reinforcement learning has generally dealt with the acquisition of optimal policies for action in an uncertain world, rather than with the concurrent shaping of sensory representations.  This paper develops a framework for representational learning which builds on the relative success of unsupervised generativemodelling accounts of cortical encodings to incorporate the effects of reinforcement in a biologically plausible way. 
Reconstructing MEG Sources with Unknown Correlations| Abstract Existing source location and recovery algorithms used in magnetoencephalographic imaging generally assume that the source activity at different brain locations is independent or that the correlation structure is known.  However, electrophysiological recordings of local field potentials show strong correlations in aggregate activity over significant distances.  Indeed, it seems very likely that stimulus-evoked activity would follow strongly correlated time-courses in different brain areas.  Here, we present, and validate through simulations, a new approach to source reconstruction in which the correlation between sources is modelled and estimated explicitly by variational Bayesian methods, facilitating accurate recovery of source locations and the time-courses of their activation. 
The final version of this article will appear| Abstract Perceptual inference fundamentally involves uncertainty, arising from noise in sensation and the ill-posed nature of many perceptual problems.  Accurate perception requires that this uncertainty be correctly represented, manipulated, and learned about.  The choices made by subjects in various psychophysical experiments suggest that they do indeed take such uncertainty into account when making perceptual inferences, posing the question as to how uncertainty is represented in the activities of neuronal populations.  Most theoretical investigations of population coding have ignored this issue altogether; the few existing proposals that address it, do so in such a way that it is fatally con#ated with another facet of perceptual problems that also needs correct handling, namely multiplicity (that is, the simultaneous presence of multiple distinct stimuli).  We present and validate a more powerful proposal for the way that population activity may encode uncertainty, both distinctly from, and simultaneously with, multiplicity. 
Extracting Dynamical Structure Embedded in Neural Activity| Abstract Spiking activity from neurophysiological experiments often exhibits dynamics beyond that driven by external stimulation, presumably reflecting the extensive recurrence of neural circuitry.  Characterizing these dynamics may reveal important features of neural computation, particularly during internally-driven cognitive operations.  For example, the activity of premotor cortex (PMd) neurons during an instructed delay period separating movement-target specification and a movementinitiation cue is believed to be involved in motor planning.  We show that the dynamics underlying this activity can be captured by a lowdimensional non-linear dynamical systems model, with underlying recurrent structure and stochastic point-process output.  We present and validate latent variable methods that simultaneously estimate the system parameters and the trial-by-trial dynamical trajectories.  These methods are applied to characterize the dynamics in PMd data recorded from a chronically-implanted 96-electrode array while monkeys perform delayed-reach tasks. 
An Extensible Infrastructure for Fully Automated Spike Sorting during Online Experiments| AbstractWhen recording extracellular neural activity, it is often necessary to distinguish action potentials arising from distinct cells near the the electrode tip, a process commonly referred to as ^spike sorting. ~ In a number of experiments, notably those that involve direct neuroprosthetic control of an effector, this cell-by-cell classication of the incoming signal must be achieved in real time.  Several commercial offerings are available for this task, but all of these require some manual supervision per electrode, making each scheme cumbersome with large electrode counts.  We present a new infrastructure that leverages existing unsupervised algorithms to sort and subsequently implement the resulting signal classication rules for each electrode using a commercially available Cerebus Neural Signal Processor.  We demonstrate an implementation of this infrastructure to classify signals from a cortical electrode array, using a probabilistic clustering algorithm (described elsewhere).  The data were collected from a rhesus monkey performing a delayed center-out reach task.  We used both sorted and unsorted (thresholded) action potentials from an array implanted in pre-motor cortex to ^predict~ the reach target, a common decoding operation in neuroprosthetic research.  The use of sorted spikes led to an improvement in decoding accuracy of between 3. 6 and 6. 4%. 
To appear in Advances in Neural Information Processing Systems 15 Evidence Optimization Techniques for Estimating Stimulus-Response Functions| Abstract An essential step in understanding the function of sensory nervous systems is to characterize as accurately as possible the stimulus-response function (SRF) of the neurons that relay and process sensory information.  One increasingly common experimental approach is to present a rapidly varying complex stimulus to the animal while recording the responses of one or more neurons, and then to directly estimate a functional transformation of the input that accounts for the neuronal firing.  The estimation techniques usually employed, such as Wiener filtering or other correlation-based estimation of the Wiener or Volterra kernels, are equivalent to maximum likelihood estimation in a Gaussian-output-noise regression model.  We explore the use of Bayesian evidence-optimization techniques to condition these estimates.  We show that by learning hyperparameters that control the smoothness and sparsity of the transfer function it is possible to improve dramatically the quality of SRF estimates, as measured by their success in predicting responses to novel input. 
Section: Neuroscience Preference: Oral Adaptation and Unsupervised Learning| Abstract Adaptation is a ubiquitous neural and psychological phenomenon, with a wealth of instantiations and implications.  Although a basic form of plasticity, it has, bar some notable exceptions, attracted computational theory of only one main variety.  In this paper, we study adaptation from the perspective of factor analysis, a paradigmatic technique of unsupervised learning.  We use factor analysis to re-interpret a standard view of adaptation, and apply our new model to some recent data on adaptation in the domain of face discrimination. 
Mixture of Trajectory Models for Neural Decoding of Goal-Directed Movements| Abstract Probabilistic techniques have been fruitfully applied to decoding physical parameters, such as arm trajectories or the position of a freely-foraging rat, from neural data.  Current trajectory models assume little or no knowledge about the direction or form of movement, but rather provide a basic smoothness constraint on the decoded trajectory.  When trajectories are goal-directed however, stronger models can be defined that reflect the typical kinematics of movement, as well as the discrete set of goal locations.  We present a mixture of trajectory models (MTM) framework that can be used with many current probabilistic decoding techniques, including the Bayes' Filter, particle filters, and Kalman filter variants.  This framework is applied to decoding arm trajectories in a center-out delayed reach task.  Neural activity was recorded using a 96-electrode array in premotor cortex of a rhesus macaque.  We found that a MTM gives 40% lower root-mean-square position error than a single trajectory model that knows little about the direction or form of the actual movements.  Using delay period neural activity to define a prior over the goal locations further improves decode performance. 
Robust Neural Decoding of Reaching Movements for Prosthetic Systems| Abstract--- A new neural prosthetic decoder architecture is presented which uses a hidden Markov model of typical arm movements to assist the reconstruction of intended trajectories from an ensemble of neural signals.  The use of such a model results in a decoder which is robust to fewer or smaller neural signals.  With limited information, the average error of the reconstructed trajectories produced by the robust decoder is half of that produced by the standard linear filter approach. 
Evidence Optimization Techniques for Estimating Stimulus-Response Functions| Abstract An essential step in understanding the function of sensory nervous systems is to characterize as accurately as possible the stimulus-response function (SRF) of the neurons that relay and process sensory information.  One increasingly common experimental approach is to present a rapidly varying complex stimulus to the animal while recording the responses of one or more neurons, and then to directly estimate a functional transformation of the input that accounts for the neuronal firing.  The estimation techniques usually employed, such as Wiener filtering or other correlation-based estimation of the Wiener or Volterra kernels, are equivalent to maximum likelihood estimation in a Gaussian-output-noise regression model.  We explore the use of Bayesian evidence-optimization techniques to condition these estimates.  We show that by learning hyperparameters that control the smoothness and sparsity of the transfer function it is possible to improve dramatically the quality of SRF estimates, as measured by their success in predicting responses to novel input. 
Doubly Distributional Population Codes: Simultaneous Representation of Uncertainty and Multiplicity|
On the Separation of Signals from Neighboring Cells in Tetrode Recordings|
