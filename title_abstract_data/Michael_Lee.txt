Combining Dimensions and Features in Similarity-Based Representations| Abstract This paper develops a new representational model of similarity data that combines continuous dimensions with discrete features.  An algorithm capable of learning these representations is described, and a Bayesian model selection approach for choosing the appropriate number of dimensions and features is developed.  The approach is demonstrated on a classic data set that considers the similarities between the numbers 0 through 9. 
Just-in-Time Requirements Analysis -- The Engine that Drives the Planning Game| Abstract Just-in-Time Requirements Analysis is an alternative approach to analysis that perfectly compliments XP development and planning.  Rather than analyzing and defining requirements up front, Just-in-Time Requirements Analysis defines requirements only when they are needed -- and only at the detailed required.  It is an iterative process that expects and embraces change and makes it easy for requirements to evolve over time.  This paper details the concepts behind Just-in-Time Requirements Analysis (JITRA) and identifies the benefits of using JITRA on XP Projects.  It outlines how JITRA is implemented in XP development and shows how JITRA fits into XP planning. 
Fast Text Classification Using Sequential Sampling Processes| Abstract.  A central problem in information retrieval is the automated classification of text documents.  While many existing methods achieve good levels of performance, they generally require levels of computation that prevent them from making su ciently fast decisions in some applied setting.  Using insights gained from examining the way humans make fast decisions when classifying text documents, two new text classification algorithms are developed based on sequential sampling processes.  These algorithms make extremely fast decisions, because they need to examine only a small number of words in each text document.  Evaluation against the Reuters-21578 collection shows both techniques have levels of performance that approach benchmark methods, and the ability of one of the classifiers to produce realistic measures of confidence in its decisions is shown to be useful for prioritizing relevant documents. 
Multiresolution Tetrahedral Meshes: An Analysis and a Comparison| Abstract The paper deals with the problem of analyzing and visualizing large-size volume data sets.  To this aim, we consider
Clustering Using the Contrast Model| Abstract An algorithm is developed for generating featural representations from similarity data using Tversky's (1977) Contrast Model. 
Navigating through triangle meshes implemented as linear quadtrees| Abstract Techniques are presented for navigating between adjacent triangles of greater or equal size in a hierarchical triangle mesh where the triangles are obtained by a recursive quadtree-like subdivision of the underlying space into four equilateral triangles.  These techniques are useful in a number of applications including finite element analysis, ray tracing, and the modeling of spherical data.  The operations are implemented in a manner analogous to that used in a quadtree representation of data on the two-dimensional plane where the underlying space is tessellated into a square mesh.  A new technique is described for labeling the triangles which is useful in implementing the quadtree triangle mesh as a linear quadtree (i. e. , a pointer-less quadtree); the navigation can then take place in this linear quadtree.  When the neighbors are of equal size, the algorithms take constant time.  The algorithms are very efficient, as they make use of just a few bit manipulation operations and can be implemented in hardware using just a few machine language instructions.  The use of these techniques when modeling spherical data by projecting in onto the faces of a regular solid whose faces are equilateral triangles which are represented as quadtree triangular meshes is discussed in detail.  The methods are applicable to the icosahedron, octahedron, and tetrahedron.  The difference lies in the way transitions are made between the faces of the polyhedron.  However, regardless of the type of polyhedron, the computational complexity of the methods is the same. 
Cryptanalysis of the SIGABA A Thesis submitted in partial satisfaction of the requirements for the degree Master of Science in Computer Science| The SIGABA is a rotor-based cryptosystem developed by the United States for use during World War II.  Its history has been shrouded in secrecy, with the result that few people know of its significance in securing American communications during and after World War II.  SIGABA's operational details were finally declassified in 1996, and the patent for its design was granted in 2001, more than 50 years after it was filed.  In this thesis I present a generic model of rotor-based cryptosystems that represents a machine at least as difficult to break as the SIGABA.  I present techniques that can be used for full plaintext recovery on a cryptosystem using one to three rotors, and I show how these techniques can be extended to systems using more rotors.  These attacks compromise not only the generic model, but also the SIGABA and related cryptosystems. 
Constant-Time Neighbor Finding in Hierarchical Tetrahedral Meshes|
in press| A simple method for generating additive clustering models with limited complexity. 
"An Applet-Based Approach to Large-Scale Distributed Computing", to appear|
Neural Feature Abstraction from Judgements of Similarity|
A Simple Method for Generating Additive Clustering Models with Limited Complexity|
Low Voltage High-Current Electronic Load|
Ethylene and ethane production in an estuarine river: formation from the decomposition of polyunsaturated fatty acids,|
Underwater Vehicle Control from a Virtual Environment Interface|
Internet Shopping, Consumer Search and Product Branding|
The Connectionist Construction of Psychological Spaces|
MCSD: Visual Basic 6 Distributed Applications Study Guide|
Building a XML-Based Unified User Interface System under J2EE Architecture|
