A 19|2GOPS, 20mW Adaptive FIR Filter.  Abstract We implemented a 48-tap, mixed-signal adaptive FIR filter with 8-bit input and 10-bit output resolution.  The filter stores its tap weights in nonvolatile analog memory cells and adapts using the Least-Mean-Square (LMS) algorithm.  We run the input through a digital tapped delay line, multiply the digital words with the analog tap weights using mixed-signal multipliers, and adapt the tap coefficients using pulse-based feedback.  The accuracy of the weight updates exceeds 13 bits.  The total die area is 2. 6mm 2 in a 0. 35m CMOS process.  The filter delivers a performance of 19. 2GOPS at 200MHz, and consumes 20mW providing a 6mA differential output current. 
A Floating-Gate Trimmable High-Resolution DAC in Standard 0|25.  Abstract We have built a 14-bit digital-to-analog converter (DAC) in a standard 0. 25m digital CMOS process.  We use analog values stored on floating-gate p-channel MOSFETs to trim the DAC linearity.  Because the storage is nonvolatile, we eliminate the need for continuous trimming.  Our design has 6 untrimmable LSBs and 8 trimmable MSBs.  The pre-trim differential nonlinearity (DNL) exceeded 130 LSBs; the post-trim DNL is less than 1. 8 LSBs.  We were able to trim the 8 MSBs to 0. 5 LSB DNL; the 1. 8 LSB error is due to an untrimmable bit.  Because our DAC does not require continuous trimming, nor laser-trimmable resistors, it occupies only 0. 17 mm 2 of die area and dissipates 11 mW at 100 MHz with a --10 dBm differential output. 
Title: Architecture Design of Reconfigurable Pipelined Datapaths Contact Author:| Abstract This paper examines reconfigurable pipelined datapaths (RaPiDs), a new architecture style for computationintensive applications that bridges the cost/performance gap between general purpose and application specific architectures.  RaPiDs can provide significantly higher performance than general purpose processors on a wide range of applications from the areas of video and signal processing, scientific computing, and communications.  Moreover, RaPiDs provide the flexibility that doesn't come with application-specific architectures.  A RaPiD architecture is optimized for highly repetitive, computationally-intensive tasks.  Very deep application-specific computation pipelines can be configured in RaPiDs that deliver very high performance for a wide range of applications.  RaPiDs achieve this using a coarse-grained reconfigurable architecture that mixes the appropriate amount of static configuration with dynamic control.  We describe the fundamental features of a RaPiD architecture, including the linear array of functional units, a programmable segmented bus structure, and a programmable control architecture.  In addition, we outline the floorplan of the architecture and provide timing data for the most critical paths.  We conclude with performance numbers for several applications on an instance of a RaPiD architecture. 
Architecture Design of Reconfigurable Pipelined Datapaths| Abstract This paper examines reconfigurable pipelined datapaths (RaPiDs), a new architecture style for computation-intensive applications that bridges the cost/performance gap between general purpose and application specific architectures.  RaPiDs can provide significantly higher performance than general purpose processors on a wide range of applications from the areas of video and signal processing, scientific computing, and communications.  Moreover, RaPiDs provide the flexibility that doesn't come with application-specific architectures.  ARaPiD architecture is optimized for highly repetitive, computationally-intensive tasks.  Very deep application-specific computation pipelines can beconfigured that deliver very high performance for a wide range of applications.  RaPiDs achieve this using a coarse-grained reconfigurable architecture that mixes the appropriate amount of static configuration with dynamic control.  We describe the fundamental features of a RaPiD architecture, including the linear array of functional units, a programmable segmented bus structure, and a programmable control architecture.  In addition, we outline the floorplan of the architecture and provide timing data for the most critical paths.  We conclude with performancenumbers for several applications on an instanceofaRaPiD architecture. 
Competitive Learning With Floating-Gate Circuits| Abstract---Competitive learning is a general technique for training clustering and classification networks.  We have developed an 11-transistor silicon circuit, that we term an automaximizing bump circuit, that uses silicon physics to naturally implement a similarity computation, local adaptation, simultaneous adaptation and computation and nonvolatile storage.  This circuit is an ideal building block for constructing competitive-learning networks.  We illustrate the adaptive nature of the automaximizing bump in two ways.  First, we demonstrate a silicon competitive-learning circuit that clusters one-dimensional (1-D) data.  We then illustrate a general architecture based on the automaximizing bump circuit; we show the effectiveness of this architecture, via software simulation, on a general clustering task.  We corroborate our analysis with experimental data from circuits fabricated in a 0. 35- m CMOS process. 
A 200MHz, 3mW, 16-Tap Mixed-Signal FIR Filter| Abstract We have built a 16-tap, 7-bit, 200MHz, mixed-signal FIR filter that consumes 3mW at 3. 3V.  The filter uses p-channel synapse transistors to store the tap coefficients; electron tunneling and hot-electron injection to modify the tap weights; digital registers for the delay line; and multiplying digital-toanalog converters to multiply the digital delay-line values with the analog tap weights.  The measured bandwidth is 225MHz; the measured tap multiplier resolution is 7 bits at 200MHz.  The total die area is 0. 13mm 2 ; we can readily scale the design to higher bit resolutions and longer delay-lines. 
An FPGA-Based Array Processor for an Ionospheric-Imaging Radar| Atmospheric scientists need to observe fluctuations in the ionosphere, both to probe the underlying atmospheric physics, and to remove the effects of these fluctuations from other measurements.  We have built an FPGA-based, pipelined array processor that allows us to make these observations, in real-time, using passive radar techniques.  Our array processor time-multiplexes 16 multiplyaccumulators across 1536 radar ranges, performing a pipelined correlation and integration of the radar signal for each range.  A DSP-based postprocessor generates realtime range-Doppler profiles of the ionospheric targets. 
Field-Programmable Learning Arrays| Abstract This paper introduces the Field-Programmable Learning Array, a new paradigm for rapid prototyping of learning primitives and machinelearning algorithms in silicon.  The FPLA is a mixed-signal counterpart to the all-digital Field-Programmable Gate Array in that it enables rapid prototyping of algorithms in hardware.  Unlike the FPGA, the FPLA is targeted directly for machine learning by providing local, parallel, online analog learning using floating-gate MOS synapse transistors.  We present a prototype FPLA chip comprising an array of reconfigurable computational blocks and local interconnect.  We demonstrate the viability of this architecture by mapping several learning circuits onto the prototype chip. 
On-Chip Compensation of Device-Mismatch Effects in Analog VLSI Neural Networks| Abstract Device mismatch in VLSI degrades the accuracy of analog arithmetic circuits and lowers the learning performance of large-scale neural networks implemented in this technology.  We show compact, low-power on-chip calibration techniques that compensate for device mismatch.  Our techniques enable large-scale analog VLSI neural networks with learning performance on the order of 10 bits.  We demonstrate our techniques on a 64-synapse linear perceptron learning with the Least-Mean-Squares (LMS) algorithm, and fabricated in a 0. 35m CMOS process. 
A Mixed-Signal Approach to High-Performance, Low-Power Linear Filters| ABSTRACT We present a new approach to the design of high-performance, low-power linear filters.  We use p-channel synapse transistors as analog memory cells, and mixed-signal circuits for fast, lowpower arithmetic.  To demonstrate the effectiveness of our approach, we have built a 16-tap, 7-bit, 200MHz, mixed-signal FIR filter that consumes 3mW at 3. 3V.  The filter uses synapse pFETs to store the analog tap-coefficients, electron tunneling and hot-electron injection to modify the coefficient values, digital registers for the delay line, and multiplying digital-to-analog converters to multiply the digital delay-line values with the analog tap-coefficients.  The measured maximum clock speed is 225MHz; the measured tap-multiplier resolution is 7 bits at 200MHz.  The total die area is 0. 13mm 2 .  We can readily scale our design to longer delay lines. 
ODESeW: automatic generation of knowledge portals for intranets and extranets|
Adaptive CMOS: From biological inspiration to systemson-a-chip,|
A Floating-Gate Trimmed, 14-bit, 250 MS/s Digital-to-Analog Converter in Standard 0|25m CMOS,". 
Communication for Social Change: An Integrated Model for Measuring the Process and Its Outcomes|
Gas exchange and chlorophyll fluorescence of C3 and C4 saltmarsh species|
A decoupled access/execute processor for matrix algorithms: architecture and programming,|
Clasificacion de Deudores y su Previsionamiento|
Support system development for forest ecosystem management|
The Triple Point of Rubidium: A Temperature Fixed Point for Biomedical Applications,|
A Silicon Primitive for Competitive Learning|
"A mixed-signal adaptive correlator for low-power signal processing,"|
Adaptive Quantization and Density Estimation in Silicon|
