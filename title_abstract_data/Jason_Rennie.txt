On L2-norm Regularization and the Gaussian Prior| Abstract We show how the regularization used for classification can be seen from the MDL viewpoint as a Gaussian prior on weights.  We consider the problem of transmitting classification labels; we select as our model class logistic regression with perfect precision where we specify a weight for each feature.  This is unrealistic since the encoding length of any such model is infinite, but if we use a Gaussian prior on weights and ignore constant factors, we find that the encoding length objective exactly matches that of logistic regression with an L2-norm regularization penalty.  Through this understanding, we see that the tradeoff parameter is the variance of the Gaussian prior.  It also delineates steps for improved regularization|both decreased resolution and feature selection could be used to decrease the encoding length.  1 The Problem Let (x 1 ; : : : ; x n ) be a set of examples.  Let (y 1 ; : : : ; y n ), y i 2 f+1; 1g, be a set of binary lables for the examples.  The problem we address is that of encoding the labels as eciently as possible.  The labels have little internal structure of their own; we use the information in the examples to help predict the labels.  Compression is a natural way to judge the degree to which a system has learned.  In this case, compression judges the effectiveness of using the examples to predict the labels.  Note that to make use of the examples, we must encode the mechanism for extracting information, so the framework imposes a sort of natural regularization.  2 Encoding To encode the labels, we estimate a conditional distribution using a linear classifier.  In one part, we encode the weights for the linear classifier and in the second part, we encode the labels, to the extent that they have not been specified by the classifier.  Define p(y i = +1jx i ; ~ w) = g l X k=0 x ik w k ! (1) to be the conditional probability of label y i being positive given example x i .  g(z) = 1 1+e z is the logistic function.  x ik is the value of the k th feature of example i.  w k is the weight for feature k.  k = 0 is the special \bias" feature; x i0 = 1 for all i.  l is the number of non-bias features.  Let z i = P k x ik w k .  Then, if we ignore the discrete practicality of coding, the encoding length for label y i is L(y i jx i ; ~ w) = log g(y i z i ): (2) All that remains to be encoded is the weights.  To encode the weights, we assume a Gaussian prior with mean zero and variance # 2 , p(w k ) = 1 p 2## 2 exp # w 2 k 2# 2 # : (3) But this is a density, not a probability mass function as we require.  However, we are not concerned with absolute encoding lengths|relative encoding lengths are sucient since we are comparing between models in a restricted class.  Using this prior and treating it as a probability mass function, we get a (reltaive) encoding length of L(w k ) = log p(w k ): (4) Now, we can write down the total encoding length.  The total encoding length sums the encoding length for all labels and all weights.  We do not encode the \bias" weight.  The total encoding length is L tot = X i log g(y i z i ) + l X k=1 # 1 2 log 2## 2 + w 2 k 2# 2 # : (5) 3 Regularized Logistic Regression Logistic regression maximizes the (log-)likelihood of the labels, where the likelihood of a label is as defined in equation 1.  For more information on
Stochastic Encoding and the "Bits-Back" Argument| Abstract The Minimum Description Length framework is powerful but is often overlooked.  I believe that one reason for this is that methods for attaining efficient encodings are subtle.  In this paper, I discuss one of those techniques, stochastic encoding.  When there are multiple nearly equally valuable choices of a parameter, it is more valuable to choose stochastically---according to a probability distribution--- rather than selecting the single best choice.  Why? Because information can be transmitted in which parameter is chosen.  This is exactly the "bitsback" argument given by Hinton and Zemel in [1].  In the Minimum Description Length (MDL) framework, the objective is to encode the data plus the model with the fewest number of bits possible.  An important advantage to this framework is that the regularizer is simple and innate.  Any complexity of the model must be encoded alongside the data.  Hence, it is of the utmost importance that the model be encoded efficiently.  In particular, the model must be encoded at the proper level of precision.  Some parameters of the model may be encoded with a low degree of precision to achieve the desired benefit, while other parameters will need a high degree of precision.  Designing a code to handle this in a dynamic fashion is not easy.  So, we do something similar to what we do with encoding data.  When encoding data, we don't try to construct a code that actually encodes the data.  That would force us to deal with the discreteness of real codes and the need to adapt the code to different distributions.  Instead, we simply encode based on the uncertainty.  If our model says that a label is highly likely, it takes us little encoding; if our model goofs and declares a label unlikely, we pay by using many bits to encode that label.  We use the encoded model to determine a conditional probability for each label given its example, p(y|x).  Assuming the label is encoded efficiently according to that probability, we use a code length of- log p(y|x) (1) bits.  Thus, we can encode the data (the labels) efficiently without having to worry about constructing a code.  We apply the same reasoning to the encoding of model parameters.  Consider transmitting model parameters using as few bits as possible.  We cannot transmit with infinite precision since doing so would require infinite bandwidth.  One option is to limit our choices to a discrete set.  However, this poses difficulties since we must establish at what level of precision we wish to transmit each parameter.  Another option is to transmit a random parameter chosen according to a distribution.  The entropy of the distribution determines the effective precision of our encoding.  It may seem that this requires as much bandwidth as transmitting parameters with infinite precision.  But, we don't choose a single value to transmit; we are satisfied with randomly selecting from a distribution.  Assume that we have established an encoding for w which is optimal according to p(w).  Let q(w) be the distribution from which we choose a parameter to send.  Then, the expected length of transmitting w is l(q) = Ew#q [- log p(w)] = - Z q(w) log p(w)dw.  (2) But, we are not done.  Since we do not send a single value but rather according to a distribution q, we could encode information in the values that we select.  The average amount information we transmit is the entropy of q.  So, the net (average) encoding length we need is l(q) = Ew#q [- log p(w)]- H(q).  (3) Or, in a more recognizable form, this is the KL-divergence, l(q) = Z # q(w) log q(w) p(w) dw.  (4) That is, the average net bits we consume is the difference between the number of bits needed to send q via its optimal encoding and the number of bits needed to send q via p's optimal encoding.  We get H(q) "bits back" since we could utilize those bits for transmitting other information.  This is the argument found in [1].  The clear benefit here is that we no longer need to
Not Too Hot, Not Too Cold: The Bundled-SVM is Just Right!| Abstract The Support Vector Machine (SVM) typically outperforms other algorithms on text classification problems, but requires training time roughly quadratic in the number of training documents.  In contrast, linear time algorithms like Naive Bayes have lower performance, but can easily handle huge training sets.  In this paper, we describe a technique that creates a continuum of classifiers between the SVM and a Naive Bayes like algorithm.  Included in that continuum is a classifier that approximates SVM performance with linear training time.  Another classifier on this continuum can outperform the SVM, yielding a breakeven point that beats other published results on Reuters-21578.  We give empirical and theoretical evidence that our hybrid approach successfully navigates the tradeoffs between speed and performance. 
6|836 Final Project: Evolving XBattle Players.  Abstract Much of the success of Genetic Algorithms (GA) come in domains where the problem or solutions to the problem can be easily represented as a genome---a string of 1s and 0s or an array of parameter values.  Less success is reported in domains where solutions are not so easily representable.  Game playing, such as chess or go, is one such domain where it is difficult to represent the strategy for a player.  Here, we take upon ourselves that challenge and show that it is possible to evolve good game players in a domain where representation is a serious challenge.  XBattle is a real-time war strategy game where agile mouse control and quick wits are essential for any good player.  In this paper, we show the process needed for genetically evolving players for this game.  We describe the tradeoffs in representation design and evolve a number of different XBattle players, each with its unique and intersting characteristics.  Through this evolutionary process emerges some of the fundamentally important strategies necessary for being a successful XBattle player. 
Learning More with Less| Abstract We investigate the problem of classification using a small number of training examples.  We assume that we have access to a "reference" classification task (and corresponding training examples) that are similar, but not identical, to the main task.  In this paper, we consider the case that the classification problem is similar enough that it is useful to directly incorporate examples from the reference task.  We find that by weighting the reference examples appropriately, they provide regularization for the main task and drastically lower classification error.  On a newsgroup classification task, using training examples from both the main and reference tasks gives error one-fourth that of using either set of examples individually. 
Large-Margin Matrix Factorization| Abstract We present a novel approach to collaborative prediction, using low-norm instead of low-rank factorizations.  The approach is inspired by, and has strong connections to, large-margin linear discrimination.  We show how to learn low-norm factorizations by solving a semi-definite program, and present generalization error bounds based on analyzing the Rademacher complexity of low-norm factorizations. 
Using Reinforcement Learning to Spider the Web Efficiently| Abstract Consider the task of exploring the Web in order to find pages of a particular kind or on a particular topic.  This task arises in the construction of search engines and Web knowledge bases.  This paper argues that the creation of ecient web spiders is best framed and solved by reinforcement learning, a branch of machine learning that concerns itself with optimal sequential decision making.  One strength of reinforcement learning is that it provides a formalism for measuring the utility of actions that give benefit only in the future.  We present an algorithm for learning a value function that maps hyperlinks to future discounted reward using a naive Bayes text classifier.  Experiments on two real-world spidering tasks show a threefold improvement in spidering eciency over traditional breadth-first search, and up to a two-fold improvement over reinforcement learning with immediate reward only. 
The Use of Transfer in Natural Language Processing| Abstract Many NLP researchers have noted that a parser trained on one domain (e. g.  WSJ articles) may not perform as well on another domain (e. g.  New Yorker articles).  Experiments have shown that replacing in-domain (target) training data with out-of-domain (reference) training data degrades parsing accuracy [Rat99].  Also, adding reference data to a set of target training data improves performance minimally [Gil01].  But, these results do not eliminate the possiblity of gaining useful information from reference data.  [Hwa99] shows that a main contribution of target data is high-level phrase structure information.  Low-level sentence structure can be learned from reference data.  [RB03] shows that reference data is more useful when (1) there is less target data, and (2) when each reference example is given 1/5 th the weight of target example.  While a parser trained on one domain is unlikely to perform well on a different domain, the reference data contains much useful information.  The challenge is finding the right way to synthesize reference and target training data.  The work we discuss shows initial progress, and also shows that there is much left to be done. 
Ecient Web Spidering with Reinforcement Learning| Abstract Consider the task of exploring the Web in order to
Building Domain-Specific Search Engines with Machine Learning Techniques| Abstract Domain-specific search engines are growing in popularity because they offer increased accuracy and extra functionality not possible with the general, Web-wide search engines.  For example, www. campsearch. com allows complex queries by age-group, size, location and cost over summer camps.  Unfortunately these domain-specific search engines are difficult and timeconsuming to maintain.  This paper proposes the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific search engines.  We describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, identifying informative text segments, and populating topic hierarchies.  Using these techniques, we have built a demonstration system: a search engine for computer science research papers.  It already contains over 50,000 papers and is publicly available at www. cora. justresearch. com. 
Automating the Construction of Internet Portals with Machine Learning|
Ifile spam classifier,|
Room temperature pulsed operation of nitride based multi-quantum-well laser diodes with cleaved facets on conventional C-face sapphire substrates|
Another system called qanda|
Another sys called quanda|
Cora Research Paper Search|
Matlab code for regularized least-squares classification,"|
Using machine learning techniques to build domain-specific search engines|
Cancer catcher: Neural net catches errors that slip through pap tests|
Automating the construction of Internet portals with machine learning, See|
Isle of Wight disease in hive bees|
DNA's New Twists|
Naive Bayes algorithm for learning to classify text"|
Wordnet::QueryData Perl module|
Logistic regression|
Not too hot, not too cold: The bundledsvm is just right!|
Editor in Chief of Scientific American Replies",|
