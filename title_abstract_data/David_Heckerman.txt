Decision-Theoretic Foundations for Causal Reasoning| Abstract We present a definition of cause and effect in terms of decision-theoretic primitives and thereby provide a principled foundation for causal reasoning.  Our definition departs from the traditional view of causation in that causal assertions may vary with the set of decisions available.  We argue that this approach provides added clarity to the notion of cause.  Also in this paper, we examine the encoding of causal relationships in directed acyclic graphs.  We describe a special class of influence diagrams, those in canonical form, and show its relationship to Pearl's representation of cause and effect.  Finally, we show how canonical form facilitates counterfactual reasoning. 
Workshop on Statistical Relational Learning and its Connections to Other Fields Workshop Co-chairs| Preface This workshop is the third in a series of workshops held in conjunction with AAAI and IJCAI.  The first workshop was held in July, 2000 at AAAI.  Notes from that workshop are available at http://robotics. stanford. edu/srl/.  The second workshop was held in July, 2003 at IJCAI.  Notes from that workshop are available at http://kdl. cs. umass. edu/srl2003/ There has been a surge of interest in this area.  The efforts have been diffused across a wide collection of sub-areas in computer science including machine learning, database management, and theoretical computer science.  The goal of this year's workshop is to reach out to related fields that have not participated in previous workshops.  Specifically, we seek to invite researchers in computer vision, spatial statistics, social network analysis, language modeling, and probabilistic inference to attend the workshop and give tutorials on the relational learning problems and techniques developed in their fields.  These fields have many years of experience in particular kinds of relational learning, and we hope that bringing these diverse communities together, we can all achieve a better understanding of the range of problems and methods that can be brought to bear on relational learning problems.  We'd like to give a big THANK YOU to the program committee.  Looking forward to a lively and productive workshop in Banff. 
Goal-Oriented Clustering| Abstract We introduce goal-oriented clustering, a process that clusters items with the explicit knowledge that the ultimate use of the clusters is prediction.  In this approach, we use data on a set of target variables (those we want to predict) and a set of input variables (those wedonotwant to predict) to learn a graphical (generative) model with a single hidden layer of discrete variables H.  The states of H correspond to clusters.  We describe a generalized EM algorithm for learning the parameters of this class of models and provide a convergence guarantee.  We compare our goal-oriented approach to a standard clustering approach on the task of targeted advertising on a web site. 
Recommendation as a Stochastic Sequential Decision Problem| Abstract Recommender systems | systems that suggest to users in e-commerce sites items that might interest them | adopt a static view of the recommendation process and treat it as a prediction problem.  In an earlier paper, we argued that it is more appropriate to view the problem of generating recommendations as a sequential decision problem and, consequently, that Markov decision processes (MDPs) provide a more appropriate model for recommender systems.  MDPs introduce two bene#ts: they take into account the long-term effects of each recommendation, and they take into account the expected value of each recommendation.  The use of MDPs in a commercial site raises three fundamental problems: providing an adequate initial model, updating this model online as new items (e. g. , books) arrive, and coping with the enormous state-space of this model.  In past work, we dealt with the first problem.  In this paper we consider the second, and especially, the third problem, which is of greater concern to researchers in decision-theoretic planning.  We show that although the model we consider has roughly 10 11 states, we can quickly provide an approximate solution by utilizing its special structure.  Our memory requirements { a serious concern for commercial online applications { are modest; and the overall resource requirements of our system are comparable to those of a well-known commercial recommender system that uses a simpler and less accurate model.  Our system is one of a handful of deployed commercial recommender systems as well as one of a handful of MDP-based deployed systems.  It has been running at www. mitos. co. il, a commercial online bookstore, since August, 2002. 
The Learning Curve Method Applied to Clustering| Abstract We describe novel fast learning curve methods | methods for scaling inductive methods to large data sets { and their application to clustering.  We describe the decision theoretic underpinnings of the approach and demonstrate significant performance gains on two real-world data sets. 
The Lumière Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users| Abstract The Lumire Project centers on harnessing probability and utilitytoprovide assistance to computer software users.  We review work on Bayesian user models that can be employed to infer a user's needs by considering a user's background, actions, and queries.  Several problems were tackled in Lumire research, including (1) the construction of Bayesian models for reasoning about the time-varying goals of computer users from their observed actions and queries, (2) gaining access to a stream of events from software applications, (3) developing a language for transforming system events into observational variables represented in Bayesian user models, (4) developing persistent profiles to capture changes in a user's expertise, and (5) the developmentofanoverall architecture for an intelligentuserinterface.  Lumire prototypes served as the basis for the Office Assistant in the Microsoft Office '97 suite of productivity applications. 
Large-Sample Learning of Bayesian Networks is NP-Hard| Abstract In this paper, we provide new complexity results for algorithms that learn discrete-variable Bayesian networks from data.  Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest structure for which the model is able to represent the generative distribution exactly.  Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset.  We show that identifying high-scoring structures is NPhard, even when any combination of one or more of the following hold: the generative distribution is perfect with respect to some DAG containing hidden variables; we are given an independence oracle; we are given an inference oracle; we are given an information oracle; we restrict potential solutions to structures in which each node has at most k parents, for all k # 3.  Our proof relies on a new technical result that we establish in the appendices.  In particular, we provide a method for constructing the local distributions in a Bayesian network such that the resulting joint distribution is provably perfect with respect to the structure of the network. 
Model-Based Clustering and Visualization of Navigation Patterns on a Web Site| Abstract We present a new methodology for exploring and analyzing navigation patterns on a web site.  The patterns that can be analyzed consist of sequences of URL categories traversed by users.  In our approach, we first partition site users into clusters such that users with similar navigation paths through the site are placed into the same cluster.  Then, for each cluster, we display these paths for users within that cluster.  The clustering approachweemploy is model-based (as opposed to distance-based) and partitions users according to the order in which they request web pages.  In particular, we cluster users by learning a mixture of first-order Markov models using the Expectation-Maximization algorithm.  The runtime of our algorithm scales linearly with the number of clusters and with the size of the data; and our implementation easily handles hundreds of thousands of user sessions in memory.  In the paper, we describe the details of our method and a visualization tool based on it called WebCANVAS.  We illustrate the use of our approach on user-traffic data from msnbc. com. 
Staged Mixture Modeling and Boosting| In this paper, we introduce and evaluate a data-driven staged mixture modeling technique for building density, regression, and classi#cation models.  Our basic approach is to sequentially add components to a finite mixture model using the structural expectation maximization (SEM) algorithm.  We show that our technique is qualitatively similar to boosting.  This correspondence is a natural byproduct of the fact that we use the SEM algorithm to sequentially fit the mixture model.  Finally, in our experimental evaluation, we demonstrate the effectiveness of our approach on a variety of prediction and density estimation tasks using real-world data. 
Challenge: Where is the Impact of Bayesian Networks in Learning?| Abstract Bayesian networks are graphical representations of probability distributions.  Over the last decade, these representations have become the method of choice for representation of uncertainly in artificial intelligence.  Today, they play a crucial role in modern expert systems, diagnosis engines, and decision support systems.  In recent years, there has been much interest in learning Bayesian networks from data.  Learning such models is desirable simply because there is a wide array of off-the-shelf tools that can apply the learned models as described above.  Practitioners also claim that adaptive Bayesian networks have advantages in their own right as a non-parametric method for density estimation, data analysis, pattern classification, and modeling.  Among the reasons cited we find: their semantic clarity and understandability by humans, the ease of acquisition and incorporation of prior knowledge, the ease of integration with optimal decision-making methods, the possibility of causal interpretation of learned models, and the automatic handling of noisy and missing data.  In spite of these claims, methods that learn Bayesian networks have yet to make the impact that other techniques such as neural networks and hidden Markov models have made in applications such as pattern and speech recognition.  In this paper, we challenge the research community to identify and characterize domains where induction of Bayesian networks makes the critical difference, and to quantify the factors that are responsible for that difference.  In addition to formalizing the challenge, we identify research problems whose solution is, in our view, crucial for meeting this challenge. 
ABayesian Approach to Filtering JunkE-nk 4| Abstract In addressing the growing problem of junkE-nk 2 on the Internet, we examine methods for the automated construction of filters to eliminate suchunwanted messages from a user's mail stream.  By casting this problem in a decision theoretic framework, we are able to make use of probabilistic learning methods inconjunc- tion with a notion of differential misclassification cost to produce filters which are especially appropriate for the nuances of this task.  While this may appear, at first, to be a straight-aigh ard text classification problem, we show that by consideringdomain-ri ecificfea- tures of this problem in addition to the raw text of E- 282 messages, we can produce much more accurate filters.  Finally,we show the efficacy of such filters in a real world usage scenario, arguing that this technology is mature enough for deployment. 
An MDP-based Recommender System| Abstract Typical Recommender systems adopt a static view of the recommendation process and treat it as a prediction problem.  We argue that it is more appropriate to view the problem of generating recommendations as a sequential decision problem and, consequently, that Markov decision processes (MDP) provide a more appropriate model for Recommender systems.  MDPs introduce two benefits: they take into account the long-term effects of each recommendation, and they take into account the expected value of each recommendation.  To succeed in practice, an MDP-based Recommender system must employ a strong initial model; and the bulk of this paper is concerned with the generation of such a model.  In particular, we suggest the use of an n-gram predictive model for generating the initial MDP.  Our n-gram model induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models.  We describe our predictive model in detail and evaluate its performance on real data.  In addition, we show how the model can be used in an MDP-based Recommender system. 
Estimating smooth deformation models of substance and noise| Abstract By representing image prototypes, or "substance", by linear subspaces spanned by deformation fields derived from low-frequecy wavelets, impressive invariance to distortion can be built into generative probability models.  The prototypes representing substance and the distribution over wavelet coefficients can be estimated using EM, since exact inference is tractable in this model.  While this approach works for noise-free data, it is prone to errors for noisy data, where the noise is deformed and then confused with the prototypes representing substance.  We describe a generative model for smooth, nonuniform deformations, in which noise fields are deformed along with the prototypes representing substance.  This prevents deformed substance from being confused with deformed noise.  We show that a variational technique can be used for inference and parameter estimation in this model.  We give results on a very difficult, contrived problem and on facial expression modeling. 
Visualization of navigation patterns on a Web site using model-based clustering| ABSTRACT We present a new methodology for visualizing navigation patterns on a Web site.  In our approach, we first partition site users into clusters such that only users with similar navigation paths through the site are placed into the same cluster.  Then, for each cluster, we display these paths for users within that cluster.  The clustering approachwe employ is model based (as opposed to distance based) and partitions users according to the order in which they request Web pages.  In particular, we cluster users by learning a mixture of first-order Markov models using the ExpectationMaximization algorithm.  Our algorithm scales linearly with both number of users and number of clusters, and our implementation easily handles millions of users and thousands of clusters in memory.  In the paper, we describe the details of our technology and a tool based on it called WebCANVAS.  We illustrate the use of our technology on user-trac data from msnbc. com. 
Empirical Analysis of Predictive Algorithms for Collaborative Filtering \Lambda| Abstract Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like.  In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods.  We compare the predictive accuracy of the various methods in a set of representative problem domains.  We use two basic classes of evaluation metrics.  The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation.  The second estimates the utility of a ranked list of suggested items.  This metric uses an estimate of the probability that a user will see a recommendation in an ordered list.  Experiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metrics for the various algorithms.  Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vectorsimilarity methods.  Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions.  Other considerations include the size of database, speed of predictions, and learning time. 
CFW: A Collaborative Filtering System Using Posteriors over Weights of Evidence| Abstract We describe CFW, a computationally ecient algorithm for collaborative filtering that uses posteriors over weights of evidence.  In experiments on real data, we show that this method predicts as well or better than other methods in situations where the size of the user query is small.  The new approach works particularly well when the user's query contains low frequency (unpopular) items.  The approach complements that of dependency networks which perform well when the size of the query is large.  Also in this paper, we argue that the use of posteriors over weights of evidence is a natural way to recommend similar items---a task that is somewhat dierent from the usual collaborative-filtering task. 
Learning Bayesian Networks From Dependency Networks: A Preliminary Study| Abstract In this paper we describe how to learn Bayesian networks from a summary of complete data in the form of a dependency network rather than from data directly.  This method allows us to gain the advantages of both representations: scalable algorithms for learning dependency networks and convenient inference with Bayesian networks.  Our approach is to use a dependency network as an "oracle" for the statistics needed to learn a Bayesian network.  We show that the general problem is NP-hard and develop a greedy search algorithm.  We conduct a preliminary experimental evaluation and find that the prediction accuracy of the Bayesian networks constructed from our algorithm almost equals that of Bayesian networks learned directly from the data. 
Causal Independence for Probability Assessment and Inference Using Bayesian Networks| Abstract A Bayesian network is a probabilistic representation for uncertain relationships, which has proven to be useful for modeling real-world problems.  When there are many potential causes of a given effect, however, both probability assessment and inference using a Bayesian network can be difficult.  In this paper, we describe causal independence, a collection of conditional independence assertions and functional relationships that are often appropriate to apply to the representation of the uncertain interactions between causes and effect.  We show how the use of causal independence in a Bayesian network can greatly simplify probability assessment as well as probabilistic inference. 
Targeted Internet Advertising Using Predictive Clustering and Linear Programming| Abstract Many Internet sites have the freedom to choose which advertisements go on which page, subject to the constraint that all paid-for ads must be shown.  To increase revenue, these sites can choose ads so as to maximize click-through rates.  We present a two-step system that does so.  In step one, the system applies predictive clustering to the pages so that the clusters are good predictors of ad click-through.  This predictive clustering is accomplished by GEM applied to a regularized log loss on click-through prediction.  In step two, the system measures click-through rates of each cluster, and then uses a linear program to optimize overall click-through rate on the site.  Using data from the msnbc. com Internet site, we show that this approach increases overall click-through rate by 38%, a dramatic improvement over the use of hand-assigned clusters. 
Learning Bayesian Networks: Search Methods and Experimental Results| Abstract We discuss Bayesian approaches for learning Bayesian networks from data.  First, we review a metric for computing the relative posterior probability of a network structure given data developed by Heckerman et al.  (1994a,b,c).  We see that the metric has a property useful for inferring causation from data.  Next, we describe search methods for identifying network structures with high posterior probabilities.  We describe polynomial algorithms for finding the highestscoring network structures in the special case where every node has at most k = 1 parent.  We show that the general case (k } 1) is NP-hard, and review heuristic search algorithms for this general case.  Finally, we describe a methodology for evaluating learning algorithms, and use this methodology to evaluate various scoring metrics and search procedures. 
A Tutorial on Learning With Bayesian Networks| Abstract A Bayesian network is a graphical model that encodes probabilistic relationships among variables of interest.  When used in conjunction with statistical techniques, the graphical model has several advantages for data analysis.  One, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing.  Two, a Bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to predict the consequences of intervention.  Three, because the model has both a causal and probabilistic semantics, it is an ideal representation for combining prior knowledge (which often comes in causal form) and data.  Four, Bayesian statistical methods in conjunction with Bayesian networks offer an efficient and principled approach for avoiding the overfitting of data.  In this paper, we discuss methods for constructing Bayesian networks from prior knowledge and summarize Bayesian statistical methods for using data to improve these models.  With regard to the latter task, we describe methods for learning both the parameters and structure of a Bayesian network, including techniques for learning with incomplete data.  In addition, we relate Bayesian-network methods for learning to techniques for supervised and unsupervised learning.  We illustrate the graphical-modeling approach using a real-world case study. 
On the Path to an Ideal ROC Curve: Considering Cost Asymmetry in Learning Classifiers| Abstract Receiver Operating Characteristic (ROC) curves are a standard way to display the performance of a set of binary classifiers for all feasible ratios of the costs associated with false positives and false negatives.  For linear classifiers, the set of classifiers is typically obtained by training once, holding constant the estimated slope and then varying the intercept to obtain a parameterized set of classifiers whose performances can be plotted in the ROC plane.  In this paper, we consider the alternative of varying the asymmetry of the cost function used for training.  We show that the ROC curve obtained by varying the intercept and the asymmetry---and hence the slope---always outperforms the ROC curve obtained by varying only the intercept.  In addition, we present a path-following algorithm for the support vector machine (SVM) that can compute efficiently the entire ROC curve, that has the same computational properties as training a single classifier.  Finally, we provide a theoretical analysis of the relationship between the asymmetric cost model assumed when training a classifier and the cost model assumed in applying the classifier.  In particular, we show that the mismatch between the step function used for testing and its convex upper bounds usually used for training leads to a provable and quantifiable difference around extreme asymmetries. 
Dependency Networks for Inference, Collaborative Filtering, and Data Visualization|
Learning Bayesian Networks: The Combination of Knowledge and Statistical Data|
Reflection and Action Under Scarce Resources: Theoretical Principles and Empirical Study|
Advances in Probabilistic Reasoning|
Inferring Informational Goals from Free-Text Queries: A Bayesian Approach|
A Bayesian Approach to Learning Causal Networks|
Bayesian Networks for Data Mining|
Learning Bayesian Networks: A Unification for Discrete and Gaussian Domains|
Probabilistic Independence Networks for Hidden Markov Probability Models|
Probabilistic Interpretation for MYCIN's Certainty Factors|
Empirical Analysis of Predictive Algorithms for Collaborative Filtering|
Bayesian Networks|
An Experimental Comparison of Several Clustering and Initialization Methods|
Separating Appearance from Deformation|
A New Look at Causal Independence|
Knowledge Representation and Inference in Similarity Networks and Bayesian Multinets|
Asymptotic Model Selection for Directed Networks with Hidden Variables|
Efficient Approximations for the Marginal Likelihood of Bayesian Networks with Hidden Variables|
Structure and Parameter Learning for Causal Independence and Causal Interaction Models|
Models and Selection Criteria for Regression and Classification|
A Bayesian Perspective on Confidence|
On the Expressiveness of Rule-based Systems for Reasoning with Uncertainty|
Learning Gaussian Networks|
Learning Mixtures of DAG Models|
Accelerating EM for Large Databases|
Causal Independence for Knowledge Acquisition and Inference|
Dependency Networks for Collaborative Filtering and Data Visualization|
A Definition and Graphical Representation for Causality|
Bayesian Networks for Knowledge Discovery|
A perspective on confidence and its use in focusing attention during knowledge acquisition|
Toward effective normative decision systems: Update on the pathfinder project|
A Decision-based View of Causality|
An Approximate Nonmyopic Computation for Value of Information|
Inference Algorithms for Similarity Networks|
A Tractable Inference Algorithm for Diagnosing Multiple Diseases|
A characterization of the dirichlet distribution through global and local parameter independence|
Probabilistic and Bayesian Representations of Uncertainty in Information Systems: A Pragmatic Introduction|
Update on the Pathfinder project|
An Experimental Comparison of Model-Based Clustering Methods|
A Decision Theoretic Approach to Targeted Advertising|
A backwards view for assessment|
On Finding a Cycle Basis with a Shortest Maximal Cycle|
Effect of log-odds noise on distribution and (b) Accuracy Variation with log-odds noise networks|
A combination of cutset conditioning with clique-tree propagation in the Pathfinder system|
Topics in Decision-Theoretic Troubleshooting: Repair and Experiment|
Real-World Applications of Bayesian Networks - Introduction|
Autoregressive Tree Models for Time-Series Analysis|
Fast Learning from Sparse Data|
An empirical comparison of three inference methods|
Decision-Theoretic Troubleshooting: A Framework for Repair and Experiment|
Challenge: What is the Impact of Bayesian Networks on Learning?|
Targeted advertising with inventory management|
A method for temporal probabilistic reasoning|
Mamdani A, editors| Real-world applications of Bayesian networks. 
An axiomatic framework for belief updates|
A Framework for Comparing Alternative Formalisms for Plausible Reasoning|
The compilation of decision models|
The Learning-Curve Sampling Method Applied to Model-Based Clustering|
separable and transitive graphoids|
The Inconsistent Use of Measures of Certainty in Artificial Intelligence Research|
The use of a heuristic problemsolving hierarchy to facilitate the explanation of hypothesis-directed reasoning|
A Characterization of the Dirichlet Distribution with Application to Learning Bayesian Networks|
Probabilistic independence networks fo hidden Markov probability models|
Similarity networks for the construction of multiple-faults belief networks|
Integrated expert systems and videodisc in surgical pathology: an overview,|
