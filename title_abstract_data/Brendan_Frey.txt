Transformed Component Analysis: Joint Estimation of Spatial Transformations and Image Components| A simple, effective way to model images is to represent each input pattern by a linear combination of \component" vectors, where the amplitudes of the vectors are modulated to match the input.  This approach includes principal component analysis, independent component analysis and factor analysis.  In practice, images are subjected to randomly selected transformations of a known nature, such as translation, rotation and scale.  Direct application of the above methods will lead to severely blurred components and even to components that only account for the transformations and ignore the more interesting and useful structure.  We propose a method called transformed component analysis, which incorporates a discrete, hidden variable that accounts for transformations and uses a linear-time expectation maximization algorithm to jointly extract components and normalize for transformations.  We illustrate the algorithm using a shading problem, facial expression modeling and handwritten digit recognition. 
A Robust and Efficient Method to Unwrap MR Phase Images| SYNOPSIS Phase unwrapping finds many important applications in MRI, ranging from field mapping to flow imaging.  In this paper, we propose a novel approach to 2-D phase unwrapping, which models the true phase as a Gaussian Markov random field.  The phase is unwrapped using the maximum a posteriori (MAP) rule.  The underlying optimization problem is solved using a two-dimensional dynamic programming algorithm, which is efficient and robust to noise.  The proposed algorithm has been tested using various MRI data (acquired using spin-echo and gradient-echo sequences), yielding excellent phase maps. 
Irregular Turbocodes| Abstract Recently, several groups have increased the coding gain of iteratively decoded Gallager codes (low density parity check codes) by varying the number of parity check equations in which each codeword bit participates.  In regular turbocodes, each \systematic bit" participates in exactly 2 trellis sections.  We construct irregular turbocodes with systematic bits that participate in varying numbers of trellis sections.  These codes can be decoded by the iterative application of the sum-product algorithm (a low-complexity, more general form of the turbodecoding algorithm).  By making the original rate 1/2 turbocode of Berrou et al.  slightly irregular, we obtain a coding gain of 0. 15 dB at a block length of N = 131; 072, bringing the irregular turbocode within 0. 3 dB of capacity.  Just like regular turbocodes, irregular turbocodes are linear-time encodable. 
The automated extraction of environmentally relevant features from digital imagery using Bayesian multi-resolution analysis| Abstract In this paper, we discuss the use of hierarchical tree-structured Bayesian networks for integrating knowledge concerning contextual relationships between environmentally relevant features extracted from digital imagery at multiple resolution scales.  In our model, conditional probability distributions over continuous valued observations are parameterized using a mixture of multivariate Gaussian distributions.  Separate classifiers for pixels and groups of pixels are used as sub-components of the overall model.  The Bayesian formalism allows models to be composed in a systematic and statistically sound manner.  We illustrate how this approach can be used to resolve ambiguity leading to classification errors and thus improve techniques for the classification of land use from aerial imagery.  We present an example relevant to ecosystem analysis, the monitoring of urban growth and the automatic generation of input parameters for hydrologic models. 
Continuous Sigmoidal Belief Networks Trained using Slice Sampling| Abstract Real-valued random hidden variables can be useful for modelling latent structure that explains correlations among observed variables.  I propose a simple unit that adds zero-mean Gaussian noise to its input before passing it through a sigmoidal squashing function.  Such units can produce a variety of useful behaviors, ranging from deterministic to binary stochastic to continuous stochastic.  I show how "slice sampling" (Neal 1996) can be used for inference and learning in top-down networks of these units and demonstrate learning on two simple problems. 
NOISE ROBUST SPEECH RECOGNITION USING GAUSSIAN BASIS FUNCTIONS FOR NON-LINEAR LIKELIHOOD FUNCTION APPROXIMATION| ABSTRACT One approach to achieving noise and distortion robust speech recognition is to remove noise and distortion with algorithms of low complexity prior to the use of much higher complexity speech recognizers.  This approach has been referred to as cleaning.  In this paper we present an approach for speech cleaning using a time-varying, non-linear probabilistic model of a signals log Mel-filter-bank representation.  We then present a new non-linear probabilistic inference technique and show results using this technique within the probabilistic cleaning model.  In this approach we represent distributions for underlying noise, speech and channel characteristics as Gaussian mixtures and use Gaussian basis functions to model the non-linear likelihood function.  This allows us to efficiently compute complex multi-modal probability distributions over speech and noise components of the underlying signal.  We show how this method can be used to clean speech features and present results using the Aurora 2 speech recognizer trained on clean speech data.  We present competitive initial results from a minimum mean square error version of this approach for a subset of the Aurora 2 noisy digits recognition tasks. 
Data Assimilation with an Extended Kalman Filter for Impact-Produced Shock-Wave Dynamics By| ABSTRACT Model assimilation of data strives to determine optimally the state of an evolving physical system from a limited number of observations.  The present study represents the first attempt of applying the extended Kalman filter (EKF) method of data assimilation to shock-wave dynamics induced by a high-speed impact.  EKF solves the full nonlinear state evolution and estimates its associated error-covariance matrix in time.  The state variables obtained by the blending of past model evolution with currently available data, along with their associated minimized errors (or uncertainties), are then used as initial conditions for further prediction until the next time at which data becomes available.  In this study, a one-dimensional (1-D) finite-difference code is used along with data measured from a 1-D flyer plate experiment.  An ensemble simulation suggests that the nonlinearity of the modeled system can be reasonably tracked by EKF.  The results demonstrate that the EKF assimilation of a limited amount of pressure data, measured at the middle of the target plate alone, helps track the evolution of all the state variables.  The fidelity of EKF is further investigated with numerically generated synthetic data from so-called "identical-twin experiments", in which the true state is known and various measurement techniques and strategies can be made easily simulated.  We find that the EKF method can effectively assimilate the density fields, which are distributed sparsely in time to mimic radiographic data, into the modeled system. 
A simple algorithm that discovers efficient perceptual codes| Abstract We describe the "wake-sleep" algorithm that allows a multilayer, unsupervised, neural network to build a hierarchy of representations of sensory input.  The network has bottom-up "recognition" connections that are used to convert sensory input into underlying representations.  Unlike most artificial neural networks, it also has top-down "generative" connections that can be used to reconstruct the sensory input from the representations.  In the "wake" phase of the learning algorithm, the network is driven by the bottom-up recognition connections and the top-down generative connections are trained to be better at reconstructing the sensory input from the representation chosen by the recognition process.  In the "sleep" phase, the network is driven top-down by the generative connections to produce a fantasized representation and a fantasized sensory input.  The recognition connections are then trained to be better at recovering the fantasized representation from the fantasized sensory input.  In both phases, the synaptic learning rule is simple and local.  The combined effect of the two phases is to create representations of the sensory input that are efficient in the following sense: On average, it takes more bits to describe each sensory input vector directly than to first describe the representation of the sensory input chosen by the recognition process and then describe the difference between the sensory input and its reconstruction from the chosen representation. 
Making stochastic source coding efficient by recovering information| Abstract In this paper, we introduce a new algorithm called "bits-back coding" that makes stochastic source codes efficient.  For a given one-to-many source code, we show that this algorithm can actually be more efficient than the algorithm that always picks the shortest codeword.  Optimal efficiency is achieved when codewords are chosen according to the Boltzmann distribution based on the codeword lengths.  After presenting a binary Bayesian network model that assigns exponentially many codewords to each symbol, we show how a tractable approximation to the Boltzmann distribution can be used for bits-back coding.  It turns out that a commonly used technique for determining parameters --- maximum likelihood estimation --- actually minimizes the optimal bitsback coding cost.  A tractable approximation to maximum likelihood estimation --incremental expectation maximization --- minimizes the bits-back coding cost as well.  We illustrate the performance of bits-back coding first on a toy problem and then using real data with a binary Bayesian network that produces 2 60 possible codewords for each symbol.  For both tasks, the rate for bits-back coding is nearly one half of that obtained by picking the shortest codeword for each symbol. 
Efficient Stochastic Source Coding and an Application to a Bayesian Network Source Model| In this paper, we introduce a new algorithm called "bits-back coding" that makes stochastic source codes efficient.  For a given one-to-many source code, we show that this algorithm can actually be more efficient than the algorithm that always picks the shortest codeword.  Optimal efficiency is achieved when codewords are chosen according to the Boltzmann distribution based on the codeword lengths.  It turns out that a commonly used technique for determining parameters --- maximum likelihood estimation --- actually minimizes the bits-back coding cost when codewords are chosen according to the Boltzmann distribution.  A tractable approximation to maximum likelihood estimation --- the generalized expectation maximization algorithm --- minimizes the bits-back coding cost.  After presenting a binary Bayesian network model that assigns exponentially many codewords to each symbol, we show how a tractable approximation to the Boltzmann distribution can be used for bits-back coding.  We illustrate the performance of bits-back coding using using nonsynthetic data with a binary Bayesian network source model that produces 2 60 possible codewords for each input symbol.  The rate for bits-back coding is nearly one half of that obtained by picking the shortest codeword for each symbol. 
Accumulator Networks: Suitors of Local Probability Propagation| Abstract One way to approximate inference in richly-connected graphical models is to apply the sum-product algorithm (a. k. a.  probability propagation algorithm), while ignoring the fact that the graph has cycles.  The sum-product algorithm can be directly applied in Gaussian networks and in graphs for coding, but for many conditional probability functions { including the sigmoid function { direct application of the sum-product algorithm is not possible.  We introduce \accumulator networks" that have low local complexity (but exponential global complexity) so the sum-product algorithm can be directly applied.  In an accumulator network, the probability of a child given its parents is computed by accumulating the inputs from the parents in a Markov chain or more generally a tree.  After giving expressions for inference and learning in accumulator networks, we give results on the \bars problem" and on the problem of extracting translated, overlapping faces from an image. 
Enforcing Integrability for Surface Reconstruction Algorithms Using Belief Propagation in Graphical Models| Abstract Accurate calculation of the three dimensional shape of an object is one of the classic research areas of computer vision.  Many of the existing methods are based on surface normal estimation, and subsequent integration of surface gradients.  In general, these methods do not produce valid surface due to violation of surface integrability.  We introduce a new method for shape reconstruction by integration of valid surface gradient maps.  The essence of the new approach is in the strict enforcement of the surface integrability via belief propagation across graphical model.  The graphical model is selected in such a way to extract information from underlying, possibly noisy, surface gradient estimators, utilize the surface integrability constraint, and produce the maximum a-posteriori estimate of a valid surface.  We demonstrate the algorithm for two classic shape reconstruction techniques; shape-from-shading and photometric stereo.  On a set of real and synthetic examples the new approach is shown to be fast and accurate, in the sense that shape can be rendered even in the presence of high levels of noise and sharp occlusion boundaries. 
Fast, large-scale transformation-invariant| Abstract In previous work on "transformed mixtures of Gaussians" and "transformed hidden Markov models", we showed how the EM algorithm in a discrete latent variable model can be used to jointly normalize data (e. g. , center images, pitch-normalize spectrograms) and learn a mixture model of the normalized data.  The only input to the algorithm is the data, a list of possible transformations, and the number of clusters to find.  The main criticism of this work was that the exhaustive computation of the posterior probabilities over transformations would make scaling up to large feature vectors and large sets of transformations intractable.  Here, we describe how a tremendous speed-up is acheived through the use of a variational technique for decoupling transformations, and a fast Fourier transform method for computing posterior probabilities.  For NN images, learning C clusters under N rotations, N scales, N x-translations and N y-translations takes only (C + 2 log N)N 2 scalar operations per iteration.  In contrast, the original algorithm takes CN 6 operations to account for these transformations.  We give results on learning a 4-component mixture model from a video sequence with frames of size 320240.  The model accounts for 360 rotations and 76,800 translations.  Each iteration of EM takes only 10 seconds per frame in MATLAB, which is over 5 million times faster than the original algorithm. 
Embedded Face and Facial Expression Recognition| Abstract A framework for embedded recognition of faces and facial expressions is described.  Faces are modeled based on the appearances and positions of facial features.  Hidden states are used to represent discrete facial expressions.  A face model is constructed for each person in the database using video segments showing di#erent facial expressions.  Face recognition and facial expression recognition are carried out using Bayesian classification.  In our current implementation, the face is divided into 9 facial features grouped in 4 regions which are detected and tracked automatically in video segments.  We report results on face and facial expression recognition using a video database of 18 people and 6 expressions. 
Does the Wake-sleep Algorithm Produce Good Density Estimators?| Abstract The wake-sleep algorithm (Hinton, Dayan, Frey and Neal 1995) is a relatively efficient method of fitting a multilayer stochastic generative model to high-dimensional data.  In addition to the top-down connections in the generative model, it makes use of bottom-up connections for approximating the probability distribution over the hidden units given the data, and it trains these bottom-up connections using a simple delta rule.  We use a variety of synthetic and real data sets to compare the performance of the wake-sleep algorithm with Monte Carlo and mean field methods for fitting the same generative model and also compare it with other models that are less powerful but easier to fit. 
Product Analysis: Learning to Model Observations as Products of Hidden Variables| Abstract Factor analysis and principal components analysis can be used to model linear relationships between observed variables and linearly map high-dimensional data to a lower-dimensional hidden space.  In factor analysis, the observations are modeled as a linear combination of normally distributed hidden variables.  We describe a nonlinear generalization of factor analysis, called \product analysis", that models the observed variables as a linear combination of products of normally distributed hidden variables.  Just as factor analysis can be viewed as unsupervised linear regression on unobserved, normally distributed hidden variables, product analysis can be viewed as unsupervised linear regression on products of unobserved, normally distributed hidden variables.  The mapping between the data and the hidden space is nonlinear, so we use an approximate variational technique for inference and learning.  Since product analysis is a generalization of factor analysis, product analysis always finds a higher data likelihood than factor analysis.  We give results on pattern recognition and illuminationinvariant image clustering. 
Learning Flexible Sprites in Video Layers| We propose a technique for automatically learning layers of \flexible sprites" { probabilistic 2-dimensional appearance maps and masks of moving, occluding objects.  The model explains each input image as a layered composition of flexible sprites.  A variational expectation maximization algorithm is used to learn a mixture of sprites from a video sequence.  For each input image, probabilistic inference is used to infer the sprite class, translation, mask values and pixel intensities (including obstructed pixels) in each layer.  Exact inference is intractable, but we show how a variational inference technique can be used to process 320 # 240 images at 1 frame/second.  The only inputs to the learning algorithm are the video sequence, the number of layers and the number of flexible sprites.  We give results on several tasks, including summarizing a video sequence with sprites, point-and-click video stabilization, and point-and-click object removal. 
Data assimilation with an extended Kalman filter for impact-produced shock-wave dynamics| Abstract Model assimilation of data strives to determine optimally the state of an evolving physical system from a limited number of observations.  The present study represents the first attempt of applying the extended Kalman filter (EKF) method of data assimilation to shock-wave dynamics induced by a high-speed impact.  EKF solves the full nonlinear state evolution and estimates its associated error-covariance matrix in time.  The state variables obtained by the
Free Energy Coding| Abstract In this paper, we introduce a new approach to the problem of optimal compression when a source code produces multiple codewords for a given symbol.  It may seem that the most sensible codeword to use in this case is the shortest one.  However, in the proposed free energy approach, random codeword selection yields an effective codeword length that can be less than the shortest codeword length.  If the random choices are Boltzmann distributed, the effective length is optimal for the given source code.  The expectation-maximization parameter estimation algorithms minimize this effective codeword length.  We illustrate the performance of free energy coding on a simple problem where a compression factor of two is gained by using the new method. 
Variational inference for continuous sigmoidal Bayesian networks| Abstract Latent random variables can be useful for modelling covariance relationships
Unsupervised Image Translation| Abstract An interesting and potentially useful vision/graphics task is to render an input image in an enhanced form or also in an unusual style; for example with increased sharpness or with some artistic qualities.  In previous work [10, 5], researchers showed that by estimating the mapping from an input image to a registered (aligned) image of the same scene in a different style or resolution, the mapping could be used to render a new input image in that style or resolution.  Frequently a registered pair is not available, but instead the user may have only a source image of an unrelated scene that contains the desired style.  In this case, the task of inferring the output image is much more difficult since the algorithm must both infer correspondences between features in the input image and the source image, and infer the unknown mapping between the images.  We describe a Bayesian technique for inferring the most likely output image.  The prior on the output image P (X ) is a patch-based Markov random field obtained from the source image.  The likelihood of the input P (Y|X) is a Bayesian network that can represent different rendering styles.  We describe a computationally efficient, probabilistic inference and learning algorithm for inferring the most likely output image and learning the rendering style.  We also show that current techniques for image restoration or reconstruction proposed in the vision literature (e. g. , image super-resolution or de-noising) and image-based nonphotorealistic rendering could be seen as special cases of our model.  We demonstrate our technique using several tasks, including rendering a photograph in the artistic style of an unrelated scene, de-noising, and texture transfer. 
Epitomic analysis of appearance and shape| We present novel simple appearance and shape models that we call epitomes.  The epitome of an image is its miniature, condensed version containing the essence of the textural and shape properties of the image.  As opposed to previously used simple image models, such as templates or basis functions, the size of the epitome is considerably smaller than the size of the image or object it represents, but the epitome still contains most constitutive elements needed to reconstruct the image (Fig.  1).  A collection of images often shares an epitome, e. g. , when images are a few consecutive frames from a video sequence, or when they are photographs of similar objects.  A particular image in a collection is defined by its epitome and a smooth mapping from the epitome to the image pixels.  When the epitomic representation is used within a hierarchical generative model, appropriate inference algorithms can be derived to extract the epitome from a single image or a collection of images and at the same time perform various inference tasks, such as image segmentation, motion estimation, object removal and super-resolution. 
A Probabilistic Framework for Embedded Face and Facial Expression Recognition| Abstract We present a Bayesian recognition framework in which a model of the whole face is enhanced by models of facial feature position and appearances.  Face recognition and facial expression recognition are carried out using maximum likelihood decisions.  The algorithm finds the model and facial expression that maximizes the likelihood of a test image.  In this framework, facial appearance matching is improved by facial expression matching.  Also, changes in facial features due to expressions are used together with facial deformation patterns to jointly perform expression recognition.  In our current implementation, the face is divided into 9 facial features grouped in 4 regions which are detected and tracked automatically in video segments.  The feature images are modeled using Gaussian distributions on a principal component sub-space.  The training procedure is supervised: we use video segments of people in which the facial expressions have been segmented and labeled by hand.  We report results on face and facial expression recognition using a video database of 18 people and 6 expressions. 
The wake-sleep algorithm for unsupervised neural networks| Abstract We describe an unsupervised learning algorithm for a multilayer network of stochastic neurons.  Bottom-up "recognition" connections convert the input into representations in successive hidden layers and top-down "generative" connections reconstruct the representation in one layer from the representation in the layer above.  In the "wake" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below.  In the "sleep" phase, neurons are driven by generative connections and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.  Supervised learning algorithms for multilayer neural networks face two problems: They require a teacher to specify the desired output of the network and they require some method of communicating error information to all of the connections.  The wake-sleep algorithm finesses both these problems.  When there is no teaching signal to be matched, some other goal is required to force the hidden units to extract underlying structure.  In the wake-sleep algorithm the goal is to learn representations that are economical to describe but allow the input to be reconstructed accurately.  Each input vector could be communicated to a receiver by first sending its hidden representation and then sending the difference between the input vector and its top-down reconstruction from the hidden representation.  The aim of learning is to minimize the "description length" which is the total number of bits that would be required to communicate the input vectors in this way [1].  No communication actually takes place, but minimizing the description length that would be required forces the network to learn economical representations that capture the underlying regularities in the data [2].  The neural network has two quite different sets of connections.  The bottom-up "recognition" connections are used to convert the input vector into a representation in one or more layers of hidden units.  The top-down "generative" connections are then used to reconstruct an approximation to the input vector from its underlying representation.  The training algorithm for these two sets of connections can be used with many different types of stochastic neuron, but for simplicity we use only stochastic binary units that have states of or # .  The state of unit # is ### and the probability that it is on is: ### # ### fiff # 25510 - ##### # ##### # ##### # # (1) where # # is the bias of the unit and # # # is the weight on a connection from unit # .  Sometimes the units are driven by the generative weights and other times by the recognition weights, but the same equation is used in both cases.  In the "wake" phase the units are driven bottom-up using the recognition weights, producing a representation of the input vector in the first hidden layer, a representation of this representation in the second hidden layer and so on.  All of these layers of representation combined are called the "total representation" of the input, and the binary state of each hidden unit, , in total representation ! is fiff" # .  This total representation could be used to communicate the input vector, $ , to a receiver.  According to Shannon's coding theorem, it requires #&%('*),+ bits to communicate an event that has probability + under a distribution agreed by the sender and receiver.  We assume that the receiver knows the top-down generative weights [3] so these can be used to create the agreed probability distributions required for communication.  First, the activity of each unit, - , in the top hidden layer is communicated using the distribution #. # "/10 ### "/ # which is obtained by applying Eq.  1 to the single generative bias weight of unit - .  Then the activities of the units in each lower layer are communicated using the distribution #(# " # 0 #2# " # # obtained by applying Eq.  1 to the already communicated activities in the layer above, # " / , and the generative weights, # / # .  The description length of the binary state of unit is: 3 # # " # # # # # " # %('*)4# " # #5# # # " # # %('*)6# #7# " # # (2) The description length for input vector $ using the total representation ! is simply the cost of describing all the hidden states in all the hidden layers plus the cost of describing the input vector given the hidden states 3 # ! 0 $ # # 3 # ! #8# 3 # $#9 ! # #;:<}=@?A: # =B< 3 # # " # #8# :DC 3 # #DE C 9F! # (3)
Trellis-Constrained Codes| Abstract We introduce a class of iteratively decodable trellis-constrained codes as a generalization of turbocodes, low-density parity-check codes, serially-concatenated convolutional codes, and product codes.  In a trellis-constrained code, multiple trellises interact to define the allowed set of codewords.  As a result of these interactions, the minimum-complexity single trellis for the code can have a state space that grows exponentially with block length.  However, as with turbocodes and low-density parity-check codes, a decoder can approximate bit-wise maximum a posteriori decoding by using the sum-product algorithm on the factor graph that describes the code.  We present two new families of codes, homogenous trellis-constrained codes and ring-connected trellis-constrained codes, and give results that show these codes perform in the same regime as do turbo-codes and low-density parity-check codes. 
Topographic Transformation as a Discrete Latent Variable| Abstract Invariance to topographic transformations such as translation and shearing in an image has been successfully incorporated into feedforward mechanisms, e. g. , \convolutional neural networks", \tangent propagation".  We describe a way to add transformation invariance to a generative density model by approximating the nonlinear transformation manifold by a discrete set of transformations.  An EM algorithm for the original model can be extended to the new model by computing expectations over the set of transformations.  We show how to add a discrete transformation variable to Gaussian mixture modeling, factor analysis and mixtures of factor analysis.  We give results on filtering microscopy images, face and facial pose clustering, and handwritten digit modeling and recognition. 
Early Detection and Trellis Splicing: Reduced-Complexity Iterative Decoding| Abstract The excellent bit error rate performance of new soft iterative decoding algorithms (eg. , turbo-codes) is achieved at the expense of a computationally burdensome iterative decoding procedure.  In this paper, we present a new method called early detection that can be used to reduce the computational complexity of a variety of soft iterative decoding methods.  Using a confidence criterion, some information symbols, state variables and codeword symbols are detected early on in the iterative decoding procedure, leading to a reduction in the computational complexity of further processing.  After presenting a general Markov random field framework (eg. , the Tanner graph) for compound codes, we use this framework to show how early detection leads to computational savings.  We then present an easily implemented instance of this algorithm, called trellis splicing, that can be used with turbo-codes.  For a simulated turbo-code system, at low BERs we obtain a reduction in computational complexity of over a factor of four relative to conventional turbo-decoding, without any increase in BER. 
Variational Learning in Mixed-State Dynamic Graphical Models| Abstract Many real-valued stochastic time-series are locally linear (Gaussian), but globally nonlinear.  For example, the trajectory of a human hand gesture can be viewed as a linear dynamic system driven by a nonlinear dynamic system that represents muscle actions.  We present a mixed-state dynamic graphical model in which a hidden Markov model drives a linear dynamic system.  This combination allows us to model both the discrete and continuous causes of trajectories such as human gestures.  The number of computations needed for exact inference is exponential in the sequence length, so we derive an approximate variational inference technique that can also be used to learn the parameters of the discrete and continuous models.  We show how the mixed-state model and the variational technique can be used to classify human hand gestures made with a computer mouse. 
Fast Transformation-Invariant Factor Analysis| Abstract Dimensionality reduction techniques such as principal component analysis and factor analysis are used to discover a linear mapping between high dimensional data samples and points in a lower dimensional subspace.  In [6], Jojic and Frey introduced mixture of transformation-invariant component analyzers (MTCA) that can account for global transformations such as translations and rotations, perform clustering and learn local appearance deformations by dimensionality reduction.  However, due to enormous computational requirements of the EM algorithm for learning the model, O(N 2 ) where N is the dimensionality of a data sample, MTCA was not practical for most applications.  In this paper, we demonstrate how fast Fourier transforms can reduce the computation to the order of NlogN .  With this speedup, we show the effectiveness of MTCA in various applications - tracking, video textures, clustering video sequences, object recognition, and object detection in images. 
Real-time on-line learning of transformed hidden Markov models from video| Abstract The transformed hidden Markov model is a temporal model that captures three typical causes of variability in video - scene/object class, appearance variability within the class, and image motion.  In our previous work, we showed that an exact EM algorithm can jointly learn the appearances of multiple objects and/or poses of an object, and track the objects or camera motion in video, starting simply from random initialization.  As such, this model can serve as a basis for both video clustering and object tracking applications.  However, the original algorithm requires a significant amount of computation that renders it impractical for video clustering and its off-line nature makes it unsuitable for real-time tracking applications.  In this paper, we propose a new, significantly faster, on-line learning algorithm that enables real-time clustering and tracking.  We demonstrate that the algorithm can extract objects using the constraints on their motion and also perform tracking while the appearance models are learned.  We also demonstrate the clustering results on an example of typical unrestricted personal media - the vacation video. 
Estimating Mixture Models of Images and Inferring Spatial Transformations Using the EM Algorithm| Abstract Mixture modeling and clustering algorithms are effective, simple ways to represent images using a set of data centers.  However, in situations where the images include background clutter and transformations such as translation, rotation, shearing and warping, these methods extract data centers that include clutter and represent different transformations of essentially the same data.  Taking face images as an example, it would be more useful for the different clusters to represent different poses and expressions, instead of cluttered versions of different translations, scales and rotations.  By including clutter and transformation as unobserved, latent variables in a mixture model, we obtain a new \transformed mixture of Gaussians", which is invariant to a specified set of transformations.  We show how a linear-time EM algorithm can be used to fit this model by jointly estimating a mixture model for the data and inferring the transformation for each image.  We show that this algorithm can jointly align images of a human head and learn different poses.  We also find that the algorithm performs better than knearest neighbors and mixtures of Gaussians on handwritten digit recognition. 
Keeping Flexible Active Contours on Track using Metropolis Updates| Abstract Condensation, a form of likelihood-weighted particle filtering, has been successfully used to infer the shapes of highly constrained "active" contours in video sequences.  However, when the contours are highly flexible (e. g.  for tracking fingers of a hand), a computationally burdensome number of particles is needed to successfully approximate the contour distribution.  We show how the Metropolis algorithm can be used to update a particle set representing a distribution over contours at each frame in a video sequence.  We compare this method to condensation using a video sequence that requires highly flexible contours, and show that the new algorithm performs dramatically better that the condensation algorithm.  We discuss the incorporation of this method into the "active contour" framework where a shape-subspace is used constrain shape variation. 
Learning Generative Models of Similarity Matrices| Abstract Recently, spectral clustering (a. k. a.  normalized graph cut) techniques have become popular for their potential ability at finding irregularlyshaped clusters in data.  The input to these methods is a similarity measure between every pair of data points.  If the clusters are well-separated, the eigenvectors of the similarity matrix can be used to identify the clusters, essentially by identifying groups of points that are related by transitive similarity relationships.  However, these techniques fail when the clusters are noisy and not wellseparated, or when the scale parameter that is used to map distances between points to similarities is not set correctly.  Our approach to solving these problems is to introduce a generative probability model that explicitly models noise and can be trained in a maximum-likelihood fashion to estimate the scale parameter.  Exact inference is computationally intractable, but we describe tractable, approximate techniques for inference and learning.  Interestingly, it turns out that greedy inference and learning in one of our models with a fixed scale parameter is equivalent to spectral clustering.  We examine several data sets, and demonstrate that our method finds better clusters compared with spectral clustering. 
Detection and Tracking of Faces and Facial Features| Abstract We describe a real-time system for face and facial feature detection and tracking in continuous video.  The core of this system consists of a set of novel facial feature detectors based on our previously proposed Information-Based Maximum Discrimination learning technique.  These classifiers are very fast and allow us to implement a fully automatic, real-time system for detection and tracking multiple faces.  In addition to locking onto up to four target faces, this system locates and tracks nine facial features as they move under facial expression changes. 
Efficient Computation of Stochastic Complexity| Abstract Stochastic complexity of a data set is defined as the shortest possible code length for the data obtainable by using some fixed set of models.  This measure is of great theoretical and practical importance as a tool for tasks such as model selection or data clustering.  Unfortunately, computing the modern version of stochastic complexity, defined as the Normalized Maximum Likelihood (NML) criterion, requires computing a sum with an exponential number of terms.  Therefore, in order to be able to apply the stochastic complexity measure in practice, in most cases it has to be approximated.  In this paper, we show that for some interesting and important cases with multinomial data sets, the exponentiality can be removed without loss of accuracy.  We also introduce a new computationally efficient approximation scheme based on analytic combinatorics and assess its accuracy, together with earlier approximations, by comparing them to the exact form.  The results suggest that due to its accuracy and efficiency, the new sharper approximation will be useful for a wide class of problems with discrete data. 
Variational Learning in Nonlinear Gaussian Belief Networks| Abstract We view perceptual tasks such as vision and speech recognition as inference problems where the goal is to estimate the posterior distribution over latent variables (e. g. , depth in stereo vision) given the sensory input.  The recent flurry of research in independent component analysis exemplifies the importance of inferring the continuousvalued latent variables of input data.  The latent variables found by this method are linearly related to the input, but perception requires nonlinear inferences such as classification and depth estimation.  In this paper, we present a unifying framework for stochastic neural networks with nonlinear latent variables.  Nonlinear units are obtained by passing the outputs of linear Gaussian units through various nonlinearities.  We present a general variational method that maximizes a lower bound on the likelihood of a training set and give results on two visual feature extraction problems.  We also show how the variational method can be used for pattern classification and compare the performance of these nonlinear networks with other methods on the problem of handwritten digit recognition. 
A SEGMENT-BASED PROBABILISTIC GENERATIVE MODEL OF SPEECH| ABSTRACT We present a purely time domain approach to speech processing which identifies waveform samples at the boundaries between glottal pulse periods (in voiced speech) or at the boundaries of unvoiced segments.  An efficient algorithm for inferring these boundaries and estimating the average spectra of voiced and unvoiced regions is derived from a simple probabilistic generative model.  Competitive results are presented on pitch tracking, voiced/unvoiced detection and timescale modification; all these tasks and several others can be performed using the single segmentation provided by inference in the model. 
Factor graphs and the sum-product algorithm| Abstract---Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of "local" functions, each of which depends on a subset of the variables.  Such a factorization can be visualized with a bipartite graph that we call a factor graph.  In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph.  Following a single, simple computational rule, the sum-product algorithm computes---either exactly or approximately---various marginal functions derived from the global function.  A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative "turbo" decoding algorithm, Pearl's belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms. 
Transformed Hidden Markov Models: Estimating Mixture Models of Images and Inferring Spatial Transformations in Video Sequences| Abstract In this paper we describe a novel generative model for video analysis called the transformed hidden Markov model (THMM). 
Very loopy belief propagation for unwrapping phase images| Abstract Since the discovery that the best error-correcting decoding algorithm can be viewed as belief propagation in a cycle-bound graph, researchers have been trying to determine under what circumstances \loopy belief propagation" is effective for probabilistic inference.  Despite several theoretical advances in our understanding of loopy belief propagation, to our knowledge, the only problem that has been solved using loopy belief propagation is error-correcting decoding on Gaussian channels.  We propose a new representation for the two-dimensional phase unwrapping problem, and we show that loopy belief propagation produces results that are superior to existing techniques.  This is an important result, since many imaging techniques, including magnetic resonance imaging and interferometric synthetic aperture radar, produce phase-wrapped images.  Interestingly, the graph that we use has a very large number of very short cycles, supporting evidence that a large minimum cycle length is not needed for excellent results using belief propagation. 
Probability Propagation and Iterative Decoding| Abstract In this paper, we present a unified graphical model framework for describing codes and deriving iterative decoding algorithms.  We illustrate how the following systems can be described using graphical models: turbo-codes, seriallyconcatenated convolutional codes, frame-oriented turbo-codes, low-density paritycheck codes, product codes, and convolutional codes on channels with memory.  Recently proposed iterative decoding algorithms (e. g. , turbo-decoding) can be viewed as a simple message passing procedure on the graphical model.  This framework provides the means to derive new iterative decoders for new codes quite easily. 
Denoising and Untangling Graphs Using Degree Priors| Abstract This paper addresses the problem of untangling hidden graphs from a set of noisy detections of undirected edges.  We present a model of the generation of the observed graph that includes degree-based structure priors on the hidden graphs.  Exact inference in the model is intractable; we present an ecient approximate inference algorithm to compute edge appearance posteriors.  We evaluate our model and algorithm on a biological graph inference problem. 
On the milliarcsecond scale structural properties of low and high redshift quasars| We analyse VLBI data of a sample of radio quasars in order to study the milliarcsecond scale structural properties of quasars in the widest available redshift range of 0:2 ! z ! 4:5.  The statistical study is based on a combination of the 5 GHz Caltech-Jodrell VLBI survey and our data for a set of extremely high redshift sources.  We show that the apparently less prominent milliarcsecond scale structures found in z ? 3 quasars do not contradict the assumption of intrinsic similarity of radio sources at different redshifts and may be explained by a difference in spectral properties of cores and extended components (jets). 
Estimating smooth deformation models of substance and noise| Abstract By representing image prototypes, or "substance", by linear subspaces spanned by deformation fields derived from low-frequecy wavelets, impressive invariance to distortion can be built into generative probability models.  The prototypes representing substance and the distribution over wavelet coefficients can be estimated using EM, since exact inference is tractable in this model.  While this approach works for noise-free data, it is prone to errors for noisy data, where the noise is deformed and then confused with the prototypes representing substance.  We describe a generative model for smooth, nonuniform deformations, in which noise fields are deformed along with the prototypes representing substance.  This prevents deformed substance from being confused with deformed noise.  We show that a variational technique can be used for inference and parameter estimation in this model.  We give results on a very difficult, contrived problem and on facial expression modeling. 
Probabilistic Inference of Speech Signals from Phaseless Spectrograms| Abstract Many techniques for complex speech processing such as denoising and deconvolution, time/frequency warping, multiple speaker separation, and multiple microphone analysis operate on sequences of short-time power spectra (spectrograms), a representation which is often well-suited to these tasks.  However, a significant problem with algorithms that manipulate spectrograms is that the output spectrogram does not include a phase component, which is needed to create a time-domain signal that has good perceptual quality.  Here we describe a generative model of time-domain speech signals and their spectrograms, and show how an efficient optimizer can be used to find the maximum a posteriori speech signal, given the spectrogram.  In contrast to techniques that alternate between estimating the phase and a spectrally-consistent signal, our technique directly infers the speech signal, thus jointly optimizing the phase and a spectrally-consistent signal.  We compare our technique with a standard method using signal-to-noise ratios, but we also provide audio files on the web for the purpose of demonstrating the improvement in perceptual quality that our technique offers. 
Transformation-Invariant Clustering Using the EM Algorithm|
The wake-sleep algorithm for self-organizing neural networks|
Mixtures of Local Linear Subspaces for Face Recognition|
Transformation-invariant clustering and dimensionality reduction|
Learning Graphical Models of Images, Videos and Their Spatial Transformations|
Time-Series Classification Using Mixed-State Dynamic Bayesian Networks|
Separating Appearance from Deformation|
Probability propogation and iterative decoding|
Learning Appearance and Transparency Manifolds of Occluded Objects in Layers|
Transformation invariant clustering and linear component analysis|
Graphical models for machine learning and digital communication The MIT Press,|
HintonGEand Dayan P 1996 Does the wake-sleep algorithm produce good density estimators? Advances in Neural Information Processing Systems 8,edDSTouretzky,|
ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition|
Accounting for uncertainty in observations: A new paradigm for robust speech recognition|
""Mixtures of local linear su spaces for face recognition","|
Event-Coupled Hidden Markov Models|
Signal-space characterization of iterative decoding|
Eds|).  Special issue on codes and graphs and iterative algorithms. 
Analysis of an iterative dynamic programming approach to 2-d phase unwrapping|
Algonquin: Iterating laplace's method to remove multiple types of acoustic distortion for robust speech recognition,|
Advances in algorithms for inference and learning in complex probability models for vision,|
Loeliger "Factor Graphs and the Sum-Product Algorithm",|
Cubic spline interpolation to full resolution in Adobe Photoshop loses the sharp edges, (|
Convolutional factor graphs as probabilistic models|
Fast, Large-Scale Transformation-Invariant Clustering|
Local Probability Propagation for Factor Analysis|
Flexible models: A powerful alternative to exemplars and explicit models|
A Factorized Variational Technique for Phase Unwrapping in Markov Random Field|
Unwrapping phase images by propagating probabilities across graphs|
Transformed Hidden Markov Models: Estimating Mixture Models of Images and Inferring Spatial Transformations in Video Sequence|
Probability propagation and iterative decoding|Factor graphs and the sum-product algorithm. 
Graphical models for pattern classification, data compression and channel coding|
\Dynamic transformed mixtures of Gaussians,"|
Factor graphs: A unification of directed and undirected graphical models|
Jr| Unwrapping phase images by propagating probabilities across graphs. 
