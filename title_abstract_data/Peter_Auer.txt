Tracking the Best Disjunction| Abstract Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions.  This algorithm (called Winnow) keeps one weight for each of the n variables and does multiplicative updates to its weights.  We develop a randomized version of Winnow and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time.  In this case a possible target disjunction schedule T is a sequence of disjunctions (one per trial) and the shift size is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence.  We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples.  This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version.  However the amortized analysis needed for obtaining worstcase mistake bounds requires new techniques.  In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term.  By combining the tracking capability with existing applications of Winnow we are able to enhance these applications to the shifting case as well. 
Gambling in a rigged casino: The adversarial multi-armed bandit problem| Abstract In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. 
Simulating access to hidden information while learning| Abstract We introduce a new technique which enables a learner without access to hidden information to learn nearly as well as a learner with access to hidden information.  We apply our technique to solve an open problem of Maass and Tur'an [18], showing that for any concept class F , the least number of queries sufficient for learning F by an algorithm which has access only to arbitrary equivalence queries is at most a factor of 1= log 2 (4=3) more than the least number of queries sufficient for learning F by an algorithm which has access to both arbitrary equivalence queries and membership queries.  Previously known results imply that the 1= log 2 (4=3) in our bound is best possible.  We describe analogous results for two generalizations of this model to function learning, and apply those results to bound the difficulty of learning in the harder of these models in terms of the difficulty of learning in the easier model.  We bound the difficulty of learning unions of k concepts from a class F in terms of the difficulty of learning F .  We bound the difficulty of learning in a noisy environment for deterministic algorithms in terms of the difficulty of learning in a noise-free environment.  We apply a variant of our technique to develop an algorithm transformation that allows probabilistic learning algorithms to nearly optimally cope with noise.  A second variant enables us to improve a general lower bound of Tur'an [19] for the PAC-learning model (with queries).  Finally, we show that logarithmically many membership queries never help to obtain computationally efficient learning algorithms. 
Learning of Depth Two Neural Networks with Constant Fan-in at the Hidden Nodes| Abstract We present algorithms for learning depth two neural networks where the hidden nodes are threshold gates with constant fan-in.  The transfer function of the output node might be more general: we have results for the cases when the threshold function, the logistic function or the identity function is used as the transfer function at the output node.  We give batch and on-line learning algorithms for these classes of neural networks and prove bounds on the performance of our algorithms.  The batch algorithms work for real valued inputs whereas the on-line algorithms assume that the inputs are discretized.  The hypotheses of our algorithms are essentially also neural networks of depth two.  However, their number of hidden nodes might be much larger than the number of hidden nodes of the neural network that has to be learned.  Our algorithms can handle such a large number of hidden nodes since they rely on multiplicative weight updates at the output node, and the performance of these algorithms scales
The Nonstochastic Multiarmed Bandit Problem| Abstract.  In the multiarmed
Approximating Hyper-Rectangles: Learning and Pseudo-Random Sets| Abstract The PAC learning of rectangles has been studied because they have been found experimentally to yield excellent hypotheses for several applied learning problems.  Also, pseudorandom sets for rectangles have been actively studied recently because (i) they are a subproblem common to the derandomization of depth-2 (DNF) circuits and derandomizing Randomized Logspace, and (ii) they approximate the distribution of n independent multivalued random variables.  We present improved upper bounds for a class of such problems of "approximating" high-dimensional rectangles that arise in PAC learning and pseudorandomness. 
An Improved On-line Algorithm for Learning Linear Evaluation Functions| Abstract We improve and extend results on a learning model where an algorithm has to make a sequence of choices based on an evaluation function [Lon97].  This evaluation function has to be learned on-line from partial information and is assumed to be linear.  The main innovation of this paper is the introductionand analysis of a new kind of on-line algorithm which is "adaptively conservative".  This algorithm changes its current hypothesis only if the hypothesis is substantially wrong.  The analysis of this algorithm establishes performance bounds which depend more directly on the quality of the best off-line approximation of the evaluation function.  This improves and unifies previous results. 
On Learning from Ambiguous Information| Abstract We investigate a variant of the Probably Almost Correct learning model where the learner has to learn from ambiguous information.  The ambiguity is introduced by assuming that the learner does not receive single instances with their correct labels as training data, but that the learner receives tuples of instances where a tuple has a negative label if all instances of the tuple should be labeled as negative and a tuple has a positive label if at least one instance of the tuple should be labeled as positive.  Thus a positive tuple is ambiguous since it is not known which of its instances is a positive instance. 
Degree of Approximation Results for Feedforward Networks Approximating Unknown Mappings and Their Derivatives| Abstract Recently Barron (1993) has given rates for hidden layer feedforward networks with sigmoid activation functions approximating a class of functions satisfying a certain smoothness condition.  These rates do not depend on the dimension of the input space.  We extend Barron's results to feedforward networks with possibly non-sigmoid activation functions approximating mappings and their derivatives simultaneously.  Our conditions are similar but not identical to Barron's, but we obtain the same rates of approximation, showing that the approximation error decreases at rates as fast as n\Gamma 1 2 , where n is the number of hidden units.  The dimension of the input space appears only in the constants of our bounds. 
Adaptive and Self-Confident On-Line Learning Algorithms| Abstract Most of the performance bounds for on-line learning algorithms are proven assuming a constant learning rate.  To optimize these bounds, the learning rate must be tuned based on quantities that are generally unknown, as they depend on the whole sequence of examples.  In this paper we show that essentially the same optimized bounds can be obtained when the algorithms adaptively tune their learning rates as the examples in the sequence are progressively revealed.  Our adaptive learning rates apply to a wide class of on-line algorithms, including p-norm algorithms for generalized linear regression and Weighted Majority for linear regression with absolute loss.  We emphasize that our adaptive tunings are radically different from previous techniques, such as the so-called doubling trick.  Whereas the doubling trick restarts the on-line algorithm several times using a constant learning rate for each run, our methods save information by changing the value of the learning rate very smoothly.  In fact, for Weighted Majority over a finite set of experts our analysis provides a better leading constant than the doubling trick. 
Finite-time Analysis of the Multiarmed Bandit Problem| Abstract Reinforcement learning policies face the exploration versus exploitation dilemma, i. e.  the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible.  A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times.  One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem.  Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays.  Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others.  In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and ecient policies, and for all reward distributions with bounded support. 
Why Students Don't Ask Questions| Abstract We analyse the number of questions which a rational student will ask in a learning situation, depending on his or her objective.  For this we propose a formal learning model and two possible objectives of the student.  In this learning model material is presented to the student in small bits, the student may ask arbitrary yes-no questions about the material, and occasionally the teacher will query the student to access his understanding of the material.  In the first scenario that we will consider, questions asked by the student are regarded as faults.  The objective of the student is to minimize the number of questions that he asks plus the number of incorrect answers that he gives to the teacher's queries.  The result of our analysis is that in such a scenario a student will ask rather few questions.  In the second scenario the student's objective is to minimize the number of incorrectly answered queries and to be ecient with her learning time.  We will argue that there are cases in which a student who asks no questions will need much more time to learn than a student who asks questions. 
Learning Nested Differences in the Presence of Malicious Noise| Abstract We investigate the learnability of nested differences of intersectionclosed classes in the presence of malicious noise.  Examples of intersectionclosed classes include axis-parallel rectangles, monomials, linear subspaces, and so forth.  We present an on-line algorithm whose mistake bound is optimal in the sense that there are concept classes for which each learning algorithm (using nested differences as hypotheses) can be forced to make at least that many mistakes.  We also present an algorithm for learning in the PAC model with malicious noise.  Surprisingly enough, the noise rate tolerable by these algorithms does not depend on the complexity of the target class but depends only on the complexity of the underlying intersection-closed class. 
On-line Learning of Rectangles in Noisy Environments| Abstract We investigate the implications of noise in the equivalence query model.  Besides some results for general target and hypotheses classes, we prove bounds on the learning complexity of d-dimensional rectangles (of size at most n d ) in the case where only rectangles are allowed as hypotheses.  Our noise model assumes that a certain fraction of the examples is noisy.  We show that d-dimensional rectangles are learnable if and only if the fraction of noisy examples is less than 1=(d+ 1), where learnable means that the learner can learn the target by a finite number of examples.  Besides this structural result we present an algorithm which learns rectangles in poly( d log n 1\Gamma r(2d+1) ) time using O( d 3 log n (1\Gamma r(2d+1)) 2 ) examples if the fraction of noise r is less than 1 2d+1 .  As a related result we prove for the noise-free case that the number of examples necessary to learn is at least \Omega( d 2 log d log n), where the best known upper bound on the learning complexity is O(d 2 log n). 
The Perceptron Algorithm Versus Winnow: Linear Versus Logarithmic Mistake Bounds when Few Input Variables are Relevant (Technical Note)| Abstract We give an adversary strategy that forces the Perceptron algorithm to make \Omega(kN ) mistakes in learning monotone disjunctions over N variables with at most k literals.  In contrast, Littlestone's algorithm Winnow makes at most O(k log N) mistakes for the same problem.  Both algorithms use thresholded linear functions as their hypotheses.  However, Winnow does multiplicative updates to its weight vector instead of the additive updates of the Perceptron algorithm.  In general, we call an algorithm additive if its weight vector is always a sum of a fixed initial weight vector and some linear combination of already seen instances.  Thus, the Perceptron algorithm is an example of an additive algorithm.  We show that an adversary can force any additive algorithm to make (N +k\Gamma 1)=2 mistakes in learning a monotone disjunction of at most k literals.  Simple experiments show that for k N , Winnow clearly outperforms the Perceptron algorithm also on nonadversarial random data. 
Worst-Case Analysis of the Bandit Problem| Abstract The multi-armed bandit is a classical problem in the area of sequential decision theory and has been studied under a variety of statistical assumptions.  In this work we investigate the bandit problem from a purely worst-case standpoint.  We present a randomized algorithm with an expected total reward of G\Gamma O(G 4=5 K 6=5 ) (disregarding log factors), where K is the number of arms and G is the (unknown) total reward of the best arm.  Our analysis holds with no assumptions whatsoever on the way rewards are generated, other than being independent of the algorithm's randomization.  Our results can also be interpreted as a novel extension of the on-line prediction model, an intensively studied framework in learning theory. 
Exponentially many local minima for single neurons| Abstract We show that for a single neuron with the logistic function as the transfer function the number of local minima of the error function based on the square loss can grow exponentially in the dimension. 
Weak Hypotheses and Boosting for Generic Object Detection and Recognition| Abstract.  In this paper we describe the first stage of a new learning system for object detection and recognition.  For our system we propose Boosting [5] as the underlying learning technique.  This allows the use of very diverse sets of visual features in the learning process within a common framework: Boosting --- together with a weak hypotheses finder --may choose very inhomogeneous features as most relevant for combination into a final hypothesis.  As another advantage the weak hypotheses finder may search the weak hypotheses space without explicit calculation of all available hypotheses, reducing computation time.  This contrasts the related work of Agarwal and Roth [1] where Winnow was used as learning algorithm and all weak hypotheses were calculated explicitly.  In our first empirical evaluation we use four types of local descriptors: two basic ones consisting of a set of grayvalues and intensity moments and two high level descriptors: moment invariants [8] and SIFTs [12].  The descriptors are calculated from local patches detected by an interest point operator.  The weak hypotheses finder selects one of the local patches and one type of local descriptor and efficiently searches for the most discriminative similarity threshold.  This differs from other work on Boosting for object recognition where simple rectangular hypotheses [22] or complex classifiers [20] have been used.  In relatively simple images, where the objects are prominent, our approach yields results comparable to the state-of-the-art [3].  But we also obtain very good results on more complex images, where the objects are located in arbitrary positions, poses, and scales in the images.  These results indicate that our flexible approach, which also allows the inclusion of features from segmented regions and even spatial relationships, leads us a significant step towards generic object recognition. 
On the Complexity of Function Learning| Abstract The majority of results in computational learning theory are concerned with concept learning, i. e.  with the special case of function learning for classes of functions with range f0; 1g.  Much less is known about the theory of learning functions with a larger range such as IN or IR.  In particular relatively few results exist about the general structure of common models for function learning, and there are only very few nontrivial function classes for which positive learning results have been exhibited in any of these models.  We introduce in this paper the notion of a binary branching adversary tree for function learning, which allows us to give a somewhat surprising equivalent characterization of the optimal learning cost for learning a class of real-valued functions (in terms of a max-min definition which does not involve any "learning" model).  Another general structural result of this paper relates the cost for learning a union of function classes to the learning costs for the individual function classes.  Furthermore, we exhibit an efficient learning algorithm for learning convex piecewise linear functions from IR d into IR.  Previously, the class of linear functions from IR d into IR was the only class of functions with multidimensional domain that was known to be learnable within the rigorous framework of a formal model for on-line learning.  Finally we give a sufficient condition for an arbitrary class F of functions from IR into IR that allows us to learn the class of all functions that can be written as the pointwise maximum of k functions from F .  This allows us to exhibit a number of further nontrivial classes of functions from IR into IR for which there exist efficient learning algorithms. 
Theory and Applications of Agnostic PAC-Learning with Small Decision Trees| Abstract We exhibit a theoretically founded algorithm T2 for agnostic PAC-learning of decision trees of at most 2 levels, whose computation time is almost linear in the size of the training set.  We evaluate the performance of this learning algorithm T2 on 15 common "real-world" datasets, and show that for most of these datasets T2 provides simple decision trees with little or no loss in predictive power (compared with C4. 5).  In fact, for datasets with continuous attributes its error rate tends to be lower than that of C4. 5.  To the best of our knowledge this is the first time that a PAC-learning algorithm is shown to be applicable to "real-world" classification problems.  Since one can prove that T2 is an agnostic PAClearning algorithm, T2 is guaranteed to produce close to optimal 2-level decision trees from sufficiently large training sets for any (!) distribution of data.  In this regard T2 differs strongly from all other learning algorithms that are considered in applied machine learning, for which no guarantee can be given about their performance on new datasets.  We also demonstrate that this algorithm T2 can be used as a diagnostic tool for the investigation of the expressive limits of 2-level decision trees.  Finally, T2, in combination with new bounds on the VC-dimension of decision trees of bounded depth that we derive, provides us now for the first time with the tools necessary for comparing learning curves of decision trees for "real-world" datasets with the theoretical estimates of PAClearning theory. 
On-line Learning with Malicious Noise and the Closure Algorithm| Abstract We investigate a variant of the on-line learning model for classes of f0; 1gvalued functions (concepts) in which the labels of a certain amount of the input instances are corrupted by adversarial noise.  We propose an extension of a general learning strategy, known as "Closure Algorithm", to this noise model, and show a worst-case mistake bound of m+ (d + 1)K for learning an arbitrary intersection-closed concept class C, where K is the number of noisy labels, d is a combinatorial parameter measuring C's complexity, and m is the worst-case mistake bound of the Closure Algorithm for learning C in the noise-free model.  For several concept classes our extended Closure Algorithm is efficient and can tolerate a noise rate up to the information-theoretic upper bound.  Finally, we show how to efficiently turn any algorithm for the on-line noise model into a learning algorithm for the PAC model with malicious noise. 
Generic object recognition with boosting|
Ageing of the labour force in OECD countries: economic and social consequences', International Labor Organisation, employment paper, Feb,|
Pseudorandomness and learning of combinatorial rectangles|
Structural Results About On-line Learning Models With and Without Queries|
The InfoSky visual explorer: exploiting hierarchical structure and document similarities|
A Boosting Approach to Multiple Instance Learning|
Reducing Communication for Distributed Learning in Neural Networks|
`The Resilience of the Long-Term Employment Relationship: Evidence from the Industrialised Countries',|
Using Upper Confidence Bounds for Online Learning|
On Learning From Multi-Instance Examples: Empirical Evaluation of a Theoretical Approach|
The p-delta rule for parallel perceptrons|
On-line prediction of depth two linear threshold circuits|
Degree of approximation results for feedforward network approximating unknown functions and their derivatives|
Tracking the best disjunction| Journal of Machine Learning, Special issue on concept drift. 
The perceptron vs| winnow: Linear vs.  logarithmic mistake bounds when few input variables are relevant. 
On learning from mult-instance examples: Empirical evaluation of a theoretical approach|
Learning without explanations nearly as well as with them,|
Some hitting probabilities of random walks on ZZ 2|
Is a rhythm-based typology possible? A study of the role of prosody in phonological typology|
Bianchi On-Line Learning with Malicious Noise and the Closure Algorithm|
Tracking in a multiuser augmented reality system|
The p-Delta Learning Rule for Parallel Perceptrons|" submitted for publication. 
On the prosody and syntax of turn-continuations|
