A Neural Network Model of the Cortico-Hippocampal Interplay: Contexts and Generalization| \Lambda.  Abstract We present computer simulations of a neural network comprising two sensory pathways, each built of preprocessing and associative memory modules perhaps corresponding to a primary and higher sensory area, and a hippocampal area that serves as an integration or fusion zone during learning and retrieval of polymodal information.  The network is able to store unimodal details about a complex environment in local assemblies restricted to the corresponding associative memory, whereas a representation of the simultaneous occurences of several stimuli is constituted and stored in a self-organizing manner in the hippocampal area.  This can be viewed as storage of a 'particular context'.  If many stimulus constellations are presented to the network during learning, it may over-learn, that is, the hippocampal area can no longer distinguish particular situations, but instead represents more general contexts or categories, a given environmental situation may belong to.  Feedback from the hippocampal region to association areas can restore particular memories; it can still act as a threshold control gate raising sensitivity in the appropriate cortex regions when it is overloaded. 
Nonlinear analysis of orientation tuning: Stationary properties of simple cells in V1| Abstract This paper presents a new approximation method for localized ("bumpy") steady state activation patterns in truly nonlinear neural field equations.  The method is applied to models for orientation tuning in V1 simple cells where it allows to study the impact of nonlinear rate-functions on tuning properties and a derivation of explicit formulas for response amplitudes and tuning widths in dependence of network parameters and stimulus properties. 
Max-Planck-Institut fur Mathematik in den Naturwissenschaften Leipzig Complete synchronization in coupled neuromodules of different types| Abstract We discuss the parametrized dynamics of two coupled recurrent neural networks comprising either additive sigmoid neurons in discrete time or biologically more plausible time-continuous leaky-integrate-and-fire cells.  General conditions for the existence of synchronized activity in such networks are given, which guarantee that corresponding neurons in both coupled sub-networks evolve synchronously.  It is, in particular, demonstrated that even the coupling of totally different network structures can result in complex dynamics constrained to a synchronization manifold M .  For additive sigmoid neurons the synchronized dynamics can be periodic, quasiperiodic as well as chaotic, and its stability can be determined by Lyapunov exponent techniques.  For leaky-integrate-and-fire cells synchronized orbits are typically periodic, often with an extremely long period duration.  In addition to synchronized attractors there often co-exist asynchronous periodic, quasiperiodic and even chaotic attractors. 
Cell Assemblies, Associative Memory and Temporal Structure in Brain Signals \Lambda| Abstract: In this work we discuss Hebb's old ideas about cell assemblies in the light of recent results concerning temporal structure and correlations in neural signals.  We want to give a conceptual, necessarily only rough picture, how ideas about `binding by synchronisation', `synfire chains', `local and global assemblies', `short and long term memory' and `behaviour' might be integrated into a coherent model of brain functioning based on neuronal assemblies. 
Gamma-oscillations support optimal retrieval in associative memories of two-compartment neurons| Abstract Theoretical studies concerning iterative retrieval in conventional associative memories suggest that cortical gamma-oscillations may constitute sequences of fast associative processes each restricted to a single period.  By providing a rhythmic threshold modulation suppressing cells that are uncorrelated with a stimulus, interneurons significantly contribute to this process.  This hypothesis is tested in the present paper utilizing a network of two-compartment model neurons developed by Pinsky and Rinzel.  It is shown that gamma-oscillations can simultaneously support an optimal speed for single pattern retrieval, an optimal repetition frequency for consecutive retrieval processes, and a very high memory capacity. 
Associative memory in a pair of cortical cell groups with reciprocal projections| Abstract We examine the functional hypothesis of bidirectional associative memory in a pair of reciprocally projecting cortical cell groups.  Our simulation model features twocompartment neurons and synaptic weights formed by Hebbian learning of pattern pairs.  After stimulation of a learned memory in one group we recorded the network activation.  At high synaptic memory load (0. 14 bit/synapse) we varied the number of cells receiving stimulation input (input activity).  The network "recalled" patterns by synchronized regular gamma spiking.  Stimulated cells also expressed bursts that fascilitated the recall with low input activity.  Performance was evaluated for onestep retrieval based on monosynaptic transmission expressed after ca.  35ms, and for bidirectional retrieval involving iterative activity propagation.  One-step retrieval performed comparably to the technical Willshaw model with small input activity, but worse in other cases.  In 80 % of the trials with low one-step performance iterative retrieval improved the result.  It achieved higher overall performance after recall times of 60--260ms. 
Generalized and Partial Synchronization of Coupled Neural Networks| Abstract Synchronization of neural signals has been proposed as a temporal
Modeling studies on the computational function of fast temporal structure in cortical circuit activity \Lambda| Abstract The interplay between modeling and experimental studies can support the exploration of the function of neuronal circuits in the cortex.  We exemplify such an approach with a study on the role of spike timing and gamma-oscillations in associative memory in strongly connected circuits of cortical neurons.  It is demonstrated how associative memory studies on different levels of abstraction can specify the functionality to be expected in real cortical neuronal circuits.  In our model overlapping random configurations of sparse cell populations correspond to memory items that are stored by simple Hebbian coincidence learning.  This associative memory task will be implemented with biophysically well tested compartmental neurons developed by Pinsky and Rinzel [Pinsky and Rinzel, 1994].  We run simulation experiments to study memory recall in two network architectures: one interconnected pool of cells, and two reciprocally connected pools.  When recalling a memory by stimulating a spatially overlapping set of cells, the completed pattern is coded by an event of synchronized single spikes occurring after 25-60ms.  These fast associations are performed even at a memory load corresponding to the memory capacity of optimally tuned formal associative networks (? 0:1 bit/synapse).  With tonic stimulation or feedback loops in the network the neurons fire periodically in the gamma-frequency range (20-80 Hz).  With fast changing inputs memory recall can be switched between items within a single gamma cycle.  Thus, oscillation is not a primary coding feature necessary for associative memory.  However, it accompanies reverberatory feedback providing an improved iterative memory recall completed after a few gamma cycles (60-260ms).  However, in the bidirectional architecture reverberations do not express in a rigid phase locking between the pools.  For small stimulation sets bursting occured in these cells acting as a supportive mechanism for associative memory. 
On the Relation Between Neural Modelling and Experimental Neuroscience \Lambda| Abstract This paper discusses the relation of theory and experiment in neuroscience exemplified by three assumptions often made in models of coherent activation in the cortex: basic feature-coding oscillators, phase-coding and global binding of whole objects.  Apparently these assumptions are not very well supported by the experimental evidence.  We propose that it is the single synchronized population-burst that matters: spikes of feature-coding cells are temporally clustered in our opinion by recurrent associative processes.  In each burst a single stimulus is processed (if there are several).  Synchronization is restricted to cortical sites which physically interact.  These principles are illustrated by computer simulations. 
Orientation Tuning Properties of Simple Cells in Area V1 Derived from an Approximate Analysis of Nonlinear Neural Field Models| Abstract We present a general approximation method for the mathematical analysis of spatially localized steady state solutions in nonlinear neural field models.  These models comprise several layers of excitatory and inhibitory cells.  Coupling kernels between and inside layers are assumed to be Gaussian shaped.  In response to spatially localized (i. e.  tuned) inputs such networks typically reveal stationary localized activity profiles in the different layers.  Qualitative properties of these solutions, like response amplitudes and tuning widths, are approximated for a whole class of nonlinear rate-functions that obey a power law above some threshold and that are zero below.  A special case of these functions is the semilinear function, which is commonly used in neural field models.  The method is then applied to models for orientation tuning in cortical simple cells: firstly, to the one-layer model with "difference of Gaussians" connectivity kernel developed by Carandini and Ringach (1997) as an abstraction of the biologically detailed simulations of Somers, Nelson, and Sur (1995); secondly, to a two-field model comprising excitatory and inhibitory cells in two separate layers.  Under certain conditions both models have the same steady states.  Comparing simulations of the field models and results derived from the approximation method we find that the approximation well predicts the tuning behavior of the full model.  Moreover, explicit formulas for approximate amplitudes and tuning widths in response to changing input strength are given and checked numerically.  Comparing the network behavior for different nonlinearities, we find that the only rate-function (from the class of functions under study) that leads to constant tuning widths and \Lambda Neural Computation, in press a linear increase of firing rates in response to increasing input is the semilinear function.  For other nonlinearities the qualitative network response depends on whether the model neurons operate in a convex (e. g. , x 2 ) or concave (e. g. , sqrt(x)) regime of their rate-function.  In the first case tuning gradually changes from input-driven at low input strength (broad tuning strongly depending on the input and roughly linear amplitudes in response to input strength) to recurrently-driven at moderate input strength (sharp tuning, supralinear increase of amplitudes in response to input strength).  For concave rate-functions the network reveals stable hysteresis between a state at low firing rates and a tuned state at high rates.  This means, the network can "memorize" tuning properties of a previously shown stimulus.  Sigmoid rate-functions can combine both effects.  In contrast to the Carandini-Ringach model the two-field model further reveals oscillations with typical frequencies in the beta- and gamma-range, when the excitatory and inhibitory connections are relatively strong.  This suggests a rhythmic modulation of tuning properties during cortical oscillations. 
ITERATIVE RETRIEVAL IN ASSOCIATIVE MEMORIES BY THRESHOLD CONTROL OF DIFFERENT NEURAL MODELS \Lambda| We investigate the retrieval properties of Hebbian auto-associative memories in the limit of sparse coding.  Appropriately chosen threshold control strategies in finite size associative memories increase the completion capacity for iterative retrieval (and even for the very fast two-step retrieval) above the asymptotic capacity for extremely large networks.  We relate these results to a biologically motivated network consisting of excitatorily coupled cells which are controlled by a globally acting inhibitory interneuron.  Choosing a homogenous coupling matrix and different excitatory single neuron types, we find in an explicit numerical comparison, that the global behavior of spiking neurons in general is different from rate-function and probabilistic binary units.  We also show that a network of spiking neurons with Hebbian coupling matrix is able to complete and segregate several distorted patterns that are simultaneously presented at the input.  In this case the global dynamics falls into rhythmic activity and processes one input pattern per period, a behavior that might be related to rhythmic cortical activity as found, for example, in the visual cortices of cats and monkeys. 
Generalized types of synchronization in networks of spiking neurons| Abstract The synchronization of neural signals has been proposed as a temporal coding scheme in distributed cortical networks.  Theoretical studies in that direction mainly focused on the synchronization of coupled oscillatory subsystems.  In the present work we show that several complex types of synchronization previously described for graded response neurons appear similarly also in biologically realistic networks of spiking and compartmental neurons.  This includes synchronized complex spatio-temporal behavior, partial and generalized synchronization.  The results suggest a similarly rich spatio-temporal behavior in real neural systems and may guide experimental research towards the study of complex modes of synchronization and their neuromodulation. 
Complete Synchronization in Coupled Neuromodules of Different Types| Abstract We discuss the parametrized dynamics of two coupled recurrent neural networks comprising either additive sigmoid neurons in discrete time or biologically more plausible time-continuous leaky-integrateand-#re cells.  General conditions for the existence of synchronized activity in such networks are given, which guarantee that corresponding neurons in both coupled sub-networks evolve synchronously.  It is, in particular, demonstrated that even the coupling of totally different network structures can result in complex dynamics constrained to a synchronization manifold M .  For additive sigmoid neurons the synchronized dynamics can be periodic, quasiperiodic as well as chaotic, and its stability can be determined by Lyapunov exponent techniques.  For leaky-integrate-and-#re cells synchronized orbits are typically periodic, often with an extremely long period duration.  In addition to synchronized attractors there often co-exist asynchronous periodic, quasiperiodic and even chaotic attractors. 
Associative Memory in Networks of Spiking Neurons| Abstract Here we develop and investigate a computational model of a network of cortical neurons on the base of biophysically well constrained and tested two-compartmental neurons developed by Pinsky and Rinzel [Pinsky and Rinzel, 1994].  To study associative memory we connect a pool of cells by a structured connectivity matrix.  The connection weights are shaped by simple Hebbian coincidence learning using a set of spatially sparse patterns.  We study the neuronal activity processes following an external stimulation of a stored memory.  In two series of simulation experiments we explore the effect of different classes of external input, tonic and flashed stimulation: With tonic stimulation the addressed memory is attractor of the network dynamics.  The memory is displayed rhythmically, coded by phase locked bursts or regular spikes.  The participating neurons have rhythmic activity in the gamma-frequency range (30-80 Hz).  If the input is switched from one memory to another, the network activity can follow this change within one or two gamma cycles.  Unlike similar models in the literataure, we studied the range of high memory capacity (in the order of 0. 1 bit/synapse), comparable to optimally tuned formal associative networks.  We explored the robustness of efficient retrieval varying the memory load, the excitation/inhibition parameters, and background activity.  A stimulation pulse applied to the identical simulation network can push away ongoing network activity and trigger a phase-locked association event within one gamma period.  Unlike with tonic stimulation, the memories are not attractors: After one association process the network activity moves to other states.  Applying in close succession pulses addressing different memories one can switch through the space of memory patterns.  The readout speed can be increased up to the point where in every gamma cycle another pattern is displayed.  With pulsed stimulation bursts become relevant for coding, their occurence can be used to discriminate retrieval processes from background activity. 
fur Mathematik in den Naturwissenschaften Leipzig Generalized Types of synchronization in networks of spiking neurons| Abstract The synchronization of neural signals has been proposed as atemporal coding scheme in distributed cortical networks.  Theoretical studies in that direction mainly focused on the synchronization ofcoupled oscillatory subsystems.  In the presentwork weshow that several complex types of synchronization previously described for gradedre- sponse neurons appear similarly also in biologically realistic networks of spiking and compartmental neurons.  This includes synchronized complexspatio-1798 oral behavior, partial and generalized synchronization.  The results suggest a similarly rich spatio- -27 oral behavior in real neural systems and may guide experimental research towards the study of complex modes of synchronization and their neuromod- ulation. 
Dynamics of spatio-temporal patterns in associative networks of spiking neurons| Abstract This paper studies dynamical properties of spatio-temporal pattern sequences ("synfire chains") in associative networks of spiking neurons.  Employing postsynaptic potentials with a finite rise-time, the replay speed of stored sequences can be controled by unspecific background signals.  In addition, the speed also depends on the number of co-activated sequences, but balanced inhibition can prevent this dependency.  An implicit equation is derived and solved numerically which relates the speed to the network parameters.  Simulations reveal instabilities for low and high control signals, which are traced back to four different destabilizing mechanisms. 
Synchronous Chaos in Highdimensional Modular Neural Networks| Abstract The relationship between certain types of highdimensional neural
Analysis of spatio-temporal patterns in associative networks of spiking neurons \Lambda| Abstract: A neural network is presented that stores spatio-temporal patterns (synfire
How imprecise is neuronal synchronization?| Abstract We investigate the contribution of single cells to collective gamma-oscillations in a network of spiking neurons subject to an inhibitory activity control.  In contrast to many earlier studies emphasizing a high precision in spike timing, cell firing is rather unreliable in our model.  Nonetheless, we qualitatively reproduce many experimental findings, some of them previously unexplored in modeling studies. 
Finite state automata resulting from temporal information maximization| Abstract We extend Linkser's Infomax principle for feedforward neural networks to a measure for stochastic interdependence that captures spatial and temporal signal properties in recurrent systems.  This measure ---"stochastic interaction"--- quantifies the Kullback-Leibler divergence of a Markov chain from a product of split chains for the single unit processes.  For unconstrained Markov chains, the maximization of stochastic interaction also called "Temporal Infomax", has been previously shown to result in almost deterministic dynamics.  The present work considers Temporal Infomax on constrained Markov chains, where part of the units are clamped to prescribed stochastic processes providing external input to the system.  Surprisingly, Temporal Infomax in that case leads to finite state automata, either completely deterministic or at most weakly non-deterministic.  Transitions between internal states of these systems are almost perfectly predictable given the complete current state and the input, but the activity of each single unit alone is virtually random.  The results are demonstrated by means of computer simulations and confirmed analytically.  We furthermore relate them to experimental data concerning the correlation dynamics and functional connectivities observed in multiple electrode recordings. 
Iterative Retrieval in Associative Memories by Threshold Control of Different Neural Models|
Generalized and Partial Synchronization in Coupled Neural Networks|
On the relation between neural modeling and experimental neuroscience|
Neural Field Model of Receptive Field Restructuring in Primary Visual Cortex|
A neural network model of the cortico- hippocampal interplay: Contexts and generalization|
Bidirectional completion of Cell Assemblies in the cortex|
Hippocampal two-stage Learning and Memory Consolidation|
Controlling the Speed of Synfire Chains|
Synchronisation und Assoziation in Neuronalen Netzen|
Associative memory in a pair of cortical cell groups with reciprocal connections|
Cell assemblies, associative memory and temporal structure in brain signals|
Dependence of oscillation frequency on stimulus parameters in primary visual cortex of monkeys: simulations and experimental results|
Spatial and temporal stochastic interaction in neuronal assemblies|
Dynamical properties of strongly interacting Markov chains|
Synfire Graphs: From Spike Patterns to Automata of Spiking Neurons|
Controlling the Speed of Synfire Chains, in: C von der Malsburg,|
in press)| Neural field model of receptive field restructuring in primary visual cortex. 
Dynamic Approximation of Spatiotemporal Receptive Fields in Nonlinear Neural Field Models|
Pattern formation in intracortical neuronal field,|
private communication, and Reduction of Large Networks of Nonlinear Maps to Small Sets of Prototypical Equations,|
"Hippocampal sharp waves, theta-rhythm and their relation to learning - a numerical study|". 
