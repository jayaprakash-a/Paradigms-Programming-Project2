Representations and Solutions for Game-Theoretic Problems| Abstract A system with multiple interacting agents (whether artificial or human) is often best analyzed using game-theoretic tools. 
In Proceedings of the Fourteenth International Conference on Machine Learning (| Abstract The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies.  Existing classification schemes which ignore the hierarchical structure and treat the topics as separate classes are often inadequate in text classification where the there is a large number of classes and a huge number of relevant features needed to distinguish between them.  We propose an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree.  As we show, each of these smaller problems can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand.  This set of relevant features varies widely throughout the hierarchy, so that, while the overall relevant feature set may be large, each classifier only examines a small subset.  The use of reduced feature sets allows us to utilize more complex (probabilistic) models, without encountering many of the standard computational and robustness difficulties. 
Structured Representation of Complex Stochastic Systems| Abstract This paper considers the problem of representing complex systems that evolve stochastically over time. 
Using Probabilistic Information in Data Integration| Abstract The goal of a mediator system is to provide users a uniform interface to the multitude of information sources.  To translate user queries, given in a mediated schema, to queries on the data sources, mediators rely on explicit mappings between the contents of the data sources and the relations in the mediated schema.  Thus far, contents of data sources were described qualitatively.  We describe the use of quantitative information in the form of probabilistic knowledge in mediator systems.  We consider several kinds of probabilistic information: information about overlap between collections in the mediated schema, coverage and completeness of the information sources, and degrees of overlap between information sources.  We address the problem of ordering accesses to multiple information sources, in order to maximize the likelihood of obtaining answers as early as possible.  We describe a declarative formalism for specifying these kinds of probabilistic information, and we propose algorithms for ordering the information sources.  Finally, we discuss a preliminary experimental evaluation of these algorithms on the domain of bibliographic sources available on the WWW. 
Probabilistic hierarchical clustering for biological data| ABSTRACT Biological data, such as gene expression profiles or protein sequences, is often organized in a hierarchy of classes, where the instances assigned to "nearby" classes in the tree are similar.  Most approaches for constructing a hierarchy use simple local operations, that are very sensitive to noise or variation in the data.  In this paper, we describe probabilistic abstraction hierarchies (PAH) [11], a general probabilistic framework for clustering data into a hierarchy, and show how it can be applied to a wide variety of biological data sets.  In a PAH, each class is associated with a probabilistic generative model for the data in the class.  The PAH clustering algorithm simultaneously optimizes three things: the assignment of data instances to clusters, the models associated with the clusters, and the structure of the abstraction hierarchy.  A unique feature of the PAH approach is that it utilizes global optimization algorithms for the last two steps, substantially reducing the sensitivity to noise and the propensity to local maxima.  We show how to apply this framework to gene expression data, protein sequence data, and HIV protease sequence data.  We also show how our framework supports hierarchies involving more than one type of data.  We demonstrate that our method extracts useful biological knowledge and is substantially more robust than hierarchical agglomerative clustering. 
A Game-Theoretic Classification of Interactive Complexity Classes| Abstract Game-theoretic characterizations of complexity classes have often proved useful in understanding the power and limitations of these classes.  One well-known example tells us that PSPACE can be characterized by two-person, perfect-information games in which the length of a played game is polynomial in the length of the description of the initial position [Chandra et al. , Journal of the ACM, 28 (1981), pp.  114--133].  In this paper, we investigate the connection between game theory and interactive computation.  We formalize the notion of a polynomially definable game system for the language L, which, informally, consists of two arbitrarily powerful players P 1 and P 2 and a polynomial-time referee V with a common input w.  Player P 1 claims that w 2 L, and player P 2 claims that w 62 L; the referee's job is to decide which of these two claims is true.  In general, we wish to study the following question: What is the effect of varying the system's game-theoretic properties on the class of languages recognizable by polynomially definable game systems? There are many possible game-theoretic properties that we could investigate in this context.  The focus of this paper is the question of what happens when one or both of the players P 1 and P 2 have imperfect information or imperfect recall.  We use polynomially definable game systems to derive new characterizations of the complexity classes NEXP and coNEXP.  We also derive partial results about other exponential complexity classes and isolate some intriguing open questions about the effects of imperfect information and imperfect recall.  These results make use of recent work on complexity-theoretic aspects of games, e. g. , [Koller et al. 
Utilities as Random Variables: Density Estimation and Structure Discovery| Abstract Decision theory does not traditionally include uncertainty over utility functions.  We argue that the a person's utility value for a given outcome can be treated as we treat other domain attributes: as a random variable with a density function over its possible values.  We show that we can apply statistical density estimation techniques to learn such a density function from a database of partially elicited utility functions.  In particular, we define a Bayesian learning framework for this problem, assuming the distribution over utilities is a mixture of Gaussians, where the mixture components represent statistically coherent subpopulations.  We can also extend our techniques to the problem of discovering generalized additivity structure in the utility functions in the population.  We define a Bayesian model selection criterion for utility function structure and a search procedure over structures.  The
Representation Dependence in Probabilistic Inference| Abstract Non-deductive reasoning systems are often representation dependent: representing the same situation in two different ways may cause such a system to return two different answers.  Some have viewed this as a significant problem.  For example, the principle of maximum entropy has been subjected to much criticism due to its representation dependence.  There has, however, been almost no work investigating representation dependence.  In this paper, we formalize this notion and show that it is not a problem specific to maximum entropy.  In fact, we show that any representation-independent probabilistic inference procedure that ignores irrelevant information is essentially entailment, in a precise sense.  Moreover, we show that representation independence is incompatible with even a weak default assumption of independence.  We then show that invariance under a restricted class of representation changes can form a reasonable compromise between representation independence and other desiderata, and provide a construction of a family of inference procedures that provides such restricted representation independence, using relative entropy. 
Nonuniform Dynamic Discretization in Hybrid Networks| Abstract We consider probabilistic inference in general hybrid networks, which include continuous and discrete variables in an arbitrary topology.  We reexamine the question of variable discretization in a hybrid network aiming at minimizing the information loss induced by the discretization.  We show that a nonuniform partition across all variables as opposed to uniform partition of each variable separately reduces the size of the data structures needed to represent a continuous function.  We also provide a simple but efficient procedure for nonuniform partition.  To represent a nonuniform discretization in the computer memory, we introduce a new data structure, which we call a Binary Split Partition (BSP) tree.  We show that BSP trees can be an exponential factor smaller than the data structures in the standard uniform discretization in multiple dimensions and show how the BSP trees can be used in the standard join tree algorithm.  We show that the accuracy of the inference process can be significantly improved by adjusting discretization with evidence.  We construct an iterative anytime algorithm that gradually improves the quality of the discretization and the accuracy of the answer on a query.  We provide empirical evidence that the algorithm converges. 
Max-norm Projections for Factored MDPs| Abstract Markov Decision Processes (MDPs) provide a coherent mathematical framework for planning under uncertainty. 
Stochastic simulation algorithms for dynamic probabilistic networks| Abstract Stochastic simulation algorithms such as likelihood weighting often give fast, accurate approximations to posterior probabilities in probabilistic networks, and are the methods of choice for very large networks.  Unfortunately, the special characteristics of dynamic probabilistic networks (DPNs), which are used to represent stochastic temporal processes, mean that standard simulation algorithms perform very poorly.  In essence, the simulation trials diverge further and further from reality as the process is observed over time.  In this paper, we present simulation algorithms that use the evidence observed at each time step to push the set of trials back towards reality.  The first algorithm, "evidence reversal" (ER) restructures each time slice of the DPN so that the evidence nodes for the slice become ancestors of the state variables.  The second algorithm, called "survival of the fittest" sampling (SOF), "repopulates" the set of trials at each time step using a stochastic reproduction rate weighted by the likelihood of the evidence according to each trial.  We compare the performance of each algorithm with likelihood weighting on the original network, and also investigate the benefits of combining the ER and SOF methods.  The ER/SOF combination appears to maintain bounded error independent of the number of time steps in the simulation. 
Discovering the Hidden Structure of Complex Dynamic Systems| Abstract Dynamic Bayesian networks provide a compact and natural representation for complex dynamic systems.  However, in many cases, there is no expert available from whom a model can be elicited.  Learning provides an alternative approach for constructing models of dynamic systems.  In this paper, we address some of the crucial computational aspects of learning the structure of dynamic systems, particularly those where some relevant variables are partially observed or even entirely unknown.  Our approach is based on the Structural Expectation Maximization (SEM) algorithm.  The main computational cost of the SEM algorithm is the gathering of expected sufficient statistics.  We propose a novel approximation scheme that allows these sufficient statistics to be computed efficiently.  We also investigate the fundamental problem of discovering the existence of hidden variables without exhaustive and expensive search.  Our approach is based on the observation that, in dynamic systems, ignoring a hidden variable typically results in a violation of the Markov property.  Thus, our algorithm searches for such violations in the data, and introduces hidden variables to explain them.  We provide empirical results showing that the algorithm is able to learn the dynamics of complex systems in a computationally tractable way. 
Workshop on Statistical Relational Learning and its Connections to Other Fields Workshop Co-chairs| Preface This workshop is the third in a series of workshops held in conjunction with AAAI and IJCAI.  The first workshop was held in July, 2000 at AAAI.  Notes from that workshop are available at http://robotics. stanford. edu/srl/.  The second workshop was held in July, 2003 at IJCAI.  Notes from that workshop are available at http://kdl. cs. umass. edu/srl2003/ There has been a surge of interest in this area.  The efforts have been diffused across a wide collection of sub-areas in computer science including machine learning, database management, and theoretical computer science.  The goal of this year's workshop is to reach out to related fields that have not participated in previous workshops.  Specifically, we seek to invite researchers in computer vision, spatial statistics, social network analysis, language modeling, and probabilistic inference to attend the workshop and give tutorials on the relational learning problems and techniques developed in their fields.  These fields have many years of experience in particular kinds of relational learning, and we hope that bringing these diverse communities together, we can all achieve a better understanding of the range of problems and methods that can be brought to bear on relational learning problems.  We'd like to give a big THANK YOU to the program committee.  Looking forward to a lively and productive workshop in Banff. 
Bayesian Fault Detection and Diagnosis in Dynamic Systems| Abstract This paper addresses the problem of tracking and diagnosing
Computing Factored Value Functions for Policies in Structured MDPs| Abstract Many large Markov decision processes (MDPs) can be represented compactly using a structured representation such as a dynamic Bayesian network.  Unfortunately, the compact representation does not help standard MDP algorithms, because the value function for the MDP does not retain the structure of the process description.  We argue that in many such MDPs, structure is approximately retained.  That is, the value functions are nearly additive: closely approximated by a linear function over factors associated with small subsets of problem features.  Based on this idea, we present a convergent, approximate value determination algorithm for structured MDPs.  The algorithm maintains an additive value function, alternating dynamic programming steps with steps that project the result back into the restricted space of additive functions.  We show that both the dynamic programming and the projection steps can be computed efficiently, despite the fact that the number of states is exponential in the number of state variables. 
Rich probabilistic models for gene expression| ABSTRACT Clustering is commonly used for analyzing gene expression data.  Despite their successes, clustering methods suffer from a number of limitations.  First, these methods reveal similarities that exist over all of the measurements, while obscuring relationships that exist over only a subset of the data.  Second, clustering methods cannot readily incorporate additional types of information, such as clinical data or known attributes of genes.  To circumvent these shortcomings, we propose the use of a single coherent probabilistic model, that encompasses much of the rich structure in the genomic expression data, while incorporating additional information such as experiment type, putative binding sites, or functional information.  We show how this model can be learned from the data, allowing us to discover patterns in the data and dependencies between the gene expression patterns and additional attributes.  The learned model reveals context-specific relationships, that exist only over a subset of the experiments in the dataset.  We demonstrate the power of our approach on synthetic data and on two real-world gene expression data sets for yeast.  For example, we demonstrate a novel functionality that falls naturally out of our framework: predicting the "cluster" of the array resulting from a gene mutation based only on the gene's expression pattern in the context of other mutations. 
A tractable probabilistic description logic| Abstract Knowledge representation languages invariably reflect a trade-off between expressivity and tractability.  Evidence suggests that the compromise chosen by description logics is a particularly successful one.  However, description logic (as for all variants of first-order logic) is severely limited in its ability to express uncertainty.  In this paper, we present P-CLASSIC, a probabilistic version of the description logic CLASSIC.  In addition to
Probabilistic Classification and Clustering in Relational Data| Abstract Supervised and unsupervised learning methods have traditionally focused on data consisting of independent instances of a single type.  However, many real-world domains are best described by relational models in which instances of multiple types are related to each other in complex ways.  For example, in a scientific paper domain, papers are related to each other via citation, and are also related to their authors.  In this case, the label of one entity (e. g. , the topic of the paper) is often correlated with the labels of related entities.  We propose a general class of models for classification and clustering in relational domains that capture probabilistic dependencies between related instances.  We show how to learn such models efficiently from data.  We present empirical results on two real world data sets.  Our experiments in a
Toward Optimal Feature Selection| Abstract In this paper, we examine a method for feature subset selection based on Information Theory.  Initially, a framework for defining the theoretically optimal, but computationally intractable, method for feature subset selection is presented.  We show that our goal should be to eliminate a feature if it gives us little or no additional information beyond that subsumed by the remaining features.  In particular, this will be the case for both irrelevant and redundant features.  We then give an efficient algorithm for feature selection which computes an approximation to the optimal feature selection criterion.  The conditions under which the approximate algorithm is successful are examined.  Empirical results are given on a number of data sets, showing that the algorithm effectively handles datasets with large numbers of features. 
Learning Probabilistic Relational Models| Abstract A large portion of real-world data is stored in commercial relational database systems.  In contrast, most statistical learning methods work only with "flat" data representations.  Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database.  This paper builds on the recent work on probabilistic relational models (PRMs), and describes how to learn them from databases.  PRMs allow the properties of an object to depend probabilistically both on other properties of that object and on properties of related objects.  Although PRMs are significantly more expressive than standard models, such as Bayesian networks, we show how to extend well-known statistical methods for learning Bayesian networks to learn these models.  We describe both parameter estimation and structure learning --- the automatic induction of the dependency structure in a model.  Moreover, we show how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets.  We present experimental results on both real and synthetic relational databases. 
Local Learning in Probabilistic Networks with Hidden Variables| Abstract Probabilistic networks, which provide compact descriptions of complex stochastic relationships among several random variables, are rapidly becoming the tool of choice for uncertain reasoning in artificial intelligence.  We show that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism similar to that used in neural networks.  We also extend the method to networks with intensionally represented distributions, including networks with continuous variables and dynamic probabilistic networks.  Because probabilistic networks provide explicit representations of causal structure, human experts can easily contribute prior knowledge to the training process, thereby significantly improving the learning rate.  Adaptive probabilistic networks (APNs) may soon compete directly with neural networks as models in computational neuroscience as well as in industrial and financial applications. 
Learning Probabilistic Relational Models with Structural Uncertainty| Abstract Most real-world data is stored in relational form.  In
Support Vector Machine Active Learning with Application sto Text Classification| Abstract Support vector machines have met with significant success in numerous real-world learning tasks.  However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance.  In many settings, we also have the option of using pool-based active learning.  Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them.  We introduce a new algorithm for performing active learning with support vector machines, i. e. , an algorithm for choosing which instances to request next.  We provide a theoretical motivation for the algorithm using the notion of a version space.  We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings. 
Learning on the Test Data: Leveraging Unseen Features| Abstract This paper addresses the problem of classification in
Learning an Agent's Utility Function by Observing Behavior| Abstract This paper considers the task of predicting the future decisions of an agent A based on his past decisions.  We assume that A is rational | he uses the principle of maximum expected utility.  We also assume that the probability distribution P he assigns to random events is known, so that we need only infer his utility function u to model his decision process.  We consider the task of using A's previous decisions to learn about u.  In particular, A's past decisions can be viewed as constraints on u.  If we have a prior probability distribution p(u) over u (e. g. , learned from a set of utility functions in the population), we can then condition on these constraints to obtain a posterior distribution q(u).  We present an ecient Markov Chain Monte Carlo scheme to generate samples from q(u), which can be used to estimate not only a single \expected" course of action for A, but a distribution over possible courses of action.  We show that this capability is particularly useful in a two-player setting where a second learning agent is trying to optimize her own payoff, which also depends on A's actions and utilities. 
In Proceedings of the Fourteenth National Conference on Artificial Intelligence (| Abstract In this paper, we propose a stochastic version of a general purpose functional programming language as a method of modeling stochastic processes.  The language contains random choices, conditional statements, structured values, defined functions, and recursion.  By imagining an experiment in which the program is "run" and the random choices made by sampling, we can interpret a program in this language as encoding a probability distribution over a (potentially infinite) set of objects.  We provide an exact algorithm for computing conditional probabilities of the form Pr(P (x)
In Proceedings of the Fifteenth National Conference on Artificial Intelligence (| Abstract Two of the most important threads of work in knowledge representation today are frame-based representation systems (FRS's) and Bayesian networks (BNs). 
Adaptive Probabilistic Networks with Hidden Variables| Abstract.  Probabilistic networks (also known as Bayesian belief networks) allow a compact
From Statistical Knowledge Bases to Degrees of Belief| Abstract An intelligent agent will often be uncertain about various properties of its environment, and when acting in that environment it will frequently need to quantify its uncertainty.  For example, if the agent wishes to employ the expected-utility paradigm of decision theory to guide its actions, she will need to assign degrees of belief (subjective probabilities) to various assertions.  Of course, these degrees of belief should not be arbitrary, but rather should be based on the information available to the agent.  This paper describes one approach for inducing degrees of belief from very rich knowledge bases which might include information about particular individuals, statistical correlations, physical laws, and default rules.  We call our approach the random-worlds method.  This method is based on a principle of indifference: it treats all of the worlds the agent considers possible as being equally likely.  It is able to integrate qualitative default reasoning with quantitative probabilistic reasoning by providing a language in which both types of information can be easily expressed.  Our results show that a number of desiderata that arise in direct inference (reasoning from statistical information to conclusions about individuals) and default reasoning follow directly from the semantics of random worlds.  For example, random worlds captures important patterns of reasoning such as specificity, inheritance, indifference to irrelevant information, and default assumptions of independence.  Furthermore, the expressive power of the language used and the intuitive semantics of random worlds allow the method to deal well with problems that are beyond the scope of many other non-deductive reasoning systems. 
Efficient Solution Algorithms for Factored MDPs| Abstract This paper addresses the problem of planning under uncertainty in large Markov Decision Processes (MDPs). 
FastSLAM 2|0: An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges.  Abstract In [15] , Montemerlo et al.  proposed an algorithm called
Generalizing Plans to New Environments in Relational MDPs| Abstract A longstanding goal in planning research is the ability to generalize plans developed for some set of environments to a new but similar environment, with minimal or no replanning.  Such generalization can both reduce planning time and allow us to tackle larger domains than the ones tractable for direct planning.  In this paper, we present an approach to the generalization problem based on a new framework of relational Markov Decision Processes (RMDPs).  An RMDP
Probabilistic Models of Text and Link Structure for Hypertext Classification| Abstract Most text classification methods treat each document as an independent instance.  However, in many text domains, documents are linked and the topics of linked documents are correlated.  For example, web pages of related topics are often connected by hyperlinks and scientific papers from related fields are commonly linked by citations.  We propose a unified probabilistic model for both the textual content and the link structure of a document collection.  Our model is based on the recently introduced framework of Probabilistic Relational Models (PRMs), which allows us to capture correlations between linked documents.  We show how to learn these models from data and use them efficiently for
Learning Continuous Time Bayesian Networks| Abstract In this paper we present a language for finite state continuous time Bayesian networks (CTBNs), which
Learning Module Networks| Abstract Methods for learning Bayesian networks can discover dependency structure between observed variables.  Although these methods are useful in many applications,
Semantics and Inference for Recursive Probability Models| Abstract In recent years, there have been several proposals that extend the expressive power of Bayesian networks with that of
Monitoring a Complez Physical System using a Hybrid Dynamic Bayes Net| Abstract The Reverse Water Gas Shift system (RWGS) is a complex physical system designed to produce oxygen from the carbon dioxide atmosphere on Mars.  If sent to Mars, it would operate without human supervision, thus requiring a reliable automated system for monitoring and control.  The RWGS presents many challenges typical of real-world systems, including: noisy and biased sensors, nonlinear behavior, effects that are manifested over different time granularities, and unobservability of many important quantities.  In this paper we model the RWGS using a hybrid (discrete/continuous) Dynamic Bayesian Network (DBN), where the state at each time slice contains 33 discrete and 184 continuous variables.  We show how the system state can be tracked using probabilistic inference over the model.  We discuss how to deal with the various challenges presented by the RWGS, providing a suite of techniques that are likely to be useful in a wide range of applications.  In particular, we describe a general framework for dealing with nonlinear behavior using numerical integration techniques, extending the successful Unscented Filter.  We also show how to use a fixed-point computation to deal with effects that develop at different time scales, specifically rapid changes occurring during slowly changing processes.  We test our model using real data collected from the RWGS, demonstrating the feasibility of hybrid DBNs for monitoring complex real-world physical systems. 
In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence (| Abstract The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory.  In the case
Irrelevance and Conditioning in First-Order Probabilistic Logic| Abstract First-order probabilistic logic is a powerful knowledge representation language. 
Constructing small sample spaces satisfying given constraints| Abstract Abstract.  The subject of this paper isfinding small sample spaces for joint distributions of n discrete random variables.  Such distributions are often only required to obey a certain limited set of constraints of the form Pr(E)=.  We show that the problem of deciding whether there exists any distribution satisfying a given set of constraints isNP-15840 However, if the constraints are consistent, then there exists adistribution satisfying them which is supported by a "small" sample space (one whose cardinalityis equal to the number of constraints).  For the important case of independenceconstraints,where the constraints have a certain form and areconsistent with a joint distribution of n independent random variables, a small sample space can be constructed in polynomial time.  This last result is also useful for de-13848-2253 algorithms.  We demonstrate this technique by an application to the problem of finding large independentsetsin sparse hypergraphs. 
Zero-096 Games in ExtensiveForm| This paper investigates the complexity offi 3160 max-min strategies forfior 4 two-person zero-sum games in the extensive form.  The problem of determining whether a player with imperfect recall can guarantee himself a certain payoff is shown to be NP-hard.  When both players have imperfect recall, this is even harder.  Moreover, the max-min behavior strategy of such a player may use irrational numbers.  Thus, for games with imperfect recall, computing the max-min strategy or the value of the game is a hard problem.  For a game with perfect recall, we present an algorithm for computing a max-min behavior strategy, which runs in time polynomial in the size of the game tree. 
Probabilistic Models for Agent's Beliefs and Decisions| Abstract Many applications of intelligent systems require reasoning about the mental states of agents in the domain.  We may want to reason about an agent's beliefs, including beliefs about other agents; we may also want to reason about an agent's preferences, and how his beliefs and preferences relate to his behavior.  We define a probabilistic epistemic logic (PEL) in which belief statements are given a formal semantics, and provide an algorithm for asserting and querying PEL formulas in Bayesian networks.  We then show how to reason about an agent's behavior by modeling his decision process as an influence diagram and assuming that he behaves rationally.  PEL can then be used for reasoning from an agent's observed actions to conclusions about other aspects of the domain, including unobserved domain variables and the agent's mental states. 
Policy Search via Density Estimation| Abstract We propose a new approach to the problem of searching a space of stochastic controllers for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP).  Following several other authors, our approach is based on searching in parameterized families of policies (for example, via gradient descent) to optimize solution quality.  However, rather than trying to estimate the values and derivatives of a policy directly, we do so indirectly using estimates for the probability densities that the policy induces on states at the different points in time.  This enables our algorithms to exploit the many techniques for efficient and robust approximate density propagation in stochastic systems.  We show how our techniques can be applied both to deterministic propagation schemes (where the MDP's dynamics are given explicitly in compact form,) and to stochastic propagation schemes (where we have access only to a generative model, or simulator, of the MDP).  We present empirical results for both of these variants on complex problems. 
An Integrated Stereo-Based Approach to Automatic Vehicle Guidance| Abstract We propose a new approach for vision based longitudinal and lateral vehicle control.  The novel feature of this approach is the use of binocular vision.  We integrate two modules consisting of a new, domain-specific, efficient binocular stereo algorithm, and a lane marker detection algorithm, and show that the integration results in a improved performance for each of the modules.  Longitudinal control is supported by detecting and measuring the distances to leading vehicles using binocular stereo.  The knowledge of the camera geometry with respect to the locally planar road is used to map the images of the road plane in the two camera views into alignment.  This allows us to separate image features into those lying in the road plane, e. g.  lane markers, and those due to other objects which are dynamically integrated into an obstacle map.  Therefore, in contrast with the previous work, we can cope with the difficulties arising from occlusion of lane markers by other vehicles.  The detection and measurement of the lane markers provides us with the positional parameters and the road curvature which are needed for lateral vehicle control.  Moreover, this information is also used to update the camera geometry with respect to the road, therefore allowing us to cope with the problem of vibrations and road inclination to obtain consistent results from binocular stereo. 
Generating and Solving Imperfect Information Games| Abstract Work on game playing in AI has typically ignored games of imperfect information such as poker.  In this paper, we present a framework for dealing with such games.  We point out several important issues that arise only in the context of imperfect information games, particularly the insufficiency of a simple game tree model to represent the players' information state and the need for randomization in the players' optimal strategies.  We describe Gala, an implemented system that provides the user with a very natural and expressive language for describing games.  From a game description, Gala creates an augmented game tree with information sets which can be used by various algorithms in order to find optimal strategies for that game.  In particular, Gala implements the first practical algorithm for finding optimal randomized strategies in two-player imperfect information competitive games [Koller et al. , 1994] .  The running time of this algorithm is polynomial in the size of the game tree, whereas previous algorithms were exponential.  We present experimental results showing that this algorithm is also efficient in practice and can therefore form the basis for a game playing system. 
Discriminative Probabilistic Models for Relational Data| Abstract In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent.  For example, in hypertext classification, the labels of linked pages are highly correlated.  A standard approach is to classify each entity independently, ignoring the correlations between them.  Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities.  In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach.  First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models.  Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy.  We show how to train these models effectively, and how to use approximate probabilistic inference over the learned model for collective classification of multiple related entities.  We provide experimental results on a webpage classification task, showing that accuracy can be significantly improved by modeling relational dependencies. 
From promoter sequence to expression: a probabilistic framework| ABSTRACT We present a probabilistic framework that models the process by which transcriptional binding explains the mRNA expression of different genes.  Our joint probabilistic model unifies the two key components of this process: the prediction of gene regulation events from sequence motifs in the gene's promoter region, and the prediction of mRNA expression from combinations of gene regulation events in different settings.  Our approach has several advantages.  By learning promoter sequence motifs that are directly predictive of expression data, it can improve the identification of binding site patterns.  It is also able to identify combinatorial regulation via interactions of different transcription factors.  Finally, the general framework allows us to integrate additional data sources, including data from the recent binding localization assays.  We demonstrate our approach on the cell cycle data of Spellman et al. , combined with the binding localization information of Simon et al.  We show that the learned model predicts expression from sequence, and that it identifies coherent co-regulated groups with significant transcription factor motifs.  It also provides valuable biological insight into the domain via these co-regulated ^modules~ and the combinatorial regulation effects that govern their behavior. 
Max-Margin Parsing| Abstract We present a novel discriminative approach to parsing inspired by the large-margin criterion underlying
Multi-Agent Algorithms for Solving Graphical Games| Abstract Consider the problem group agents trying to find stable strategy profile for joint interaction.  A standard approach describe the situation as single multi-player game and find an equilibrium strategy profile that game.  However, most algorithms for finding equilibria are computationally expensive; they are also centralized, requiring that all relevant payoff information be available a single agent (or computer) who must determine the entire equilibrium profile.  In this paper, we exploit two ideas address these problems.  We consider structured game representations, where the interaction between the agents is sparse, assumption that holds in many real-world situations.  We also consider the slightly relaxed task of finding approximate equilibrium.  We present two algorithms for finding approximate equilibria in these games, one based on hill-climbing approach and one on constraint satisfaction.  We show that these algorithms exploit the game structure to achieve faster computation.  They are also inherently local, requiring only limited communication between directly interacting agents.  They can thus be scaled to games involving large numbers of agents, provided the interaction between the agents not too dense. 
Restricted Bayes Optimal Classifiers| Abstract We introduce the notion of restricted Bayes optimal classifiers.  These classifiers attempt to combine the flexibility of the generative approach to classification with the high accuracy associated with discriminative learning.  They first create a model of the joint distribution over class labels and features.  Instead of choosing the decision boundary induced directly from the model, they restrict the allowable types of decision boundaries and learn the one that minimizes the probability of misclassification relative to the estimated joint distribution.  In this paper, we investigate two particular instantiations of this approach.  The first uses a non-parametric density estimator --- Parzen Windows with Gaussian kernels --and hyperplane decision boundaries.  We show that the resulting classifier is asymptotically equivalent to a maximal margin hyperplane classifier, a highly successful discriminative classifier.  We therefore provide an alternative justification for maximal margin hyperplane classifiers.  The second instantiation uses a mixture of Gaussians as the estimated density; in experiments on real-world data, we show that this approach allows data with missing values to be handled in a principled manner, leading to improved performance over regular discriminative approaches. 
Statistical Models for Relational Data| Abstract.  We introduce a new type of probabilistic model for relational domains, a statistical relational model (SRM).  An SRM is a statistical model of a particular database instantiation.  The SRM captures the tuple frequencies in the database, and in particular the SRM captures the frequencies with which tuples join.  The SRM provides a compact model of a data base and can be used to quickly give (approximate) answers to queries on this database.  Because it models a joint distribution over tuples from multiple tables, it is ideally to mining multi-relational databases.  We describe the semantics of SRMs and a learning algorithm for SRMs.  We provide experimental results showing that using only a small fraction of the space of the original database, we can still accurately answer a wide range of queries. 
Forming beliefs about a changing world \Lambda| Abstract The situation calculus is a popular technique for reasoning about action and change.  However, its restriction to a firstorder syntax and pure deductive reasoning makes it unsuitable in many contexts.  In particular, we often face uncertainty, due either to lack of knowledge or to some probabilistic aspects of the world.  While attempts have been made to address aspects of this problem, most notably using nonmonotonic reasoning
First-Order Conditional Logic Revisited| Abstract Conditional logics play an important role in recent attempts to investigate default reasoning.  This paper investigates firstorder conditional logic.  We show that, as for first-order probabilistic logic, it is important not to confound statistical conditionals over the domain (such as "most birds fly"), and subjective conditionals over possible worlds (such as "I believe that Tweety is unlikely to fly").  We then address the issue of ascribing semantics to first-order conditional logic.  As in the propositional case, there are many possible semantics.  To study the problem in a coherent way, we use plausibility structures. 
Learning Probabilistic Models of Relational Structure| We describe the appropriate conditions for using each model and present learning algorithms for each.  We present experimental results showing that the learned models can be used to predict relational structure and, moreover, the observed relational structure can be used to provide better predictions for the attributes in the model. 
Constructing Flexible Dynamic Belief Networks from First-Order Probalistic Knowledge Bases| probability tables that can be used to decrease the size of the created belief networks.  We provide an inference algorithm for our sublanguage using the paradigm of knowledge-based model construction.  Given a FOPL knowledge base and a particular situation, our algorithm constructs a propositional dynamic belief network, which can be solved using standard belief network inference algorithms.  In contrast to common dynamic belief networks, the structure of our networks is more flexible and better adapted to the given situation.  We demonstrate the expressive power of our language and the flexibility of the resulting belief networks using a simple knowledge base modeling the propagation of infectious diseases. 
Learning Probabilities for Noisy First-Order Rules| Abstract First-order logic is the traditional basis for knowledge representation languages. 
The Correlated Correspondence Algorithm for Unsupervised Registration of Nonrigid Surfaces| Abstract We present an unsupervised algorithm for registering 3D surface scans of an object undergoing significant deformations.  Our algorithm does not use markers, nor does it assume prior knowledge about object shape, the dynamics of its deformation, or scan alignment.  The algorithm registers two meshes by optimizing a joint probabilistic model over all point-topoint correspondences between them.  This model enforces preservation of local mesh geometry, as well as more global constraints that capture the preservation of geodesic distance between corresponding point pairs.  The algorithm applies even when one of the meshes is an incomplete range scan; thus, it can be used to automatically fill in the remaining surfaces for this partial scan, even if those surfaces were previously only seen in a different configuration.  We evaluate the algorithm on several real-world datasets, where we demonstrate good results in the presence of significant movement of articulated parts and non-rigid surface deformation.  Finally, we show that the output of the algorithm can be used for compelling computer graphics tasks such as interpolation between two scans of a non-rigid object and automatic recovery of articulated object models. 
Policy Iteration for Factored MDPs| Abstract Many large MDPs can be represented compactly using a dynamic Bayesian network.  Although the structure of the value function does not retain the structure of the process, recent work has suggested that value functions in factored MDPs can often be approximated well using a factored value function: a linear combination of restricted basis functions, each of which refers only to a small subset of variables.  An approximate factored value function for a particular policy can be computed using approximate dynamic programming, but this approach (and others) can only produce an approximation relative to a distance metric which is weighted by the stationary distribution of the current policy.  This type of weighted projection is ill-suited to policy improvement.  We present a new approach to value determination, that uses a simple closed-form computation to compute a least-squares decomposed approximation to the value function for any weights directly.  We then use this value determination algorithm as a subroutine in a policy iteration process.  We show that, under reasonable restrictions, the policies induced by a factored value function can be compactly represented as a decision list, and can be manipulated eciently in a policy iteration process.  We also present a method for computing error bounds for decomposed value functions using a variableelimination algorithm for function optimization.  The complexity of all of our algorithms depends on the factorization of the system dynamics and of the approximate value function. 
Context-Specific Independence in Bayesian Networks| Abstract Bayesiannetworks provide a languagefor qualitatively representing the conditional independence properties of a distribution.  This allows a natural and compact representation of the distribution, eases knowledge acquisition, and supports effective inference algorithms.  It is well-known, however, that there are certain independencies that we cannot capture qualitatively within the Bayesian network structure: independencies that hold only in certain contexts, i. e. , given a specific assignment of values to certain variables.  In this paper, we propose a formal notion of context-specific independence (CSI), based on regularities in the conditional probability tables (CPTs) at a node.  We present a technique, analogous to (and based on) d-separation, for determining when such independence holds in a given network.  We then focus on a particular qualitative representation scheme---tree-structured CPTs--for capturing CSI.  We suggest ways in which this representation can be used to support effective inference algorithms.  In particular, we present a structural decomposition of the resulting network which can improve the performance of clustering algorithms, and an alternative algorithm based on cutset conditioning. 
Fast algorithms for finding randomized strategies in game trees| Abstract Interactions among agents can be conveniently described by game trees.  In order to analyze a game, it is important to derive optimal (or equilibrium) strategies for the dierent players.  The standard approach to finding such strategies in games with imperfect information is, in general, computationally intractable.  The approach is to generate the normal form of the game (the matrix containing the payofor each strategy combination), and then solve a linear program (LP) or a linear complementarity problem (LCP).  The size of the normal form, however, is typically exponential in the size of the game tree, thus making this method impractical in all but the simplest cases.  This paper describes a new representation of strategies which results in a practical linear formulation of the problem of two-player games with perfect recall (i. e. , games where players never forget anything, which is a standard assumption).  Standard LP or LCP solvers can then be applied to find optimal randomized strategies.  The
Tractable Inference for Complex Stochastic Processes| Abstract --- The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory.  In the case of a stochastic system, these tasks typically involve the use of a belief state---a probability distribution over the state of the process at a given point in time.  Unfortunately, the state spaces of complex processes are very large, making an explicit representation of a belief state intractable.  Even in dynamic Bayesian networks (DBNs), where the process itself can be represented compactly, the representation of the belief state is intractable.  We investigate the idea of utilizing a compact approximation to the true belief state, and analyze the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make our answers completely irrelevant.  We show that the error in a belief state contracts exponentially as the process evolves.  Thus, even with multiple approximations, the error in our process remains bounded indefinitely.  We show how the additional structure of a DBN can be used to design our approximation scheme, improving its performance significantly.  We demonstrate the applicability of our ideas in the context of a monitoring task, showing that orders of magnitude faster inference can be achieved with only a small degradation in accuracy. 
Team-Maxmin Equilibria| In a noncooperative game, a team is a set of players that have identical payoffs.  We investigate zero-sum games where a team of several players plays against a single adversary.  The team is not regarded as a single player because the team members might not be able to coordinate their actions.  In such a game, a certain equilibrium can be selected naturally: the team-maxmin equilibrium.  It assures the team players the best payoff they can hope for, given their inability to coordinate.  A team-maxmin equilibrium exists, and in a generic game it is unique.  Journal of Economic Literature Classification Number: C72. 
Approximate probabilistic inference in dynamic processes| Abstract When dealing with a dynamic process, we are typically interested in keeping track of where we are, and in predicting where we will be in the future.  When the dynamic process is stochastic and partially observable, as it invariably is, the best we can hope for is to have accurate beliefs about the state of the system.  Thus, we want to maintain a belief state: a probability distribution over the possible states the system can be in.  When the state space is large (or infinite), it is typically impossible to maintain a completely accurate representation of the belief state.  In this paper, we investigate the possibility of maintaining an approximate belief state.  We argue that it can be very useful to use the (approximate) belief state at time t to focus attention on the relevant aspects of the situation at time t+1, thereby providing guidance to the algorithm that computes the next belief state.  Thus, our belief state should guide not just our "real world" actions, but also our computational actions.  We present some preliminary results supporting this claim in the context of stochastic simulation algorithms, and suggest ways in which this idea can be extended. 
Multiagent Planning with Factored MDPs| Abstract We present a principled and efficient planning algorithm for cooperative multiagent dynamic systems.  A striking feature of our method is that the coordination and communication between the agents is not imposed, but derived directly from the system dynamics and function approximation architecture.  We view the entire multiagent system as a single, large Markov decision process (MDP), which we assume can be represented in a factored way using a dynamic Bayesian network (DBN).  The action space of the resulting MDP is the joint action space of the entire set of agents.  Our approach is based on the use of factored linear value functions as an approximation to the joint value function.  This factorization of the value function allows the agents to coordinate their actions at runtime using a natural message passing scheme.  We provide a simple and efficient method for computing such an approximate value function by solving a single linear program, whose size is determined by the interaction between the value function structure and the DBN.  We thereby avoid the exponential blowup in the state and action space.  We show that our approach compares favorably with approaches based on reward sharing.  We also show that our algorithm is an efficient alternative to more complicated algorithms even in the single agent case. 
Learning Hierarchical Object Maps of Non-Stationary Environments with Mobile Robots| environments.  The approach outperforms a previously developed non-hierarchical algorithm that models objects but lacks class templates. 
Finding the Hidden Path: Time Bounds for All-Pairs Shortest Paths| Abstract.  We investigate the all-pairs shortest paths problem in weighted graphs.  We present an algorithm---
Selectivity Estimation using Probabilistic Models| ABSTRACT Estimating the result size of complex queries that involve selection on multiple attributes and the join of several relations is a difficult but fundamental task in database query processing.  It arises in cost-based query optimization, query profiling, and approximate query answering.  In this paper, we show how probabilistic graphical models can be effectively used for this task as an accurate and compact approximation of the joint frequency distribution of multiple attributes across multiple relations.  Probabilistic Relational Models (PRMs) are a recent development that extends graphical statistical models such as Bayesian Networks to relational domains.  They represent the statistical dependencies between attributes within a table, and between attributes across foreign-key joins.  We provide an efficient algorithm for constructing a PRM from a database, and show how a PRM can be used to compute selectivity estimates for a broad class of queries.  One of the major contributions of this work is a unified framework for the estimation of queries involving both select and foreign-key join operations.  Furthermore, our approach is not limited to answering a small set of predetermined queries; a single model can be used to effectively estimate the sizes of a wide collection of potential queries across multiple tables.  We present results for our approach on several real-world databases.  For both single-table multi-attribute queries and a general class of select-join queries, our approach produces more accurate estimates than standard approaches to selectivity estimation, using comparable space and time. 
Multi-Agent Influence Diagrams for Representing and Solving Games| Abstract The traditional representations of games using the extensive form or the strategic (normal) form obscure much of the structure that is present in real-world games.  In this paper, we propose a new representation language for general multiplayer games --- multi-agent influence diagrams (MAIDs). 
Exploiting the Architecture of Dynamic Systems| Technical report 1999/11/30 Abstract --- Consider the problem of monitoring the state of a complex dynamic system, and predicting its future evolution.  Exact algorithms for this task typically maintain a belief state, or distribution over the states at some point in time.  Unfortunately, these algorithms fail when applied to complex processes such as those represented as dynamic Bayesian networks (DBNs), as the representation of the belief state grows exponentially with the size of the process.  In [ Boyen & Koller, 1998 ] , we recently proposed an efficient approximate tracking algorithm that maintains an approximate belief state that has a compact representation as a set of independent factors.  Its performance depends on the error introduced by approximating a belief state of this process by a factored one.  We informally argued that this error is low if the interaction between variables in the processes is "weak".  In this paper, we give formal information-theoretic definitions for notions such as weak interaction and sparse interaction of processes.  We use these notions to analyze the conditions under which the error induced by this type of approximation is small.  We demonstrate several cases where our results formally support intuitions about strength of interaction. 
Context-Specific Multiagent Coordination and Planning with Factored MDPs| Abstract We present an algorithm for coordinated decision making in cooperative multiagent settings, where the agents' value function can be represented as a sum of context-specific value rules.  The task of finding an optimal joint action in this setting leads to an algorithm where the coordination structure between agents depends on the current state of the system and even on the actual numerical values assigned to the value rules.  We apply this framework to the task of multiagent planning in dynamic systems, showing how a joint value function of the associated Markov Decision Process can be approximated as a set of value rules using an efficient linear programming algorithm.  The agents then apply the coordination graph algorithm at each iteration of the process to decide on the highest-value joint action, potentially leading to a different coordination pattern at each step of the plan. 
A Continuation Method for Nash Equilibria in Structured Games| Abstract We describe algorithms for computing Nash equilibria in structured game representations, including both graphical games and multi-agent influence diagrams (MAIDs).  The algorithms are derived from a continuation method for normal-form and extensive-form games due to Govindan and Wilson; they follow a trajectory through the space of perturbed games and their equilibria.  Our
Max-Margin Markov Networks| Abstract In typical classification tasks, we seek a function which assigns a label to a single object. 
Discovering Hidden Variables: A Structure-Based Approach| Abstract A serious problem in learning probabilistic models is the presence of hidden variables.  These variables are not observed, yet interact with several of the observed variables.  As such, they induce seemingly complex dependencies among the latter.  In recent years, much attention has been devoted to the development of algorithms for learning parameters, and in some cases structure, in the presence of hidden variables.  In this paper, we address the related problem of detecting hidden variables that interact with the observed variables.  This problem is of interest both for improving our understanding of the domain and as a preliminary step that guides the learning procedure towards promising models.  A very natural approach is to search for "structural signatures" of hidden variables --substructures in the learned network that tend to suggest the presence of a hidden variable.  We make this basic idea concrete, and show how to integrate it with structure-search algorithms.  We evaluate this method on several synthetic and real-life datasets, and show that it performs surprisingly well. 
Decomposing Gene Expression into Cellular Processes| Abstract We propose a probabilistic model for cellular processes, and an algorithm for discovering them from gene expression data.  A process is associated with a set of genes that participate in
Discovering molecular pathways from protein interaction and gene expression data| ABSTRACT In this paper, we describe an approach for identifying "pathways" from gene expression and protein interaction data.  Our approach is based on the assumption that many pathways exhibit two properties: their genes exhibit a similar gene expression profile, and the protein products of the genes often interact.  Our approach is based on a unified probabilistic model, which is learned from the data using the EM algorithm.  We present results on two S.  Cerevisiae gene expression data sets, combined with a binary protein interaction data set.  Our results show that our approach is much more successful than other approaches at discovering both coherent functional groups and entire protein complexes. 
Link Prediction in Relational Data| Abstract Many real-world domains are
Simultaneous Mapping and Localization With Sparse Extended Information Filters: Theory and Initial Results| Abstract This paper describes a scalable algorithm for the simultaneous mapping and localization (SLAM) problem.  SLAM is the problem of determining the location of environmental features with a roving robot.  Many of today's popular techniques are based on extended Kalman filters (EKFs), which require update time quadratic in the number of features in the map.  This paper develops the notion of sparse extended information filters (SEIFs), as a new method for solving the SLAM problem.  SEIFs exploit structure inherent in the SLAM problem, representing maps through local, Web-like networks of features.  By doing so, updates can be performed in constant time, irrespective of the number of features in the map.  This paper presents several original constant-time results of SEIFs, and provides simulation results that show the high accuracy of the resulting maps in comparison to the computationally more cumbersome EKF solution. 
Using Learning for Approximation in Stochastic Processes| Abstract To monitor or control a stochastic dynamic system, we need to reason about its current state.  Exact inference for this task requires that we maintain a complete joint probability distribution over the possible states, an impossible requirement for most processes.  Stochastic simulation algorithms provide an alternative solution by approximating the distribution at time t via a (relatively small) set of samples. 
Efficient Reinforcement Learning in Factored MDPs| Abstract We present a provably efficient and near-optimal algorithm for reinforcement learning in Markov decision processes (MDPs) whose transition model can be factored as a dynamic Bayesian network (DBN).  Our algorithm generalizes the recent E 3 algorithm of Kearns and Singh, and assumes that we are given both an algorithm for approximate planning and the graphical structure (but not the parameters) of the DBN.  Unlike the original E 3 algorithm, our new algorithm exploits the DBN structure to achieve a running time that scales polynomially in the number of parameters of the DBN, which may be exponentially smaller than the number of global states. 
A system for probabilistic object-oriented knowledge representation| Abstract In previous work, we pointed out the limitations of standard Bayesian networks as a modeling framework for large, complex domains.  We proposed a new, richly structured modeling language, Object-oriented Bayesian Networks, that we argued would be able to deal with such domains.  However, it turns out that OOBNs are not expressive enough to model many interesting aspects of complex domains: the existence of specific named objects, arbitrary relations between objects, and uncertainty over domain structure.  These aspects are crucial in real-world domains such as battlefield awareness.  In this paper, we present SPOOK, an implemented system that addresses these limitations.  SPOOK implements a more expressive language that allows it to represent the battlespace domain naturally and compactly.  We present a new inference algorithm that utilizes the model structure in a fundamental way, and show empirically that it achieves orders of magnitude speedup over existing approaches. 
From Statistics to Beliefs \Lambda| Abstract An intelligent agent uses known facts, including statistical knowledge, to assign degrees of belief to assertions it is uncertain about.  We investigate three principled techniques for doing this.  All three are applications of the principle of indifference, because they assign equal degree of belief to all basic "situations" consistent with the knowledge base.  They differ because there are competing intuitions about what the basic situations are.  Various natural patterns of reasoning, such as the preference for the most specific statistical data available, turn out to follow from some or all of the techniques.  This is an improvement over earlier theories, such as work on direct inference and reference classes, which arbitrarily postulate these patterns without offering any deeper explanations or guarantees of consistency.  The three methods we investigate have surprising characterizations: there are connections to the principle of maximum entropy, a principle of maximal independence, and a ``center of mass" principle.  There are also unexpected connections between the three, that help us understand why the specific language chosen (for the knowledge base) is much more critical in inductive reasoning of the sort we consider than it is in traditional deductive reasoning. 
Making Rational Decisions Using Adaptive Utility Elicitation| Abstract Rational decision making requires full knowledge of the
Being Bayesian about Network Structure| Abstract In many domains, we are interested in analyzing the structure of the underlying
Asymptotic Conditional Probabilities: The Non-unary Case \Lambda| Abstract Motivated by problems that arise in computing degrees of belief, we consider the problem of computing asymptotic conditional probabilities for first-order sentences.  Given first-order sentences ' and `, we consider the structures with domain f1; : : : ; Ng that satisfy `, and compute the fraction of them in which ' is true.  We then consider what happens to this fraction as N gets large.  This extends the work on 0-1 laws that considers the limiting probability of first-order sentences, by considering asymptotic conditional probabilities.  As shown by Liogon'kii [Lio69], if there is a non-unary predicate symbol in the vocabulary, asymptotic conditional probabilities do not always exist.  We extend this result to show that asymptotic conditional probabilities do not always exist for any reasonable notion of limit.  Liogon'kii also showed that the problem of deciding whether the limit exists is undecidable.  We analyze the complexity of three problems with respect to this limit: deciding whether it is well-defined, whether it exists, and whether it lies in some nontrivial interval.  Matching upper and lower bounds are given for all three problems, showing them to be highly undecidable. 
Statistical Foundations for Default Reasoning| Abstract We describe a new approach to default reasoning, based on a principle of indifference among possible worlds.  We interpret default rules as extreme statistical statements, thus obtaining a knowledge base KB comprised of statistical and first-order statements.  We then assign equal probability to all worlds consistent with KB in order to assign a degree of belief to a statement '.  The degree of belief can be used to decide whether to defeasibly conclude '.  Various natural patterns of reasoning, such as a preference for more specific defaults, indifference to irrelevant information, and the ability to combine independent pieces of evidence, turn out to follow naturally from this technique.  Furthermore, our approach is not restricted to default reasoning; it supports a spectrum of reasoning, from quantitative to qualitative.  It is also related to other systems for default reasoning.  In particular, we show that the work of [ Goldszmidt et al. , 1990 ] , which applies maximum entropy ideas to ffl-semantics, can be embedded in our framework. 
Asymptotic Conditional Probabilities for First-Order Logic| Abstract Motivated by problems that arise in computing degrees of belief, we consider the problem of computing asymptotic conditional probabilities for first-order formulas.  That is, given first-order formulas ' and `, we consider the number of structures with domain f1; : : : ; Ng that satisfy `, and compute the fraction of them in which ' is true.  We then consider what happens to this probability as N gets large.  This is closely connected to the work on 0-1 laws that considers the limiting probability of first-order formulas, except that now we are considering asymptotic conditional probabilities.  Although work has been done on special cases of asymptotic conditional probabilities, no general theory has been developed.  This is probably due in part to the fact that it has been known that, if there is a binary predicate symbol in the vocabulary, asymptotic conditional probabilities do not always exist.  We show that in this general case, almost all the questions one might want to ask (such as deciding whether the asymptotic probability exists) are highly undecidable.  On the other hand, we show that the situation with unary predicates only is much better.  If the vocabulary consists only of unary predicate and constant symbols, it is decidable whether the limit exists, and if it does, there is an effective algorithm for computing it.  The complexity depends on two parameters: whether there is a fixed finite vocabulary or an infinite one, and whether there is a bound on the depth of quantifier nesting. 
Exact Inference in Networks with Discrete Children of Continuous Parents| Abstract Many real life domains contain a mixture of discrete and continuous variables and can be modeled as hybrid Bayesian Networks (BNs).  An important subclass of hybrid BNs are conditional linear Gaussian (CLG) networks, where the conditional distribution of the continuous variables given an assignment to the discrete variables is a multivariate Gaussian.  Lauritzen's extension to the clique tree algorithm can be used for exact inference in CLG networks.  However, many domains include discrete variables that depend on continuous ones, and CLG networks do not allow such dependencies to be represented.  In this paper, we propose the first "exact" inference algorithm for augmented CLG networks --- CLG networks augmented by allowing discrete children of continuous parents.  Our algorithm is based on Lauritzen's algorithm, and is exact in a similar sense: it computes the exact distributions over the discrete nodes, and the exact first and second moments of the continuous ones, up to inaccuracies resulting from numerical integration used within the algorithm.  In the special case of softmax CPDs, we show that integration can often be done efficiently, and that using the first two moments leads to a particularly accurate approximation.  We show empirically that our algorithm achieves substantially higher accuracy at lower cost than previous algorithms for this task. 
Automatic Symbolic Traffic Scene Analysis Using Belief Networks| Abstract Automatic symbolic traffic scene analysis is essential to many areas of IVHS (Intelligent Vehicle Highway Systems).  Traffic scene information can be used to optimize traffic flow during busy periods, identify stalled vehicles and accidents, and aid the decision-making of an autonomous vehicle controller.  Improvements in technologies for machine vision-based surveillance and high-level symbolic reasoning have enabled us to develop a system for detailed, reliable traffic scene analysis.  The machine vision component of our system employs a contour tracker and an affine motion model based on Kalman filters to extract vehicle trajectories over a sequence of traffic scene images.  The symbolic reasoning component uses a dynamic belief network to make inferences about traffic events such as vehicle lane changes and stalls.  In this paper, we discuss the key tasks of the vision and reasoning components as well as their integration into a working prototype. 
In Proceedings of the Eleventh Conference on Advances in Neural Information Processing| Abstract Inference is a key component in learning probabilistic models from partially observable data.  When learning temporal models, each of the many inference phases requires a traversal over an entire long data sequence; furthermore, the data structures manipulated are exponentially large, making this process computationally expensive.  In [2], we describe an approximate inference algorithm for monitoring stochastic processes, and prove bounds on its approximation error.  In this paper, we apply this algorithm as an approximate forward propagation step in an EM algorithm for learning temporal Bayesian networks.  We provide a related approximation for the backward step, and prove error bounds for the combined algorithm.  We show empirically that, for a real-life domain, EM using our inference algorithm is much faster than EM using exact inference, with almost no degradation in quality of the learned model.  We extend our analysis to the online learning task, showing a bound on the error resulting from restricting attention to a small window of observations.  We present an online EM learning algorithm for dynamic systems, and show that it learns much faster than standard offline EM. 
Probability Estimation in Face of Irrelevant Information| Abstract In this paper, we consider one aspect of the problem of applying decision theory to the design of agents that learn how to make decisions under uncertainty.  This aspect concerns how an agent can estimate probabilities for the possible states of the world, given that it only makes limited observations before committing to a decision.  We show that the naive application of statistical tools can be improved upon if the agent can determine which of his observations are truly relevant to the estimation problem at hand.  We give a framework in which such determinations can be made, and define an estimation procedure to use them.  Our framework also suggests several extensions, which show how additional knowledge can be used to improve the estimation procedure still further. 
(De)randomized Construction of Small Sample Spaces in \calNC| Abstract Koller and Megiddo introduced the paradigm of constructing compact distributions that satisfy a given set of constraints, and showed how it can be used to efficiently derandomize certain types of algorithm.  In this paper, we significantly extend their results in two ways.  First, we show how their approach can be applied to deal with more general expectation constraints.  More importantly, we provide the first
FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem| Abstract The ability to simultaneously localize a robot and
Probabilistic Abstraction Hierarchies| Abstract Many domains are naturally organized in an abstraction hierarchy or taxonomy, where the instances in "nearby" classes in the taxonomy are similar.  In this
In Proceedings of the Fifteenth Annual Conference on Uncertainty in Artificial Intelligence (| Abstract The clique tree algorithm is the standard method for doing inference in Bayesian networks.  It works by manipulating clique potentials --- distributions over the variables in a clique.  While this approach works well for many networks, it is limited by the need to maintain an exact representation of the clique potentials.  This paper presents a new unified approach that combines approximate inference and the clique tree algorithm,
Active Learning for Structure in Bayesian Networks| Abstract The task of causal structure discovery from empirical data is a fundamental problem in many areas.  Experimental data is
A Logic for Approximate Reasoning| Abstract We investigate the problem of reasoning with imprecise quantitative information.  We give formal semantics to a notion of approximate observations, and define two types of entailment for a knowledge base with imprecise information: a cautious notion, which allows only completely justified conclusions, and a bold one, which allows jumping to conclusions.  Both versions of the entailment relation are shown to be decidable.  We investigate the behavior of the two alternatives on various examples, and show that the answers obtained are intuitively desirable.  The behavior of these two entailment relations is completely characterized for a certain sublanguage, in terms of the logic of true equality.  We demonstrate various properties of the full logic, and show how it applies to many situations of interest. 
P-CLASSIC: A tractable probabilistic description logic| Abstract Knowledge representation languages invariably reflect a trade-off between expressivity and tractability.  Evidence suggests that the compromise chosen by description logics is a particularly successful one.  However, description logic (as for all variants of first-order logic) is severely limited in its ability to express uncertainty.  In this paper, we present P-CLASSIC, a probabilistic version of the description logic CLASSIC.  In addition to terminological knowledge, the language utilizes Bayesian networks to express uncertainty about the basic properties of an individual, the number of fillers for its roles, and the properties of these fillers.  We provide a semantics for P-CLASSIC and an effective inference procedure for probabilistic subsumption: computing the probability that a random individual in class C is also in class D.  The effectiveness of the algorithm relies on independence assumptions and on our ability to execute lifted inference: reasoning about similar individuals as a group rather than as separate ground terms.  We show that the complexity of the inference algorithm is the best that can be hoped for in a language that combines description logic with Bayesian networks.  In particular, if we restrict to Bayesian networks that support polynomial time inference, the complexity of our inference procedure is also polynomial time. 
SPOOK: A system for probabilistic object-oriented knowledge representation| Abstract In previous work, we pointed out the limitations of standard Bayesian networks as a modeling framework for large, complex domains.  We proposed a new, richly structured modeling language, Object-oriented Bayesian Networks, that we argued would be able to deal with such domains.  However, it turns out that OOBNs are not expressive enough to model many interesting aspects of complex domains: the existence of specific named objects, arbitrary relations between objects, and uncertainty over domain structure.  These aspects are crucial in real-world domains such as battlefield awareness.  In this paper, we present SPOOK, an implemented system that addresses these limitations.  SPOOK implements a more expressive language that allows it to represent the battlespace domain naturally and compactly.  We present a new inference algorithm that utilizes the model structure in a fundamental way, and show empirically that it achieves orders of magnitude speedup over existing approaches. 
Object-Oriented Bayesian Networks|
Approximate Learning of Dynamic Models|
Probabilistic Frame-Based Systems|
Hierarchically Classifying Documents Using Very Few Words|
Update Rules for Parameter Estimation in Bayesian Networks|
Active Learning for Parameter Estimation in Bayesian Networks|
A module map showing conditional activity of expression modules in cancer,"|
Reinforcement Learning Using Approximate Belief States|
Efficient computation of equilibria for extensive form games|
Random Worlds and Maximum Entropy|
From Statistics to Beliefs|
State-space approximations for extensive form games| Workshop paper at First World Congress on Game Theory,. 
Understanding tuberculosis epidemiology using structured statistical models|
Generating Degrees of Belief from Statistical Information: An Overview|
Genome-wide discovery of transcriptional modules from DNA sequence and gene expression|
Using Feature Hierarchies in Bayesian Network Learning|
Being Bayesian About Network Structure| A Bayesian Approach to Structure Discovery in Bayesian Networks. 
Information agents: A new challenge for ai|
Generating New Beliefs from Old|
Probabilistic Relational Models|
and Bernhard von Stengel: Fast algorithms for finding randomized strategies in game trees,|
Representation, reasoning, learning| IJCAI Computers and Thought Award talk,. 
Asymptotic Conditional Probabilities: The Non-Unary Case|
Adaptive probabilistic networks|
Structured Probabilistic Models: Bayesian Networks and Beyond|
Forming Beliefs about a Changing World|
Learning associative Markov networks|
A Response to "Believing on the Basis of the Evidence"|
