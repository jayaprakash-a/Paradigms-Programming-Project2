Law Discovery from Financial Data using Neural Networks| Abstract This paper describes an experimental study for discovering underlying laws of market capitalization using BS (Balance Sheet) items.  For this purpose, we apply law discovery methods based on neural networks: RF5 (Rule Finder) discovers a single numeric law from data containing only numeric values, RF6 discovers a set of nominally conditioned polynomials from data containing both nominal and numeric values, and MCV regularizer is used to improve both the generalization performance and the readability.  Our preliminary experimental results show that these methods are promising for discovering underlying laws from financial data. 
Application of Variational Bayesian Approach to Speech Recognition| Abstract In this paper, we propose a Bayesian framework, which constructs shared-state triphone HMMs based on a variational Bayesian approach, and recognizes speech based on the Bayesian prediction classification; variational Bayesian estimation and clustering for speech recognition (VBEC).  An appropriate model structure with high recognition performance can be found within a VBEC framework.  Unlike conventional methods, including BIC or MDL criterion based on the maximum likelihood approach, the proposed model selection is valid in principle, even when there are insufficient amounts of data, because it does not use an asymptotic assumption.  In isolated word recognition experiments, we show the advantage of VBEC over conventional methods, especially when dealing with small amounts of data. 
Parametric Embedding for Class Visualization| Abstract In this paper, we propose a new method, Parametric Embedding (PE), for visualizing the posteriors estimated over a mixture model.  PE
Parametric Mixture Models for Multi-Labeled Text| Abstract We propose probabilistic generative models, called parametric mixture models (PMMs), for multiclass, multi-labeled text categorization problem.  Conventionally, the binary classification approach has been employed, in which whether or not text belongs to a category is judged by the binary classifier for every category.  In contrast, our approach can simultaneously detect multiple categories of text using PMMs.  We derive efficient learning and prediction algorithms for PMMs.  We also empirically show that our method could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages. 
Application of the Variational Bayesian Approach to Speech Recognition| Abstract In this paper, we propose a method based on the variational Bayesian (VB) approach, for training shared-state triphone HMMs (SST-HMMs) for robust speech recognition.  An appropriate model structure with high recognition performance can be found within the VB framework.  Unlike conventional methods including BIC or MDL criterion based on the maximum likelihood approach, the proposed model selection is valid in principle, even in the case of insufficient amounts of data, because it does not use an asymptotic assumption.  In isolated word recognition experiments, we show the advantage of the proposed method over conventional methods, especially when dealing with small amounts of data. 
SMEM Algorithm for Mixture Models| Abstract We present a split and merge EM (SMEM) algorithm to overcome the local maxima problem in parameter estimation of finite mixture models.  In the case of mixture models, local maxima often involve having too many components of a mixture model in one part of the space and too few in another, widely separated part of the space.  To escape from such configurations we repeatedly perform simultaneous split and merge operations using a new criterion for efficiently selecting the split and merge candidates.  We apply the proposed algorithm to the training of Gaussian mixtures and mixtures of factor analyzers using synthetic and real data and show the effectiveness of using the split and merge operations to improve the likelihood of both the training data and of held-out test data.  We also show the practical usefulness of the proposed algorithm by applying it to image compression and pattern recognition problems. 
Deterministic annealing EM algorithm|
Tracking Moving Contours Using Energy-Minimizing Elastic Contour Models|
Deterministic Annealing Variant of the EM Algorithm|
A Matching Algorithm of Deformed Planar Curves Using Multiscale Convex/|
Optimal Linear Combination of Neural Networks for Improving Classification Performance|
A new learning approach based on equidistortion principle for optimal vector quantizer design|
Generalization error of ensemble estimators|
"Variational Bayesian estimation and clustering for speech recognition,|
Bayesian model search for mixture models based on optimizing variational bounds|
Learning Visual Models from Shape Contours Using Multiscale Convex/Concave Structure Matching|
Characteristics of High Occurrence Frequency N-gram of Spoken Japanese Corpora",|
Exploitation of unlabeled sequences in hidden Markov models|
Retrieving slightly annotated images|
Prediction of the In-Plane Electrical Conductivity of a Misoriented Short Fiber Composite: Fiber Percolation Model Versus Effective Medium Theory,|
Statistical analysis of the generalization error of ensemble estimators| (submitted to). 
Deterministic annealing variants of EM|
A contour tracking method using elastic contour model and energy minimization approach,|
Optimal Model Inference for Bayesian Mixture of Experts,|
A new competitive learning approach based on an equidistortion principle for designing optimal vector quantizers|
Generalisation Error of Ensemble Estimators,|
Design, construction and performance of the INS RFQ linac; p 2975,|
