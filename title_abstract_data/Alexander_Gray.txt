An Investigation of Practical Approximate Nearest Neighbor Algorithms| Abstract This paper concerns approximate nearest neighbor searching algorithms, which have become increasingly important, especially in high dimensional perception areas such as computer vision, with dozens of publications in recent years.  Much of this enthusiasm is due to a successful new approximate nearest neighbor approach called Locality Sensitive Hashing (LSH).  In this paper we ask the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how? We introduce a new kind of metric tree that allows overlap: certain datapoints may appear in both the children of a parent.  We also introduce new approximate k-NN search algorithms on this structure.  We show why these structures should be able to exploit the same randomprojection-based approximations that LSH enjoys, but with a simpler algorithm and perhaps with greater efficiency.  We then provide a detailed empirical evaluation on five large, high dimensional datasets which show accelerations one to three orders of magnitude over LSH.  This result holds true throughout the spectrum of approximation levels. 
Submitted to ApJ Preprint typeset using L A T E X style| ABSTRACT We present the two{point correlation function (2PCF) for narrow-line active galactic nuclei (AGN) selected within the First Data Release of the Sloan Digital Sky Survey.  Using a sample of 13605 AGN in the redshift range 0:055 < z < 0:2, we find that the AGN auto{correlation function is consistent with the observed galaxy auto{correlation function on scales 0:2h 1 Mpc to } 100h 1 Mpc.  The AGN hosts trace an intermediate population of galaxies and are not detected in the bluest (youngest) disk{dominated galaxies or many of the reddest (oldest) galaxies.  We show that the AGN 2PCF is dependent on the luminosity of the narrow [OIII] emission line (L [OIII] ), with low L [OIII] AGN having a higher clustering amplitude than high L [OIII] AGN.  This is consistent with lower activity AGN residing in more massive galaxies than higher activity AGN, and L [OIII] providing a good indicator of the fueling rate.  Using an AGN model embedded in cosmological simulations, we show that AGN hosted by # 10 12 M# dark matter halos have a 2PCF that matches that of the observed sample.  This mass scale implies a mean black hole mass for the sample of MBH # 10 8 M# . 
Automatic Derivation of the Multinomial PCA Algorithm| Abstract Machine learning has reached a point where probabilistic methods can be understood as variations, extensions, and combinations of a small set of abstract themes, e. g. , as different instances of the EM algorithm, or as exponential family methods.  This allows the automatic derivation of algorithms customized for different models.  One interesting new model is a multinomial version of PCA which has received attention due to its ability to better model documents as having multiple topics.  Here we explain how AutoBayes, an automatic synthesis system for machine learning programs, derives from a high-level statistical specification of this model code similar to the original non-negative matrix factorization algorithm of Lee and Seung.  The derivation combines multiple statistical schemes to solve a new problem not originally envisaged.  This demonstrates that the approach can be scaled up from text-book problems to research-level algorithm design. 
Automatic Derivation of Statistical Algorithms: The EM Family and Beyond| Abstract Machine learning has reached a point where many probabilistic methods can be understood as variations, extensions and combinations of a much smaller set of abstract themes, e. g. , as different instances of the EM algorithm.  This enables the systematic derivation of algorithms customized for different models.  Here, we describe the AUTOBAYES system which takes a high-level statistical model specification, uses powerful symbolic techniques based on schema-based program synthesis and computer algebra to derive an efficient specialized algorithm for learning that model, and generates executable code implementing that algorithm.  This capability is far beyond that of code collections such as Matlab toolboxes or even tools for model-independent optimization such as BUGS for Gibbs sampling: complex new algorithms can be generated without new programming, algorithms can be highly specialized and tightly crafted for the exact structure of the model and data, and efficient and commented code can be generated for different languages or systems.  We present automatically-derived algorithms ranging from closed-form solutions of Bayesian textbook problems to recently-proposed EM algorithms for clustering, regression, and a multinomial form of PCA. 
Nonparametric Density Estimation: Toward Computational Tractability| Abstract Density estimation is a core operation of virtually all
Efficient Exact k-NN and Nonparametric Classification in High Dimensions| Abstract This paper is about non-approximate acceleration of high dimensional nonparametric operations such as k nearest neighbor classifiers and the prediction phase of Support Vector Machine classifiers.  We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly find the datapoints close to the query, but merely need to ask questions about the properties about that set of datapoints.  This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited.  For clarity, this paper concentrates on pure k-NN classification and the prediction phase of SVMs.  We introduce new ball tree algorithms that on real-world datasets give accelerations of 2-fold up to 100-fold compared against highly optimized traditional ball-tree-based k-NN.  These results include datasets with up to 10 6 dimensions and 10 5 records, and show non-trivial speedups while giving exact answers. 
Rapid Evaluation of Multiple Density Models|
`N-Body' Problems in Statistical Learning|
Retrofitting Decision Tree Classifiers Using Kernel Density Estimation|
Linear-time Smoothed Particle Hydrodynamics|
New Algorithms for Ecient High Dimensional Non-|
New Algorithms for efficient high-dimensional nonparametric classification|
Automated Design of Quantum Circuits|
Ecient kernel density algorithms|
Higher-Order Divide-and-Conquer and Generalized N-Body Problems|
