Diagnosis by a Waiter and a Mars Explorer| Abstract--- This paper shows how state-of-the-art state estimation techniques can be used to provide efficient solutions to the difficult problem of real-time diagnosis in mobile robots.  The power of the adopted estimation techniques resides in our ability to combine particle filters with classical algorithms, such as Kalman filters.  We demonstrate these techniques in two scenarios: a mobile waiter robot and planetary rovers designed by NASA for Mars exploration. 
A Blessing of Dimensionality: Measure Concentration and Probabilistic Inference| Abstract This paper proposes an ecient sampling method for inference in probabilistic graphical models.  The method exploits a blessing of dimensionality known as the concentration of measure phenomenon in order to derive analytic expressions for proposal distributions.  The method can also be interpreted in a variational setting, were one minimises an upperbound on the estimator variance.  The results on simple settings are very promising.  We believe this method has great potential in graphical models used for diagnosis. 
Object Recognition as Machine Translation -- Part 2: Exploiting Image Database Clustering Models| Abstract.  We treat object recognition as a process of attaching words to images and image regions.  To accomplish this we exploit clustering methods which learn the joint statistics of words and image regions.  We show how these models can then be used to attach words to images outside the training set.  This "auto-annotation" process has applications such as image indexing, as well as being related to object recognition.  Predicted words can be compared to actual words associated with images in a held out set, and we introduce several performance measures based on this observation.  These measures are then used to make principled comparisons of model variants, and proposed enhancements.  Word prediction is most simply done as a function of the entire image.  However, for recognition we need to learn the correspondence between words and specific image regions.  Here we first show that the existing models can be used for this purpose, and then we propose modifications to improve performance based on this goal.  Finally, we propose word prediction performance as a segmentation measure and report the results for two segmentation approaches. 
A Statistical Model for General Contextual Object Recognition| Abstract.  We consider object recognition as the process of attaching meaningful labels to specific regions of an image, and propose a model that learns spatial relationships between objects.  Given a set of images and their associated text (e. g.  keywords, captions, descriptions), the objective is to segment an image, in either a crude or sophisticated fashion, then to find the proper associations between words and regions.  Previous models are limited by the scope of the representation.  In particular, they fail to exploit spatial context in the images and words.  We develop a more expressive model that takes this into account.  We formulate a spatially consistent probabilistic mapping between continuous image feature vectors and the supplied word tokens.  By learning both word-to-region associations and object relations, the proposed model augments scene segmentations due to smoothing implicit in spatial consistency.  Context introduces cycles to the undirected graph, so we cannot rely on a straightforward implementation of the EM algorithm for estimating the model parameters and densities of the unknown alignment variables.  Instead, we develop an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step.  The experiments indicate that our approximate inference and learning algorithm converges to good local solutions.  Experiments on a diverse array of images show that spatial context considerably improves the accuracy of object recognition.  Most significantly, spatial context combined with a nonlinear discrete object representation allows our models to cope well with over-segmented scenes. 
Smart Visible Sets for Networked Virtual Environments| Abstract - The real-time visualization of complex virtual environments across the network is a challenging problem in Computer Graphics.  The use of pre-computed visibility associated to regions in space, such as in the Potentially Visible Sets (PVS) approach, may reduce the amount of data sent across the network.  However, a PVS for a region may still be complex, and further partitions of the PVS are necessary.  In this paper we introduce the concept of a Smart Visible Set (SVS), which corresponds to (1) a partition of PVS information into dynamic subsets that take into account client position, and (2) an ordering mechanism that enumerates these dynamic sets using a visual importance metric.  Results comparing the SVS and the PVS approach are presented. 
Fast Krylov Methods for N-Body Learning| Abstract This paper addresses the issue of numerical computation in machine learning domains where one needs to evaluate similarity metrics.  Examples of these domains include dimensionality reduction with kernels, spectral clustering and Gaussian processes.  The paper presents a solution strategy based on Krylov subspace iteration and fast N-body learning methods.  The main benefit of this strategy is that it is very general and easy to adapt to new domains involving similarity metrics.  The experiments show significant gains in computation and storage on datasets arising in image segmentation, object detection and dimensionality reduction.  The paper also presents theoretical bounds on the stability of these iterative methods. 
Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs of Arbitrary Topology| Abstract This paper presents a new sampling algorithm for approximating functions of variables representable as undirected graphical models of arbitrary connectivity with pairwise potentials, as well as for estimating the notoriously difficult partition function of the graph.  The algorithm fits into the framework of sequential Monte Carlo methods rather than the more widely used MCMC, and relies on constructing a sequence of intermediate distributions which get closer to the desired one.  While the idea of using "tempered" proposals is known, we construct a novel sequence of target distributions where, rather than dropping a global temperature parameter, we sequentially couple individual pairs of variables that are, initially, sampled exactly from a spanning tree of the variables.  We present experimental results on inference and estimation of the partition function for sparse and densely-connected graphs. 
Rao-Blackwellised Particle Filtering via Data Augmentation| Abstract In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations.  This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation.  Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers.  We focus on sequential binary classifiers that consist of linear combinations of basis functions, whose coecients evolve according to a Gaussian smoothness prior.  Our results show significant improvements. 
Rao-Blackwellised particle filtering for fault diagnosis|
Fast computational methods for visually guided robots|
Bayesian feature weighting for unsupervised learning, with application to object recognition|
Empirical testing of fast kernel density estimation algorithms|
Machine Learning for Computer Games|
The touring test: Human-like play in computer games| Unpublished research paper,. 
Bayesian latent semantic analysis of multimedia databases|
