Stochastic simulation of ants that forage by expectation| Abstract Stochastic simulation has been used to create an artificial colony of ants in order to study ant foraging strategies and the links between individual activity and the colony's self-organised behaviour.  The ants, which forage by expectation, use a deterministic mathematical model developed by Ollason (1980, Theor.  Pop.  Biol. 
RECOGNITION OF OCCLUDED SPEECH BY HIDDEN MARKOV MODELS| ABSTRACT Previous work at Sheffield on computational models of auditory scene analysis has attempted to separate the acoustic evidence from simultaneous sound sources by techniques grounded in auditory grouping processes.  For this work to be useful in automatic speech recognition, we need to develop recognition techniques which can cope with 'occluded' speech.  The separation stage will group together components of the sound mixture which were produced by the same source, but will contain little or no information for those parts of the spectrum which were obscured by other sources.  We present a method which allows conventional hidden Markov model (HMM) based speech recognition systems, trained on good-quality data, to be applied to occluded speech material.  We show that, for continuous density HMMs, the probability of observing such a partial data vector in a given state can be computed from the appropriate marginal distribution.  We show formally that this distribution can be derived from the full mixture density function associated with the state by striking out the rows and columns from the mean vector and covariance matrix corresponding to the missing elements.  We present empirical evidence for the robustness of this method: on phone models for the TIMIT database it is possible to delete 50% of the observation vector at random without serious degradation in recognition performance (accuracy falls from 58. 9% to 51. 5% for 10 mixture, diagonal covariance models, whilst correctness falls from 69. 6% to 66. 0%).  Even with 80% removed some competence remains (30. 5% accuracy, 55. 0% correct).  We conclude that auditory scene analysis followed by recognition of occluded speech can be seen as an attractive paradigm for robust automatic speech recognition; it makes no assumptions about the nature of the noise or the number of sound sources present. 
Computer Science Technical Report Introduction to Computational Neural Modeling for Computer Scientists and Mathematicians| Abstract The rise in availability of powerful personal computers allows researchers in many dierent disciplines access to problems that were, in the recent past, computationally intractable.  Biologically realistic neural models are one example of a problem that is both computationally expensive, but also multidisciplinary by nature.  These neural models incorporate fundamental neuroscience principles into a mathematical framework that may be understood and studied by experts in computer science and mathematics.  Moreover, the inclusion of these disciplines into neural modeling research is essential as the models grow larger, more detailed, and hence more complicated in both construction and analysis.  Neural modeling demands collaboration among widely diering scientific disciplines and thus, demands an easily accessible introduction to researchers grounded in the mathematical sciences.  This introduction attempts to simply and succinctly introduce the basic biological, chemical, and physical science upon which neural models are built.  The introduction then defines, derives, and explains, stepwise, numerical integration of the compartment model using the Backward Euler method. 
Assessing Neural Networks as Guides for Testing Activities| Abstract As test case automation increases, the volume of tests can become a problem.  Further, it may not be immediately obvious whether the test generation tool generates effective test cases.  Indeed, it might be useful to have a mechanism that is able to learn, based on past history, which test cases are likely to yield more failures versus those that are not likely to uncover any.  We present experimental results on using a neural network for pruning a testcase set while preserving its effectiveness. 
FINAL REPORT Colorado Advanced Software Institute MODELING STUDENT PILOTS FOR INTELLIGENT TRAINING| In 1995, the FAA and NASA formed a consortium to advance the concept of a small aircraft transportation system.  The consortium's primary focus is the Advanced General Aviation Transport Experiments (AGATE).  The goal of this government-industry-university partnership is to develop technologies for safety, affordability, and ease of use for single pilot, single engine, near all weather transportation aircraft and related training, airspace, and ground infrastructure systems.  Targeted training technologies include cockpit-based onboard training systems, computer-based training desktop devices, simulation, virtual environment systems, and expert systems.  It is in this field of advanced training concepts for General Aviation (GA) pilots that this research is targeted.  Teaching a person to fly a GA airplane is a complex and time consuming task.  The approach of using one-on-one training with an instructor in the co-pilot's seat of a real airplane has been used for decades.  While real aircraft offer the ultimate in training realism, they are expensive to operate and maintain, and safety considerations restrict the tasks that can be practiced.  Augmenting instructor training in a real airplane with computer simulation promises to reduce training costs and allow instruction in emergencies in a forgiving environment Today, low end flight training devices (FTDs) are sometimes employed as self paced instruction for specific tasks.  For the GA marketplace these devices are classified as part task trainers (navigation, reading basic flight instruments, etc. ).  They do not have the aircraft system comprehensiveness, accuracy, nor the simulated reality of the full flight simulators used by major airlines and the military.  On the other hand, FTDs don't have the high development and operation cost of full flight simulators.  With modern advances in computer graphics, microcomputer processing power, and electro-mechanical control loading, it is possible to build FTDs that approach the capabilities of full flight simulators at a significantly reduced price.  For this CASI research project, we investigated augmenting FTD simulation capabilities with adaptive techniques that model the abilities of each student pilot.  Ultimately the ability to predict each student's capabilities and to adapt the simulation according to their strengths and weaknesses will reduce the number of human instructor hours required and allow for better training over a shorter period of time.  Our first thrust at this broad problem was to develop a system that builds dynamic models of a student's current flying ability and predicts their trajectory in FTD simulations. 
Comparison of CMACs and Radial Basis Functions for Local Function Approximators in Reinforcement Learning| Abstract CMACs and Radial Basis Functions are often used in reinforcement learning to learn value function approximations having local generalization properties.  We examine the similarities and differences between CMACs, RBFs and normalized RBFs and compare the performance of Q-learning with each representation applied to the mountain car problem.  We discuss ongoing research efforts to exploit the flexibility of adaptive units to better represent the local characteristics of the state space. 
SAR for Agriculture and Forestry (SAFE) : Technical Requirements| ABSTRACT A summary of a study on the use of spaceborne SAR for forestry and agriculture in Europe is given.  User requirements were surveyed, then translated into physical parameters which may potentially be inferred from measurements by an appropriate instrument.  The performance of SAR in estimating the required parameters was then assessed from the literature.  Overall performance assessments are given, and system options are suggested.  We also consider the methodology, limitations and accomplishments of the study. 
A&A manuscript no| Abstract.  The solar 2. 297 GHz radiation has been observed and investigated by very long baseline interferometry (VLBI).  The radio observatories of Medicina, Noto, Onsala, and Weilheim were involved yielding baselines between 360 km and 3800 km and a nominal resolution of 0. 09 00 to 0. 008 00 or 70 to 6 km on the Sun.  This solar VLBI network operated successfully with at least one useful baseline for 167 hours during five campaigns at the maximum of the most recent activity cycle in 1989 and 1990.  The Phoenix spectrometer at Zurich was used to detect and classify the radio bursts.  A total of 59 solar radio bursts were observed at the VLBI frequency, of which 26 events were analyzed, including narrowband millisecond spikes, type III bursts, patches, pulsations, and diffuse broadband (gyrosynchrotron) emission.  Neither during bursts nor in quiet times significant fringes were detected.  All sources were well resolved including the narrowband spikes.  We interpret the result in terms of relatively large radio sources and/or by scattering to apparent source sizes larger than the lowest resolution and by the lack of `speckles'.  The results are consistent with scattering of the radio emission in the corona.  The upper and lower limits of the source size of spikes are discussed.  For the apparent source size, `a , we find 65 km ! `a ! 16 000 km, and for the original source size before scattering ` ! 200 km. 
A PHYSICALLY-BASED MODEL OF OCEAN BACKSCATTER FOR WIND SPEED RETRIEVAL FROM SAR, SCATTEROMETER AND ALTIMETER| ABSTRACT A comprehensive theoretical model of radar backscatter from the ocean surface is discussed.  It combines alternative models of the interaction between the wind and the sea surface, and different descriptions of the ocean waveheight spectrum of wind seas, with two alternative scattering theories, namely the composite-surface model and the integral equation method.  The effects of swell, limited fetch, and perturbations due to rain, surface slicks and currents may be included.  The model is able to show the expected sensitivity of radar backscatter to all these factors, and some results for the dependence on swell are shown.  Hence it indicates possible improvements to current empirical models as well as implications for future missions such as Envisat.  The model predictions are also compared against Topex altimeter data which are collocated with buoy measurements, and against an empirical scatterometer model function.  The results at nadir agree well with the empirically observed dependence on wind speed, while the dependence on swell is consistent with recent studies of the influence of swell on the relation between wind stress and wind speed.  Results at off-nadir incidence angles are more sensitive to the choice of ocean waveheight spectrum.  In particular, the directional spread of waves is not well understood; this leads to a systematic discrepancy between dependences of backscatter on wind direction predicted by the empirical and theoretical models. 
EEG Subspace Representations and Feature Selection for Brain-Computer Interfaces| Abstract Electroencephalogram (EEG) signals recorded from a persons scalp have been used to control binary cursor movements.  Multiple choice paradigms will require more sophisticated protocols involving multiple mental tasks and signal representations that capture discriminatory characteristics of the EEG signals.  In this study, six-channel EEG is recorded from a subject performing two mental tasks.  The signals are transformed via the Karhunen-Loeve or maximum noise fraction transformations and classified by quadratic discriminant analysis.  In addition, classification accuracy is tested for all subsets of the six EEG channels.  Best results are approximately 90% correct when training and testing data are recorded on the same day and 75% correct when training and testing data are recorded on different days. 
Classification of EEG Signals Using a Sparse Polynomial Builder| Abstract Sutton and Matheus' algorithm for sparse polynomial construction is used to construct a classifier to recognize a mental task from recorded EEG signals.  Data used is from Keirn [Keirn 88].  Since the data set is very limited, the classification accuracy was calculated by the jack knife or loom method of cross validation.  Results indicate that the classifier does not generalize well on untrained data; accuracy averaged only 65%.  This was believed to be the result of having too many features, initially causing over fitting.  Since the algorithm starts with the features and only add news ones, initial over fitting remains.  To overcome this limitation, the polynomial was modified to have zero features initially.  On average the classification accuracy was unimproved, although most subjects' accuracy was 10 to 20% higher.  The low accuracy is speculated to be the result of bad feature selection and the algorithm's susceptibility to noisy output and incomplete sampling of patterns.  One result of this project is a reusable and modular set of C++ classes for training classifiers based on Sutton and Matheus' method. 
Experiences with Extension Programming and Scripting in Python| Abstract Our experiences interfacing Python with optimization software are presented.  The same work was done using extension programming and scripting.  Due to the nature of the C libraries we were using, we found problems related to memory corruption and C namespace collisions when we used the libraries as Python extensions.  For our application and the software we are interfacing to, we found that using the libraries as standalone programs connected via Python scripting was a better way to use the optimization codes via Python. 
Behavioral Cloning of Student Pilots with Modular Neural Networks| Abstract This paper investigates how behavioral cloning can be used to decrease training time for students learning to fly on simulators.  The challenges presented to each student must be tailored to their unique learning experiences.  This requires an intelligent training regime that exploits a model of each student that predicts where the student's performance will be deficient.  Here we show that cloning the behavior of student pilots with a modular neural network results in the automatic decomposition of the behavior into sets of skills.  This decomposition may provide a means for identifying when certain skills are acquired by students and which skills are defficient.  This information may then be used to decrease training time by altering the sequence of simulation experiences to just those that the student needs.  1.  Problem In 1995, the FAA and NASA formed a consortium to advance the concept of a small aircraft transportation system.  The consortium's primary focus is the Advanced General Aviation Transport Experiments (AGATE).  The goal of this government-industryuniversity partnership is to develop technologies for safety, a#ordability, and ease of use for single pilot,
Computer Science Technical Report Fast Generation of NURBS Surfaces from Polygonal Mesh Models of Human Anatomy| Abstract Visible Productions, Inc. , of Fort Collins, CO, produces 3-D human models that are recognized as some of the most accurate models in the world.  Their models currently are based on meshes of 3-D triangles.  Such meshes can be rendered as smooth surfaces byinterpolating color values across a triangular mesh, but for a number of applications the smooth surface must be explicitly represented.  Clients for Visible Productions' models have asked for surfaces defined by NURBS (Non-Uniform Rational B-Splines).  This project developed and implemented algorithms for transforming polygonal meshes into NURBS.  This requires a time-intensive, iterative optimization process.  Weinvestigated the use of neural networks to by-pass a large part of the optimization process. 
Q-Learning with Hidden-Unit Restarting| Abstract Platt's resource-allocation network (RAN) (Platt, 1991a, 1991b) is modified for a reinforcement-learning paradigm and to \restart" existing hidden units rather than adding new units.  After restarting, units continue to learn via back-propagation.  The resulting restart algorithm is tested in a Q-learning network that learns to solveaninverted pendulum problem.  Solutions are found faster on average with the restart algorithm than without it. 
Strategy Learning with Multilayer Connectionist Representations| Abstract Results are presented that demonstrate the learning and fine-tuning of search strategies using connectionist mechanisms.  Previous studies of strategy learning within the symbolic, production-rule formalism have not addressed fine-tuning behavior.  Here a two-layer connectionist system is presented that develops its search from aweak to a task-specific strategy and #ne-tunes its performance.  The system is applied to a simulated, realtime, balance-control task.  We compare the performance of one-layer and two-layer networks, showing that the ability of the two-layer network to discover new features and thus enhance the original representation is critical to solving the balancing task. 
Traffic Light Control Using SARSA with Three State Representations| Abstract SARSA is applied to a simulated traffic light control problem and compared with a fixed-duration strategy and a simple, rule-based strategy.  The performance of SARSA with three different representations of the current state of traffic is analyzed.  SARSA is shown to be superior to the best, fixed-duration light timing and close to optimal for the simulation used in this article. 
A Multigrid Form of Value Iteration Applied to a Markov Decision Problem| Abstract We explore the use of multigrid techniques to speed the convergence of value iteration for Markov Decision Problems by applying it to the mountain car problem.  We look at some of the fundamental differences between these kinds of problems and those traditionally treated with multigrid methods.  We demonstrate that significant performance improvements can be achieved by using these techniques. 
On the Use of Neural Networks to Guide Software Testing Activities| Abstract As test case automation increases, the volume of tests can become a problem.  Further, it may not be immediately obvious whether the test generation tool generates effective test cases.  Indeed, it might be useful to have a mechanism that is able to learn, based on past history, which test cases are likely to yield more failures versus those that are not likely to uncover any.  We present experimental results on using a neural network for pruning a testcase set while preserving its effectiveness. 
Discriminating Mental Tasks Using EEG Represented by AR Models| Abstract---EEG signals are modeled using single-channel and multi-channel autoregressive (AR) techniques.  The coefficients of these models are used to classify EEG data into one of two classes corresponding to the mental task the subjects are performing.  A neural network is trained to perform the classification.  When applying a trained network to test data, we find that the multivariate AR representation performs slightly better, resulting in an average classification accuracy of about 91%. 
Using Temporal Neighborhoods to Adapt Function Approximators in Reinforcement Learning| Abstract To avoid the curse of dimensionality, function approximators are used in reinforcement learning to learn value functions for individual states.  In order to make better use of computational resources (basis functions) many researchers are investigating ways to adapt the basis functions during the learning process so that they better fit the value-function landscape.  Here weintroduce temporal neighborhoods as small groups of states that experience frequentintragroup transitions during on-line sampling.  We then form basis functions along these temporal neighborhoods.  Empirical evidence is provided which demonstrates the effectiveness of this scheme.  We discuss a class of RL problems for which this method mightbe plausible.  1 Overview In reinforcement learning an agentnavigates an environment (a state space) by selecting various actions in each state.  As the agent makes actions, it receives rewards indicating the \goodness" of the action.  Reinforcement learning is a methodology which allows the agent to discover which actions to select in order to optimize the rewards in each state.  The value of a state is the immediate reward an agent will receive from that state and the discounted sum of all future rewards encountered by the agent.  Detailed reviews of reinforcement learning are available [2, 3].  On-line algorithms use the experience of the agent as it moves about the state space to learn the values of each state.  Tables are often employed to \memorize" the value for each individual state.  However, many RL problems involvevery large state spaces, especially when the state space is multidimensional.  The curse of dimensionality arises because state spaces grow too large to store all individual state values in a single table.  To lessen the curse of dimensionality, function approximators are commonly utilized: they require far fewer resources than a table look-up method, and they generalize over other parts of the state space so that learning experience can be shared among states.  Function approximators commonly use fixed basis functions (such as CMACs and Radial Basis Functions) which have shown to be stable in both theory and in practice [8, 9].  Despite the proofs of convergence for fixed basis function approximators, these RL algorithms are often slow to converge in practice.  Research indicates that different types of basis functions are better suited to different problems, and they often need to be \#ne-tuned" to the particular task [4].  Fixed basis functions also tend to be somewhat wasteful of computational resources because they do not accommodate the pecularities of the value function landscape; one needs to be certain to employ enough fixed basis functions of adaquately fine resolution to learn a value function well.  There have been many attempts to adapt basis functions during learning to better fit the value function landscape.  The most common methods perform gradient descent on an error metric but these techniques are generally slow to converge and are overly sensativetovarious parameters.  Singh's soft state aggregation demonstrates success using a gradient descent technique to shape the basis functions [7].  There are also various other adaptive approaches.  Anderson's Hidden Restart Method [1] relocates basis functions to regions of the state space which are not adequately modelled.  Whitehead and Choate employ genetic algorithms to position and form basis functions [10].  Moore's Parti-Game Algorithm learns value functions by dynamically creating variable resolution \basis functions" [6].  Here we develop a novel approach in which the basis functions are adapted according to the perceived state transition probabilities.  McCallum has shown successful results in using Transitional Proximity for a faster Q-value update scheme [5].  We use the same information in much different manner.  Additionally,we provide a theoretical discussion regarding the types of RL tasks that would benefit from using state transitions.  In Section 2 we define temporal neighborhoods and discuss their role in forming basis functions for function approximation.  Section 3 shows a simple example illustrating the advantage of temporal neighborhoods.  The details of the algorithm are presented in Section 4.  In Section 5 we apply the algorithm to the more complex Mountain Car task.  A summary and discussion of future work are presented in Section 6.  2 Temporal Neighborhoods With most local function approximators, basis functions are created to span a small neighborhood of physically adjacent states.  By \physically adjacent states" we mean states which are near each other in Euclidean distance.  Although states maybephysically adjacent, in many control problems it may be unlikely (or even impossible) that the agent can transition between them.  A better notion of nearness is temporal adjacency.  As the agentinteracts with the environment, there tend to be pathways or trajectories through the state space which the agent uses with high frequency.  The states which lie along these trajectories are temporaly adjacent.  Two states are temporally adjacent if when the agent currently occupies one state, there exists a high probability that the agent will transition to the other state on the next move. 
On the Efficiency of a Compound Poisson Stopping Rule for Mixed Strategy Testing| Abstract---When testing software, testers rarely use only one technique to generate tests that, they hope, will fulfill their testing criteria.  Malaiya showed that testers switch strategies when testing yield saturates.  We present and evaluate a stopping rule that can be used to determine when it is time to switch to a different testing technique, because the current one is not likely to increase criteria fulfilment.  We demonstrate use of the stopping rule on a program that is being tested for branch coverage with five different testing techniques.  We compare savings and accuracy of stopping both with and without using the stopping rule. 
Multigrid Q-Learning| Abstract Reinforcement learning scales poorly when reinforcements are delayed.  The problem of propagating information from delayed reinforcements to the states and actions that have an effect the reinforcement is similar to the problem of propagating information in a discretized boundary value problem.  Multigrid methods have been shown to decrease the number of updates required to solve boundary value problems.  Here we extend Q-Learning by casting it as a multigrid method and show a reduction in updates required to reach a given error level in the Q-function for a simple, 1-d Markov decision task. 
EEG SIGNAL COMPRESSION WITH ADPCM SUBBAND CODING| ABSTRACT An EEG signal compression method that combines both octave-band filter bank frequency decomposition and coding in subbands using adaptive differential pulse code modulation (ADPCM) is proposed.  Besides being computationally effective, this compression method in its simplest form yields 70 % data reductions with very little distortion.  Higher compression rate are obtained by increasing the order of the predictor used. 
Estimating Ignition Timing from Engine Cylinder Pressure with Neural Networks| Abstract A study was conducted to determine the ability of neural networks to extract high level control information from cylinder pressure data.  Various experiments were performed using neural networks for pattern recognition on a series of data files consisting of cylinder pressure versus crank angle.  The goal of these experiments was to estimate spark timing based on the cylinder pressure signature -- all other engine parameters were held constant during the data collection process.  Test results indicate that an approximate spark timing value can be obtained using cylinder pressure data as the inputs to a neural network and spark timing as the output. 
Reinforcement Learning with Modular Neural Networks for Control| Abstract Reinforcement learning methods can be appliedto control problems with the objective of optimizing the value of a function over time.  They have been used to train single neural networks that learn solutions to whole tasks.  Jacobs and Jordan [5] have shown that a set of expert networks combined via a gating network can more quickly learn tasks that can bedecomposed.  Even the decomposition can belearned.  Inspiredby Boyan's work of modular neural networks for learning with temporal-di#erence methods [4], we modify the reinforcement learning algorithm called Q-Learning to train a modular neural network to solve a control problem.  The resulting algorithm is demonstratedonthe classical pole-balancing problem.  The advantage of such a method is that it makes it possible to deal with complex dynamic control problem effectively by using task decomposition and competitive learning. 
Efficient Indexing for Object Recognition Using Large Networks \Lambda| Abstract Template matching is an effective means of locating vehicles in outdoor scenes, but it tends to be a computationally expensive.  To reduce processing
Case Studies in Gaussian Process Modelling of Computer Codes| Abstract: In this paper we present a number of recent applications in which
ALONZO CHURCH'S CONTRIBUTIONS TO PHILOSOPHY AND INTENSIONAL LOGIC| 0.  Alonzo Church's contributions to philosophy and to that most philosophical part of logic, intensional logic, are impressive indeed.  He wrote relatively few papers actually devoted to specifically philosophical issues, as distinguished from related technical work in logic.  Many of his contributions appear in reviews for The Journal of Symbolic Logic, 1 and it can hardly be maintained that one finds there a "philosophical system".  But there occur a clearly articulated and powerful methodology, terse arguments, often of "crushing cogency", 2 and philosophical observations of the first importance.  Many of the less formal philosophical contributions center around questions concerning meaning, but there are important clarifications and insights into matters of the epistemology and ontology of the sciences, especially the formal sciences.  1.  Methodology, epistemology, and ontology.  1. 1.  The logistic method.  Church's writings on philosophical matters exhibit an unwavering commitment to what he called the "logistic method".  3 The term did not catch on and now one would just speak of "formalization".  The use of these ideas is now so common and familiar among logicians
Modelling the Occurrence of Large Concentration Values in Pollutant Plumes| Abstract: Large concentration values are of particular interest in assessing hazards or nuisance associated with clouds or plumes of toxic, flammable or malodorous gases.  Previously we have used statistical extreme value theory to analyse the probability distribution of large concentrations at a fixed point in space.  Here we present a probabilistic model for the temporal occurrence (at a discrete set of points in space -- the receptor locations) of large concentrations in a plume.  We consider a fixed downwind distance, and take the plume centreline to be at one of a discrete set of crosswind positions.  Changes of centreline position are modelled by a continuous time Markov chain.  At each receptor location the large concentration values are taken to occur at the points of a Poisson process in time whose rate depends on the distance from the centreline.  We present some results from fitting this model to data from atmospheric point source experiments.  The fitted parameters for the Markov chain are not very robust or reliable.  Possible reasons for this are discussed, and suggestions are made for how the results might be improved. 
Computer Science Technical Report Robust Reinforcement Learning Control with Static and Dynamic Stability| Abstract Robust control theory is used to design stable controllers in the presence of uncertainties.  By replacing nonlinear and time-varying aspects of a neural network with uncertainties, a robust reinforcement learning procedure results that is guaranteed to remain stable even as the neural network is being trained.  The behavior of this procedure is demonstrated and analyzed on two simple control tasks.  For one task, reinforcement learning with and without robust constraints results in the same control performance, but at intermediate stages the system without robust constraints goes through a period of unstable behavior that is avoided when the robust constraints are included. 
The Largest Inclusions in a Piece of Steel| Abstract Fatigue properties of steels are strongly influenced by the presence of microscopic particles of oxides or foreign material known as inclusions.  The size of the largest inclusion is an important determinant of fatigue strength.  This paper studies the problem of estimating the sizes of large inclusions from measurements made on a two-dimensional section of the steel.  The approach combines traditional stereological ideas with more recent extreme value modelling.  It is shown that both likelihood and Bayesian approaches are useful in the inference. 
How Much Testing is Enough? Applying Stopping Rules to Behavioral Model Testing| Abstract Testing behavioral models before they are released to the synthesis and logic design phase is a tedious process, to say the least.  A common practice is the test-it-to-death approach in which millions or even billions of vectors are applied and the results are checked for possible bugs.  The vectors applied to behavioral models include functional vectors, but the significant amount of the vectors are random in nature, including random combinations of instructions.  In this paper, we present and evaluate a stopping rule that can be used to determine when to stop the current testing phase using a given testing technique, and move on to the next phase using a different testing technique.  We demonstrate the use of the stopping rule on two complex VHDL models that were tested for branch coverage with 4 different testing phases.  We compare savings and quality of testing both with and without using the stopping rule. 
Reinforcement Learning, Neural Networks and PI Control Applied to a Heating Coil| Abstract An accurate simulation of a heating coil is used to compare the performance of a PI controller, a neural network trained to predict the steady-state output of the PI controller, a neural network trained to minimize the n-step ahead error between the coil output and the set point, and a reinforcement learning agent trained to minimize the sum of the squared error over time.  Although the PI controller works very well for this task, the neural networks do result in improved performance. 
Neuronlike elements that can solve difficult learning control problems|
Learning to control an inverted pendulum using neural networks|
Cooperativity in networks of pattern recognizing stochastic learning automata|
III| Subcontinuations. 
ci#c| Classification of eeg signals from four subjects during five mental tasks. 
Learning and Problem Solving with Multilayer Connectionist Systems|
A challenging set of control problems|
Feature generation and selection by a layered network of reinforcement learning elements: some initial experiments|
Extreme value theory for a class of discrete distributions with applications to some stochastic processes,|
Synthesis of nonlinear control surfaces by a layered associative search network|
Improving the Performance of BusBased Multiprocessors|
Learning a Nonlinear Model of a Manufacturing Process Using Multilayer Connectionist Networks,|
Centralized vs| Decentralized Control in manufacturing: lessons from social insects.  Complexity and Complex Systems in Industry,. 
Application of the Generalized Pareto distribution to the estimation of the size of the maximum inclusion in clean steels|
Comparison of extreme value statistics methods for predicting maximum inclusion size in clean steels|
The precision of methods using the statistics of extremes for the estimation of the maximum size of inclusions in clean steels|
Neurobiological computational systems|
Do non-strategic sanctions obey the law of demand? The demand for punishment in the voluntary contribution mechanism|
A switching Poisson process model for high concentrations in short-range atmospheric dispersion,|
A generalised Pareto distribution model for high concentrations in short-range atmospheric dispersion,|
Multivariate autoregressive models for classification of spontaneous electroencephalographic signals during mental tasks,|
Geometric analysis for the characterization of nonstationary time-series|
Structural learning in connectionist systems|
Deregulation, Disintermediation, and Agency Costs of Debt: Evidence from Japan"|
More is Different|
Rapid computation of the discrete Fourier transform,|
A computational steering system for studying microwave interactions with missile bodies|
On choosing test criteria for behavioral level harware design verification|
Strategy learning with multilayer connectionist representation|
Approximating a policy can be easier than approximating a value function|
Pole-balancing simulator and controller|
EEG Signal Classification with Different Signal Representations|
Sums and maxima of stationary sequences with heavy tailed distributions|
"xFS Attribute Manager Design|
The organization of foraging in insect societies|
1960s Law Applied to Internet Threat,|
Modeling of periodic great earthquakes on the San Andreas fault: Effects of nonlinear crustal rheology,|
Development of a CLARiiON Fibre Channel Device Driver for Linux|
Wave climate variability and impact on offshore design extremes| Report for Shell International and the Organization of Oil &. 
DNA damage activates p53 through a phosphorylation-acetylation cascade|
Foreign Ownership in the Privatization Process:Empirical Evidence from Czech Privatization," working paper,|
Mapping the Territory: issues in evaluating large-scale learning technology initiatives|
Computer assisted modeling of affective tone in written documents|
Modelling emotional tone in stories using tension levels and categorical states|
A human RNA polymerase II complex associated with SRB and DNA-repair proteins [published erratum appears|
Genetic reinforcement learning for neurocontrol problems,|
Classification of EEG signals from four subjects during five mental tasks|
Recent advances in EEG signal analysis and classification|
Comparison of linear and nonlinear methods for eeg signal classification|
Effects of variations in neural network topology and output averaging on the discrimination of mental tasks from spontaneous electroencephalogram|
The Effects of APU Characteristics on the Design of Hybrid Control Strategies for Hybrid Electric Vehicles,|
"The implementation and optimization of Portable Standard Lisp for the Cray,|
If desired, the present analysis of the stochastic neuronal dynamics can be replaced by an analysis of this deterministic neuronal dynamics,|
Determining Mental State from EEG Signals Using Neural Networks|
Tower of Hanoi with Connectionist Networks: Learning New Features|
Changing middle school students' conceptions of matter and molecules|
Transitive square-free algebras,|
Students Conceptions of Chemical Change|
Reduced Median-Joining network analysis of complete mitochondrial DNA coding-region sequences for major African, Asian and European haplogroups|
Financial contracting under extreme uncertainty: an analysis of Brazilian corporate debentures|
Learning coordinated behaviors for control of a simulated robot|
Two human 90kDa heat shock proteins are phosphorylated in vivo at conserved serines that are phosphorylated in vitro by casein kinase II,|
Self-organization in relation to several similar concepts: Are the boundaries to self-organisation indistinct?|
User &Programmer Guide for RT2 (Version 3e),|
Linear and Non-Linear Methods for BrainComputer Interfaces",|
Neural nets in boundary tracing tasks|
Design, synthesis and study of 9-substituted ellipticine and 2-methylellipticinium analogues as potential CNSselective antitumor agents|
Lisp and Symbolic and Computation,|
The joint limiting distribution of sums and maxima of stationary sequences|
Contributions to the Asymptotic Theory of Extreme Values|
The impact of contextual and process factors on the evaluation of activity-based costing systems|
The LiNC Project: Learning in Networked Communities|
Interactive region bounding with neural nets|
Machine learned contours to assist boundary tracing|
On vortex method,|
Personal Finance and the Rush to Competence: Financial Literacy Education in|
"Appropriating Scientific Practices and Discourses with Future Elementary Teachers",|
An Operating System Development: Windows 3, Industrial Experiences presentation at ICSE 18|
Creation of desirable complexity: Strategies for designing self-organized systems|
