A Generalized Representer Theorem| Abstract Wahba's classical representer theorem states that the solutions of certain risk minimization problems involving an empirical risk term and a quadratic regularizer can be written as expansions in terms of the training examples.  We generalize the theorem to a larger class of regularizers and empirical risk terms, and give a self-contained proof utilizing the feature space associated with a support vector kernel.  The result shows that a wide range of problems have optimal solutions that live in the finite dimensional span of the training examples mapped into feature space, thus enabling us to carry out kernel algorithms independent of the (potentially infinite) dimensionality of the feature space. 
Learning on Graphs in the Game of Go| Abstract We consider the game of Go from the point of view of machine learning and as a well-defined domain for learning on graph representations.  We discuss the representation of both board positions and candidate moves and introduce the common fate graph (CFG) as an adequate representation of board positions for learning.  Single candidate moves are represented as feature vectors with features given by subgraphs relative to the given move in the CFG.  Using this representation we train a support vector machine (SVM) and a kernel perceptron to discriminate good moves from bad moves on a collection of life-and-death problems and on 9 \Theta 9 game records.  We thus obtain kernel machines that solve Go problems and play 9 \Theta 9 Go. 
Generalization Bounds for the Area Under the ROC Curve| Abstract We study generalization properties of the area under the ROC curve (AUC), a quantity that has been advocated as an evaluation criterion for the bipartite ranking problem.  The AUC is a different term than the error rate used for evaluation in classification problems; consequently, existing generalization bounds for the classification error rate cannot be used to draw conclusions about the AUC.  In this paper, we define the expected accuracy of a ranking function (analogous to the expected error rate of a classification function), and derive distribution-free probabilistic bounds on the deviation of the empirical AUC of a ranking function (observed on a finite data sequence) from its expected accuracy.  We derive both a large deviation bound, which serves to bound the expected accuracy of a ranking function in terms of its empirical AUC on a test sequence, and a uniform convergence bound, which serves to bound the expected accuracy of a learned ranking function in terms of its empirical AUC on a training sequence.  Our uniform convergence bound is expressed in terms of a new set of combinatorial parameters that we term the bipartite rank-shatter coefficients; these play the same role in our result as do the standard VC-dimension related shatter coefficients (also known as the growth function) in uniform convergence results for the classification error rate.  A comparison of our result with a recent uniform convergence result derived by Freund et al.  (2003) for a quantity closely related to the AUC shows that the bound provided by our result can be considerably tighter. 
Generalisation Error Bounds for Sparse Linear Classifiers| Abstract We provide small sample size bounds on the generalisation error of linear classifiers that are sparse in their dual representation given by the expansion coefficients of the weight vector in terms of the training data.  These results theoretically justify algorithms like the Support Vector Machine, the Relevance Vector Machine and K-nearest-neighbour.  The bounds are a-posteriori bounds to be evaluated after learning when the attained level of sparsity is known.  In a PAC-Bayesian style prior knowledge about the expected sparsity is incorporated into the bounds.  The proofs avoid the use of double sample arguments by taking into account the sparsity that leaves unused training points for the evaluation of classifiers.  We furthermore give a PAC-Bayesian bound on the average generalisation error over subsets of parameter space that may pave the way combining sparsity in the expansion coefficients and margin in a single bound.  Finally, reinterpreting a mistake bound for the classical perceptron algorithm due to Novikoff we demonstrate that our new results put classifiers found by this algorithm on a firm theoretical basis. 
Online Bayes Point Machines| Abstract.  We present a new and simple algorithm for learning large margin classifiers that works in a truly online manner.  The algorithm generates a linear classifier by averaging the weights associated with several perceptron-like algorithms run in parallel in order to approximate the Bayes point.  A random subsample of the incoming data stream is used to ensure diversity in the perceptron solutions.  We experimentally study the algorithm's performance on online and batch learning settings.  The online experiments showed that our algorithm produces a low prediction error on the training sequence and tracks the presence of concept drift.  On the batch problems its performance is comparable to the maximum margin algorithm which explicitly maximises the margin. 
Bayesian Learning in Reproducing Kernel Hilbert Spaces| Abstract Support Vector Machines find the hypothesis that corresponds to the centre of the largest hypersphere that can be placed inside version space, i. e.  the space of all consistent hypotheses given a training set.  The boundaries of version space touched by this hypersphere define the support vectors.  An even more promising approach is to construct the hypothesis using the whole of version space.  This is achieved by the Bayes point: the midpoint of the region of intersection of all hyperplanes bisecting version space into two volumes of equal magnitude.  It is known that the centre of mass of version space approximates the Bayes point [31].  The centre of mass is estimated by averaging over the trajectory of a billiard in version space.  We derive bounds on the generalisation error of Bayesian classifiers in terms of the volume ratio of version space and parameter space.  This ratio serves as an effective VC dimension and greatly influences generalisation.  We present experimental results indicating that Bayes Point Machines consistently outperform Support Vector Machines.  Moreover, we show theoretically and experimentally how Bayes Point Machines can easily be extended to admit training errors. 
Classification on Pairwise Proximity Data| Abstract We investigate the problem of learning a classification task on data represented in terms of their pairwise proximities.  This representation does not refer to an explicit feature representation of the data items and is thus more general than the standard approach of using Euclidean feature vectors, from which pairwise proximities can always be calculated.  Our first approach is based on a combined linear embedding and classification procedure resulting in an extension of the Optimal Hyperplane algorithm to pseudo-Euclidean data.  As an alternative we present another approach based on a linear threshold model in the proximity values themselves, which is optimized using Structural Risk Minimization.  We show that prior knowledge about the problem can be incorporated by the choice of distance measures and examine different metrics w. r. t.  their generalization.  Finally, the algorithms are successfully applied to protein structure data and to data from the cat's cerebral cortex.  They show better performance than K-nearest-neighbor classification. 
Classification on Proximity Data with LP--Machines| Abstract We provide a new linear program to deal with classification of data in the case of data given in terms of pairwise proximities.  This allows to avoid the problems inherent in using feature spaces with indefinite metric in Support Vector Machines, since the notion of a margin is purely needed in input space where the classification actually occurs.  Moreover in our approach we can enforce sparsity in the proximity representation by sacrificing training error.  This turns out to be favorable for proximity data.  Similar to --SV methods, the only parameter needed in the algorithm is the (asymptotical) number of data points being classified with a margin.  Finally, the algorithm is successfully compared with --SV learning in proximity space and K--nearest-neighbors on real world data from Neuroscience and molecular biology. 
A Large Deviation Bound for the Area Under the ROC Curve| Abstract The area under the ROC curve (AUC) has been advocated as an evaluation criterion for the bipartite ranking problem.  We study large deviation properties of the AUC; in particular, we derive a distribution-free large deviation bound for the AUC which serves to bound the expected accuracy of a ranking function in terms of its empirical AUC on an independent test sequence.  A comparison of our result with a corresponding large deviation result for the classification error rate suggests that the test sample size required to obtain an #-accurate estimate of the expected accuracy of a ranking function with #-confidence is larger than that required to obtain an #-accurate estimate of the expected error rate of a classification function with the same confidence.  A simple application of the union bound allows the large deviation bound to be extended to learned ranking functions chosen from finite function classes. 
From Margin to Sparsity| Abstract We present an improvement of Noviko#'s perceptron convergence theorem.  Reinterpreting this mistake bound as a margin dependent sparsity guarantee allows us to give a PAC#style generalisation error bound for the classifier learned by the perceptron learning algorithm.  The bound value crucially depends on the margin a support vector machine would achieve on the same data set using the same kernel.  Ironically, the bound yields better guarantees than are currently available for the support vector solution itself. 
Semi-Definite Programming by Perceptron Learning| Abstract We present a modified version of the perceptron learning algorithm (PLA) which solves semidefinite programs (SDPs) in polynomial time.  The algorithm is based on the following three observations: (i) Semidefinite programs are linear programs with infinitely many (linear) constraints; (ii) every linear program can be solved by a sequence of constraint satisfaction problems with linear constraints; (iii) in general, the perceptron learning algorithm solves a constraint satisfaction problem with linear constraints in finitely many updates.  Combining the PLA with a probabilistic rescaling algorithm (which, on average, increases the size of the feasable region) results in a probabilistic algorithm for solving SDPs that runs in polynomial time.  We present preliminary results which demonstrate that the algorithm works, but is not competitive with state-of-the-art interior point methods. 
EXACT TAIL BOUND OF BINOMIAL DISTRIBUTED VARIABLES| Sets will be denoted by upper roman capital letters, e. g.  X , whilst elements are denoted by roman lower capital letters, e. g.  x.  We shall only be concerned with measure spaces (N; P (N)), i. e.  natural numbers and the collection of all power sets.  We denote a probability measure by PX , where the sans serif X will be called random variable 1 .  The expectation value is denoted by EX [g (X)] and is defined by EX [g (X)] = 1 X x=0 g (x) PX (x) : If X 1 ; : : : ; Xn are independent random variables, we define X = 1 n P n i=1 X i as the mean of the random variables.  Then, the Law of Large numbers tells us that for any probability measure PX we have 8# } 0 lim n!1 PX n EX [X] X } # # = 0 : The binomial distribution B n;p with parameters n 2 N and 0 # p # 1 is defined by 80 # k 2 N # n B n;p (k) = # n k # p k (1 p) n k : Suppose we are given a binomial distributed variable X with known success probability p.  Then, we call T p (k) = P (X } k) the tail of the distribution of X.  If we have no knowledge of p we define the tail bound T to be T = max p fT p g : If X is distributed according to B 1;p we call X a Bernoulli variable.  2.  Tail bounds The value of tail bounds for binomial distributed variables becomes obvious if we consider that for n iid Bernoulli variables Y i we have X = P n i=1 Y i = nY binomial B n;p distributed and PY n p Y } # # = PX (np X } n#) = PX (X < np n#) = 1 T p (dnp n# 1e) # 1 T (dnp n# 1e) : 1 Such a distribution is sometimes called arithmetic with span 1 (see [3, p. 138]).  1 2 RALF HERBRICH,
Bayes Point Machines: Estimating the Bayes Point in Kernel Space| Abstract From a Bayesian perspective Support Vector Machines choose the hypothesis corresponding to the largest possible hypersphere that can be inscribed in version space, i. e.  in the space of all consistent hypotheses given a training set.  Those boundaries of version space which are tangent to the hypersphere define the support vectors.  An alternative and potentially better approach is to construct the hypothesis using the whole of version space.  This is achieved by using a Bayes Point Machine which finds the midpoint of the region of intersection of all hyperplanes bisecting version space into two halves of equal volume (the Bayes point).  It is known that the center of mass of version space approximates the Bayes point [ Watkin, 1993 ] .  We suggest estimating the center of mass by averaging over the trajectory of a billiard ball bouncing in version space.  Experimental results are presented indicating that Bayes Point Machines consistently outperform Support Vector Machines. 
Efficient `-Subsumption based on Graph Algorithms| Abstract.  The `-subsumption problem is crucial to the efficiency of ILP learning systems.  We discuss two `-subsumption algorithms based on strategies for preselecting suitable matching literals.  The class of clauses, for which subsumption becomes polynomial, is a superset of the deterministic clauses.  We further map the general problem of `-subsumption to a certain problem of finding a clique of fixed size in a graph, and in return show that a specialization of the pruning strategy of the Carraghan and Pardalos clique algorithm provides a dramatic reduction of the subsumption search space.  We also present empirical results for the mesh design data set. 
Adaptive Margin Support Vector Machines for Classification| Abstract In this paper we propose a new learning algorithm for classification learning based on the Support Vector Machine (SVM) approach.  Existing approaches for constructing SVMs [12] are based on minimization of a regularized margin loss where the margin is treated equivalently for each training pattern.  We propose a reformulation of the minimization problem such that adaptive margins for each training pattern are utilized, which we call the Adaptive Margin (AM--) SVM.  We give bounds on the generalization error of AM--SVMs which justify their robustness against outliers, and show experimentally that the generalization error of AM--SVMs is comparable to classical SVMs on benchmark datasets from the UCI repository. 
Invariant Pattern Recognition by Semi-Definite Programming Machines| Abstract Knowledge about local invariances with respect to given pattern transformations can greatly improve the accuracy of classification.  Previous approaches are either based on regularisation or on the generation of virtual (transformed) examples.  We develop a new framework for learning linear classifiers under known transformations based on semidefinite programming.  We present a new learning algorithm--the Semidefinite Programming Machine (SDPM)---which is able to find a maximum margin hyperplane when the training examples are polynomial trajectories instead of single points.  The solution is found to be sparse in dual variables and allows to identify those points on the trajectory with minimal real-valued output as virtual support vectors.  Extensions to segments of trajectories, to more than one transformation parameter, and to learning with kernels are discussed.  In experiments we use a Taylor expansion to locally approximate rotational invariance in pixel images from USPS and find improvements over known methods. 
Fast Sparse Gaussian Process Methods: The Informative Vector Machine| Abstract We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on informationtheoretic principles, previously suggested for active learning.  Our goal is not only to learn d--sparse predictors (which can be evaluated in O(d) rather than O(n), d # n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements.  The scaling of our method is at most O(n d 2 ), and in large real-world classification experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be significantly faster in training.  In contrast to the SVM, our approximation produces estimates of predictive probabilities (rror bars'), allows for Bayesian model selection and is less complex in implementation. 
Sparsity vs| Large Margins for Linear Classifiers.  Abstract We provide small sample size bounds on the generalisation error of linear classifiers that take advantage of large observed margins on the training set and sparsity in the data dependent expansion coefficients.  It is already known from results in the luckiness framework that both criteria independently have a large impact on the generalisation error.  Our new results show that they can be combined which theoretically justifies learning algorithms like the Support Vector Machine [4] or the Relevance Vector Machine [12].  In contrast to previous studies we avoid using the classical technique of symmetrisation by a ghost sample but directly using the sparsity for the estimation of the generalisation error.  We demonstrate that our result leads to practical useful results even in case of small sample size if the training set witnesses our prior belief in sparsity and large margins. 
The Kernel Gibbs Sampler| Abstract We present an algorithm that samples the hypothesis space of kernel classifiers.  Given a uniform prior over normalised weight vectors and a likelihood based on a model of label noise leads to a piecewise constant posterior that can be sampled by the kernel Gibbs sampler (KGS).  The KGS is a Markov Chain Monte Carlo method that chooses a random direction in parameter space and samples from the resulting piecewise constant density along the line chosen.  The KGS can be used as an analytical tool for the exploration of Bayesian transduction, Bayes point machines, active learning, and evidence-based model selection on small data sets that are contaminated with label noise.  For a simple toy example we demonstrate experimentally how a Bayes point machine based on the KGS outperforms an SVM that is incapable of taking into account label noise. 
Unbiased Assessment of Learning Algorithms| Abstract In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets.  Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a minimal error rate on the test set.  The same rate is then used to rank the algorithm, which causes an optimistic bias.  We quantify this bias, showing, in particular, that an algorithm with more parameters will probably be ranked higher than an equally good algorithm with fewer parameters.  We demonstrate this result, showing the number of parameters and trials required in order to pretend to outperform C4. 5 or FOIL, respectively, for various benchmark problems.  We then describe out how unbiased ranking experiments should be conducted. 
Bayes Point Machines| the improvement over support vector machines is shown to be reduced.  Finally, we demonstrate that the realvalued output of single Bayes points on novel test points is a valid confidence measure and leads to a steady decrease in generalisation error when used as a rejection criterion. 
SUPPORT VECTOR REGRESSION FOR BLACK-BOX SYSTEM IDENTIFICATION| ABSTRACT In this paper, we demonstrate the use of support vector regression (SVR) techniques for black-box system identification.  These methods derive from statistical learning theory, and are of great theoretical and practical interest.  We briefly describe the theory underpinning SVR, and compare support vector methods with other approaches using radial basis networks.  Finally, we apply SVR to modeling the behaviour of a hydraulic robot arm, and show that SVR improves on previously published results. 
AVERAGE PRECISION AND THE PROBLEM OF GENERALISATION| Abstract In this paper we study the problem of generalisation in information retrieval.  In particular we
Algorithms and architectures Presentation preference: Oral Not previously submitted elsewhere Fast Sparse Gaussian Process Methods: The Informative Vector Machine| Abstract We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on informationtheoretical principles, previously suggested for active learning.  In contrast to most previous work on sparse GPs, our goal is not only to learn sparse predictors (which can be evaluated in O(d) rather than O(n), d # n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements.  The scaling of our method is at most O(n # d 2 ), and in large real-world classification experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet it requires only a fraction of the training time.  In contrast to the SVM, our approximation produces estimates of predictive probabilities (rror bars'), allows for Bayesian model selection and is less complex in implementation. 
Large Scale Bayes Point Machines| Abstract The concept of averaging over classifiers is fundamental to the Bayesian analysis of learning.  Based on this viewpoint, it has recently been demonstrated for linear classifiers that the centre of mass of version space (the set of all classifiers consistent with the training set) # also known as the Bayes point # exhibits excellent generalisation abilities.  However, the billiard algorithm as presented in [4] is restricted to small sample size because it requires O m 2 # of memory and O N # m 2 # computational steps where m is the number of training patterns and N is the number of random draws from the posterior distribution.  In this paper we present a method based on the simple perceptron learning algorithm which allows to overcome this algorithmic drawback.  The method is algorithmically simple and is easily extended to the multi-class case.  We present experimental results on the MNIST data set of handwritten digits which show that Bayes point machines (BPMs) are competitive with the current world champion, the support vector machine.  In addition, the computational complexity of BPMs can be tuned by varying the number of samples from the posterior.  Finally, rejecting test points on the basis of their (approximative) posterior probability leads to a rapid decrease in generalisation error, e. g.  0:1% generalisation error for a given rejection rate of 10%. 
Robust Bayes Point Machines| Abstract.  Support Vector Machines choose the hypothesis corresponding to the centre of the largest hypersphere that can be inscribed in version space.  If version space is elongated or irregularly shaped a potentially superior approach is take into account the whole of version space.  We propose to construct the Bayes point which is approximated by the centre of mass.  Our implementation of a Bayes Point Machine (BPM) uses an ergodic billiard to estimate this point in the kernel space.  We show that BPMs outperform hard margin Support Vector Machines (SVMs) on real world datasets.  We introduce a technique that allows the BPM to construct hypotheses with non{zero training error similar to soft margin SVMs with quadratic penelisation of the margin slacks.  An experimental study reveals that with decreasing penelisation of training error the improvement of BPMs over SVMs decays, a finding that is explained by geometrical considerations. 
Regression Models for Ordinal Data: A Machine Learning Approach| Abstract In contrast to the standard machine learning tasks of classification and metric regression we investigate the problem of predicting variables of ordinal scale, a setting referred to as ordinal regression.  The task of ordinal regression arises frequently in the social sciences and in information retrieval where human preferences play a major role.  Also many multi--class problems are really problems of ordinal regression due to an ordering of the classes.  Although the problem is rather novel to the Machine Learning Community it has been widely considered in Statistics before.  All the statistical methods rely on a probability model of a latent (unobserved) variable and on the condition of stochastic ordering.  In this paper we develop a distribution independent formulation of the problem and give uniform bounds for our risk functional.  The main difference to classification is the restriction that the mapping of objects to ranks must be transitive and asymmetric.  Combining our theoretical framework with results from measurement theory we present an approach that is based on a mapping from objects to scalar utility values and thus guarantees transitivity and asymmetry.  Applying the principle of Structural Risk Minimization as employed in Support Vector Machines we derive a new learning algorithm based on large margin rank boundaries for the task of ordinal regression.  Our method is easily extended to nonlinear utility functions.  We give experimental results for an Information Retrieval task of learning the order of documents with respect to an initial query.  Moreover, we show that our algorithm outperforms more naive approaches to ordinal regression such as Support Vector Classification and Support Vector Regression in the case of more than two ranks 1 .  1 This paper is a preliminary version of (Herbrich et al.  1999)
The Perceptron Algorithm with Uneven Margins| Abstract The perceptron algorithm with margins is a simple, fast and effective learning algorithm for linear classifiers; it produces decision hyperplanes within some constant ratio of the maximal margin.  In this paper we study this algorithm and a new variant: the perceptron algorithm with uneven margins, tailored for document categorisation problems (i. e.  problems where classes are highly unbalanced and performance depends on the ranking of patterns).  We discuss the interest of these algorithms from a theoretical point of view, provide a generalisation of Noviko#'s theorem for uneven margins, give a geometrically description of these algorithms and show experimentally that both algorithms yield equal or better performances than support vector machines, while reducing training time and sparsity, in classification (USPS) and document categorisation (Reuters) problems. 
Neural Networks in Economics: Background, Applications and New Developments| Abstract Neural Networks were developed in the sixties as devices for classification and regression.  The approach was originally inspired from Neuroscience.  Its attractiveness lies in the ability to "learn", i. e.  to generalize to as yet unseen observations.  One aim of this paper is to give an introduction to the technique of Neural Networks and an overview of the most popular architectures.  We start from statistical learning theory to introduce the basics of learning.  Then, we give an overview of the general principles of neural networks and of their use in the field of Economics.  A second purpose is to introduce a recently developed Neural Network Learning technique, so called Support Vector Network Learning, which is an application of ideas from statistical learning theory.  This approach has shown very promising results on problems with a limited amount of training examples.  Moreover, utilizing a technique that is known as the kernel trick, Support Vector Networks can easily be adapted to nonlinear models.  Finally, we present an economic application of this approach from the field of preference learning. 
The Structure of Version Space| Abstract We investigate the generalisation performance of consistent classifiers, i. e.  classifiers that are contained in the so-called version space, both from a theoretical and experimental angle.  In contrast to classical VC analysis --- where no single classifier within version space is singled out on grounds of a generalisation error bound --- the data dependent structural risk minimisation framework suggests that there is one particular classifiers that is to be preferred because it minimises the generalisation error bound.  This is usually taken to provide a theoretical justification for learning algorithms such as the well known support vector machine.  A reinterpretation of a recent PAC-Bayesian result, however, reveals that given a suitably chosen hypothesis space there is a huge number of classifiers with small generalisation error albeit we cannot identify them for a specific learning task.  This result is complemented with an empirical study for kernel classifiers on the task of handwritten digit recognition which demonstrates that even classifiers with a small margin exhibit excellent generalisation. 
Algorithmic Luckiness| Abstract In contrast to standard statistical learning theory which studies uniform bounds on the expected error we present a framework that exploits the specific learning algorithm used.  Motivated by the luckiness framework [8] we are also able to exploit the serendipity of the training sample.  The main difference to previous approaches lies in the complexity measure; rather than covering all hypotheses in a given hypothesis space it is only necessary to cover the functions which could have been learned using the fixed learning algorithm.  We show how the resulting framework relates to the VC, luckiness and compression frameworks.  Finally, we present an application of this framework to the maximum margin algorithm for linear classifiers which results in a bound that exploits both the margin and the distribution of the data in feature space. 
Large margin rank boundaries for ordinal regression|
A PAC-Bayesian margin bound for linear classifiers|
Learning a preference relation for information retrieval|
Support vector learning for ordinal regression|
Learning Linear Classifiers - Theory and Algorithms|
Bayesian Transduction|
Adaptive margin support vector machines,|
From Margin To Sparsity| Advances in Neural Information Processing Systems 13,. 
A sparse Bayesian compression scheme - the informative vector machine|
Learning Kernel Classifiers: Theory and|
Using unlabeled data for supervised learning,|
Average precision and the problem of generalization|
Estimating the Leave-One-Out Error for Classification Learning with SVMs|
Sparse Bayesian learning: The informative vector machine|
Supervised learning of preference relations|
Learning to fight|
A generalized representer theorem|
A generalized representer theorem, In \Proceedings of the 14th Annual Conference on Computational Learning Theory",|
Sparse representation for Gaussian process models|
Generalization error bounds for sparse linear classifiers|
Behaviour and convergence of the constrained covariance|
Efficient #-subsumption based on graph algorithms|
