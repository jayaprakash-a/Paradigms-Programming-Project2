Adjustment Learning and Relevant Component Analysis| Abstract.  We propose a new learning approach for image retrieval, which we call adjustment learning, and demonstrate its use for face recognition and color matching.  Our approach is motivated by a frequently encountered problem, namely, that variability in the original data representation which is not relevant to the task may interfere with retrieval and make it very dicult.  Our key observation is that in real applications of image retrieval, data sometimes comes in small chunks - small subsets of images that come from the same (but unknown) class.  This is the case, for example, when a query is presented via a short video clip.  We call these groups chunklets, and we call the paradigm which uses chunklets for unsupervised learning adjustment learning.  Within this paradigm we propose a linear scheme, which we call Relevant Component Analysis; this scheme uses the information in such chunklets to reduce irrelevant variability in the data while amplifying relevant variability.  We provide results using our method on two problems: face recognition (using a database publicly available on the web), and visual surveillance (using our own data).  In the latter application chunklets are obtained automatically from the data without the need of supervision. 
Computing Gaussian Mixture Models with EM using Side-Information| Abstract Estimation of Gaussian mixture models is an efficient and popular technique for clustering and density estimation.  An EM procedure is widely used to estimate the model parameters.  In this paper we show how side information in the form of equivalence constraints can be incorporated into this procedure, leading to improved clustering results.  Equivalence constraints are prior knowledge concerning pairs of data points, indicating if the points arise from the same source (positive constraint) or from different sources (negative constraint).  Such constraints can be gathered automatically in some learning problems, and are a natural form of supervision in others.  We present a closed form EM procedure for handling positive constraints, and a Generalized EM procedure using a Markov net for the incorporation of negative constraints.  Using publicly available data sets we demonstrate that such side information may lead to considerable improvement in clustering tasks, and that our algorithm is preferable to another suggested method using this type of side information. 
Video Synthesis made simple with the X-Slits Projection| Abstract We propose novel algorithms for image based rendering (IBR) by simulating a new family of scene-to-image projections, the Crossed-Slits (X-Slits) projections.  New X-Slits images can be easily generated from a sequence of images captured by a translating pinhole camera, and those images look compelling and realistic.  We show how this can be used for rendering movies of virtual walkthroughs by a very fast and simple mosaicing algorithm, providing a strong 3-D sensation of parallax and occlusions, as well as specularity and transparency. 
Dual Computation of Projective Shape and Camera Positions from Multiple Images| Abstract.  Given multiple image data from a set of points in 3-D, there are two fundamental questions that can be addressed: ffl What is the structure of the set of points in 3-D? ffl What are the positions of the cameras relative to the points? In this paper we show that, for projective views and with structure and position defined projectively, these problems are dual because they can be solved using constraint equations where space points and camera positions occur in a reciprocal way.  More specifically, by using canonical projective reference frames for all points in space and images, the imaging of point sets in space by multiple cameras can be captured by constraint relations involving three different kinds of parameters only, which are the coordinates of :(1) space points, (2) camera positions (3) image points.  The duality implies that the problem of computing camera positions from p points in q views can be solved with the same algorithm as the problem of directly reconstructing q + 4 points in p\Gamma 4 views.  This unifies different approaches to projective reconstruction: methods based on external calibration and direct methods exploiting constraints that exist between shape and image invariants. 
Boosting margin based distance functions for clustering| Abstract The performance of graph based clustering methods critically depends on the quality of the distance function used to compute similarities between pairs of neighboring nodes.  In this paper we learn distance functions by training binary classifiers with margins.  The classifiers are defined over the product space of pairs of points and are trained to distinguish whether two points come from the same class or not.  The signed margin is used as the distance value.  Our main contribution is a distance learning method (DistBoost), which combines boosting hypotheses over the product space with a weak learner based on partitioning the original feature space.  Each weak hypothesis is a Gaussian mixture model computed using a semi-supervised constrained EM algorithm, which is trained using both unlabeled and labeled data.  We also consider SVM and decision trees boosting as margin based classifiers in the product space.  We experimentally compare the margin based distance functions with other existing metric learning methods, and with existing techniques for the direct incorporation of constraints into various clustering algorithms.  Clustering performance is measured on some benchmark databases from the UCI repository, a sample from the MNIST database, and a data set of color images of animals.  In most cases the DistBoost algorithm significantly and robustly outperformed its competitors. 
Shape Tensors for Efficient and Learnable Indexing| Abstract Multi-point geometry: The geometry of 1 point in N images under perspective projection has been thoroughly investigated, identifying bilinear, trilinear, and quadrilinear relations between the projections of 1 point in 2, 3 and 4 frames respectively.  The dual problem - the geometry of N points in 1 image - has been studied mostly in the context of object recognition, often assuming weak perspective or affine projection.  We provide here a complete description of this problem.  We employ a formalism in which multiframe and multi-point geometries appear in symmetry: points and projections are interchangeable.  We then derive bilinear equations for 6 points (dual to 4frame geometry), trilinear equations for 7 points (dual to 3-frame geometry), and quadrilinear equations for 8 points (dual to the epipolar geometry).  We show that the quadrilinear equations are dependent on the the bilinear and trilinear equations, and we show that adding more points will not generate any new equation.  Applications to reconstruction and recognition: The new equations are used to design new algorithms for the reconstruction of shape from many frames, and for learning invariant relations for indexing into a data-base.  We describe algorithms which require matching 6 (or more) corresponding points from at least 4 images, 7 (or more) points from at least 3 images, or 8 (or more) points from at least 2 images.  Unlike previous approaches, the equations developed here lead to direct and linear solutions without going through the cameras' geometry.  Our final linear shape computation uses all the available data -- all points and all frames simultaneously: it uses a factorization of the matrix of invariant relations into 2 components of rank 4, a shape matrix and a coordinate-system matrix. 
Secure Authentication Schemes suitable for an Associative Memory Leibniz Center for Research in Computer Science Technical Report 2004-30| Abstract Most security protocols are designed to secure the interaction between computers.  User authentication, an interaction between a computer and a human, merits a different approach since human memory is fundamentally associative.  We describe here a secure authentication protocol which relies on picture recognition, a skill which people find relatively easy.  The human and the computer share a secret, which is a set of 60-100 pictures.  Authentication is done via a challenge-response protocol: the computer poses a sequence of challenges to the user, which can only be answered correctly by someone who knows the shared secret.  Once the probability of random guessing goes below a fixed threshold, the computer authenticates the user.  We report user studies showing that the protocol is feasible for humans to use, with high reliably and for a long period of time.  We also describe probabilistic attacks on the protocol, which demonstrate the protocol's computational merits and limitations. 
Learning Distance Functions using Equivalence Relations| Abstract We address the problem of learning distance metrics using side-information in the form of groups of "similar" points.  We propose to use the RCA algorithm, which is a simple and efficient algorithm for learning a full ranked Mahalanobis metric (Shental et al. , 2002).  We first show that RCA obtains the solution to an interesting optimization problem, founded on an information theoretic basis.  If the Mahalanobis matrix is allowed to be singular, we show that Fisher's linear discriminant followed by RCA is the optimal dimensionality reduction algorithm under the same criterion.  We then show how this optimization problem is related to the criterion optimized by another recent algorithm for metric learning (Xing et al. , 2002), which uses the same kind of side information.  We empirically demonstrate that learning a distance metric using the RCA algorithm significantly improves clustering performance, similarly to the alternative algorithm.  Since the RCA algorithm is much more efficient and cost effective than the alternative, as it only uses closed form expressions of the data, it seems like a preferable choice for the learning of full rank Mahalanobis distances. 
From Ordinal to Euclidean Reconstruction with Partial Scene Calibration| Abstract.  Since uncalibrated images permit only projective reconstruction, metric information requires either camera or scene calibration.  We propose a stratified approach to projective reconstruction, in which gradual increase in domain information for scene calibration leads to gradual increase in 3D information.  Our scheme includes the following steps: (1) Register the images with respect to a reference plane; this can be done using limited scene information, e. g. , the knowledge that two pairs of lines on the plane are parallel.  We show that this calibration is sufficient for ordinal reconstruction - sorting the points by their height over the reference plane.  (2) If available, use the relative height of two additional out-of-plane points to compute the height of the remaining points up to constant scaling.  Our scheme is based on the dual epipolar geometry in the reference frame, which we develop below.  We show good results with five sequences of real images, using mostly scene calibration that can be inferred directly from the images themselves. 
LEIBNIZ CENTER FOR RESEARCH IN COMPUTER SCIENCE TECHNICAL REPORT 2003-43 Computing Gaussian Mixture Models with EM using Equivalence Constraints| Abstract Gaussian mixture models for density estimation are usually estimated in an unsupervised manner, using an Expectation Maximization (EM) procedure.  In this paper we show how equivalence constraints can be incorporated into this procedure, leading to improved model estimation and improved clustering results.  Equivalence constraints provide additional information on pairs of data points, indicating if the points arise from the same source (positive constraint) or from different sources (negative constraint).  Such constraints can be gathered automatically in some learning problems, and are a natural form of supervision in others.  We present a closed form EM procedure for handling positive constraints, and a Generalized EM procedure using a Markov network for the incorporation of negative constraints.  Using publicly available data sets, we demonstrate that incorporating equivalence constraints leads to considerable improvement in clustering performance, and that our algorithm outperforms all available competitors. 
On View Likelihood and Stability| Abstract--We define two measures on views: view likelihood and view stability.  View likelihood measures the probability that a certain view of a given 3D object is observed; it may be used to identify typical, or "characteristic", views.  View stability measures how little the image changes as the viewpoint is slightly perturbed; it may be used to identify ``generic" views.  Both definitions are shown to be identical up to the prior probability of camera orientations, and determined by the 2D metric used to compare images.  We analytically derive the stability and likelihood measures for two feature-based 2D metrics, where the most stable and most likely view is shown to be the flattest view of the 3D shape.  Incorporating view likelihood or stability in 3D object recognition and 3D reconstruction increases the chance of robust performance.  In particular, we propose to use these measures to enhance 3D object recognition and 3D reconstruction algorithms, by adding a second step where the most likely solution is selected among all feasible solutions.  These applications are demonstrated using simulated and real images. 
Motion of disturbances: detection and tracking of multi-body non-rigid motion| Abstract We present a new approach to the tracking of very non rigid patterns of motion, such as water flowing down a stream.  The algorithm is based on
Learning via Equivalence Constraints, with applications to the Enhancement of Image and Video Retrieval| Abstract Making sense of large amounts of unlabeled data is hard, but this is what we are up against in
Classification with Nonmetric Distances: Image Retrieval and Class Representation| Abstract One of the key problems in appearance-based vision is understanding how to use a set of labeled images to classify new images.  Classification systems that can model human performance, or that use robust image matching methods, often make use of similarity judgments that are non-metric; but when the triangle inequality is not obeyed, most existing pattern recognition techniques are not applicable.  We note that exemplar-based (or nearest-neighbor) methods can be applied naturally when using a wide class of non-metric similarity functions.  The key issue, however, is to find methods for choosing good representatives of a class that accurately characterize it.  We show that existing condensing techniques for finding class representatives are ill-suited to deal with non-metric dataspaces.  We then focus on developing techniques for solving this problem, emphasizing two points: First, we show that the distance between two images is not a good measure of how well one image can represent another in non-metric spaces.  Instead, we use the vector correlation between the distances from each image to other previously seen images.  Second, we show that in non-metric spaces, boundary points are less significant for capturing the structure of a class than they are in Euclidean spaces.  We suggest that atypical points may be more important in describing classes.  We demonstrate the importance of these ideas to learning that generalizes from experience by improving performance using both synthetic and real images.  In addition, we suggest ways of applying parametric techniques to supervised learning problems that involve a specific nonmetric distance functions, showing in particular how to generalize the idea of linear discriminant functions in a way that may be more useful in non-metric spaces. 
Learning Distance Functions with Product Space Boosting| Abstract A good distance function is an essential tool in applications which involve querying large databases, such as image retrieval and bioinformatics.  We describe a non-parametric algorithm for distance function learning which is based on the boosting of low grade weak learners in a product space.  The algorithm learns a function defined over pairs of points, using supervision in the form of equivalence constraints.  The weak learners are based on partitioning the original feature space, using a generic density estimation generative model (GMM) augmented by equivalence constraints on pairs of datapoints.  Using a number of databases from the UCI repository, we show significantly improved results over methods which learn the parametric Mahalanobis distance.  We also show initial results of image retrieval, using a large database of facial images (YaleB). 
Model-based invariants for 3D vision| Abstract Invariance under a group of 3D transformations seems a desirable component of an efficient 3D shape representation.  We propose representations which are invariant under weak perspective to either rigid or affine 3D transformations, and we show how they can be computed efficiently from a sequence of images with a linear and incremental algorithm.  We show simulated results with perspective projection and noise, and the results of model acquisition from a real sequence of images.  The use of linear computation, together with the integration through time of invariant representations, offers improved robustness and stability.  Using these invariant representations, we derive model-based projective invariant functions of general 3D objects.  We discuss the use of the model-based invariants with existing recognition strategies: alignment without transformation, and constant time indexing from 2D images of general 3D objects. 
Distance Metric between 3D Models and 2D Images for Recognition and Classification| Abstract Similarity measurements between 3D objects and 2D images are useful for the tasks of object recognition and classification.  We distinguish between two types of similarity metrics: metrics computed in image-space (image metrics) and metrics computed in transformation-space (transformation metrics).  Existing methods typically use image metrics; namely, metrics that measure the difference in the image between the observed image and the nearest view of the object.  Example for such a measure is the Euclidean distance between feature points in the image and their corresponding points in the nearest view.  (This measure can be computed by solving the exterior orientation calibration problem. ) In this paper we introduce a different type of metrics: transformation metrics.  These metrics penalize for the deformations applied to the object to produce the observed image.  In particular, we define a transformation metric that optimally penalizes for "affine deformations" under weak-perspective.  A closed-form solution, together with the nearest view according to this metric, are derived.  The metric is shown to be equivalent to the Euclidean image metric, in the sense that they bound each other from both above and below.  It therefore provides an easy-to-use closed-form approximation for the commonly-used least-squares distance between models and images.  We demonstrate an image understanding application, where the true dimensions of a photographed battery charger are estimated by minimizing the transformation metric. 
Analyzing Auditory Neurons by Learning Distance Functions| Abstract We present a novel approach to the characterization of complex sensory neurons.  One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (defining iso-response manifolds).  We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar.  Here we show how to successfully train such distance functions using rather limited amount of information.  The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds.  For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar.  The distance function was trained to fit these constraints.  The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 
Maximum Likelihood 3D Image Understanding and Object Recognition \Lambda| Abstract We describe a general framework for resolving ambiguities in object recognition and image understanding using maximum likelihood estimation, augmenting existing geometrical techniques.  This extension is needed when images are noisy and the database is large, when existing techniques of 3D image understanding and model-based object recognition cannot provide a unique answer.  We define measures of likelihood and stability of interpretations, and show how to compute these quantities directly from any difference function used to compare between 2D images and 3D shapes.  We then discuss when the most likely interpretation is the most stable one.  We thus give a practical way to measure how "generic" views are, and identify ``characteristic" views.  The proposed approach is concrete, general and relatively easy to use.  To demonstrate the usefulness of this framework, we develop the proposed stability and likelihood functions using two "natural" image metrics, which compare images of objects composed of localized features.  For such objects, the stability and likelihood of any 3D interpretation can be evaluated from a simple expression involving only the three principal second moments of the 3D shape.  Moreover, the most stable and most likely interpretation is the "flattest" view of the 3D shape, obtained when the three dimensional object has its minimal spread along the viewing direction.  Examples of maximum likelihood image understanding and object recognition, using simulated and real images, are given. 
SUPERPARAMAGNETIC CLUSTERING OF DATA: APPLICATION TO COMPUTER VISION| Abstract The aim of clustering is to partition data according to natural classes present in it.  We proposed recently a method that makes no explicit assumption about the structure of the data and under very general and natural assumptions solves the clustering problem by evaluating thermal properties of a disordered (granular) magnet.  The method was tested successfully on a variety of artificial and real-life problems; here we emphasize its application to analyze results obtained by a novel method of computer vision.  The combination of these two techniques provides a powerful tool that succeeded to cluster properly 90 images of 6 objects on the basis of their pairwise dissimilarities.  These dissimilarities, which constitute a highly nonmetric set of pairwise distances between the images, form the input for clustering.  A hierarchical organization of the images that agrees with human intuition, was obtained without assigning to the images coordinates in some abstract space. 
Using Bilateral Symmetry To Improve 3D Reconstruction From Image Sequences| Abstract In previous applications, bilateral symmetry of objects was used either as a descriptive feature in domains such as recognition and grasping, or as a way to reduce the complexity of structure from motion.  In this paper we demonstrate how bilateral symmetry can be used to improve the accuracy in 3D reconstruction.  The symmetry property is used to "symmetrize" data before and after reconstruction.  We first show how to compute the closest symmetric 2D and 3D configurations given noisy data.  This gives us a symmetrization procedure, which we apply to images before reconstruction, and which we apply to the 3D configuration after reconstruction.  We demonstrate a significant improvement obtained with real images.  We demonstrate the relative merits of symmetrization before and after reconstruction using simulated and real data. 
Non-Perspective Imaging and Rendering with the Crossed-Slits Projection| Abstract We describe a new family of projection models defined by two slits - the Crossed-Slits (XSlits) projection.  In this model the projection ray of every 3D point is defined by the line that passes through the point and intersects the two slits.  The intersection of these rays with the imaging surface defines the image.  Algebraically the X-Slits projection is a second-order transformation from 3-D to 2-D.  For our main application we show that new X-Slits images can be generated by straightforward mosaicing from a sequence of images captured by a translating pinhole camera.  This can be used for rendering movies of virtual walkthroughs from a single sequence of images very fast and very eciently, without recovering any 3-D geometry.  We show a number of examples where we move the camera around and change its orientation; the examples demonstrate realistic changes in parallax, reflections, and occlusions.  The second proposed application is 3-D object visualization. 
Learning Distance Functions for Image Retrieval| Abstract Image retrieval critically relies on the distance function used to compare a query image to images in the database.  We suggest to learn such distance functions by training binary classifiers with margins, where the classifiers are defined over the product space of pairs of images.  The classifiers are trained to distinguish between pairs in which the images are from the same class and pairs which contain images from different classes.  The signed margin is used as a distance function.  We explore several variants of this idea, based on using SVM and Boosting algorithms as product space classifiers.  Our main contribution is a distance learning method which combines boosting hypotheses over the product space with a weak learner based on partitioning the original feature space.  The weak learner used is a Gaussian mixture model computed using a constrained EM algorithm, where the constraints are equivalence constraints on pairs of data points.  This approach allows us to incorporate unlabeled data into the training process.  Using some benchmark databases from the UCI repository, we show that our margin based methods significantly outperform existing metric learning methods, which are based on learning a Mahalanobis distance.  We then show comparative results of image retrieval in a distributed learning paradigm, using two databases: a large database of facial images (YaleB), and a database of natural images taken from a commercial CD.  In both cases our GMM based boosting method outperforms all other methods, and its generalization to unseen classes is superior. 
New View Generation with a Bi-centric Camera| Abstract.  We propose a novel method for new view generation from a rectified sequence of images.  Our new images correspond to a new camera model, which we call a bi-centric camera; in this model the centers of horizontal and vertical projections lie in different locations on the camera's optical axis.  This model reduces to the regular pinhole camera when the two projection centers coincide, and the pushbroom camera when one projection center lies at infinity.  We first analyze the properties of this camera model.  We then show how to generate new bi-centric views from vertical cuts in the epipolar volume of a rectified sequence.  Every vertical cut generates a new bi-centric view, where the specific parameters of the cut determine the location of the projection centers.  We discuss and demonstrate applications, including the generation of images where the virtual camera lies behind occluding surfaces (e. g. , behind the back wall of a room), and in unreachable positions (e. g. , in front of a glass window).  Our final application is the generation of movies taken by a simulated forward moving camera, using as input a movie taken by a sideways moving camera. 
Duality of Multi-Point and Multi-Frame Geometry: Fundamental Shape Matrices and Tensors| Abstract.  We provide a complete analysis of the geometry of N points in 1 image, employing a formalism in which multi-frame and multi-point geometries appear in symmetry: points and projections are interchangeable.  We derive bilinear equations for 6 points, trilinear equations for 7 points, and quadrilinear equations for 8 points.  The new equations are used to design new algorithms for the reconstruction of projective shape from many frames.  Shape is represented by shape descriptors, which are sufficient for object recognition, and for the simulation of new images of the object.  We further propose a linear shape reconstruction scheme which uses all the available data - all points and all frames - simultaneously.  Unlike previous approaches, the equations developed here lead to direct and linear computation of shape, without going through the cameras' geometry. 
What if cameras could see themselves?| Abstract We propose a camera design where the camera records images through an attached aperture, which can be seen in the image.  In such a design camera calibration is reduced to the problem of camera localization, with 3 degrees of freedom remaining which correspond to the unknown location of the camera.  9 degrees of freedom which correspond to the unknown camera's internal parameters and orientation are eliminated by the registration of the aperture.  We discuss two applications: pointing target detection when pointing towards the camera, and depth estimation from two or more uncalibrated cameras.  We conclude with experimental results which demonstrate the usefulness and robustness of our approach. 
Linear and Incremental Acquisition of Invariant Shape Models From Image Sequences| Abstract We showhow to automatically acquire similarity-invariant shape representations of objects from noisy image sequences under weak perspective.  The proposed method is linear and
On the Epipolar Geometry of the Crossed-Slits Projection| Abstract The Crossed-Slits (X-Slits) camera is defined by two nonintersecting slits, which replace the pinhole in the common perspective camera.  Each point in space is projected to the image plane by a ray which passes through the point and the two slits.  The X-Slits projection model includes the pushbroom camera as a special case.  In addition, it describes a certain class of panoramic images, which are generated from sequences obtained by translating pinhole cameras.  In this paper we develop the epipolar geometry of the XSlits projection model.  We show an object which is similar to the fundamental matrix; our matrix, however, describes a quadratic relation between corresponding image points (using the Veronese mapping).  Similarly the equivalent of epipolar lines are conics in the image plane.  Unlike the pinhole case, epipolar surfaces do not usually exist in the sense that matching epipolar lines lie on a single surface; we analyze the cases when epipolar surfaces exist, and characterize their properties.  Finally, we demonstrate the matching of points in pairs of X-Slits panoramic images. 
Mechanisms of Generalization in Perceptual Learning| Abstract Learning in many visual perceptual tasks has been shown to be specific to practiced stimuli, while new stimuli have to be learned from scratch.  Here we demonstrate generalization using a novel paradigm in motion discrimination where learning has been previously shown to be specific.  We trained subjects to discriminate directions of moving dots, and verified the previous results that learning does not transfer from a trained direction to a new one.  However, by tracking the subjects' performance across time in the new direction, we found that their speed of learning doubled.  Therefore, we found generalization in a task previously considered too difficult to generalize.  We also replicated, in a second experiment, transfer following training with "easy" stimuli, when the difference between motion directions is enlarged.  In a third experiment we found a new mode of generalization: after mastering the task with an easy stimulus, subjects who have practiced briefly to discriminate the easy stimulus in a new direction generalize to a difficult stimulus in that direction.  This generalization depends on both the mastering and the brief practice.  The specificity of perceptual learning and the dichotomy between learning of "easy" vs.  "difficult" tasks have been assumed to involve different learning processes at different cortical areas.  Here we show how to interpret these results in terms of signal detection theory.  With the assumption of limited computational capacity, we obtain the observed phenomena --- direct transfer and acceleration of learning --- for increasing levels of task difficulty.  Human perceptual learning and generalization, therefore, concur with a generic discrimination system. 
Enhancing Image and Video Retrieval: Learning via Equivalence Constraint| Abstract This paper is about learning using partial information in the form of equivalence constraints.  Equivalence constraints provide relational information about the labels of data points, rather than the labels themselves.  Our work is motivated by the observation that in many real life applications partial information about the data can be obtained with very little cost.  For example, in video indexing we may want to use the fact that a sequence of faces obtained from successive frames in roughly the same location is likely to contain the same unknown individual.  Learning using equivalence constraints is different from learning using labels and poses new technical challenges.  In this paper we present three novel methods for clustering and classification which use equivalence constraints.  We provide results of our methods on a distributed image querying system that works on a large facial image database, and on the clustering and retrieval of surveillance data.  Our results show that we can significantly improve the performance of image retrieval by taking advantage of such assumptions as temporal continuity in the data.  Significant improvement is also obtained by making the users of the system take the role of distributed teachers, which reduces the need for expensive labeling by paid human labor. 
Class Representation and Image Retrieval with Non-Metric Distances| Abstract One of the key problems in appearance-based vision is understanding how to use a set of labeled images to classify new images. 
Passwords you'll never forget, but can't recall| ABSTRACT We identify a wide range of human memory phenomena as potential certificates of identity.  These "imprinting" behaviors are characterized by vast capacity for complex experiences, which can be recognized without apparent effort and yet cannot be transferred to others.  They are suitable for use in near zero-knowledge protocols, which minimize the amount of secret information exposed to prying eyes while identifying an individual.  We sketch several examples of such phenomena[1-3], and apply them in secure certification protocols.  This provides a novel approach to human-computer interfaces, and raises new questions in several classic areas of psychology. 
Utilizing symmetry in the reconstruction of three-dimensional shape from noisy images| Abstract.  In previous applications, bilateral symmetry of objects was used either as a descriptive feature in domains such as recognition and grasping, or as a way to reduce the complexity of structure from motion.  In this paper we propose a novel application, using the symmetry property to "symmetrize" data before and after reconstruction.  We first show how to compute the closest symmetric 2D and 3D configurations given noisy data.  This gives us a symmetrization procedure, which we apply to images before reconstruction, and which we apply to the 3D configuration after reconstruction.  We demonstrate a significant improvement obtained with real images.  We demonstrate the relative merits of symmetrization before and after reconstruction using simulated and real data. 
Minimal decomposition of model-based invariants| Abstract.  Model-based invariants are relations between model parameters and image measurements, which are independent of the imaging parameters.  Such relations are true for all images of the model.  Here we describe an algorithm which, given L independent model-based polynomial invariants describing some shape, will provide a linear re-parameterization of the invariants.  This re-parameterization has the properties that: (i) it includes the minimal number of terms, and (ii) the shape terms are the same in all the model-based invariants.  This final representation has 2 main applications: (1) it gives new representations of shape in terms of hyperplanes, which are convenient for object recognition; (2) it allows the design of new linear shape from motion algorithms.  In addition, we use this representation to identify object classes that have universal invariants. 
From Reference Frames to Reference Planes: Multi-View Parallax Geometry and Applications| Abstract.  This paper presents a new framework for analyzing the geometry of multiple 3D scene points from multiple uncalibrated images, based on decomposing the projection of these points on the images into two stages: (i) the projection of the scene points onto a (real or virtual) physical reference planar surface in the scene; this creates a virtual "image" on the reference plane, and (ii) the re-projection of the virtual image onto the actual image plane of the camera.  The positions of the virtual image points are directly related to the 3D locations of the scene points and the camera centers relative to the reference plane alone.  All dependency on the internal camera calibration parameters and the orientation of the camera are folded into homographies relating each image plane to the reference plane.  Bi-linear and tri-linear constraints involving multiple points and views are given a concrete physical interpretation in terms of geometric relations on the physical reference plane.  In particular, the possible dualities in the relations between scene points and camera centers are shown to have simple and symmetric mathematical forms.  In contrast to the plane+parallax (p+p) representation, which also uses a reference plane, the approach described here removes the dependency on a reference image plane and extends the analysis to multiple views.  This leads to simpler geometric relations and complete symmetry in multi-point multiview duality.  The simple and intuitive expressions derived in the reference-plane based formulation lead to useful applications in 3D scene analysis.  In particular, simpler tri-focal constraints are derived that lead to simple methods for New View Synthesis.  Moreover, the separation and compact packing of the unknown camera calibration and orientation into the 2D projection transformation (a homography) allows also partial reconstruction using partial calibration information. 
Flexible Syntactic Matching of Curves and Its Application to Automatic Hierarchical Classification of Silhouettes|
Self-Organization in Vision: Stochastic Clustering for Image Segmentation, Perceptual Grouping, and Image Database Organization|
Learning with Equivalence Constraints and the Relation to Multiclass Learning|
A Self-Organizing Multiple-View Representations of 3D Objects|
Shape from motion algorithms: a comparative analysis of scaled orthography and perspective|
A Randomized Algorithm for Pairwise Clustering|
Flexible Syntactic Matching of Curves|
Direct Computation of Qualitative 3-D Shape and Motion Invariants|
Similarity and Affine Invariant Distances Between 2D Point Sets|
Stability and Likelihood of Views of Three Dimensional Objects|
Complexity of Indexing: Efficient and Learnable Large Database Indexing|
Mosaicing New Views: The Crossed-Slits Projection|
Measures for Silhouettes Resemblance and Representative Silhouettes of Curved Objects|
Stochastic Image Segmentation by Typical Cuts|
Non-Perspective Imaging and Rendering with the Crossed-|
Distance Metric Between 3D Models and 2D Images for Recognition and Classification|
Application of Qualitiative Depth and Shape from Stereo,|
Classification in Non-Metric Spaces|
A Computer Vision System for On-Screen Item Selection by Finger Pointing|
Qualitative Depth from Stereo, with Applications|
