Utilizing Large Scale Vision and Text Datasets for Image Segmentation from Referring Expressions.
Deep Compositional Question Answering with Neural Module Networks.
Grounding Action Descriptions in Videos.
Generating Visual Explanations.
Multi-view Pictorial Structures for 3D Human Pose Estimation.
Commonsense in Parts: Mining Part-Whole Relations from the Web and Image Tags.
Transfer Learning in a Transductive Setting.
Spatial Semantic Regularisation for Large Scale Object Detection.
3D Object Detection with Multiple Kinects.
Long-term recurrent convolutional networks for visual recognition and description.
Coherent Multi-sentence Video Description with Variable Level of Detail.
Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding.
Combining Language Sources and Robust Semantic Relatedness for Attribute-Based Knowledge Transfer.
Grounding of Textual Phrases in Images by Reconstruction.
What helps where - and why? Semantic relatedness for knowledge transfer.
Script Data for Attribute-Based Recognition of Composite Activities.
A Dataset for Movie Description.
A database for fine grained activity detection of cooking activities.
Segmentation from Natural Language Expressions.
Coherent Multi-Sentence Video Description with Variable Level of Detail.
The Long-Short Story of Movie Description.
Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images.
Learning to Compose Neural Networks for Question Answering.
Combining visual recognition and computational linguistics : linguistic knowledge for visual recognition and natural language descriptions of visual content.
Recognizing Fine-Grained and Composite Activities using Hand-Centric Features and Script Data.
A dataset for Movie Description.
Natural Language Object Retrieval.
Long-term Recurrent Convolutional Networks for Visual Recognition and Description.
Sequence to Sequence - Video to Text.
Movie Description.
Ask Your Neurons: A Deep Learning Approach to Visual Question Answering.
Ask Your Neurons: A Neural-based Approach to Answering Questions about Images.
The Benefits of Dense Stereo for Pedestrian Detection.
Captioning Images with Diverse Objects.
A Multi-scale Multiple Instance Video Description Network.
Evaluating knowledge transfer and zero-shot learning in a large-scale setting.
Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data.
Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data.
Translating Video Content to Natural Language Descriptions.
Translating Videos to Natural Language Using Deep Recurrent Neural Networks.
Attributes as Semantic Units between Natural Language and Visual Recognition.
High-Level Fusion of Depth and Intensity for Pedestrian Classification.
