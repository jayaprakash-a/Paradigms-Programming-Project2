Regularized Policy Iteration.
Hybrid Behavior Co-evolution and Structure Learning in Behavior-based Systems.
Interaction of Culture-Based Learning and Cooperative Co-Evolution and its Application to Automatic Behavior-Based System Design.
Learning from Limited Demonstrations.
Error Propagation for Approximate Policy and Value Iteration.
Learning-Based Modular Indirect Adaptive Control for a Class of Nonlinear Systems.
Robust Jacobian estimation for uncalibrated visual servoing.
Truncated Approximate Dynamic Programming with Task-Dependent Terminal Value.
Channel Assignment using Chaotic Simulated Annealing Enhanced Hopfield Neural Network.
Towards Learning Robotic Reaching and Pointing: An Uncalibrated Visual Servoing Approach.
Global visual-motor estimation for uncalibrated visual servoing.
Learning to Coordinate Behaviors in Soft Behavior-Based Systems Using Reinforcement Learning.
Model-based and model-free reinforcement learning for visual servoing.
Approximate MaxEnt Inverse Optimal Control and Its Application for Mental Simulation of Human Interactions.
Action-Gap Phenomenon in Reinforcement Learning.
Reports of the AAAI 2014 Conference Workshops.
Regularized Fitted Q-Iteration: Application to Planning.
Model selection in reinforcement learning.
Behavior hierarchy learning in a behavior-based system using reinforcement learning.
Value Pursuit Iteration.
Bellman Error Based Feature Generation using Random Projections on Sparse Spaces
Classification-Based Approximate Policy Iteration.
Classification-based Approximate Policy Iteration: Experiments and Extended Discussions.
Sample-based approximate regularization.
Manifold-adaptive dimension estimation.
Bellman Error Based Feature Generation using Random Projections on Sparse Spaces.
