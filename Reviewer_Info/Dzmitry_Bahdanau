End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results.
Blocks and Fuel: Frameworks for deep learning.
End-to-end attention-based large vocabulary speech recognition.
End-to-End Attention-based Large Vocabulary Speech Recognition.
Task Loss Estimation for Sequence Prediction.
Overcoming the Curse of Sentence Length for Neural Machine Translation using Automatic Segmentation.
Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.
On the Properties of Neural Machine Translation: Encoder-Decoder Approaches.
Neural Machine Translation by Jointly Learning to Align and Translate.
An Actor-Critic Algorithm for Sequence Prediction.
Attention-Based Models for Speech Recognition.
