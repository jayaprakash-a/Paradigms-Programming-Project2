Learning Algorithms for the Classification Restricted Boltzmann Machine.
A neurodynamical model for working memory.
On the Number of Linear Regions of Deep Neural Networks.
Advances in optimizing recurrent networks.
Theano: new features and speed improvements
Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks.
Autotagging music with conditional restricted Boltzmann machines
Contextual tag inference.
Pylearn2: a machine learning research library.
Extraction of quadrics from noisy point-clouds using a sensor noise model.
Identifying and attacking the saddle point problem in high-dimensional non-convex optimization.
Deep Learners Benefit More from Out-of-Distribution Examples.
Metric-Free Natural Gradient for Joint-Training of Boltzmann Machines
Malware classification with recurrent networks.
Natural Gradient Revisited
On the number of inference regions of deep feed forward networks with piece-wise linear activations.
Progressive Neural Networks.
On the difficulty of training recurrent neural networks.
Advances in Optimizing Recurrent Networks
Deep Self-Taught Learning for Handwritten Character Recognition
Learned-norm pooling for deep neural networks.
Natural Neural Networks.
Understanding the exploding gradient problem
Policy Distillation.
How to Construct Deep Recurrent Neural Networks.
Combining modality specific deep neural networks for emotion recognition in video.
On the saddle point problem for non-convex optimization.
